<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Diffusion effects | Statistical Tools for Causal Inference</title>
  <meta name="description" content="This is an open source collaborative book." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Diffusion effects | Statistical Tools for Causal Inference" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an open source collaborative book." />
  <meta name="github-repo" content="chabefer/STCI" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Diffusion effects | Statistical Tools for Causal Inference" />
  
  <meta name="twitter:description" content="This is an open source collaborative book." />
  

<meta name="author" content="Sylvain ChabÃ©-Ferret" />


<meta name="date" content="2024-07-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="LaLonde.html"/>
<link rel="next" href="Distribution.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
$$
\newcommand{\uns}[1]{\mathbf{1}[#1]}
\newcommand{\esp}[1]{\mathbf{E}[#1]}
\newcommand{\hatesp}[1]{\hat{\mathbf{E}}[ #1 ]}
\newcommand{\espE}{\mathbf{E}}
\newcommand{\Ind}{\perp\kern-5pt\perp}
\newcommand{\var}[1]{\mathbf{V}[ #1 ]}
\newcommand{\hatvar}[1]{\hat{\mathbf{V}}[ #1 ]}
\newcommand{\cov}[1]{\mathbf{C}[ #1 ]}
\newcommand{\plim}[1]{\text{plim}_{ #1 \rightarrow \infty}}
\newcommand{\plims}{\text{plim}}
\newcommand{\distr}{\stackrel{d}{\rightarrow}}
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\partdersq}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\asym}{Asym}
$$


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Tools for Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Fundamental Problems of Inference</b></span></li>
<li class="chapter" data-level="" data-path="introduction-the-two-fundamental-problems-of-inference.html"><a href="introduction-the-two-fundamental-problems-of-inference.html"><i class="fa fa-check"></i>Introduction: the Two Fundamental Problems of Inference</a></li>
<li class="chapter" data-level="1" data-path="FPCI.html"><a href="FPCI.html"><i class="fa fa-check"></i><b>1</b> Fundamental Problem of Causal Inference</a>
<ul>
<li class="chapter" data-level="1.1" data-path="FPCI.html"><a href="FPCI.html#rubin-causal-model"><i class="fa fa-check"></i><b>1.1</b> Rubin Causal Model</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="FPCI.html"><a href="FPCI.html#treatment-allocation-rule"><i class="fa fa-check"></i><b>1.1.1</b> Treatment allocation rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="FPCI.html"><a href="FPCI.html#potential-outcomes"><i class="fa fa-check"></i><b>1.1.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="1.1.3" data-path="FPCI.html"><a href="FPCI.html#switching-equation"><i class="fa fa-check"></i><b>1.1.3</b> Switching equation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="FPCI.html"><a href="FPCI.html#treatment-effects"><i class="fa fa-check"></i><b>1.2</b> Treatment effects</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="FPCI.html"><a href="FPCI.html#individual-level-treatment-effects"><i class="fa fa-check"></i><b>1.2.1</b> Individual level treatment effects</a></li>
<li class="chapter" data-level="1.2.2" data-path="FPCI.html"><a href="FPCI.html#average-treatment-effect-on-the-treated"><i class="fa fa-check"></i><b>1.2.2</b> Average treatment effect on the treated</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="FPCI.html"><a href="FPCI.html#fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Fundamental problem of causal inference</a></li>
<li class="chapter" data-level="1.4" data-path="FPCI.html"><a href="FPCI.html#intuitive-estimators-confounding-factors-and-selection-bias"><i class="fa fa-check"></i><b>1.4</b> Intuitive estimators, confounding factors and selection bias</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="FPCI.html"><a href="FPCI.html#withwithout-comparison-selection-bias-and-cross-sectional-confounders"><i class="fa fa-check"></i><b>1.4.1</b> With/Without comparison, selection bias and cross-sectional confounders</a></li>
<li class="chapter" data-level="1.4.2" data-path="FPCI.html"><a href="FPCI.html#the-beforeafter-comparison-temporal-confounders-and-time-trend-bias"><i class="fa fa-check"></i><b>1.4.2</b> The before/after comparison, temporal confounders and time trend bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FPSI.html"><a href="FPSI.html"><i class="fa fa-check"></i><b>2</b> Fundamental Problem of Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="FPSI.html"><a href="FPSI.html#sec:sampnoise"><i class="fa fa-check"></i><b>2.1</b> What is sampling noise? Definition and illustration</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="FPSI.html"><a href="FPSI.html#sec:definitionnoise"><i class="fa fa-check"></i><b>2.1.1</b> Sampling noise, a definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisepop"><i class="fa fa-check"></i><b>2.1.2</b> Sampling noise for the population treatment effect</a></li>
<li class="chapter" data-level="2.1.3" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisesamp"><i class="fa fa-check"></i><b>2.1.3</b> Sampling noise for the sample treatment effect</a></li>
<li class="chapter" data-level="2.1.4" data-path="FPSI.html"><a href="FPSI.html#sec:confinterv"><i class="fa fa-check"></i><b>2.1.4</b> Building confidence intervals from estimates of sampling noise</a></li>
<li class="chapter" data-level="2.1.5" data-path="FPSI.html"><a href="FPSI.html#reporting-sampling-noise-a-proposal"><i class="fa fa-check"></i><b>2.1.5</b> Reporting sampling noise: a proposal</a></li>
<li class="chapter" data-level="2.1.6" data-path="FPSI.html"><a href="FPSI.html#sec:effectsize"><i class="fa fa-check"></i><b>2.1.6</b> Using effect sizes to normalize the reporting of treatment effects and their precision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FPSI.html"><a href="FPSI.html#sec:estimsampnoise"><i class="fa fa-check"></i><b>2.2</b> Estimating sampling noise</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="FPSI.html"><a href="FPSI.html#sec:assumptions"><i class="fa fa-check"></i><b>2.2.1</b> Assumptions</a></li>
<li class="chapter" data-level="2.2.2" data-path="FPSI.html"><a href="FPSI.html#sec:cheb"><i class="fa fa-check"></i><b>2.2.2</b> Using Chebyshevâs inequality</a></li>
<li class="chapter" data-level="2.2.3" data-path="FPSI.html"><a href="FPSI.html#sec:CLT"><i class="fa fa-check"></i><b>2.2.3</b> Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.4" data-path="FPSI.html"><a href="FPSI.html#sec:resamp"><i class="fa fa-check"></i><b>2.2.4</b> Using resampling methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Methods of Causal Inference</b></span></li>
<li class="chapter" data-level="3" data-path="RCT.html"><a href="RCT.html"><i class="fa fa-check"></i><b>3</b> Randomized Controlled Trials</a>
<ul>
<li class="chapter" data-level="3.1" data-path="RCT.html"><a href="RCT.html#sec:design1"><i class="fa fa-check"></i><b>3.1</b> Brute Force Design</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="RCT.html"><a href="RCT.html#identification"><i class="fa fa-check"></i><b>3.1.1</b> Identification</a></li>
<li class="chapter" data-level="3.1.2" data-path="RCT.html"><a href="RCT.html#estimating-ate"><i class="fa fa-check"></i><b>3.1.2</b> Estimating ATE</a></li>
<li class="chapter" data-level="3.1.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise"><i class="fa fa-check"></i><b>3.1.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="RCT.html"><a href="RCT.html#sec:design2"><i class="fa fa-check"></i><b>3.2</b> Self-Selection design</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="RCT.html"><a href="RCT.html#identification-1"><i class="fa fa-check"></i><b>3.2.1</b> Identification</a></li>
<li class="chapter" data-level="3.2.2" data-path="RCT.html"><a href="RCT.html#estimating-tt"><i class="fa fa-check"></i><b>3.2.2</b> Estimating TT</a></li>
<li class="chapter" data-level="3.2.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="RCT.html"><a href="RCT.html#sec:design3"><i class="fa fa-check"></i><b>3.3</b> Eligibility design</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="RCT.html"><a href="RCT.html#identification-2"><i class="fa fa-check"></i><b>3.3.1</b> Identification</a></li>
<li class="chapter" data-level="3.3.2" data-path="RCT.html"><a href="RCT.html#estimating-the-ite-and-the-tt"><i class="fa fa-check"></i><b>3.3.2</b> Estimating the ITE and the TT</a></li>
<li class="chapter" data-level="3.3.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-2"><i class="fa fa-check"></i><b>3.3.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="RCT.html"><a href="RCT.html#sec:design4"><i class="fa fa-check"></i><b>3.4</b> Encouragement Design</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="RCT.html"><a href="RCT.html#identification-3"><i class="fa fa-check"></i><b>3.4.1</b> Identification</a></li>
<li class="chapter" data-level="3.4.2" data-path="RCT.html"><a href="RCT.html#IVRCT"><i class="fa fa-check"></i><b>3.4.2</b> Estimating the Local Average Treatment Effect and the Intention to Treat Effect</a></li>
<li class="chapter" data-level="3.4.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-3"><i class="fa fa-check"></i><b>3.4.3</b> Estimating sampling noise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="NE.html"><a href="NE.html"><i class="fa fa-check"></i><b>4</b> Natural Experiments</a>
<ul>
<li class="chapter" data-level="4.1" data-path="NE.html"><a href="NE.html#instrumental-variables"><i class="fa fa-check"></i><b>4.1</b> Instrumental Variables</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="NE.html"><a href="NE.html#an-example-where-monotonicity-does-not-hold"><i class="fa fa-check"></i><b>4.1.1</b> An example where Monotonicity does not hold</a></li>
<li class="chapter" data-level="4.1.2" data-path="NE.html"><a href="NE.html#identification-4"><i class="fa fa-check"></i><b>4.1.2</b> Identification</a></li>
<li class="chapter" data-level="4.1.3" data-path="NE.html"><a href="NE.html#estimation"><i class="fa fa-check"></i><b>4.1.3</b> Estimation</a></li>
<li class="chapter" data-level="4.1.4" data-path="NE.html"><a href="NE.html#estimation-of-sampling-noise"><i class="fa fa-check"></i><b>4.1.4</b> Estimation of sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="NE.html"><a href="NE.html#regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2</b> Regression Discontinuity Designs</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="NE.html"><a href="NE.html#sharp-regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2.1</b> Sharp Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="4.2.2" data-path="NE.html"><a href="NE.html#fuzzy-regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2.2</b> Fuzzy Regression Discontinuity Designs</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="NE.html"><a href="NE.html#DID"><i class="fa fa-check"></i><b>4.3</b> Difference In Differences</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="NE.html"><a href="NE.html#sec:DIDbasic"><i class="fa fa-check"></i><b>4.3.1</b> Difference In Differences with two time periods</a></li>
<li class="chapter" data-level="4.3.2" data-path="NE.html"><a href="NE.html#sec:DIDr"><i class="fa fa-check"></i><b>4.3.2</b> Reverse Difference In Differences designs with two time periods</a></li>
<li class="chapter" data-level="4.3.3" data-path="NE.html"><a href="NE.html#DIDStaggered"><i class="fa fa-check"></i><b>4.3.3</b> Difference In Differences with multiple time periods</a></li>
<li class="chapter" data-level="4.3.4" data-path="NE.html"><a href="NE.html#difference-in-differences-with-instrumental-variables"><i class="fa fa-check"></i><b>4.3.4</b> Difference In Differences with Instrumental Variables</a></li>
<li class="chapter" data-level="4.3.5" data-path="NE.html"><a href="NE.html#difference-in-differences-with-continuous-treatment-variables-and-staggered-adoption"><i class="fa fa-check"></i><b>4.3.5</b> Difference In Differences with Continuous Treatment Variables and Staggered Adoption</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="OM.html"><a href="OM.html"><i class="fa fa-check"></i><b>5</b> Observational Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="OM.html"><a href="OM.html#parametric-methods"><i class="fa fa-check"></i><b>5.1</b> Parametric methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="OM.html"><a href="OM.html#assuming-espy_i0x_i-is-known"><i class="fa fa-check"></i><b>5.1.1</b> Assuming <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known</a></li>
<li class="chapter" data-level="5.1.2" data-path="OM.html"><a href="OM.html#assuming-espy_i1x_i-is-known"><i class="fa fa-check"></i><b>5.1.2</b> Assuming <span class="math inline">\(\esp{Y_i^1|X_i}\)</span> is known</a></li>
<li class="chapter" data-level="5.1.3" data-path="OM.html"><a href="OM.html#BiasOLS"><i class="fa fa-check"></i><b>5.1.3</b> Properties of the OLS estimator under Conditional Independence</a></li>
<li class="chapter" data-level="5.1.4" data-path="OM.html"><a href="OM.html#problems-with-parametric-methods"><i class="fa fa-check"></i><b>5.1.4</b> Problems with parametric methods</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="OM.html"><a href="OM.html#nonparametric-methods"><i class="fa fa-check"></i><b>5.2</b> Nonparametric methods</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="OM.html"><a href="OM.html#identification-13"><i class="fa fa-check"></i><b>5.2.1</b> Identification</a></li>
<li class="chapter" data-level="5.2.2" data-path="OM.html"><a href="OM.html#estimation-9"><i class="fa fa-check"></i><b>5.2.2</b> Estimation</a></li>
<li class="chapter" data-level="5.2.3" data-path="OM.html"><a href="OM.html#estimating-precision-2"><i class="fa fa-check"></i><b>5.2.3</b> Estimating precision</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="OM.html"><a href="OM.html#imputation-methods"><i class="fa fa-check"></i><b>5.3</b> Imputation methods</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="threats.html"><a href="threats.html"><i class="fa fa-check"></i><b>6</b> Threats to the validity of Causal Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="threats.html"><a href="threats.html#threats-to-internal-validity"><i class="fa fa-check"></i><b>6.1</b> Threats to internal validity</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="threats.html"><a href="threats.html#survey-bias"><i class="fa fa-check"></i><b>6.1.1</b> Survey bias</a></li>
<li class="chapter" data-level="6.1.2" data-path="threats.html"><a href="threats.html#experimenter-bias"><i class="fa fa-check"></i><b>6.1.2</b> Experimenter bias</a></li>
<li class="chapter" data-level="6.1.3" data-path="threats.html"><a href="threats.html#substitution-bias"><i class="fa fa-check"></i><b>6.1.3</b> Substitution bias</a></li>
<li class="chapter" data-level="6.1.4" data-path="threats.html"><a href="threats.html#diffusion-bias"><i class="fa fa-check"></i><b>6.1.4</b> Diffusion bias</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="threats.html"><a href="threats.html#threats-to-the-measurement-of-precision"><i class="fa fa-check"></i><b>6.2</b> Threats to the measurement of precision</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="threats.html"><a href="threats.html#insufficient-precision"><i class="fa fa-check"></i><b>6.2.1</b> Insufficient precision</a></li>
<li class="chapter" data-level="6.2.2" data-path="threats.html"><a href="threats.html#clustering"><i class="fa fa-check"></i><b>6.2.2</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="threats.html"><a href="threats.html#threats-to-external-validity"><i class="fa fa-check"></i><b>6.3</b> Threats to external validity</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="threats.html"><a href="threats.html#randomization-bias"><i class="fa fa-check"></i><b>6.3.1</b> Randomization bias</a></li>
<li class="chapter" data-level="6.3.2" data-path="threats.html"><a href="threats.html#equilibrium-effects"><i class="fa fa-check"></i><b>6.3.2</b> Equilibrium effects</a></li>
<li class="chapter" data-level="6.3.3" data-path="threats.html"><a href="threats.html#context-effects"><i class="fa fa-check"></i><b>6.3.3</b> Context effects</a></li>
<li class="chapter" data-level="6.3.4" data-path="threats.html"><a href="threats.html#site-selection-bias"><i class="fa fa-check"></i><b>6.3.4</b> Site selection bias</a></li>
<li class="chapter" data-level="6.3.5" data-path="threats.html"><a href="threats.html#publication-bias"><i class="fa fa-check"></i><b>6.3.5</b> Publication bias</a></li>
<li class="chapter" data-level="6.3.6" data-path="threats.html"><a href="threats.html#ethical-and-political-issues"><i class="fa fa-check"></i><b>6.3.6</b> Ethical and political issues</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Additional Topics</b></span></li>
<li class="chapter" data-level="7" data-path="Power.html"><a href="Power.html"><i class="fa fa-check"></i><b>7</b> Power Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Power.html"><a href="Power.html#basics-of-traditional-power-analysis-using-test-statistics"><i class="fa fa-check"></i><b>7.1</b> Basics of traditional power analysis using test statistics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="Power.html"><a href="Power.html#power"><i class="fa fa-check"></i><b>7.1.1</b> Power</a></li>
<li class="chapter" data-level="7.1.2" data-path="Power.html"><a href="Power.html#minimum-detectable-effect"><i class="fa fa-check"></i><b>7.1.2</b> Minimum Detectable Effect</a></li>
<li class="chapter" data-level="7.1.3" data-path="Power.html"><a href="Power.html#minimum-required-sample-size"><i class="fa fa-check"></i><b>7.1.3</b> Minimum Required Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Power.html"><a href="Power.html#traditional-power-analysis-in-practice"><i class="fa fa-check"></i><b>7.2</b> Traditional power analysis in practice</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="Power.html"><a href="Power.html#power-analysis-for-randomized-controlled-trials"><i class="fa fa-check"></i><b>7.2.1</b> Power Analysis for Randomized Controlled Trials</a></li>
<li class="chapter" data-level="7.2.2" data-path="Power.html"><a href="Power.html#power-analysis-for-natural-experiments"><i class="fa fa-check"></i><b>7.2.2</b> Power Analysis for Natural Experiments</a></li>
<li class="chapter" data-level="7.2.3" data-path="Power.html"><a href="Power.html#power-analysis-for-observational-methods"><i class="fa fa-check"></i><b>7.2.3</b> Power Analysis for Observational Methods</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Power.html"><a href="Power.html#limitations-of-and-alternatives-to-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3</b> Limitations of and alternatives to traditional power analysis</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="Power.html"><a href="Power.html#limitations-of-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3.1</b> Limitations of traditional power analysis</a></li>
<li class="chapter" data-level="7.3.2" data-path="Power.html"><a href="Power.html#an-alternative-to-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3.2</b> An alternative to traditional power analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="placebo.html"><a href="placebo.html"><i class="fa fa-check"></i><b>8</b> Placebo Tests</a>
<ul>
<li class="chapter" data-level="8.1" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-randomized-controlled-trials"><i class="fa fa-check"></i><b>8.1</b> Placebo tests for randomized controlled trials</a></li>
<li class="chapter" data-level="8.2" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-natural-experiments"><i class="fa fa-check"></i><b>8.2</b> Placebo tests for natural experiments</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-instrumental-variables"><i class="fa fa-check"></i><b>8.2.1</b> Placebo tests for Instrumental Variables</a></li>
<li class="chapter" data-level="8.2.2" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-regression-discontinuity-designs"><i class="fa fa-check"></i><b>8.2.2</b> Placebo tests for Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="8.2.3" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-difference-in-differences"><i class="fa fa-check"></i><b>8.2.3</b> Placebo tests for Difference in Differences</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="placebo.html"><a href="placebo.html#placebo-tests-for-observational-methods"><i class="fa fa-check"></i><b>8.3</b> Placebo tests for observational methods</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>9</b> Clustering</a>
<ul>
<li class="chapter" data-level="9.1" data-path="cluster.html"><a href="cluster.html#ClusterRCT"><i class="fa fa-check"></i><b>9.1</b> Clustering in Randomized Controlled Trials</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="cluster.html"><a href="cluster.html#an-example"><i class="fa fa-check"></i><b>9.1.1</b> An example</a></li>
<li class="chapter" data-level="9.1.2" data-path="cluster.html"><a href="cluster.html#design-effect"><i class="fa fa-check"></i><b>9.1.2</b> Design effect</a></li>
<li class="chapter" data-level="9.1.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-accounting-for-clustering"><i class="fa fa-check"></i><b>9.1.3</b> Estimating sampling noise accounting for clustering</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="cluster.html"><a href="cluster.html#clustering-in-panel-data"><i class="fa fa-check"></i><b>9.2</b> Clustering in panel data</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="cluster.html"><a href="cluster.html#an-example-1"><i class="fa fa-check"></i><b>9.2.1</b> An example</a></li>
<li class="chapter" data-level="9.2.2" data-path="cluster.html"><a href="cluster.html#design-effect-in-panel-data"><i class="fa fa-check"></i><b>9.2.2</b> Design effect in panel data</a></li>
<li class="chapter" data-level="9.2.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-in-panel-data-with-autocorrelated-error-terms"><i class="fa fa-check"></i><b>9.2.3</b> Estimating sampling noise in panel data with autocorrelated error terms</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="cluster.html"><a href="cluster.html#spatial-correlation"><i class="fa fa-check"></i><b>9.3</b> Spatial correlation</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="cluster.html"><a href="cluster.html#an-example-2"><i class="fa fa-check"></i><b>9.3.1</b> An example</a></li>
<li class="chapter" data-level="9.3.2" data-path="cluster.html"><a href="cluster.html#design-effect-in-spatially-autocorrelated-data"><i class="fa fa-check"></i><b>9.3.2</b> Design effect in spatially autocorrelated data</a></li>
<li class="chapter" data-level="9.3.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-with-spatially-autocorrelated-data"><i class="fa fa-check"></i><b>9.3.3</b> Estimating sampling noise with spatially autocorrelated data</a></li>
<li class="chapter" data-level="9.3.4" data-path="cluster.html"><a href="cluster.html#testing-for-spatial-autocorrelation"><i class="fa fa-check"></i><b>9.3.4</b> Testing for spatial autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="cluster.html"><a href="cluster.html#clustering-on-a-network"><i class="fa fa-check"></i><b>9.4</b> Clustering on a network</a></li>
<li class="chapter" data-level="9.5" data-path="cluster.html"><a href="cluster.html#multi-way-clustering"><i class="fa fa-check"></i><b>9.5</b> Multi-way clustering</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="cluster.html"><a href="cluster.html#at-which-level-should-we-cluster"><i class="fa fa-check"></i><b>9.5.1</b> At which level should we cluster?</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="cluster.html"><a href="cluster.html#what-to-do-when-there-are-few-clusters"><i class="fa fa-check"></i><b>9.6</b> What to do when there are few clusters?</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="cluster.html"><a href="cluster.html#aggregation"><i class="fa fa-check"></i><b>9.6.1</b> Aggregation</a></li>
<li class="chapter" data-level="9.6.2" data-path="cluster.html"><a href="cluster.html#permutation-tests"><i class="fa fa-check"></i><b>9.6.2</b> Permutation tests</a></li>
<li class="chapter" data-level="9.6.3" data-path="cluster.html"><a href="cluster.html#wild-bootstrap"><i class="fa fa-check"></i><b>9.6.3</b> Wild bootstrap</a></li>
<li class="chapter" data-level="9.6.4" data-path="cluster.html"><a href="cluster.html#ibragimov-and-muller-2010-group-based-inference"><i class="fa fa-check"></i><b>9.6.4</b> Ibragimov and Muller (2010) group-based inference</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="cluster.html"><a href="cluster.html#CLTDD"><i class="fa fa-check"></i><b>9.7</b> Central Limit Theorems for Dependent Data</a></li>
<li class="chapter" data-level="9.8" data-path="cluster.html"><a href="cluster.html#DesignBasedClusters"><i class="fa fa-check"></i><b>9.8</b> Sampling-based and design-based approaches to clustering</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LaLonde.html"><a href="LaLonde.html"><i class="fa fa-check"></i><b>10</b> LaLonde Tests</a></li>
<li class="chapter" data-level="11" data-path="Diffusion.html"><a href="Diffusion.html"><i class="fa fa-check"></i><b>11</b> Diffusion effects</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Diffusion.html"><a href="Diffusion.html#allowing-for-diffusion-effects-in-rubin-causal-model"><i class="fa fa-check"></i><b>11.1</b> Allowing for diffusion effects in Rubin Causal Model</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="Diffusion.html"><a href="Diffusion.html#potential-outcomes-and-treatment-effects-with-diffusion-effects"><i class="fa fa-check"></i><b>11.1.1</b> Potential outcomes and treatment effects with diffusion effects</a></li>
<li class="chapter" data-level="11.1.2" data-path="Diffusion.html"><a href="Diffusion.html#encoding-the-absence-of-diffusion-effects"><i class="fa fa-check"></i><b>11.1.2</b> Encoding the absence of diffusion effects</a></li>
<li class="chapter" data-level="11.1.3" data-path="Diffusion.html"><a href="Diffusion.html#TreatmentExposure"><i class="fa fa-check"></i><b>11.1.3</b> Treatment exposure</a></li>
<li class="chapter" data-level="11.1.4" data-path="Diffusion.html"><a href="Diffusion.html#fundamental-problem-of-causal-inference-for-diffusion-effects"><i class="fa fa-check"></i><b>11.1.4</b> Fundamental problem of causal inference for diffusion effects</a></li>
<li class="chapter" data-level="11.1.5" data-path="Diffusion.html"><a href="Diffusion.html#bias-of-one-step-randomized-controlled-trials"><i class="fa fa-check"></i><b>11.1.5</b> Bias of one-step randomized controlled trials</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="Diffusion.html"><a href="Diffusion.html#diffusion-effects-with-coarse-networks"><i class="fa fa-check"></i><b>11.2</b> Diffusion effects with coarse networks</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="Diffusion.html"><a href="Diffusion.html#optimal-treatment-allocation-under-monotone-response"><i class="fa fa-check"></i><b>11.2.1</b> Optimal treatment allocation under monotone response</a></li>
<li class="chapter" data-level="11.2.2" data-path="Diffusion.html"><a href="Diffusion.html#identifying-optimal-treatment-levels"><i class="fa fa-check"></i><b>11.2.2</b> Identifying optimal treatment levels</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="Diffusion.html"><a href="Diffusion.html#diffusion-effects-with-detailed-networks"><i class="fa fa-check"></i><b>11.3</b> Diffusion effects with detailed networks</a></li>
<li class="chapter" data-level="11.4" data-path="Diffusion.html"><a href="Diffusion.html#nonparametric-test-for-the-existence-of-diffusion-effects-based-on-randomization-inference"><i class="fa fa-check"></i><b>11.4</b> Nonparametric test for the existence of diffusion effects based on randomization inference</a></li>
<li class="chapter" data-level="11.5" data-path="Diffusion.html"><a href="Diffusion.html#diffusion-effects-with-did"><i class="fa fa-check"></i><b>11.5</b> Diffusion effects with DID</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Distribution.html"><a href="Distribution.html"><i class="fa fa-check"></i><b>12</b> Distributional effects</a></li>
<li class="chapter" data-level="13" data-path="meta.html"><a href="meta.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and Publication Bias</a>
<ul>
<li class="chapter" data-level="13.1" data-path="meta.html"><a href="meta.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="meta.html"><a href="meta.html#basic-setting"><i class="fa fa-check"></i><b>13.1.1</b> Basic setting</a></li>
<li class="chapter" data-level="13.1.2" data-path="meta.html"><a href="meta.html#why-vote-counting-does-not-work"><i class="fa fa-check"></i><b>13.1.2</b> Why vote-counting does not work</a></li>
<li class="chapter" data-level="13.1.3" data-path="meta.html"><a href="meta.html#MetaWA"><i class="fa fa-check"></i><b>13.1.3</b> Meta-analysis when treatment effects are homogeneous: the fixed effects approach</a></li>
<li class="chapter" data-level="13.1.4" data-path="meta.html"><a href="meta.html#meta-analysis-when-treatment-effects-are-heterogeneous-the-random-effects-approach"><i class="fa fa-check"></i><b>13.1.4</b> Meta-analysis when treatment effects are heterogeneous: the random effects approach</a></li>
<li class="chapter" data-level="13.1.5" data-path="meta.html"><a href="meta.html#meta-regression"><i class="fa fa-check"></i><b>13.1.5</b> Meta-regression</a></li>
<li class="chapter" data-level="13.1.6" data-path="meta.html"><a href="meta.html#constantly-updated-meta-analysis"><i class="fa fa-check"></i><b>13.1.6</b> Constantly updated meta-analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="meta.html"><a href="meta.html#publication-bias-and-site-selection-bias"><i class="fa fa-check"></i><b>13.2</b> Publication bias and site selection bias</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="meta.html"><a href="meta.html#sources-of-publication-bias-and-of-site-selection-bias-and-questionable-research-practices"><i class="fa fa-check"></i><b>13.2.1</b> Sources of publication bias and of site selection bias and Questionable Research Practices</a></li>
<li class="chapter" data-level="13.2.2" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-publication-bias"><i class="fa fa-check"></i><b>13.2.2</b> Detection of and correction for publication bias</a></li>
<li class="chapter" data-level="13.2.3" data-path="meta.html"><a href="meta.html#getting-rid-of-publication-bias-registered-reports-and-pre-analysis-plans"><i class="fa fa-check"></i><b>13.2.3</b> Getting rid of publication bias: registered reports and pre-analysis plans</a></li>
<li class="chapter" data-level="13.2.4" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-site-selection-bias"><i class="fa fa-check"></i><b>13.2.4</b> Detection of and correction for site selection bias</a></li>
<li class="chapter" data-level="13.2.5" data-path="meta.html"><a href="meta.html#vote-counting-and-publication-bias"><i class="fa fa-check"></i><b>13.2.5</b> Vote counting and publication bias</a></li>
<li class="chapter" data-level="13.2.6" data-path="meta.html"><a href="meta.html#the-value-of-a-statistically-significant-result"><i class="fa fa-check"></i><b>13.2.6</b> The value of a statistically significant result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Bounds.html"><a href="Bounds.html"><i class="fa fa-check"></i><b>14</b> Bounds</a></li>
<li class="chapter" data-level="15" data-path="mediation-analysis.html"><a href="mediation-analysis.html"><i class="fa fa-check"></i><b>15</b> Mediation Analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-a-framework"><i class="fa fa-check"></i><b>15.1</b> Mediation analysis: a framework</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#defining-mediated-and-unmediated-treatment-effects"><i class="fa fa-check"></i><b>15.1.1</b> Defining mediated and unmediated treatment effects</a></li>
<li class="chapter" data-level="15.1.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#decomposing-mediated-and-unmediated-effects"><i class="fa fa-check"></i><b>15.1.2</b> Decomposing mediated and unmediated effects</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#the-fundamental-problem-of-mediation-analysis"><i class="fa fa-check"></i><b>15.2</b> The Fundamental Problem of Mediation Analysis</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#the-fundamental-problem-of-mediation-analysis-1"><i class="fa fa-check"></i><b>15.2.1</b> The Fundamental Problem of Mediation Analysis</a></li>
<li class="chapter" data-level="15.2.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#biases-of-intuitive-comparisons"><i class="fa fa-check"></i><b>15.2.2</b> Biases of Intuitive Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-experimental-data"><i class="fa fa-check"></i><b>15.3</b> Mediation analysis with experimental data</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-parallel-design"><i class="fa fa-check"></i><b>15.3.1</b> Mediation analysis in the Parallel design</a></li>
<li class="chapter" data-level="15.3.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-sequential-self-selection-design"><i class="fa fa-check"></i><b>15.3.2</b> Mediation analysis in the Sequential Self-Selection design</a></li>
<li class="chapter" data-level="15.3.3" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-crossover-design"><i class="fa fa-check"></i><b>15.3.3</b> Mediation analysis in the Crossover design</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-under-unconfoundedness"><i class="fa fa-check"></i><b>15.4</b> Mediation analysis under unconfoundedness</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#non-parametric-identification-under-sequential-ignorability"><i class="fa fa-check"></i><b>15.4.1</b> Non-parametric identification under sequential ignorability</a></li>
<li class="chapter" data-level="15.4.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-under-sequential-ignorability-in-linear-models"><i class="fa fa-check"></i><b>15.4.2</b> Mediation analysis under sequential ignorability in linear models</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-panel-data"><i class="fa fa-check"></i><b>15.5</b> Mediation analysis with panel data</a></li>
<li class="chapter" data-level="15.6" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-instruments"><i class="fa fa-check"></i><b>15.6</b> Mediation analysis with instruments</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="stratification.html"><a href="stratification.html"><i class="fa fa-check"></i><b>16</b> Stratification</a>
<ul>
<li class="chapter" data-level="16.1" data-path="stratification.html"><a href="stratification.html#ClassicalStratification"><i class="fa fa-check"></i><b>16.1</b> Analysis of classical stratified experiments</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="stratification.html"><a href="stratification.html#an-example-3"><i class="fa fa-check"></i><b>16.1.1</b> An example</a></li>
<li class="chapter" data-level="16.1.2" data-path="stratification.html"><a href="stratification.html#estimating-treatment-effects-with-stratified-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.1.2</b> Estimating treatment effects with stratified randomized controlled trials</a></li>
<li class="chapter" data-level="16.1.3" data-path="stratification.html"><a href="stratification.html#estimating-sampling-noise-in-stratified-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.1.3</b> Estimating sampling noise in stratified randomized controlled trials</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="stratification.html"><a href="stratification.html#analysis-of-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2</b> Analysis of pairwise randomized controlled trials</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="stratification.html"><a href="stratification.html#building-a-sample-of-pairs"><i class="fa fa-check"></i><b>16.2.1</b> Building a sample of pairs</a></li>
<li class="chapter" data-level="16.2.2" data-path="stratification.html"><a href="stratification.html#estimating-treatment-effects-in-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2.2</b> Estimating treatment effects in pairwise randomized controlled trials</a></li>
<li class="chapter" data-level="16.2.3" data-path="stratification.html"><a href="stratification.html#estimating-sampling-noise-in-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2.3</b> Estimating sampling noise in pairwise randomized controlled trials</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="proofs.html"><a href="proofs.html"><i class="fa fa-check"></i><b>A</b> Proofs</a>
<ul>
<li class="chapter" data-level="A.1" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-reffpsi"><i class="fa fa-check"></i><b>A.1</b> Proofs of results in Chapter @ref(FPSI)</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="proofs.html"><a href="proofs.html#proofcheb"><i class="fa fa-check"></i><b>A.1.1</b> Proof of Theorem @ref(thm:uppsampnoise)</a></li>
<li class="chapter" data-level="A.1.2" data-path="proofs.html"><a href="proofs.html#proofCLT"><i class="fa fa-check"></i><b>A.1.2</b> Proof of Theorem @ref(thm:asympnoiseWW)</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refrct"><i class="fa fa-check"></i><b>A.2</b> Proofs of results in Chapter @ref(RCT)</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="proofs.html"><a href="proofs.html#proofIdentLATE"><i class="fa fa-check"></i><b>A.2.1</b> Proof of Theorem @ref(thm:IdentLATE)</a></li>
<li class="chapter" data-level="A.2.2" data-path="proofs.html"><a href="proofs.html#proofWaldIV"><i class="fa fa-check"></i><b>A.2.2</b> Proof of Theorem @ref(thm:WaldIV)</a></li>
<li class="chapter" data-level="A.2.3" data-path="proofs.html"><a href="proofs.html#ProofAsymWald"><i class="fa fa-check"></i><b>A.2.3</b> Proof of Theorem @ref(thm:asymWald)</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refne"><i class="fa fa-check"></i><b>A.3</b> Proofs of results in Chapter @ref(NE)</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="proofs.html"><a href="proofs.html#proofEstimDID"><i class="fa fa-check"></i><b>A.3.1</b> Proof of Theorem @ref(thm:EstimDID)</a></li>
<li class="chapter" data-level="A.3.2" data-path="proofs.html"><a href="proofs.html#proofasympnoiseDIDCross"><i class="fa fa-check"></i><b>A.3.2</b> Proof of Theorem @ref(thm:asympnoiseDIDCross)</a></li>
<li class="chapter" data-level="A.3.3" data-path="proofs.html"><a href="proofs.html#proofEquivDIDSApop"><i class="fa fa-check"></i><b>A.3.3</b> Proof of Theorem @ref(thm:EquivDIDSApop)</a></li>
<li class="chapter" data-level="A.3.4" data-path="proofs.html"><a href="proofs.html#proofEquivDIDSAsamp"><i class="fa fa-check"></i><b>A.3.4</b> Proof of Theorem @ref(thm:EquivDIDSAsamp)</a></li>
<li class="chapter" data-level="A.3.5" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSACross"><i class="fa fa-check"></i><b>A.3.5</b> Proof of Theorem @ref(thm:asympnoiseSACross)</a></li>
<li class="chapter" data-level="A.3.6" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTCross"><i class="fa fa-check"></i><b>A.3.6</b> Proof of Theorem @ref(thm:asympnoiseSATTCross)</a></li>
<li class="chapter" data-level="A.3.7" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSAPanel"><i class="fa fa-check"></i><b>A.3.7</b> Proof of Theorem @ref(thm:asympnoiseSAPanel)</a></li>
<li class="chapter" data-level="A.3.8" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTPanel"><i class="fa fa-check"></i><b>A.3.8</b> Proof of Theorem @ref(thm:asympnoiseSATTPanel)</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refom"><i class="fa fa-check"></i><b>A.4</b> Proofs of results in Chapter @ref(OM)</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="proofs.html"><a href="proofs.html#proofAsympWWOLS10"><i class="fa fa-check"></i><b>A.4.1</b> Proof of Theorem @ref(thm:AsympWWOLS10)</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refcluster"><i class="fa fa-check"></i><b>A.5</b> Proofs of results in Chapter @ref(cluster)</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="proofs.html"><a href="proofs.html#proofVarWWClus"><i class="fa fa-check"></i><b>A.5.1</b> Proof of Theorem @ref(thm:VarWWClus)</a></li>
<li class="chapter" data-level="A.5.2" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTPanelAR1"><i class="fa fa-check"></i><b>A.5.2</b> Proof of Theorem @ref(thm:asympnoiseSATTPanelAR1)</a></li>
<li class="chapter" data-level="A.5.3" data-path="proofs.html"><a href="proofs.html#proofVarWWSpatial"><i class="fa fa-check"></i><b>A.5.3</b> Proof of Theorem @ref(thm:VarWWSpatial)</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refdiffusion"><i class="fa fa-check"></i><b>A.6</b> Proofs of results in Chapter @ref(Diffusion)</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="proofs.html"><a href="proofs.html#proofSmoothSymAlloc"><i class="fa fa-check"></i><b>A.6.1</b> Proof of Theorem @ref(thm:SmoothSymAlloc)</a></li>
<li class="chapter" data-level="A.6.2" data-path="proofs.html"><a href="proofs.html#proofIdentSmoothSymAlloc"><i class="fa fa-check"></i><b>A.6.2</b> Proof of Theorem @ref(thm:IdentSmoothSymAlloc)</a></li>
<li class="chapter" data-level="A.6.3" data-path="proofs.html"><a href="proofs.html#proofContagionDiffusionSmoothSymAlloc"><i class="fa fa-check"></i><b>A.6.3</b> Proof of Theorem @ref(thm:ContagionDiffusionSmoothSymAlloc)</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refstratification"><i class="fa fa-check"></i><b>A.7</b> Proofs of results in Chapter @ref(stratification)</a>
<ul>
<li class="chapter" data-level="A.7.1" data-path="proofs.html"><a href="proofs.html#proofSFEdecomp"><i class="fa fa-check"></i><b>A.7.1</b> Proof of Theorem @ref(thm:SFEdecomp)</a></li>
<li class="chapter" data-level="A.7.2" data-path="proofs.html"><a href="proofs.html#proofSFEconsistent"><i class="fa fa-check"></i><b>A.7.2</b> Proof of Theorem @ref(thm:SFEconsistent)</a></li>
<li class="chapter" data-level="A.7.3" data-path="proofs.html"><a href="proofs.html#proofSATUnbiasedConsistent"><i class="fa fa-check"></i><b>A.7.3</b> Proof of Theorem @ref(thm:SATUnbiasedConsistent)</a></li>
<li class="chapter" data-level="A.7.4" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATStrata"><i class="fa fa-check"></i><b>A.7.4</b> Proof of Theorem @ref(thm:asympnoiseSATStrata)</a></li>
<li class="chapter" data-level="A.7.5" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSFEStrata"><i class="fa fa-check"></i><b>A.7.5</b> Proof of Theorem @ref(thm:asympnoiseSFEStrata)</a></li>
<li class="chapter" data-level="A.7.6" data-path="proofs.html"><a href="proofs.html#proofPairUnbiasedConsistent"><i class="fa fa-check"></i><b>A.7.6</b> Proof of Theorem @ref(thm:PairUnbiasedConsistent)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Tools for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Diffusion" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Diffusion effects<a href="Diffusion.html#Diffusion" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Up until now, we have assumed that the treatment received by one unit in the population did not have any impact on any other unit.
We have not encoded this assumption formally, but we have implicitly made it all along, starting with our encoding of Rubin Causal Model in Chapter <a href="FPCI.html#FPCI">1</a>.
In this chapter, we are going to relax that assumption, and learn how to deal with the more general cases that then appear.
We are going to cover a host of very important applications, that go from identifying contagion effects to identifying the optimal proportion of individuals to treat at independent locations.
We are first going to start by introducing an extended Rubin Causal Model allowing for diffusion effects and introducing ways to discipline this model so that it becomes estimable.
We are then going to look at various ways to estimate this model and the precision of the resulting estimates, using RCTs, DID, and both parametric and non parametric approaches.
Most of these developments are fairly recent and will enable us to get rapidly in touch with the research frontier.</p>
<div id="allowing-for-diffusion-effects-in-rubin-causal-model" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Allowing for diffusion effects in Rubin Causal Model<a href="Diffusion.html#allowing-for-diffusion-effects-in-rubin-causal-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we are going to detail how to encode causality in the presence of diffusion effects.
We are going to start with potential outcomes and a general framework, before considering two very important special cases: the case where diffusion effects are absent and the case where they take a specific form.</p>
<div id="potential-outcomes-and-treatment-effects-with-diffusion-effects" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> Potential outcomes and treatment effects with diffusion effects<a href="Diffusion.html#potential-outcomes-and-treatment-effects-with-diffusion-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The main starting point for an extended Rubin Causal Model is to acknowledge that the treatment status of the <span class="math inline">\(N^*\)</span> observations in the population (with <span class="math inline">\(N^*\)</span> possibly infinite) might influence the observed outcome for individual <span class="math inline">\(i\)</span>.
Let <span class="math inline">\(\mathbf{d}=\left\{d_1,\dots,d_{N^*}\right\}\)</span>, with <span class="math inline">\(d_j\in\left\{0,1\right\}\)</span>, <span class="math inline">\(\forall j\in\left\{1,\dots,N^*\right\}\)</span>.
We can therefore write the generalized potential outcome for individual <span class="math inline">\(i\)</span> as <span class="math inline">\(Y_i^{\mathbf{d}}\)</span>.
If we write <span class="math inline">\(\mathbf{D}=\left\{D_1,\dots,D_{N^*}\right\}\)</span>, we can then write the observed outcome for individual <span class="math inline">\(i\)</span> as <span class="math inline">\(Y_i^{\mathbf{D}}\)</span>.
The average effect of the treatment becomes:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{ATE}(\mathbf{D}) &amp; = \esp{Y_i^{\mathbf{D}}-Y_i^{\mathbf{0}}}\\
                &amp; = \esp{Y_i^{\mathbf{D}}-Y_i^{\mathbf{0}}|D_i=1}\Pr(D_i=1)+\esp{Y_i^{\mathbf{D}}-Y_i^{\mathbf{0}}|D_i=0}\Pr(D_i=0)\\
                &amp; = \Delta^Y_{TT}(\mathbf{D})\Pr(D_i=1)+\Delta^Y_{TUT}(\mathbf{D})\Pr(D_i=0)\\
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\mathbf{0}\)</span> is the null vector of length <span class="math inline">\(N^*\)</span>.
Note that the average effect of the treatment is equal to a weighted average of the effect on the treated and the effect of the untreated.
Note also that these effects differ from the ones we defined in Chapters <a href="FPCI.html#FPCI">1</a> and <a href="FPSI.html#FPSI">2</a>: they depend on the whole vector of treatment assignments.
Indeed, the effect on the untreated is not the one we defined in Section <a href="OM.html#BiasOLS">5.1.3</a>: it is not the difference between taking the treatment and not taking the treatment for those who do not take it.
The TUT we have defined here is the difference in outcomes for the ones who do not take the treatment between a case where the treated individuals in the population receive the treatment and a case where no one receives the treatment.
The only effect of the treatment on the untreated is indirect: it is the effect that transits through diffusion of the treatment effects from the treated to the untreated.
It can be when farmers adopt technologies after seeing their treated neighbors adopt them, or when people contract less diseases because their neighbors are vaccinated.
These effects can also be negative, for example when untreated job seekers are crowded out of a job by the job counselling received by the treated.
In general, I like to call these effects <strong>contagion</strong> effects, to insist on the fact that they are indirect.</p>
<p>Note that the effect on the treated also is different and depends on the whole treatment vector.
In that case, we allow for the effect on the treated to depend on whether or not some or all of their neighbors are treated.
The effect of a vaccine might for example be higher when more people around us are vaccinated.
Or a technology is more likely to be adopted if more neighbors are informed that it exists and encourage to adopt it.
I call these types of effects <strong>amplification</strong> effects, to denote the fact that whether the treated react a lot or not to the treatment might depend on whether their neighbors are also treated.
These effects might also be negative, for example when more job seekers receive counselling, the effectiveness of counselling on the treated might very well decrease.</p>
</div>
<div id="encoding-the-absence-of-diffusion-effects" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Encoding the absence of diffusion effects<a href="Diffusion.html#encoding-the-absence-of-diffusion-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we are going to state the assumption of absence of diffusion effects, that is required for all our previous estimators to work.
This assumption, called the Stable Unit Treatment Value Assumption, is stated as follows:</p>
<div class="hypothesis">
<p><span id="hyp:SUTVA" class="hypothesis"><strong>Hypothesis 11.1  (Stable Unit Treatment Value Assumption) </strong></span>We assume that the effect of the treatment on individual <span class="math inline">\(i\)</span> only depends on whether <span class="math inline">\(i\)</span> receives the treatment or not, and not on whether other individuals in the population receive the treatment as well: <span class="math inline">\(\forall i\)</span>, <span class="math inline">\(D_i=D&#39;_i\Rightarrow Y_i^{\mathbf{D}}=Y_i^{\mathbf{D&#39;}}\)</span>, <span class="math inline">\(\forall\mathbf{D}\neq\mathbf{D&#39;}\)</span>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-252" class="remark"><em>Remark</em>. </span>SUTVA has been coined by Don Rubin in a series of papers: Rubin (<a href="https://doi.org/10.1214/aos/1176344064">1978</a>, <a href="https://doi.org/10.2307/2287653">1980</a>, <a href="https://doi.org/10.1214/ss/1177012032">1990</a>).</p>
</div>
<p>SUTVA implies the version of Rubin Causal Model that we have introduced in Chapter <a href="FPCI.html#FPCI">1</a>.
Indeed, SUTVA implies that the only treatment status that matters for the potential outcomes of individual <span class="math inline">\(i\)</span> is the treatment status of individual <span class="math inline">\(i\)</span>.
As a consequence, we have the following results:</p>
<div class="theorem">
<p><span id="thm:RCMSUTVA" class="theorem"><strong>Theorem 11.1  (Rubin Causal Model and Treatment Effects Under SUTVA) </strong></span>Under Assumption <a href="Diffusion.html#hyp:SUTVA">11.1</a>, the potential outcome of individual <span class="math inline">\(i\)</span> only depends on its treatment status: <span class="math inline">\(\forall i\)</span>, <span class="math inline">\(Y_i^{\mathbf{D}}=Y_i^{D_i}\)</span>.
As a consequence:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT}(\mathbf{D}) &amp; = \Delta^Y_{TT}\\
  \Delta^Y_{TUT}(\mathbf{D}) &amp; = 0.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-253" class="proof"><em>Proof</em>. </span>The proof of the first result that <span class="math inline">\(Y_i^{\mathbf{D}}=Y_i^{D_i}\)</span> is straightforward from Assumption <a href="Diffusion.html#hyp:SUTVA">11.1</a>.
We therefore have</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT}(\mathbf{D}) &amp; = \esp{Y_i^{\mathbf{D}}-Y_i^{\mathbf{0}}|D_i=1}\\
                            &amp; = \esp{Y_i^{D_i}-Y_i^{0}|D_i=1}\\
                            &amp; = \esp{Y_i^{1}-Y_i^{0}|D_i=1}\\
                            &amp; =   \Delta^Y_{TT}\\
  \Delta^Y_{TUT}(\mathbf{D})&amp; = \esp{Y_i^{\mathbf{D}}-Y_i^{\mathbf{0}}|D_i=0}\\
                            &amp; = \esp{Y_i^{D_i}-Y_i^{0}|D_i=0}\\
                            &amp; = \esp{Y_i^{0}-Y_i^{0}|D_i=0}\\
                            &amp; = 0.
\end{align*}\]</span></p>
</div>
</div>
<div id="TreatmentExposure" class="section level3 hasAnchor" number="11.1.3">
<h3><span class="header-section-number">11.1.3</span> Treatment exposure<a href="Diffusion.html#TreatmentExposure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In general, it is going to prove extremely difficult to do econometric analysis using the very general setting we have defined so far, with potential outcomes depending on the whole treatment vector in the population.
A useful simplifying assumption that we often have to resort to is to specify an exposure mapping, that relates the whole treatment vector to the specifications relevant for the outcomes of interest.
In order to specify the exposure mapping, we are going to assume that all units in the population are part of a network.
This network is summarized by an <span class="math inline">\(N^*\times N^*\)</span> contiguity matrix <span class="math inline">\(A\)</span> where each element <span class="math inline">\(a_{j,i}\)</span> (with <span class="math inline">\(j\)</span> denoting the line and <span class="math inline">\(i\)</span> the column) measures the strength of the relationship between <span class="math inline">\(j\)</span> and <span class="math inline">\(i\)</span>.
For example, if <span class="math inline">\(j\)</span> mentions <span class="math inline">\(i\)</span> as a friend, <span class="math inline">\(a_{j,i}=1\)</span>, whereas <span class="math inline">\(a_{i,j}=1\)</span> whenever <span class="math inline">\(i\)</span> mentions <span class="math inline">\(j\)</span> as a friend.
We can enforce the graph to be symmetric, that is <span class="math inline">\(a_{j,i}=a_{i,j}\)</span>, <span class="math inline">\(\forall (i,j)\)</span>, but it does not have to be the case.
For example, water quality at some point <span class="math inline">\(i\)</span> along a river stream depends on whether water is treated at a point <span class="math inline">\(j\)</span> upstream, but water quality in <span class="math inline">\(j\)</span> does not depend on treatments in a downstream point <span class="math inline">\(i\)</span>.
Because water flows in one direction, the network is not symmetric.</p>
<p>Equipped with a network of links, and denoting <span class="math inline">\(\mathbf{\Omega}=2^{N^*}\)</span> the set of possible treatment allocations, and <span class="math inline">\(\mathbf{\Theta}\)</span> the set of parameters <span class="math inline">\(\theta_i\)</span> relevant for the value of treatment exposure of unit <span class="math inline">\(i\)</span> (possibly containing features of the <span class="math inline">\(A\)</span> matrix), we can define treatment exposure as a mapping <span class="math inline">\(f\)</span> from <span class="math inline">\(\mathbf{\Omega}\times\mathbf{\Theta}\)</span> to <span class="math inline">\(\mathbf{\Delta}\)</span>, the set of possible treatment exposure: <span class="math inline">\(\Delta_i=f(\mathbf{D},\theta_i)\)</span>.
A key assumption we are going to make is that the exposure mapping is propermy specified, that is that it captures perfectly the intricacies of the effects of various treatment vectors:</p>
<div class="hypothesis">
<p><span id="hyp:PropSpecifyExpMap" class="hypothesis"><strong>Hypothesis 11.2  (Properly specified exposure mapping) </strong></span><span class="math inline">\(\forall i\)</span>, <span class="math inline">\(\forall\mathbf{D}\neq\mathbf{D&#39;}\in\mathbf{\Omega}\)</span>, <span class="math inline">\(\forall \theta_i\in\mathbf{\Theta}\)</span>, <span class="math inline">\(f(\mathbf{D},\theta_i)=f(\mathbf{D&#39;},\theta_i)\Rightarrow Y_i^{\mathbf{D}}=Y_i^{\mathbf{D&#39;}}\)</span>.</p>
</div>
<p>Under Assumption <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, the potential outcomes can be written as functions of treatment exposure only: <span class="math inline">\(Y_i^{\Delta_i}\)</span>.<br />
As a consequence, we can now define the average treatment effect of the treatment on the treated as follows:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT}(\mathbf{d}) &amp; = \esp{Y_i^{\mathbf{d}}-Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\Delta^Y_{TT}(\mathbf{d})\)</span> measures the impact of treatment exposure <span class="math inline">\(\mathbf{d}\)</span> on those who have received it.</p>
<div class="remark">
<p><span id="unlabeled-div-254" class="remark"><em>Remark</em>. </span>The framework based on the use of an exposure mapping has been developped by <a href="https://doi.org/10.1111/j.1368-423X.2012.00368.x">Manski (2013)</a> and <a href="https://doi.org/10.1214/16-AOAS1005">Aronow and Samii (2017)</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-255" class="remark"><em>Remark</em>. </span>I use the term ``average treatment effect on the treatedââ because <span class="math inline">\(\Delta^Y_{ATE}(\mathbf{d})\)</span> measures the effect of receiving a treatment vector <span class="math inline">\(d\)</span> on those who receive it.</p>
</div>
<p>We are now equipped with tools that enable us to define treatment effects in the presence of diffusion effects, and to identify various types of diffusion effects.
The key concept that we are going to have to specify is treatment exposure: how does it change with various applications and how do we go around identifying it in various precise cases?
What can we do as well to test for features of treatment exposure without completely specifying it?
This is what we are going to see in what follows, first in the case of Randomized Controlled Trials, and then in the case of Difference in Differences.
We are going to go step by step, and first we ware going to start with simpler networks, that I call coarse networks, before looking at what we can do with more complex networks.</p>
</div>
<div id="fundamental-problem-of-causal-inference-for-diffusion-effects" class="section level3 hasAnchor" number="11.1.4">
<h3><span class="header-section-number">11.1.4</span> Fundamental problem of causal inference for diffusion effects<a href="Diffusion.html#fundamental-problem-of-causal-inference-for-diffusion-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With diffusion effects and treatment exposure, the Fundamental Problem of Causal Inference strikes again.
Let state the problem using our more general framework of treatment exposure:</p>
<div class="theorem">
<p><span id="thm:FPCIDiff" class="theorem"><strong>Theorem 11.2  (Fundamental problem of causal inference with diffusion effects) </strong></span>It is impossible to observe <span class="math inline">\(\Delta^Y_{TT}(\mathbf{d})\)</span>, <span class="math inline">\(\forall d\in\mathbf{\Delta}\)</span>, either in the population or in the sample.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-256" class="proof"><em>Proof</em>. </span>For the population TT:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT}(\mathbf{d}) &amp; = \esp{Y_i^{\mathbf{d}}-Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}} \\
                &amp; = \esp{Y_i^{\mathbf{d}}|\Delta_i=\mathbf{d}}-\esp{Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}}\\
                &amp; = \esp{Y_i|\Delta_i=\mathbf{d}}-\esp{Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}}.
\end{align*}\]</span></p>
<p><span class="math inline">\(\esp{Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}}\)</span> is unobserved, and so is <span class="math inline">\(\Delta^Y_{TT}\)</span>.
A similar reasoning holds for the sample average treatment effect.</p>
</div>
<p>We also have a novel formulation of the bias of intuitive methods.
For example, selection bias now depends on <span class="math inline">\(\mathbf{d}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{SB}(\mathbf{d}) &amp; = \Delta^Y_{WW}(\mathbf{d})-\Delta^Y_{TT}(\mathbf{d}) \\
              &amp; = \esp{Y_i|\Delta_i=\mathbf{d}}-\esp{Y_i|\Delta_i=\mathbf{0}}-\esp{Y_i^{\mathbf{d}}-Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}}\\
              &amp; = \esp{Y_i^{\mathbf{0}}|\Delta_i=\mathbf{d}}-\esp{Y_i^{\mathbf{0}}|\Delta_i=\mathbf{0}}.
\end{align*}\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-257" class="remark"><em>Remark</em>. </span>Why is the with/without comparison of individuals with treatment exposure <span class="math inline">\(\Delta_i=\mathbf{d}\)</span> and those with treatment exposure <span class="math inline">\(\Delta_i=\mathbf{0}\)</span> biased for average treatment effect on the treated <span class="math inline">\(\Delta^Y_{TT}(\mathbf{d})\)</span>?
This is because treatment exposure might be correlated with unobserved confounders: individuals with higher treatment exposure might be systematically different from those with the reference level of treatment exposure (here <span class="math inline">\(\mathbf{0}\)</span>).</p>
</div>
</div>
<div id="bias-of-one-step-randomized-controlled-trials" class="section level3 hasAnchor" number="11.1.5">
<h3><span class="header-section-number">11.1.5</span> Bias of one-step randomized controlled trials<a href="Diffusion.html#bias-of-one-step-randomized-controlled-trials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Explain direction of bias</strong></p>
</div>
</div>
<div id="diffusion-effects-with-coarse-networks" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Diffusion effects with coarse networks<a href="Diffusion.html#diffusion-effects-with-coarse-networks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Coarse networks are networks where we do not have a lot of information on the connections between individuals: we only know whether they belong to the same influence group or not.
This type of network characterizes for example of a group of villages, or municipalities, or classes, for which we do not know which links individuals have between each other other than they belong to the same group.
More formally, coarse networks can be characterized by the following property:</p>
<div class="hypothesis">
<p><span id="hyp:CoarseNetwork" class="hypothesis"><strong>Hypothesis 11.3  (Coarse network) </strong></span>We say that our population is characterized by a coarse network if the observed matrix of connections <span class="math inline">\(A\)</span> is block diagonal and we do not know which nodes are activated within each block.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-258" class="remark"><em>Remark</em>. </span>A blog diagonal influence matrix is composed of a set of groups or clusters within which observations influence each other and across which we assume all influences are muted.
This is of course a simplification: some units within a cluster might not really be connected, while some units might be connected to units in an other group.
Also, not all units might be equivalent within a group, with some being more central (<em>e.g.</em> connected) than others.
In a coarse network, we are assuming these differences away.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-259" class="remark"><em>Remark</em>. </span>Another way of framing coarse networks is to say that there is unknown interference within clusters (and no interference across).
This is <a href="http://arxiv.org/abs/2011.08174">Viviano (2023)</a>âs definition.
With Vivianoâs approach to coarse networks, we do not know which units interfere within each network and how they do.</p>
</div>
<p>With a coarse network approach, under Assumption <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, we might specialize the exposure mapping to things we might know, that is whether the unit itself is treated or not and the proportion of units that are treated in a given cluster <span class="math inline">\(c\)</span>, <span class="math inline">\(p_c\)</span>, or, more generally, the proportion of units with characteristics <span class="math inline">\(X_i=x\)</span> that are treated within clusters with characteristics <span class="math inline">\(Z_c=z\)</span>: <span class="math inline">\(p(x,z)\)</span>.
As a consequence, we might write potential outcomes as <span class="math inline">\(Y_i^{D_i,p_c}\)</span> or, more generally, <span class="math inline">\(Y_i^{D_i,\left\{p(x,Z_c)\right\}_{x\in\mathcal{X}}}\)</span>, with <span class="math inline">\(\mathcal{X}\)</span> the support of <span class="math inline">\(X_i\)</span>.</p>
<div class="remark">
<p><span id="unlabeled-div-260" class="remark"><em>Remark</em>. </span>Lemma 2.1 in <a href="http://arxiv.org/abs/2011.08174">Viviano (2023)</a> shows an example of assumptions under which we can simplify the exposiure mapping and obtain potential outcomes as a function of the proportion of treated units and cluster and unit characteristics.</p>
</div>
<p>Under Assumption <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, we can write the average effect of treating a cluster with a proportion of treated <span class="math inline">\(p_c=p\)</span> as follows:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT}(p) &amp; = \esp{Y_i^{D_i,p}-Y_i^{0,0}|p_c=p}\\
                &amp; = \esp{Y_i^{1,p}-Y_i^{0,0}|D_i=1,p_c=p}\Pr(D_i=1|p_c=p)\\
                &amp; \phantom{=} +\esp{Y_i^{0,p}-Y_i^{0,0}|D_i=0,p_c=p}\Pr(D_i=0|p_c=p)\\
                &amp; = \Delta^Y_{TDT}(p)\Pr(D_i=1|p_c=p)+\Delta^Y_{TIT}(p)\Pr(D_i=0|p_c=p),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\Delta^Y_{TDT}(p)\)</span> is the Average Treatment Effect on the Directly Treated and <span class="math inline">\(\Delta^Y_{TIT}(p)\)</span> is the Average Treatment Effect on the Indirectly Treated.</p>
<p>The main question under Assumption <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a> is to find the allocation of treated units that maximizes some objective function.
We are going to make a distinction between two different cases:</p>
<ol style="list-style-type: decimal">
<li>In the first case, we have a pre-specified budget for treatment effort (in terms of number of treated units) and we have to choose how to spend it optimally.
This often happens in practical policy applications where the budget has been pre-approved but you do not know how to implement it in the most optimal way possible.</li>
<li>In the second case, we already have an existing policy in place, and we would like to know whether it is optimal, and in which direction we should take it if we happen to have some additional budget.</li>
</ol>
<div id="optimal-treatment-allocation-under-monotone-response" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Optimal treatment allocation under monotone response<a href="Diffusion.html#optimal-treatment-allocation-under-monotone-response" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I develop result on this setting in my own ongoing research.
In order to fix ideas, we are going to start with a simple network with two clusters.
We will then look at what happens with a more general network.
Finally, we will look at how we can use two-steps clustered RCTs to estimate the required parameters and decide on the optimal allocation.</p>
<div id="a-simple-model" class="section level4 hasAnchor" number="11.2.1.1">
<h4><span class="header-section-number">11.2.1.1</span> A simple model<a href="Diffusion.html#a-simple-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Letâs start with a very simple example of a network with two clusters <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span>.
Letâs also consider only the case of a discrete outcome (such as participation in a program, getting vaccinated, contracting a disease, adopting a technology, etc.).
For simplicity, we are also going to write that potential outcomes are realizations of a continuous utility variable crossing a threshold:</p>
<p><span class="math display">\[\begin{align*}
  Y_{i}^{0,P_c} &amp; = \uns{\underbrace{\delta_0 + \beta_0 P_{c} -\epsilon_{i,0}}_{Y^*_{i,0}}\geq0}\\
  Y_{i}^{1,P_c} &amp; = \uns{\underbrace{\delta_1 + \beta_1 P_{c} -\epsilon_{i,1}}_{Y^*_{i,1}}\geq0}.
\end{align*}\]</span></p>
<p>What this models tells us is that, when no one else in the cluster is treated (<span class="math inline">\(P_c=0\)</span>), the individual level effect of being treated is equal to <span class="math inline">\(\Delta^Y_i=\uns{\epsilon_{i,1}\leq\delta_1}-\uns{\epsilon_{i,0}\leq\delta_0}\)</span>.
When some units starts receiving the treatment, we have two indirect effects:</p>
<ul>
<li>Increasing the proportion of treated units impacts the outcomes of untreated units, through <span class="math inline">\(\beta_0\)</span>.
This is what I call a <strong>contagion</strong> effect, in which untreated units are somehow contaminated by the treatment received by the treated individuals in the same cluster.
Contagion might refer to receiving information about the existence of a program and eventually deciding the enroll, or being protected by the fact that some neighbors are taking a treatment (in that case, contagion effects might actually prevent some untreated units from being contaminated).
Contagion effects might be negative, if for example treated individuals who receive job training or job search assistance end up finding jobs that would have been allocated to some of the untreated individuals in the absence of the treatment.</li>
<li>Increasing the proportion of treated units impacts the outcomes of treated units, through <span class="math inline">\(\beta_1\)</span>.
This is what I call an <strong>amplification</strong> effect.
There is amplification each time a treated units increases its likelihood of a positive outcome because more units are treated.
This might happen when technological adoption occurs only after most individuals in the cluster have been exposed to it and convinced to make a change.</li>
</ul>
<p>In order to get even more intuition on this problem, we are going to specialize it even further by making the following set of assumptions:</p>
<div class="hypothesis">
<p><span id="hyp:SimpleAllocHyp" class="hypothesis"><strong>Hypothesis 11.4  (Simplified Allocation Problem) </strong></span>We assume that the allocation problem is characterized as follows:</p>
<ul>
<li>There are only two nodes <span class="math inline">\(c=1\)</span> and <span class="math inline">\(c=2\)</span>.</li>
<li>A mass of <span class="math inline">\(1\)</span> units reside at each node.</li>
<li>We can only treat a mass of <span class="math inline">\(1\)</span> units.</li>
<li>We assume the constraint is saturated so that we use all available treatments: <span class="math inline">\(p_1+p_2=1\)</span>.</li>
<li><span class="math inline">\(\epsilon_1\)</span> and <span class="math inline">\(\epsilon_0\)</span> are uniform on <span class="math inline">\(\left[0,1\right]\)</span>.</li>
</ul>
</div>
<p>Under Assumption <a href="Diffusion.html#hyp:SimpleAllocHyp">11.4</a>, we can set <span class="math inline">\(p_1=p\)</span> and <span class="math inline">\(p_2=1-p\)</span>.
Letâs assume our goal is to maximize the total amount of people with <span class="math inline">\(Y_i=1\)</span>.
Under Assumption <a href="Diffusion.html#hyp:SimpleAllocHyp">11.4</a>, this is equivalent to maximizing the sum of the adoption rates at both nodes.
Using the fact that the constraint is saturated, we can write the objective function we aim to maximize as follows:</p>
<p><span class="math display">\[\begin{align*}
  W(p) &amp; = \underbrace{pF_{\epsilon,1}(\alpha_1 + \beta_1p)+(1-p)F_{\epsilon,0}(\alpha_0 + \beta_0p)}_{A(p)}\\
  &amp; \phantom{=}+\underbrace{(1-p)F_{\epsilon,1}(\alpha_1 + \beta_1(1-p))+pF_{\epsilon,0}(\alpha_0 + \beta_0(1-p))}_{A(1-p)}
\end{align*}\]</span></p>
<p>The <span class="math inline">\(A\)</span> function measures how much the probability of observing the favorable outcome <span class="math inline">\(Y_i=1\)</span> in a given cluster increases with the proportion of treated individuals in the cluster, <span class="math inline">\(p\)</span>.
It turns out that the properties of the <span class="math inline">\(A\)</span> function are key to determine the optimal allocation of treatment effort across nodes in the general case with more than two nodes.
For now, in the two-node case and under substantial simplifications, we have the following result:</p>
<div class="theorem">
<p><span id="thm:SimpleAlloc" class="theorem"><strong>Theorem 11.3  (Optimal allocation of treatment effort with two nodes) </strong></span>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a> and <a href="Diffusion.html#hyp:SimpleAllocHyp">11.4</a>, we have three possible cases for the optimal allocation of treatment effort:</p>
<ul>
<li>When amplification effects dominate (<span class="math inline">\(\beta_1&gt;\beta_0\)</span>): either <span class="math inline">\(p^*=1\)</span> or <span class="math inline">\(p^*=0\)</span></li>
<li>When contagion effects dominate (<span class="math inline">\(\beta_0&gt;\beta_1\)</span>): <span class="math inline">\(p^*=\frac{1}{2}\)</span></li>
<li>When amplification and contagion effects are of the same size (<span class="math inline">\(\beta_0=\beta_1\)</span>): <span class="math inline">\(p^*=\left[0,1\right]\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-261" class="proof"><em>Proof</em>. </span>Under Assumption <a href="Diffusion.html#hyp:SimpleAllocHyp">11.4</a>, we have:</p>
<p><span class="math display">\[\begin{align*}
  W(p) &amp; = p(\alpha_1 + \beta_1p)+(1-p)(\alpha_0 + \beta_0p)+(1-p)(\alpha_1 + \beta_1(1-p))+p(\alpha_0 + \beta_0(1-p))\\
      &amp; = \alpha_0+\alpha_1+\beta_1+2(\beta_0-\beta_1)p(1-p),
\end{align*}\]</span></p>
<p>where the second line follows after some algebra.
The problem <span class="math inline">\(\max_{p\in\left[0,1\right]}W(p)\)</span> has the folowing first order condition: <span class="math inline">\(W&#39;(p)=2(\beta_0-\beta_1)(1-2p)=0\)</span> and the following second order condition: <span class="math inline">\(W&#39;&#39;(p)=-4(\beta_0-\beta_1)\)</span>.
When <span class="math inline">\(\beta_0&gt;\beta_1\)</span>, <span class="math inline">\(W&#39;&#39;(p)&lt;0\)</span>, and the interior solution <span class="math inline">\(p^*=\frac{1}{2}\)</span> maximizes <span class="math inline">\(W\)</span>.
When <span class="math inline">\(\beta_0&lt;\beta_1\)</span>, <span class="math inline">\(W&#39;&#39;(p)&gt;0\)</span>, and the interior solution <span class="math inline">\(p^*=\frac{1}{2}\)</span> minimizes <span class="math inline">\(W\)</span>.
In that case, the optimal solution is at a corner, either at <span class="math inline">\(p^*=1\)</span> or at <span class="math inline">\(p^*=0\)</span>.
Since <span class="math inline">\(W(1)=W(0)\)</span>, they are both maxima.
When <span class="math inline">\(\beta_0=\beta_1\)</span>, <span class="math inline">\(W\)</span> is constant and any value in <span class="math inline">\(\left[0,1\right]\)</span> maximizes <span class="math inline">\(W\)</span>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-262" class="remark"><em>Remark</em>. </span>Theorem <a href="Diffusion.html#thm:SimpleAlloc">11.3</a> shows that when amplification effects dominate, it is optimal to focus all treatment effort on one of the two nodes (for example the first, but they are interchangeable).
This is because returns are increasing in this case: the <span class="math inline">\(A\)</span> function is convex, with more people responding to the treatment as more of them receive the treatment.
When contagion effects dominate, it is optimal to treat both nodes, with half of the observations receiving the treatment.
This is because in that case, the <span class="math inline">\(A\)</span> function is concave, and the marginal returns are decreasing when we treat more people.
When both contagion and amplification effects are equal, there is no optimum, or, equivalently, any allocation <span class="math inline">\(p\)</span> will yield the same result.</p>
</div>
</div>
<div id="a-general-model" class="section level4 hasAnchor" number="11.2.1.2">
<h4><span class="header-section-number">11.2.1.2</span> A general model<a href="Diffusion.html#a-general-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>One open question is whether we can generalize the result in Theorem <a href="Diffusion.html#thm:SimpleAlloc">11.3</a> to a much more general setting with several nodes and more general functional forms.
It is actually the case.
Let us now formulate a more general setting:</p>
<div class="hypothesis">
<p><span id="hyp:SymAllocHyp" class="hypothesis"><strong>Hypothesis 11.5  (Symmetric Allocation Problem) </strong></span>We assume that the allocation problem is characterized as follows:</p>
<ul>
<li><span class="math inline">\(K\)</span> nodes indexed from <span class="math inline">\(1\)</span> to <span class="math inline">\(K\)</span>, and each node has size <span class="math inline">\(n_k\)</span>.</li>
<li>At each node, we can choose to treat <span class="math inline">\(r_k\)</span> individuals.</li>
<li>The total number of individuals on the network is <span class="math inline">\(N=\sum_{k=1}^Kn_k\)</span>.</li>
<li>The total number of treated individuals is <span class="math inline">\(R=\sum_{k=1}^Kr_k\)</span>.</li>
<li>We cannot treat more than <span class="math inline">\(\bar{R}\)</span> individuals.</li>
<li>We cannot treat everyone: <span class="math inline">\(\bar{R}&lt;N\)</span>.</li>
<li>The expected outcome at each node (or response function) is only a function of <span class="math inline">\(p\)</span>, that we denote <span class="math inline">\(A(p)\)</span>, with <span class="math inline">\(A&#39;&gt;0\)</span>.</li>
</ul>
</div>
<p><strong><span class="math inline">\(A\)</span> is two things at the same time: connection matrix and response function</strong></p>
<div class="remark">
<p><span id="unlabeled-div-263" class="remark"><em>Remark</em>. </span>Assumption <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a> is mainly restrictive in making the problem symmetric: all nodes are treated in the same way.
The only thing that distinguishes nodes is their respective size.
Apart from that, they all respond in the same (average) way to the treatment.
We do not try to distinguish between nodes based on observed characteristics of the nodes.
We also do not try to vary the identity of treated units based on their observed characteristics.
Another restriction is that <span class="math inline">\(A&#39;&gt;0\)</span>: we only consider treatments for which the response is always strictly increasing in <span class="math inline">\(p\)</span> (and not weakly).</p>
</div>
<p>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a> and <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a>, we can cast our optimization problem as follows:</p>
<p><span class="math display">\[\begin{align*}
  \max_{\left\{r_k\right\}_{k=1}^K} &amp; \sum_{k=1}^K n_kA(\frac{r_k}{n_k})\label{eqn:MainProbMax}\\
   &amp; \text{under the constraints} \nonumber\\
   R  &amp; =\sum_{k=1}^Kr_k \leq \bar{R} \label{eqn:MainProbR}\\
   r_k &amp; \leq n_k\text{, }\forall k\label{eqn:MainProbn}\\
   r_k &amp; \geq 0\text{, }\forall k.\label{eqn:MainProbr}
\end{align*}\]</span></p>
<p>In my work, I have been able to solve this problem for a smooth response function <span class="math inline">\(A\)</span>, in the following sense:</p>
<div class="hypothesis">
<p><span id="hyp:SmoothResponseHyp" class="hypothesis"><strong>Hypothesis 11.6  (Monotone Response Function) </strong></span>We assume that the reponse function <span class="math inline">\(A\)</span> has constant second derivative on its full support: either <span class="math inline">\(A&#39;&#39;(p)&gt;0\)</span> <span class="math inline">\(\forall p\in\left[0,1\right]\)</span> or <span class="math inline">\(A&#39;&#39;(p)&lt;0\)</span> <span class="math inline">\(\forall p\in\left[0,1\right]\)</span>.</p>
</div>
<p>We can indeed prove the following result:</p>
<div class="theorem">
<p><span id="thm:SmoothSymAlloc" class="theorem"><strong>Theorem 11.4  (Optimal allocation under monotone response with $K$ symmetric nodes) </strong></span>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a> and <a href="Diffusion.html#hyp:SmoothResponseHyp">11.6</a>, the optimal allocation of treatment across nodes is as follows:</p>
<p><span class="math display">\[\begin{align*}
  \frac{r^*_k}{n_k} &amp; =
\begin{cases}
\frac{\bar{R}}{N}\text{, }\forall k &amp; \text{ if }A&#39;&#39;&lt;0\\
\begin{cases}
  0 &amp; \text{ for a set of nodes } \mathcal{J} \text{ such that } \sum_{j\in\mathcal{J}}n_j=N-\bar{R},\\
  1 &amp; \text{ for a set of nodes } \mathcal{L} \text{ such that } \sum_{l\in\mathcal{L}}n_j=\bar{R},
  \end{cases}
&amp;  \text{ if } A&#39;&#39;&gt;0.\\
  \end{cases}
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-264" class="proof"><em>Proof</em>. </span>See Section <a href="proofs.html#proofSmoothSymAlloc">A.6.1</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-265" class="remark"><em>Remark</em>. </span>Theorem <a href="Diffusion.html#thm:SmoothSymAlloc">11.4</a> shows that the very simple intuition that we got in the two nodes problem transports well to more complex settings.
The optimal allocation depends on the sign of the second derivative.
When returns are decreasing, we treat each node symmetrically with the same share <span class="math inline">\(p^*=\frac{\bar{R}}{N}\)</span> of the treatment effort.
When returns are increasing, we treat a share <span class="math inline">\(\frac{\bar{R}}{N}\)</span> of the nodes with <span class="math inline">\(p^*=1\)</span> and a share <span class="math inline">\(1-\frac{\bar{R}}{N}\)</span> with <span class="math inline">\(p^*=0\)</span>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-266" class="remark"><em>Remark</em>. </span>There are several open questions on this research front.
To list but a few:</p>
<ul>
<li>Can we relax Assumption <a href="Diffusion.html#hyp:SmoothResponseHyp">11.6</a>?
For example, we know that <span class="math inline">\(A&#39;&#39;\)</span> has not constant sign when the error terms are normal in the model with two nodes, but we still have an optimal solution that has the same shape.</li>
<li>Can we relax Assumption <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a>?<br />
Especially, can we allow for responses that vary as a function of node characteristics and can we allow for treatment allocation based on unit characteristics?</li>
</ul>
</div>
</div>
<div id="using-two-step-clustered-randomized-controlled-trials-to-find-the-optimal-treatment-allocation" class="section level4 hasAnchor" number="11.2.1.3">
<h4><span class="header-section-number">11.2.1.3</span> Using two-step clustered randomized controlled trials to find the optimal treatment allocation<a href="Diffusion.html#using-two-step-clustered-randomized-controlled-trials-to-find-the-optimal-treatment-allocation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this section, we are going to see that conducting a two-step clustered randomized controlled trial is going to enable us to identify the optimal treatment allocation under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a> and <a href="Diffusion.html#hyp:SimpleAllocHyp">11.4</a>.
A two-step clustered randomized controlled trial works as follows:</p>
<ul>
<li>In a first step, we randomly select three sets of nodes, <span class="math inline">\(ST\)</span> and <span class="math inline">\(PT\)</span> and <span class="math inline">\(SC\)</span>, with <span class="math inline">\(K_{ST}+K_{PT}+K_{SC}=\tilde{K}\)</span> and <span class="math inline">\(\tilde{K}\leq K\)</span>.
When <span class="math inline">\(\tilde{K}&lt; K\)</span>, <span class="math inline">\(\tilde{K}\)</span> is a random subset of the <span class="math inline">\(K\)</span> nodes.
<ul>
<li>Nodes that belong to <span class="math inline">\(ST\)</span>, the set of nodes of size <span class="math inline">\(K_{ST}\)</span>, are called <strong>Super Treated</strong> nodes.
The proportion of treated units is <span class="math inline">\(p^R_c=1\)</span>, <span class="math inline">\(\forall c \in ST\)</span>.</li>
<li>Nodes that belong to <span class="math inline">\(PT\)</span>, the set of nodes of size <span class="math inline">\(K_{ST}\)</span>, are called <strong>Partially Treated</strong> nodes.
The proportion of treated units is <span class="math inline">\(p^R_c=\frac{\bar{R}}{N}\equiv p^*\)</span>, <span class="math inline">\(\forall c \in PT\)</span>.</li>
<li>Nodes that belong to <span class="math inline">\(SC\)</span>, the set of nodes of size <span class="math inline">\(K_{SC}\)</span>, are called <strong>Super Control</strong> nodes.
The proportion of treated units is <span class="math inline">\(p^R_c=0\)</span>, <span class="math inline">\(\forall c \in SC\)</span>.</li>
</ul></li>
<li>In a second step, we randomly select <span class="math inline">\(N^1_c=\frac{\bar{R}}{N}N_c\)</span> units to be treated (with <span class="math inline">\(R_i=1\)</span>) and <span class="math inline">\(N^0_c=N_c-N^1_c\)</span> to be in the control group (<span class="math inline">\(R_i=0\)</span>), <span class="math inline">\(\forall c \in PT\)</span>, with <span class="math inline">\(N_c\)</span> the number of units in node <span class="math inline">\(c\)</span>.</li>
</ul>
<p>When implementing the treatment, all units in <span class="math inline">\(ST\)</span> are treated, only <span class="math inline">\(N^1_c\)</span> units are treated in <span class="math inline">\(PT\)</span> and no unit is treated in <span class="math inline">\(SC\)</span>.</p>
<div class="remark">
<p><span id="unlabeled-div-267" class="remark"><em>Remark</em>. </span>Note that rigorously, we should have <span class="math inline">\(N_c^1=\lfloor\frac{\bar{R}}{N}N_c\rfloor\)</span>, but we disregard the complexities brought about by the fact that the number of units has to be an integer.</p>
</div>
<p>The one thing we need to identify now in order to apply Theorem <a href="Diffusion.html#thm:SmoothSymAlloc">11.4</a> is the sign of the second derivative of the <span class="math inline">\(A\)</span> function.
We are going to show that the sign of <span class="math inline">\(A&#39;&#39;\)</span> can be identified in a two-step clustered randomized controlled trial.
Before that, we are going to encode the validity of the two-step clustered randomized controlled trial:</p>
<div class="hypothesis">
<p><span id="hyp:independence2StepCluster" class="hypothesis"><strong>Hypothesis 11.7  (Independence in a two-step clustered design) </strong></span>We assume that the allocation of the proportion of neighbors treated and of the individual treatment level are independent of potential outcomes:</p>
<p><span class="math display">\[\begin{align*}
  (R_i,p^R_c)\Ind\left(\left\{Y_i^{0,p},Y_i^{1,p}\right\}_{p\in\left[0,1\right]}\right).
\end{align*}\]</span></p>
</div>
<p>We also assume that the randomized allocation does not interfere with how units respond to the treatment:</p>
<div class="hypothesis">
<p><span id="hyp:TwoStepClusterValidity" class="hypothesis"><strong>Hypothesis 11.8  (Validity of the 2-step clustered design) </strong></span>We assume that the randomized allocation of the program does not interfere with how potential outcomes are generated:</p>
<p><span class="math display">\[\begin{align*}
Y_i &amp; =
  \begin{cases}
    Y_i^{1,p} &amp; \text{ if } R_i=1 \text{ and } p^R_c=p\\
    Y_i^{0,p} &amp; \text{ if } R_i=0 \text{ and } p^R_c=p      
  \end{cases}
\end{align*}\]</span></p>
<p>with <span class="math inline">\(Y_i^{1,p}\)</span> and <span class="math inline">\(Y_i^{0,p}\)</span> the same potential outcomes as defined with a routine allocation of the treatment.</p>
</div>
<p>We are now equipped to prove the identification of <span class="math inline">\(A&#39;&#39;\)</span>:</p>
<div class="theorem">
<p><span id="thm:IdentSmoothSymAlloc" class="theorem"><strong>Theorem 11.5  (Identification of $A''$ in a 2-step clustered randomized controlled trial) </strong></span>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a>, <a href="Diffusion.html#hyp:SmoothResponseHyp">11.6</a>, <a href="Diffusion.html#hyp:independence2StepCluster">11.7</a>, and <a href="Diffusion.html#hyp:TwoStepClusterValidity">11.8</a>, the numerator of <span class="math inline">\(A&#39;&#39;\)</span> is identified by the following quantity:</p>
<p><span class="math display">\[\begin{align*}
  \text{sign}(A&#39;&#39;) &amp; = \text{sign}\left(\frac{\esp{Y_i|p^R_c=1}-\esp{Y_i|p^R_c=p^*}}{1-p^*}-\frac{\esp{Y_i|p^R_c=p^*}-\esp{Y_i|p^R_c=0}}{p^*}\right).
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-268" class="proof"><em>Proof</em>. </span>See Section <a href="proofs.html#proofIdentSmoothSymAlloc">A.6.2</a>.</p>
</div>
<p>One thing that is pretty amazing is that we can relate the sign of <span class="math inline">\(A&#39;&#39;\)</span> to the relative size of contagion and amplification effects:</p>
<div class="theorem">
<p><span id="thm:ContagionDiffusionSmoothSymAlloc" class="theorem"><strong>Theorem 11.6  (The sign of $A''$ depends on the relative size of contagion vs amplification effects) </strong></span>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a>, <a href="Diffusion.html#hyp:SmoothResponseHyp">11.6</a>, <a href="Diffusion.html#hyp:independence2StepCluster">11.7</a>, and <a href="Diffusion.html#hyp:TwoStepClusterValidity">11.8</a>, we have:</p>
<p><span class="math display">\[\begin{align*}
  \text{sign}(A&#39;&#39;) &amp; = \text{sign}\left(\frac{\esp{Y^{1,1}_i-Y^{1,p^*}}}{1-p^*} -\frac{\esp{Y^{0,p^*}_i-Y^{0,0}_i}}{p^*}\right),
\end{align*}\]</span>
where <span class="math inline">\(\esp{Y^{1,1}_i-Y^{1,p^*}}\)</span> measures the strength of amplification effects and <span class="math inline">\(\esp{Y^{0,p^*}_i-Y^{0,0}_i}\)</span> measures the strength of contagion effects.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-269" class="proof"><em>Proof</em>. </span>See Section <a href="proofs.html#proofContagionDiffusionSmoothSymAlloc">A.6.3</a>.</p>
</div>
<p>Theorem <a href="Diffusion.html#thm:ContagionDiffusionSmoothSymAlloc">11.6</a> suggests an alternative identification strategy for the sign of <span class="math inline">\(A&#39;&#39;\)</span>:</p>
<div class="theorem">
<p><span id="thm:IdentContagionDiffusionSmoothSymAlloc" class="theorem"><strong>Theorem 11.7  (Identifying the sign of $A''$ from the relative size of contagion and amplification effects) </strong></span>Under Assumptions <a href="Diffusion.html#hyp:PropSpecifyExpMap">11.2</a>, <a href="Diffusion.html#hyp:CoarseNetwork">11.3</a>, <a href="Diffusion.html#hyp:SymAllocHyp">11.5</a>, <a href="Diffusion.html#hyp:SmoothResponseHyp">11.6</a>, <a href="Diffusion.html#hyp:independence2StepCluster">11.7</a>, and <a href="Diffusion.html#hyp:TwoStepClusterValidity">11.8</a>, we have:</p>
<p><span class="math display">\[\begin{align*}
    \text{sign}(A&#39;&#39;) &amp; = \text{sign}\left(\frac{\esp{Y_i|R_i=1,p^R_c=1}-\esp{Y_i|R_i=1,p^R_c=p^*}}{1-p^*}\right.\\
                      &amp; \phantom{=\text{sign}\left(\right.}\left.-\frac{\esp{Y_i|R_i=0,p^R_c=p^*}-\esp{Y_i|R_i=0,p^R_c=0}}{p^*}\right)
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-270" class="proof"><em>Proof</em>. </span>The proof is immediate using Theorem <a href="Diffusion.html#thm:ContagionDiffusionSmoothSymAlloc">11.6</a> and Assumptions <a href="Diffusion.html#hyp:independence2StepCluster">11.7</a> and <a href="Diffusion.html#hyp:TwoStepClusterValidity">11.8</a>.</p>
</div>
<p>Thanks to Theorems <a href="Diffusion.html#thm:IdentSmoothSymAlloc">11.5</a> and <a href="Diffusion.html#thm:IdentContagionDiffusionSmoothSymAlloc">11.7</a>, we therefore have two ways to estimate the sign of <span class="math inline">\(A&#39;&#39;\)</span>: either by comparing the overall changes in expected outcomes when moving from <span class="math inline">\(0\)</span> to <span class="math inline">\(p^*\)</span> and from <span class="math inline">\(p^*\)</span> to <span class="math inline">\(1\)</span>, or by comparing the relative size of amplification and contagion effects.
As a consequence, we can form two with/without estimators of <span class="math inline">\(A&#39;&#39;\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  \hat{A}&#39;&#39;_{All}(\frac{1}{2}) &amp; = \frac{\frac{\sum_{i\in\mathcal{I}_{ST}}Y_i}{N_{ST}}-\frac{\sum_{i\in\mathcal{I}_{PT}}Y_i}{N_{PT}}}{1-p^*}-
                         \frac{\frac{\sum_{i\in\mathcal{I}_{SP}}Y_i}{N_{SP}}-\frac{\sum_{i\in\mathcal{I}_{SC}}Y_i}{N_{SC}}}{p^*}\\
  \hat{A}&#39;&#39;_{Diff}(\frac{1}{2}) &amp; = \frac{\frac{\sum_{i\in\mathcal{I}_{ST}}Y_i}{N_{ST}}-\frac{\sum_{i\in\mathcal{I}^1_{PT}}Y_i}{N^1_{PT}}}{1-p^*}-
                         \frac{\frac{\sum_{i\in\mathcal{I}^0_{SP}}Y_i}{N^0_{SP}}-\frac{\sum_{i\in\mathcal{I}_{SC}}Y_i}{N_{SC}}}{p^*},
\end{align*}\]</span></p>
<p>with <span class="math inline">\(\mathcal{I}_{T}\)</span>, <span class="math inline">\(T\in\left\{ST,SC,PT\right\}\)</span>, the set of units <span class="math inline">\(i\)</span> that belong to a cluster of type <span class="math inline">\(T\)</span>, <span class="math inline">\(\mathcal{I}^d_{PT}\)</span>, <span class="math inline">\(d\in\left\{0,1\right\}\)</span>, the set of units that belong to a cluster of type <span class="math inline">\(PT\)</span> and have <span class="math inline">\(R_i=d\)</span>, <span class="math inline">\(N_{T}\)</span>, <span class="math inline">\(T\in\left\{ST,SC,PT\right\}\)</span>, the number of units <span class="math inline">\(i\)</span> belonging to clusters of type <span class="math inline">\(T\)</span>, and <span class="math inline">\(\mathcal{N}^d_{PT}\)</span>, <span class="math inline">\(d\in\left\{0,1\right\}\)</span>, the number of units that belong to clusters of type <span class="math inline">\(PT\)</span> and have <span class="math inline">\(R_i=d\)</span>.
Following usual arguments, these estimators are both unbiased and consistent (as the number of clusters goes to infinity) for <span class="math inline">\(A&#39;&#39;(\frac{1}{2})\)</span>.
Their components can both be estimated separately by using OLS with a linear model on separate subsamples.
The covariance of each separate with/without comparison can be estimated by estimating both components jointly, for example by estimating the following model by OLS:</p>
<p><span class="math display">\[\begin{align*}
  Y_i &amp; = \alpha^{All} + \beta^{All}_{PT}\uns{i\in\mathcal{I}_{PT}} + \beta^{All}_{ST}\uns{i\in\mathcal{I}_{ST}} + \epsilon_i^{All}\\
  Y_i &amp; = \alpha^{Diff} + \alpha^{Diff}_{1}\uns{R_i=1} + \beta^{Diff}_{0}\uns{i\in\mathcal{I}^0_{PT}}+ \beta^{Diff}_{1}\uns{i\in\mathcal{I}_{ST}} + \epsilon_i^{All}.
\end{align*}\]</span></p>
<p>With these parameter estimates, we have:</p>
<p><span class="math display">\[\begin{align*}
  \hat{A}&#39;&#39;_{All}(\frac{1}{2}) &amp; = \frac{\hat\beta^{All}_{ST}}{1-p^*}-\frac{\hat\beta^{All}_{SP}}{p^*}\\
  \hat{A}&#39;&#39;_{Diff}(\frac{1}{2}) &amp; = \frac{\hat\beta^{Diff}_{1}}{1-p^*}-\frac{\hat\beta^{Diff}_{0}}{p^*}.
\end{align*}\]</span></p>
<p>To estimate the precision of each of the parameters, one has to use standard errors clustered at the cluster level.
To obtain the precision of <span class="math inline">\(\hat{A}&#39;&#39;(\frac{1}{2})\)</span>, one can simply use the Delta Method.</p>
<div class="remark">
<p><span id="unlabeled-div-271" class="remark"><em>Remark</em>. </span>Note that in practice, the actual proportion of treated in each cluster of type <span class="math inline">\(PT\)</span> is going to differ from <span class="math inline">\(p^*\)</span>.
Does this affect consistency and unbiasedness of both estimators?
Could we estimate <span class="math inline">\(\hat p^*\)</span> and try to use it to get access to a wider share of the <span class="math inline">\(A\)</span> function, or at least to an average effect?
See Davideâs discussion of that issue.</p>
</div>
</div>
</div>
<div id="identifying-optimal-treatment-levels" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Identifying optimal treatment levels<a href="Diffusion.html#identifying-optimal-treatment-levels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous section, we discussed ways of identifying diffusion effects, and we focused on the task of finding the optimal treatment allocation when total treatment capacity was fixed to a limited number of treatments.
In that scenario, what turned out to be super important was the shape of the returns to treatment effort (convex or concave), and it turned out to be related to whether contagion or amplification effects dominated.
Though this scenario of constant treatment effort sometimes happens in real life, in other situations, policymakers might want to decide whether to increase or decrease their treatment effort, and to find the optimal treatment level, taking into account diffusion effects.
This is the goal of this section, which is fully based on Davide <a href="http://arxiv.org/abs/2011.08174">Viviano (2023)</a>âs recent working paper on the topic.</p>
<div id="setup-and-assumptions" class="section level4 hasAnchor" number="11.2.2.1">
<h4><span class="header-section-number">11.2.2.1</span> Setup and assumptions<a href="Diffusion.html#setup-and-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Davide considers a setting with <span class="math inline">\(K\)</span> clusters of equal size <span class="math inline">\(N\)</span>.
Researchers sample a proportion <span class="math inline">\(\lambda\in\left]0,1\right]\)</span> of the <span class="math inline">\(N\)</span> units in each cluster at each period <span class="math inline">\(t\)</span> and they have access to the following information for the sampled observations in each cluster: <span class="math inline">\(\left(Y^{(k)}_{i,t},X^{(k)}_{i},D^{(k)}_{i,t}\right)_{i=1}^n\)</span> where <span class="math inline">\(n=\lambda N\)</span> and <span class="math inline">\(X^{(k)}_{i}\)</span> are baseline characteristics.</p>
<p>Davide describes the latent process that takes place between units in each cluster.
Units are spaced on a latent space, and each unit can interact with at most the <span class="math inline">\(\sqrt{\gamma_N}\)</span> closest units.
Let <span class="math inline">\(\uns{i_k\leftrigharrow j_{k}}\)</span> denote whether or not <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> can be connected in the resulting the latent network.
Let <span class="math inline">\(\mathcal{I}_k\)</span> be the matrix of these potential connections in cluster <span class="math inline">\(k\)</span>.
Davideâs first assumption is:</p>
<div class="hypothesis">
<p><span id="hyp:iidConnect" class="hypothesis"><strong>Hypothesis 11.9  (Network) </strong></span>Actual connections are generated as follows:</p>
<p><span class="math display">\[\begin{align*}
    A_{i,j}^{(k)} &amp; = l(X^{(k)}_{i},X^{(k)}_{j},U^{(k)}_{i},U^{(k)}_{j})\uns{i_k\leftrigharrow j_{k}},
  \end{align*}\]</span></p>
<p>for some function <span class="math inline">\(l\)</span> and unobservables <span class="math inline">\(U^{(k)}_{i}\)</span> with <span class="math inline">\(\left(X^{(k)}_{i},U^{(k)}_{i}\right)|\mathcal{I}_k\sim F_{U|X}F_{X}\)</span> and with <span class="math inline">\(\sum_{j=1}^N\uns{i_k\leftrigharrow j_{k}}=\sqrt{\gamma_N}\)</span>.</p>
</div>
<p>The second assumption Davide makes is on how potential outcomes are generated:</p>
<div class="hypothesis">
<p><span id="hyp:PoNetwork" class="hypothesis"><strong>Hypothesis 11.10  (Potential outcomes) </strong></span>Potential outcomes are generated as follows:</p>
<p><span class="math display">\[\begin{align*}
    Y^{(k)}_{i,t}(\mathbf{D}_1^{(k)},\dots,\mathbf{D}_t^{(k)}) &amp; = r(D_{i,t}^{(k)},\mathbf{D}_{\mathcal{N}_i^{k},t}^{(k)},X^{(k)}_{i},X^{(k)}_{\mathcal{N}_i^{k},t},U^{(k)}_{i},U^{(k)}_{\mathcal{N}_i^{k},t},A^{(k)}_{i,.},|\mathcal{N}_i^{k}|,\nu^{(k)}_{i,t})+\tau_k+\alpha_t,
  \end{align*}\]</span></p>
<p>for some function <span class="math inline">\(r\)</span> which attains the same value for any permutations of the entries of <span class="math inline">\(A^{(k)}_{i,.}\)</span>, with <span class="math inline">\(A^{(k)}_{i,.}\)</span> the vector of connections of <span class="math inline">\(i\)</span> in , and unobservables <span class="math inline">\(\nu^{(k)}_{i,t}|\left(X^{(k)}_{i},U^{(k)}_{i}\right)\sim F_{\nu}\)</span>, and where <span class="math inline">\(\mathcal{N}_i^{k}=\left\{j:A^{(k)}_{i,j}&gt;0\right\}\)</span>.</p>
</div>
<p>The main assumption that Davide makes on how units interact in the network</p>
</div>
</div>
</div>
<div id="diffusion-effects-with-detailed-networks" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Diffusion effects with detailed networks<a href="Diffusion.html#diffusion-effects-with-detailed-networks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Leung</p>
</div>
<div id="nonparametric-test-for-the-existence-of-diffusion-effects-based-on-randomization-inference" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Nonparametric test for the existence of diffusion effects based on randomization inference<a href="Diffusion.html#nonparametric-test-for-the-existence-of-diffusion-effects-based-on-randomization-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Athey and Imbens</p>
</div>
<div id="diffusion-effects-with-did" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Diffusion effects with DID<a href="Diffusion.html#diffusion-effects-with-did" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sylvainâs approach vs Kyleâs approach</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="LaLonde.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Distribution.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/chabefer/STCI/blob/master/10_Diffusion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["STCI.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 1
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
