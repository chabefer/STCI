[["index.html", "Statistical Tools for Causal Inference Introduction", " Statistical Tools for Causal Inference Sylvain Chabé-Ferret 2023-01-17 Introduction Tools of causal inference are the basic statistical building block behind most scientific results. It is thus extremely useful to have an open source collectively aggreed upon resource presenting and assessing them, as well as listing the current unresolved issues. The content of this book covers the basic theoretical knowledge and technical skills required for implementing staistical methods of causal inference. This means: Understanding of the basic language to encode causality, Knowledge of the fundamental problems of inference and the biases of intuitive estimators, Understanding of how econometric methods recover treatment effects, Ability to compute these estimators along with an estimate of their precision using the statistical software R. This book is geared for teaching causal inference to graduate students that want to apply statistical tools of causal inference. The demonstration of theoretical results are provided, but the final goal is not to have students reproduce them, but mostly to enable them to grasp a better understanding of the fundations for the tools that they will be using. The focus is on understanding the issues and solutions more than understanding the maths that are behind, even though the maths are there and are used to convey the notions rigorously. All the notions and estimators are introduced using a numerical example and simulations, so that each notion is illustrated and appears more intuitive to the students. The second version of this book will contain examples using real applications. The third version will contain exercises. This book is written in Rmarkdown using the bookdown package. It is available both as a web-book and as a pdf book. This book is a collaborative effort that is part of the Social Science Knowledge Accumulation Initiative (SKY). The code behind this book is publically available on GitHub and you can propose corrections and updates. How to make contributions to this book is explained on the SKY website. Do not hesitate to make suggestions, modifications and extensions. This way this book will grow and become the living open source collaborative reference for methodological work that it could be. "],["introduction-the-two-fundamental-problems-of-inference.html", "Introduction: the Two Fundamental Problems of Inference", " Introduction: the Two Fundamental Problems of Inference When trying to estimate the effect of a program on an outcome, we face two very important and difficult problems: the Fundamental Problem of Causal Inference (FPCI) and the Fundamental Problem of Statistical Inference (FPSI). In its most basic form, the FPCI states that our causal parameter of interest (\\(TT\\), short for Treatment on the Treated, that we will define shortly) is fundamentally unobservable, even when the sample size is infinite. The main reason for that is that one component of \\(TT\\), the outcome of the treated had they not received the program, remains unobservable. We call this outcome a counterfactual outcome. The FPCI is a very dispiriting result, and is actually the basis for all of the statistical methods of causal inference. All of these methods try to find ways to estimate the counterfactual by using observable quantities that hopefully approximate it as well as possible. Most people, including us but also policymakers, generally rely on intuitive quantities in order to generate the counterfactual (the individuals without the program or the individuals before the program was implemented). Unfortunately, these approximations are generally very crude, and the resulting estimators of \\(TT\\) are generally biased, sometimes severely. The Fundamental Problem of Statistical Inference (FPSI) states that, even if we have an estimator \\(E\\) that identifies \\(TT\\) in the population, we cannot observe \\(E\\) because we only have access to a finite sample of the population. The only thing that we can form from the sample is a sample equivalent \\(\\hat{E}\\) to the population quantity \\(E\\), and \\(\\hat{E}\\neq E\\). Why is \\(\\hat{E}\\neq E\\)? Because a finite sample is never perfectly representative of the population. What can we do to deal with the FPSI? I am going to argue that there are mainly two things that we might want to do: estimating the extent of sampling noise and decreasing sampling noise. "],["FPCI.html", "Chapter 1 Fundamental Problem of Causal Inference 1.1 Rubin Causal Model 1.2 Treatment effects 1.3 Fundamental problem of causal inference 1.4 Intuitive estimators, confounding factors and selection bias", " Chapter 1 Fundamental Problem of Causal Inference In order to state the FPCI, we are going to describe the basic language to encode causality set up by Rubin, and named Rubin Causal Model (RCM). RCM being about partly observed random variables, it is hard to make these notions concrete with real data. That’s why we are going to use simulations from a simple model in order to make it clear how these variables are generated. The second virtue of this model is that it is going to make it clear the source of selection into the treatment. This is going to be useful when understanding biases of intuitive comparisons, but also to discuss the methods of causal inference. A third virtue of this approach is that it makes clear the connexion between the treatment effects literature and models. Finally, a fourth reason that it is useful is that it is going to give us a source of sampling variation that we are going to use to visualize and explore the properties of our estimators. I use \\(X_i\\) to denote random variable \\(X\\) all along the notes. I assume that we have access to a sample of \\(N\\) observations indexed by \\(i\\in\\left\\{1,\\dots,N\\right\\}\\). ’‘\\(i\\)’’ will denote the basic sampling units when we are in a sample, and a basic element of the probability space when we are in populations. Introducing rigorous measure-theoretic notations for the population is feasible but is not necessary for comprehension. When the sample size is infinite, we say that we have a population. A population is a very useful fiction for two reasons. First, in a population, there is no sampling noise: we observe an infinite amount of observations, and our estimators are infinitely precise. This is useful to study phenomena independently of sampling noise. For example, it is in general easier to prove that an estimator is equal to \\(TT\\) under some conditions in the population. Second, we are most of the time much more interested in estimating the values of parameters in the population rather than in the sample. The population parameter, independent of sampling noise, gives a much better idea of the causal parameter for the population of interest than the parameter in the sample. In general, the estimator for both quantities will be the same, but the estimators for the effetc of sampling noise on these estimators will differ. Sampling noise for the population parameter will generally be larger, since it is affected by another source of variability (sample choice). 1.1 Rubin Causal Model RCM is made of three distinct building blocks: a treatment allocation rule, that decides who receives the treatment; potential outcomes, that measure how each individual reacts to the treatment; the switching equation that relates potential outcomes to observed outcomes through the allocation rule. 1.1.1 Treatment allocation rule The first building block of RCM is the treatment allocation rule. Throughout this class, we are going to be interested in inferring the causal effect of only one treatment with respect to a control condition. Extensions to multi-valued treatments are in general self-explanatory. In RCM, treatment allocation is captured by the variable \\(D_i\\). \\(D_i=1\\) if unit \\(i\\) receives the treatment and \\(D_i=0\\) if unit \\(i\\) does not receive the treatment and thus remains in the control condition. The treatment allocation rule is critical for several reasons. First, because it switches the treatment on or off for each unit, it is going to be at the source of the FPCI. Second, the specific properties of the treatment allocatoin rule are going to matter for the feasibility and bias of the various econometric methods that we are going to study. Let’s take a few examples of allocation rules. These allocation rules are just examples. They do not cover the space of all possible allocation rules. They are especially useful as concrete devices to understand the sources of biases and the nature of the allocation rule. In reality, there exists even more complex allocation rules (awareness, eligibility, application, acceptance, active participation). Awareness seems especially important for program participation and has only been tackled recently by economists. First, some notation. Let’s imagine a treatment that is given to individuals. Whether each individual receives the treatment partly depends on the level of her outcome before receiving the treatment. Let’s denote this variable \\(Y^B_i\\), with \\(B\\) standing for “Before”. It can be the health status assessed by a professional before deciding to give a drug to a patient. It can be the poverty level of a household used to assess its eligibilty to a cash transfer program. 1.1.1.1 Sharp cutoff rule The sharp cutoff rule means that everyone below some threshold \\(\\bar{Y}\\) is going to receive the treatment. Everyone whose outcome before the treatment lies above \\(\\bar{Y}\\) does not receive the treatment. Such rules can be found in reality in a lot of situations. They might be generated by administrative rules. One very simple way to model this rule is as follows: \\[\\begin{align}\\label{eq:cutoff} D_i &amp; = \\uns{Y_i^B\\leq\\bar{Y}}, \\end{align}\\] where \\(\\uns{A}\\) is the indicator function, taking value \\(1\\) when \\(A\\) is true and \\(0\\) otherwise. Example 1.1 (Sharp cutoff rule) Imagine that \\(Y_i^B=\\exp(y_i^B)\\), with \\(y_i^B=\\mu_i+U_i^B\\), \\(\\mu_i\\sim\\mathcal{N}(\\bar{\\mu},\\sigma^2_{\\mu})\\) and \\(U_i^B\\sim\\mathcal{N}(0,\\sigma^2_{U})\\). Now, let’s choose some values for these parameters so that we can generate a sample of individuals and allocate the treatment among them. I’m going to switch to R for that. param &lt;- c(8,.5,.28,1500) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;) param ## barmu sigma2mu sigma2U barY ## 8.00 0.50 0.28 1500.00 Now, I have choosen values for the parameters in my model. For example, \\(\\bar{\\mu}=\\) 8 and \\(\\bar{Y}=\\) 1500. What remains to be done is to generate \\(Y_i^B\\) and then \\(D_i\\). For this, I have to choose a sample size (\\(N=1000\\)) and then generate the shocks from a normal. # for reproducibility, I choose a seed that will give me the same random sample each time I run the program set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) Let’s now build a histogram of the data that we have just generated. # building histogram of yB with cutoff point at ybar # Number of steps Nsteps.1 &lt;- 15 #step width step.1 &lt;- (log(param[&quot;barY&quot;])-min(yB[Ds==1]))/Nsteps.1 Nsteps.0 &lt;- (-log(param[&quot;barY&quot;])+max(yB[Ds==0]))/step.1 breaks &lt;- cumsum(c(min(yB[Ds==1]),c(rep(step.1,Nsteps.1+Nsteps.0+1)))) hist(yB,breaks=breaks,main=&quot;&quot;) abline(v=log(param[&quot;barY&quot;]),col=&quot;red&quot;) Figure 1.1: Histogram of \\(y_B\\) You can see on Figure 1.1 a histogram of \\(y_i^B\\) with the red line indicating the cutoff point: \\(\\bar{y}=\\ln(\\bar{Y})=\\) 7.3. All the observations below the red line are treated according to the sharp rule while all the one located above are not. In order to see how many observations eventually receive the treatment with this allocation rule, let’s build a contingency table. table.D.sharp &lt;- as.matrix(table(Ds)) knitr::kable(table.D.sharp,caption=&#39;Treatment allocation with sharp cutoff rule&#39;,booktabs=TRUE) Table 1.1: Treatment allocation with sharp cutoff rule 0 771 1 229 We can see on Table 1.1 that there are 229 treated observations. 1.1.1.2 Fuzzy cutoff rule This rule is less sharp than the sharp cutoff rule. Here, other criteria than \\(Y_i^B\\) enter into the decision to allocate the treatment. The doctor might measure the health status of a patient following official guidelines, but he might also measure other factors that will also influence his decision of giving the drug to the patient. The officials administering a program might measure the official income level of a household, but they might also consider other features of the household situation when deciding to enroll the household into the program or not. If these additional criteria are unobserved to the econometrician, then we have the fuzzy cutoff rule. A very simple way to model this rule is as follows: \\[\\begin{align}\\label{eq:fuzzcutoff} D_i &amp; = \\uns{Y_i^B+V_i\\leq\\bar{Y}}, \\end{align}\\] where \\(V_i\\) is a random variable unobserved to the econometrician and standing for the other influences that might drive the allocation of the treatment. \\(V_i\\) is distributed according to a, for the moment, unspecified cumulative distribution function \\(F_V\\). When \\(V_i\\) is degenerate ( it has only one point of support: it is a constant), the fuzzy cutoff rule becomes the sharp cutoff rule. 1.1.1.3 Eligibility \\(+\\) self-selection rule It is also possible that households, once they have been made eligible to the treatment, can decide whether they want to receive it or not. A patient might be able to refuse the drug that the doctor suggests she should take. A household might refuse to participate in a cash transfer program to which it has been made eligible. Not all programs have this feature, but most of them have some room for decisions by the agents themselves of whether they want to receive the treatment or not. One simple way to model this rule is as follows: \\[\\begin{align}\\label{eq:eligself} D_i &amp; = \\uns{D^*_i\\geq0}E_i, \\end{align}\\] where \\(D^*_i\\) is individual \\(i\\)’s valuation of the treatment and \\(E_i\\) is whether or not she is deemed eligible for the treatment. \\(E_i\\) might be choosen according to the sharp cutoff rule of to the fuzzy cutoff rule, or to any other eligibility rule. We will be more explicit about \\(D_i^*\\) in what follows. SIMULATIONS ARE MISSING FOR THESE LAST TWO RULES 1.1.2 Potential outcomes The second main building block of RCM are potential outcomes. Let’s say that we are interested in the effect of a treatment on an outcome \\(Y\\). Each unit \\(i\\) can thus be in two potential states: treated or non treated. Before the allocation of the treatment is decided, both of these states are feasible for each unit. Definition 1.1 (Potential outcomes) For each unit \\(i\\), we define two potential outcomes: \\(Y_i^1\\): the outcome that unit \\(i\\) is going to have if it receives the treatment, \\(Y_i^0\\): the outcome that unit \\(i\\) is going to have if it does not receive the treatment. Example 1.2 Let’s choose functional forms for our potential outcomes. For simplicity, all lower case letters will denote log outcomes. \\(y_i^0=\\mu_i+\\delta+U_i^0\\), with \\(\\delta\\) a time shock common to all the observations and \\(U_i^0=\\rho U_i^B+\\epsilon_i\\), with \\(|\\rho|&lt;1\\). In the absence of the treatment, part of the shocks \\(U_i^B\\) that the individuals experienced in the previous period persist, while some part vanish. \\(y_i^1=y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i\\). In order to generate the potential outcomes, one has to define the laws for the shocks and to choose parameter values. Let’s assume that \\(\\epsilon_i\\sim\\mathcal{N}(0,\\sigma^2_{\\epsilon})\\) and \\(\\eta_i\\sim\\mathcal{N}(0,\\sigma^2_{\\eta})\\). Now let’s choose some parameter values: l &lt;- length(param) param &lt;- c(param,0.9,0.01,0.05,0.05,0.05,0.1) names(param)[(l+1):length(param)] &lt;- c(&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) param ## barmu sigma2mu sigma2U barY rho ## 8.00 0.50 0.28 1500.00 0.90 ## theta sigma2epsilon sigma2eta delta baralpha ## 0.01 0.05 0.05 0.05 0.10 We can finally generate the potential outcomes; epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) Now, I would like to visualize my potential outcomes: plot(y0,y1) Figure 1.2: Potential outcomes You can see on the resulting Figure 1.2 that both potential outcomes are positively correlated. Those with a large potential outcome when untreated (e.g. in good health without the treatment) also have a positive health with the treatment. It is also true that individuals with bad health in the absence of the treatment also have bad health with the treatment. 1.1.3 Switching equation The last building block of RCM is the switching equation. It links the observed outcome to the potential outcomes through the allocation rule: \\[\\begin{align} \\tag{1.1} Y_i &amp; = \\begin{cases} Y_i^1 &amp; \\text{if } D_i=1\\\\ Y_i^0 &amp; \\text{if } D_i=0 \\end{cases} \\\\ &amp; = Y_i^1D_i + Y_i^0(1-D_i) \\nonumber \\end{align}\\] Example 1.3 In order to generate observed outcomes in our numerical example, we simply have to enforce the switching equation: y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) What the switching equation (1.1) means is that, for each individual \\(i\\), we get to observe only one of the two potential outcomes. When individual \\(i\\) belongs to the treatment group (i.e. \\(D_i=1\\)), we get to observe \\(Y_i^1\\). When individual \\(i\\) belongs to the control group (i.e. \\(D_i=0\\)), we get to observe \\(Y_i^0\\). Because the same individual cannot be at the same time in both groups, we can NEVER see both potential outcomes for the same individual at the same time. For each of the individuals, one of the two potential outcomes is unobserved. We say that it is a counterfactual. A counterfactual quantity is a quantity that is, according to Hume’s definition, contrary to the observed facts. A counterfactual cannot be observed, but it can be conceived by an effort of reason: it is the consequence of what would have happened had some action not been taken. Remark. One very nice way of visualising the switching equation has been proposed by Jerzy Neyman in a 1923 prescient paper. Neyman proposes to imagine two urns, each one filled with \\(N\\) balls. One urn is the treatment urn and contains balls with the id of the unit and the value of its potential outcome \\(Y_i^1\\). The other urn is the control urn, and it contains balls with the value of the potential outcome \\(Y_i^0\\) for each unit \\(i\\). Following the allocation rule \\(D_i\\), we decide whether unit \\(i\\) is in the treatment or control group. When unit \\(i\\) is in the treatment group, we take the corresponding ball from the first urn and observe the potential outcome on it. But, at the same time, the urns are connected so that the corresponding ball with the potential outcome of unit \\(i\\) in the control urn disappears as soon as we draw ball \\(i\\) from the treatment urn. The switching equation works a lot like Schrodinger’s cat paradox. Schrodinger’s cat is placed in a sealed box and receives a dose of poison when an atom emits a radiation. As long as the box is sealed, there is no way we can know whether the cat is dead or alive. When we open the box, we observe either a dead cat or a living cat, but we cannot observe the cat both alive and dead at the same time. The switching equation is like opening the box, it collapses the observed outcome into one of the two potential ones. Example 1.4 One way to visualize the inner workings of the switching equation is to plot the potential outcomes along with the criteria driving the allocation rule. In our simple example, it simply amounts to plotting observed (\\(y_i\\)) and potential outcomes (\\(y_i^1\\) and \\(y_i^0\\)) along \\(y_i^B\\). plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y1[Ds==1],pch=3) points(yB[Ds==0],y1[Ds==0],pch=3,col=&#39;red&#39;) points(yB[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) test &lt;- 5.8 i.test &lt;- which(abs(yB-test)==min(abs(yB-test))) points(yB[abs(yB-test)==min(abs(yB-test))],y1[abs(yB-test)==min(abs(yB-test))],col=&#39;green&#39;,pch=3) points(yB[abs(yB-test)==min(abs(yB-test))],y0[abs(yB-test)==min(abs(yB-test))],col=&#39;green&#39;) abline(v=log(param[&quot;barY&quot;]),col=&quot;red&quot;) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;y0|D=1&#39;,&#39;y1|D=0&#39;,paste(&#39;y0&#39;,i.test,sep=&#39;&#39;),paste(&#39;y1&#39;,i.test,sep=&#39;&#39;)),pch=c(1,3,1,3,1,3),col=c(&#39;black&#39;,&#39;black&#39;,&#39;red&#39;,&#39;red&#39;,&#39;green&#39;,&#39;green&#39;),ncol=3) Figure 1.3: Potential outcomes plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y1[Ds==1],pch=3) legend(5,11,c(&#39;y|D=0&#39;,&#39;y|D=1&#39;),pch=c(1,3)) abline(v=log(param[&quot;barY&quot;]),col=&quot;red&quot;) Figure 1.4: Observed outcomes Figure 1.3 plots the observed outcomes \\(y_i\\) along with the unobserved potential outcomes. Figure 1.3 shows that each individual in the sample is endowed with two potential outcomes, represented by a circle and a cross. Figure 1.4 plots the observed outcomes \\(y_i\\) that results from applying the switching equation. Only one of the two potential outcomes is observed (the cross for the treated group and the circle for the untreated group) and the other is not. The observed sample in Figure 1.4 only shows observed outcomes, and is thus silent on the values of the missing potential outcomes. 1.2 Treatment effects RCM enables the definition of causal effects at the individual level. In practice though, we generally focus on a summary measure: the effect of the treatment on the treated. 1.2.1 Individual level treatment effects Potential outcomes enable us to define the central notion of causal inference: the causal effect, also labelled the treatment effect, which is the difference between the two potential outcomes. Definition 1.2 (Individual level treatment effect) For each unit \\(i\\), the causal effect of the treatment on outcome \\(Y\\) is: \\(\\Delta^Y_i=Y_i^1-Y_i^0\\). Example 1.5 The individual level causal effect in log terms is: \\(\\Delta^y_i=\\alpha_i=\\bar{\\alpha}+\\theta\\mu_i+\\eta_i\\). The effect is the sum of a part common to all individuals, a part correlated with \\(\\mu_i\\): the treatment might have a larger or a smaller effect depending on the unobserved permanent ability or health status of individuals, and a random shock. It is possible to make the effect of the treatment to depend on \\(U_i^B\\) also, but it would complicate the model. In Figure 1.3, the individual level treatment effects are the differences between each cross and its corresponding circle. For example, for observation 264, the two potential outcomes appear in green in Figure 1.3. The effect of the treatment on unit 264 is equal to: \\[ \\Delta^y_{264}=y^1_{264}-y^0_{264}=6.98-6.64=0.34. \\] Since observation 264 belongs to the treatment group, we can only observe the potential outcome in the presence of the treatment, \\(y^1_{264}\\). RCM allows for heterogeneity of treatment effects. The treatment has a large effect on some units and a much smaller effect on other units. We can even have some units that benefit from the treatment and some units that are harmed by the treatment. The individual level effect of the treatment is itself a random variable (and not a fixed parameter). It has a distribution, \\(F_{\\Delta^Y}\\). Heterogeneity of treatment effects seems very natural: the treatment might interact with individuals’ different backgrounds. The effect of a drug might depend on the genetic background of an individual. An education program might only work for children that already have sufficient non-cognitive skills, and thus might depend in turn on family background. An environmental regulation or a behavioral intervention might only trigger reactions by already environmentally aware individuals. A CCT might have a larger effect when indiviuals are credit-constrained or face shocks. Example 1.6 In our numerical example, the distribution of \\(\\Delta^y_i=\\alpha_i\\) is a normal: \\(\\alpha_i\\sim\\mathcal{N}(\\bar{\\alpha}+\\theta\\bar{\\mu},\\theta^2\\sigma^2_{\\mu}+\\sigma^2_{\\eta})\\). We would like to visualize treatment effect heterogeneity. For that, we can build a histogram of the individual level causal effect. On top of the histogram, we can also draw the theoretical distribution of the treatment effect: a normal with mean 0.18 and variance 0.05. hist(alpha,main=&quot;&quot;,prob=TRUE) curve(dnorm(x, mean=(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]), sd=sqrt(param[&quot;theta&quot;]^2*param[&quot;sigma2mu&quot;]+param[&quot;sigma2eta&quot;])), add=TRUE,col=&#39;red&#39;) Figure 1.5: Histogram of \\(\\Delta^y\\) The first thing that we can see on Figure 1.5 is that the theoretical and the empirical distributions nicely align with each other. We also see that the majority of the observations lies to the right of zero: most people experience a positive effect of the treatment. But there are some individuals that do not benefit from the treatment: the effect of the treatment on them is negative. 1.2.2 Average treatment effect on the treated We do not generally estimate individual-level treatment effects. We generally look for summary statistics of the effect of the treatment. By far the most widely reported causal parameter is the Treatment on the Treated parameter (TT). It can be defined in the sample at hand or in the population. Definition 1.3 (Average and expected treatment effects on the treated) The Treatment on the Treated parameters for outcome \\(Y\\) are: The average Treatment effect on the Treated in the sample: \\[\\begin{align*} \\Delta^Y_{TT_s} &amp; = \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^N(Y_i^1-Y_i^0)D_i, \\end{align*}\\] The expected Treatment effect on the Treated in the population: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i^1-Y_i^0|D_i=1}. \\end{align*}\\] The TT parameters measure the average effect of the treatment on those who actually take it, either in the sample at hand or in the popluation. It is generally considered to be the most policy-relevant parameter since it measures the effect of the treatment as it has actually been allocated. For example, the expected causal effect on the overall population is only relevant if policymakers are considering implementing the treatment even on those who have not been selected to receive it. For a drug or an anti-poverty program, it would mean giving the treatment to healthy or rich people, which would make little sense. TT does not say anything about how the effect of the treatment is distributed in the population or in the sample. TT does not account for the heterogneity of treatment effects. In Lecture 7, we will look at other parameters of interest that look more closely into how the effect of the treatment is distributed. Example 1.7 The value of TT in our sample is: \\[ \\Delta^y_{TT_s}=0.168. \\] Computing the population value of \\(TT\\) is slightly more involved: we have to use the formula for the conditional expectation of a censored bivariate normal random variable: \\[\\begin{align*} \\Delta^y_{TT} &amp; = \\esp{\\alpha_i|D_i=1}\\\\ &amp; = \\bar{\\alpha}+\\theta\\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\bar{\\alpha}+\\theta\\left(\\bar{\\mu} - \\frac{\\sigma^2_{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right)\\\\ &amp; = \\bar{\\alpha}+\\theta\\bar{\\mu}-\\theta\\left(\\frac{\\sigma^2_{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right), \\end{align*}\\] where \\(\\phi\\) and \\(\\Phi\\) are respectively the density and the cumulative distribution functions of the standard normal. The second equality follows from the definition of \\(\\alpha_i\\) and \\(D_i\\) and from the fact that \\(\\eta_i\\) is independent from \\(\\mu_i\\) and \\(U_i^B\\). The third equality comes from the formula for the expectation of a censored bivariate normal random variable. In order to compute the population value of TT easily for different sets of parameter values, let’s write a function in R: delta.y.tt &lt;- function(param){return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;] -param[&quot;theta&quot;]*((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]) *pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))))} The population value of TT computed using this function is: \\(\\Delta^y_{TT}=\\) 0.172. We can see that the values of TT in the sample and in the population differ slightly. This is because of sampling noise: the units in the sample are not perfectly representative of the units in the population. 1.3 Fundamental problem of causal inference At least in this lecture, causal inference is about trying to infer TT, either in the sample or in the population. The FPCI states that it is impossible to directly observe TT because one part of it remains fundamentally unobserved. Theorem 1.1 (Fundamental problem of causal inference) It is impossible to observe TT, either in the population or in the sample. Proof. The proof of the FPCI is rather straightforward. Let me start with the sample TT: \\[\\begin{align*} \\Delta^Y_{TT_s} &amp; = \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^N(Y_i^1-Y_i^0)D_i \\\\ &amp; = \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_i^1D_i- \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_i^0D_i \\\\ &amp; = \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_iD_i- \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_i^0D_i. \\end{align*}\\] Since \\(Y_i^0\\) is unobserved whenever \\(D_i=1\\), \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_i^0D_i\\) is unobserved, and so is \\(\\Delta^Y_{TT_s}\\). The same is true for the population TT: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i^1-Y_i^0|D_i=1} \\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^0|D_i=1}\\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i^0|D_i=1}. \\end{align*}\\] \\(\\esp{Y_i^0|D_i=1}\\) is unobserved, and so is \\(\\Delta^Y_{TT}\\). The key insight in order to understand the FPCI is to see that the outcomes of the treated units had they not been treated are unobservable, and so is their average or expectation. We say that they are counterfactual, contrary to what has happened. Definition 1.4 (Couterfactual) Both \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^NY_i^0D_i\\) and \\(\\esp{Y_i^0|D_i=1}\\) are counterfactual quantities that we will never get to observe. Example 1.8 The average counterfactual outcome of the treated is the mean of the red circles in the \\(y\\) axis on Figure 1.3: \\[ \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^Ny_i^0D_i= 6.91. \\] Remember that we can estimate this quantity only because we have generated the data ourselves. In real life, this quantity is hopelessly unobserved. \\(\\esp{y_i^0|D_i=1}\\) can be computed using the formula for the expectation of a censored normal random variable: \\[\\begin{align*} \\esp{y_i^0|D_i=1} &amp; = \\esp{\\mu_i+\\delta+U_i^0|D_i=1}\\\\ &amp; = \\esp{\\mu_i+\\delta+\\rho U_i^B+\\epsilon_i|D_i=1}\\\\ &amp; = \\delta + \\esp{\\mu_i+\\rho U_i^B|y_i^B\\leq\\bar{y}}\\\\ &amp; = \\delta + \\bar{\\mu} - \\frac{\\sigma^2_{\\mu}+\\rho\\sigma^2_U}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}. \\end{align*}\\] We can write a function in R to compute this value: esp.y0.D1 &lt;- function(param){ return(param[&quot;delta&quot;]+param[&quot;barmu&quot;] -((param[&quot;sigma2mu&quot;]+param[&quot;rho&quot;]*param[&quot;sigma2U&quot;]) *dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;]) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))) } The population value of TT computed using this function is: \\(\\esp{y_i^0|D_i=1}=\\) 6.9. 1.4 Intuitive estimators, confounding factors and selection bias In this section, we are going to examine the properties of two intuitive comparisons that laypeople, policymakers but also ourselves make in order to estimate causal effects: the with/wihtout comparison (\\(WW\\)) and the before/after comparison (\\(BA\\)). \\(WW\\) compares the average outcomes of the treated individuals with those of the untreated individuals. \\(BA\\) compares the average outcomes of the treated after taking the treatment to their average outcomes before they took the treatment. These comparisons try to proxy for the expected counterfactual outcome in the treated group by using an observed quantity. \\(WW\\) uses the expected outcome of the untreated individuals as a proxy. \\(BA\\) uses the expected outcome of the treated before they take the treatment as a proxy. Unfortunately, both of these proxies are generally poor and provide biased estimates of \\(TT\\). The reason that these proxies are poor is that the treatment is not the only factor that differentiates the treated group from the groups used to form the proxy. The intuitive comparisons are biased because factors, other than the treatment, are correlated to its allocation. The factors that bias the intuitive comparisons are generally called confouding factors or confounders. The treatment effect measures the effect of a ceteris paribus change in treatment status, while the intuitive comparisons capture both the effect of this change and that of other correlated changes that spuriously contaminate the comparison. Intuitive comparisons measure correlations while treatment effects measure causality. The old motto “correlation is not causation” applies vehemently here. Remark. A funny anecdote about this expression “correlation is not causation”. This expression is due to Karl Pearson, the father of modern statistics. He coined the phrase in his famous book “The Grammar of Science.” Pearson is famous for inventing the correlation coefficient. He actually thought that correlation was a much superior, much more rigorous term, than causation. In his book, he actually used the sentence to argue in favor of abandoning causation altogether and focusing on the much better-defined and measurable concept of correlation. Interesting turn of events that his sentence is now used to mean that correlation is weaker than causation, totally reverting the original intended meaning. In this section, we are going to define both comparisons, study their biases and state the conditions under which they identify \\(TT\\). This will prove to be a very useful introduction to the notion of identification. It is also very important to be able to understand the sources of bias of comparisons that we use every day and that come very naturally to policy makers and lay people. Remark. In this section, we state the definitions and formulae in the population. This is for two reasons. First, it is simpler, and lighter in terms of notation. Second, it emphasizes that the problems with intuitive comparisons are independent of sampling noise. Most of the results stated here for the population extend to the sample, replacing the expectation operator by the average operator. I will nevertheless give examples in the sample, since it is so much simpler to compute. I will denote sample equivalents of population estimators with a hat. 1.4.1 With/Without comparison, selection bias and cross-sectional confounders The with/without comparison (\\(WW\\)) is very intuitive: just compare the outcomes of the treated and untreated individuals in order to estimate the causal effect. This approach is nevertheless generally biased. We call the bias of \\(WW\\) selection bias (\\(SB\\)). Selection bias is due to unobserved confounders that are distributed differently in the treatment and control group and that generate differences in outcomes even in the absence of the treatment. In this section, I define the \\(WW\\) estimator, derives its bias, introduces the confounders and states conditions under which it is unbiased. 1.4.1.1 With/Without comparison The with/without comparison (\\(WW\\)) is very intuitive: just compare the outcomes of the treated and untreated individuals in order to estimate the causal effect. Definition 1.5 (With/without comparison) The with/without comparison is the difference between the expected outcomes of the treated and the expected outcomes of the untreated: \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i|D_i=0}. \\end{align*}\\] Example 1.9 In the population, \\(WW\\) can be computed using the traditional formula for the expectation of a truncated normal distribution: \\[\\begin{align*} \\Delta^y_{WW} &amp; = \\esp{y_i|D_i=1}-\\esp{y_i|D_i=0} \\\\ &amp; = \\esp{y_i^1|D_i=1}-\\esp{y^0_i|D_i=0} \\\\ &amp; = \\esp{\\alpha_i|D_i=1}+\\esp{\\mu_i+\\rho U_i^B|\\mu_i+U_i^B\\leq\\bar{y}}-\\esp{\\mu_i+\\rho U_i^B|\\mu_i+U_i^B&gt;\\bar{y}} \\\\ &amp; = \\bar{\\alpha}+\\theta\\left(\\bar{\\mu}-\\frac{\\sigma^2_{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right) -\\frac{\\sigma^2_{\\mu}+\\rho\\sigma^2_{U}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\left(\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}+\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{1-\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right). \\end{align*}\\] In order to compute this parameter, we are going to set up a R function. For reasons that will become clearer later, we will define two separate functions to compute the first and second part of the formula. In the first part, you should have recognised \\(TT\\), that we have already computed in Lecture 1. We are going to call the second part \\(SB\\), for reasons that will become explicit in a bit. delta.y.tt &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;theta&quot;] *((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;]) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;]) /(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } delta.y.sb &lt;- function(param){ return(-(param[&quot;sigma2mu&quot;]+param[&quot;rho&quot;]*param[&quot;sigma2U&quot;])/sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]) *dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) *(1/pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) +1/(1-pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } delta.y.ww &lt;- function(param){ return(delta.y.tt(param)+delta.y.sb(param)) } As a conclusion of all these derivations, \\(WW\\) in the population is equal to -1.298. Remember that the value of \\(TT\\) in the population is 0.172. In order to compute the \\(WW\\) estimator in a sample, I’m going to generate a brand new sample and I’m going to choose a seed for the pseudo-random number generator so that we obtain the same result each time we run the code. I use set.seed(1234) in the code chunk below. param &lt;- c(8,.5,.28,1500) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;) set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 l &lt;- length(param) param &lt;- c(param,0.9,0.01,0.05,0.05,0.05,0.1) names(param)[(l+1):length(param)] &lt;- c(&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In this sample, the average outcome of the treated in the presence of the treatment is \\[ \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iy_i= 7.074. \\] It is materialized by a circle on Figure 1.6. The average outcome of the untreated is \\[ \\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)y_i= 8.383. \\] It is materialized by a plus sign on Figure 1.6. Figure 1.6: Evolution of average outcomes in the treated and control group before (Time =1) and after (Time=2) the treatment The estimate of the \\(WW\\) comparison in the sample is thus: \\[\\begin{align*} \\hat{\\Delta^Y_{WW}} &amp; = \\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i). \\end{align*}\\] We have \\(\\hat{\\Delta^y_{WW}}=\\) -1.308. Remember that the value of \\(TT\\) in the sample is \\(\\Delta^y_{TT_s}=\\) 0.168. Overall, \\(WW\\) severely underestimates the effect of the treatment in our example. \\(WW\\) suggests that the treatment has a negative effect on outcomes whereas we know by construction that it has a positive one. 1.4.1.2 Selection bias When we form the with/without comparison, we do not recover the \\(TT\\) parameter. Instead, we recover \\(TT\\) plus a bias term, called selection bias: \\[\\begin{align*} \\Delta^Y_{WW} &amp; =\\Delta^Y_{TT}+\\Delta^Y_{SB}. \\end{align*}\\] Definition 1.6 (Selection bias) Selection bias is the difference between the with/without comparison and the treatment on the treated parameter: \\[\\begin{align*} \\Delta^Y_{SB} &amp; = \\Delta^Y_{WW}-\\Delta^Y_{TT}. \\end{align*}\\] \\(WW\\) tries to approximate the counterfactual expected outcome in the treated group by using \\(\\esp{Y_i^0|D_i=0}\\), the expected outcome in the untreated group . Selection bias appears because this proxy is generally poor. It is very easy to see that selection bias is indeed directly due to this bad proxy problem: Theorem 1.2 (Selection bias and counterfactual) Selection bias is the difference between the counterfactual expected potential outcome in the absence of the treatment among the treated and the expected potential outcome in the absence of the treatment among the untreated. \\[\\begin{align*} \\Delta^Y_{SB} &amp; = \\esp{Y_i^0|D_i=1}-\\esp{Y_i^0|D_i=0}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{SB} &amp; = \\Delta^Y_{WW}-\\Delta^Y_{TT} \\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i|D_i=0}-\\esp{Y_i^1-Y_i^0|D_i=1}\\\\ &amp; = \\esp{Y_i^0|D_i=1}-\\esp{Y_i^0|D_i=0}. \\end{align*}\\] The first and second equalities stem only from the definition of both parameters. The third equality stems from using the switching equation: \\(Y_i=Y_i^1D_i+Y_i^0(1-D_i)\\), so that \\(\\esp{Y_i|D_i=1}=\\esp{Y^1_i|D_i=1}\\) and \\(\\esp{Y_i|D_i=0}=\\esp{Y_i^0|D_i=0}\\). Example 1.10 In the population, \\(SB\\) is equal to \\[\\begin{align*} \\Delta^y_{SB} &amp; = \\Delta^y_{WW}-\\Delta^y_{TT} \\\\ &amp; = -1.298 - 0.172 \\\\ &amp; = -1.471 \\end{align*}\\] We could have computed \\(SB\\) directly using the formula from Theorem 1.2: \\[\\begin{align*} \\Delta^y_{SB} &amp; = \\esp{y_i^0|D_i=1}-\\esp{y_i^0|D_i=0}\\\\ &amp; = -\\frac{\\sigma^2_{\\mu}+\\rho\\sigma^2_{U}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\left(\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}+\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{1-\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right). \\end{align*}\\] When using the R function for \\(SB\\) that we have defined earlier, we indeed find: \\(\\Delta^y_{SB}=\\) -1.471. In the sample, \\(\\hat{\\Delta^y_{SB}}=\\)-1.308-0.168 \\(=\\) -1.476. Selection bias emerges because we are using a bad proxy for the counterfactual. The average outcome for the untreated is equal to \\(\\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)y_i=\\) 8.383 while the counterfactual average outcome for the treated is \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iy^0_i=\\) 6.906. Their difference is as expected equal to \\(SB\\): \\(\\hat{\\Delta^y_{SB}}=\\) 6.906 \\(-\\) 8.383 \\(=\\) -1.476. The counterfactual average outcome of the treated is much smaller than the average outcome of the untreated. On Figure 1.6, this is materialized by the fact that the plus sign is located much above the triangle. Remark. The concept of selection bias is related to but different from the concept of sample selection bias. With sample selection bias, we worry that selection into the sample might bias the estimated effect of a treatment on outcomes. With selection bias, we worry that selection into the treatment itself might bias the effect of the treatment on outcomes. Both biases are due to unbserved covariates, but they do not play out in the same way. For example, estimating the effect of education on women’s wages raises both selection bias and sample selection bias issues. Selection bias stems from the fact that more educated women are more likely to be more dynamic and thus to have higher earnings even when less educated. Selection bias would be positive in that case, overestimating the effect of education on earnings. Sample selection bias stems from the fact that we can only use a sample of working women in order to estimate the effect of education on wages, since we do not observe the wages on non working women. But, selection into the labor force might generate sample selection bias. More educated women participate more in the labor market, while less educated women participate less. As a consequence, less educated women that work are different from the overall sample of less educated women. They might be more dynamic and work-focused. As a consequence, their wages are higher than the average wages of the less educated women. Comparing the wages of less educated women that work to those of more educated women that work might understate the effect of education on earnings. Sample selection bias would generate a negative bias on the education coefficient. 1.4.1.3 Confounding factors Confounding factors are the factors that generate differences between treated and untreated individuals even in the absence of the treatment. The confounding factors are thus responsible for selection bias. In general, the mere fact of being selected for receiving the treatment means that you have a host of characteristics that would differentiate you from the unselected individuals, even if you were not to receive the treatment eventually. For example, if a drug is given to initially sicker individuals, then, we expect that they will be sicker that the untreated in the absence of the treatment. Comparing sick individuals to healthy ones is not a sound way to estimate the effect of a treatment. Obviously, even if our treatment performs well, healthier individuals will be healthier after the treatment has been allocated to the sicker patients. The best we can expect is that the treated patients have recovered, and that their health after the treatment is comparable to that of the untreated patients. In that case, the with/without comparison is going to be null, whereas the true effect of the treatment is positive. Selection bias is negative in that case: in the absence of the treatment, the average health status of the treated individuals would have been smaller than that of the untreated individuals. The confounding factor is the health status of individuals when the decision to allocate the drug has been taken. It is correlated to both the allocation of the treatment (negatively) and to health in the absence of the treatment (positively). Example 1.11 In our example, \\(\\mu_i\\) and \\(U_i^B\\) are the confounding factors. Because the treatment is only given to individuals with pre-treament outcomes smaller than a threshold (\\(y_i^B\\leq\\bar{y}\\)), participants tend to have smaller \\(\\mu_i\\) and \\(U_i^B\\) than non participants, as we can see on Figure 1.7. Figure 1.7: Distribution of confounders in the treated and control group Since confounding factors are persistent, they affect the outcomes of participants and non participants after the treatment date. \\(\\mu_i\\) persists entirely over time, and \\(U_i^B\\) persists at a rate \\(\\rho\\). As a consequence, even in the absence of the treatment, participants have lower outcomes than non participants, as we can see on Figure 1.7. We can derive the contributions of both confouding factors to overall SB: \\[\\begin{align*} \\esp{Y_i^0|D_i=1} &amp; = \\esp{\\mu_i+\\delta+U_i^0|\\mu_i+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\delta + \\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y}} + \\rho\\esp{U_i^B|\\mu_i+U_i^B\\leq\\bar{y}}\\\\ \\Delta^y_{SB} &amp; = \\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y}}-\\esp{\\mu_i|\\mu_i+U_i^B&gt;\\bar{y}} \\\\ &amp; \\phantom{=} + \\rho\\left(\\esp{U_i^B|\\mu_i+U_i^B\\leq\\bar{y}}-\\esp{U_i^B|\\mu_i+U_i^B&gt;\\bar{y}}\\right)\\\\ &amp; = -\\frac{\\sigma^2_{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\left(\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}+\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{1-\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right) \\\\ &amp; \\phantom{=} -\\frac{\\rho\\sigma^2_{U}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\left(\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}+\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{1-\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right) \\end{align*}\\] In order to evaluate these quantities, let’s build two R functions: delta.y.sb.mu &lt;- function(param){ return(-(param[&quot;sigma2mu&quot;])/sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]) *dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) *(1/pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) +1/(1-pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } delta.y.sb.U &lt;- function(param){ return(-(param[&quot;rho&quot;]*param[&quot;sigma2U&quot;])/sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]) *dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) *(1/pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) +1/(1-pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } The contribution of \\(\\mu_i\\) to selection bias is -0.978 while that of \\(U_i^0\\) is of -0.493. 1.4.1.4 When does \\(WW\\) identify \\(TT\\)? Are there conditions under which \\(WW\\) identify \\(TT\\)? The answer is yes: when there is no selection bias, the proxy used by \\(WW\\) for the counterfactual quantity is actually valid. Formally, \\(WW\\) identifies \\(TT\\) when the following assumption holds: Definition 1.7 (No selection bias) We assume the following: \\[\\begin{align*} \\esp{Y_i^0|D_i=1} &amp; = \\esp{Y_i^0|D_i=0}. \\end{align*}\\] Under Assumption 1.7, the expected counterfactual outcome of the treated is equal to the expected potential outcome of the untreated in the absence of the treatment. This yields to the following result: Theorem 1.3 Under Assumption 1.7, \\(WW\\) identifies the \\(TT\\) parameter: \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\Delta^Y_{TT}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i|D_i=0}\\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^0|D_i=0}\\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^0|D_i=1} \\\\ &amp; = \\Delta^Y_{TT}, \\end{align*}\\] where the second equation uses the switching equation and the third uses Assumption 1.7. So, under Assumption 1.7, the \\(WW\\) comparison actually identifies the \\(TT\\) parameter. We say that Assumption 1.7 is an identification assumption: it serves to identify the parameter of interest using observed data. The intuition for this result is simply that, under Assumption 1.7, there are no confounding factors and thus no selection bias. under Assumption 1.7, the factors that yield individuals to receive or not the treatment are mean-independent of the potential outcomes in the absence of the treatment. In this case, the expected outcome in the untreated group actually is a perfect proxy for the counterfactual expected outcome of the treated group. Obviously, Assumption 1.7 is extremely unlikely to hold in real life. For Assumption 1.7 to hold, it has to be that all the determinants of \\(D_i\\) are actually unrelated to \\(Y_i^0\\). One way to enforce Assumption 1.7 is to randomize treatment intake. We will see this in the Lecture on RCTs. It might also be possible that Assumption 1.7 holds in the data in the absence of an RCT. But this is not very likely, and should be checked by every mean possible. One way to test for the validity of Assumption 1.7 is to compare the values of observed covariates in the treated and untreated group. For Assumption 1.7 to be credible, observed covariates should be distributed in the same way. Another nice way to test for the validity of Assumption 1.7 with observed data is to implement a placebo test. A placebo test looks for an effect where there should be none, if we believe the identification assumptions. For example, under Assumption 1.7 it should be (even though it is not rigorously implied) that outcomes before the treatment are also mean-independent of the treatment allocation. And actually, since a future treatment cannot have an effect today (unless people anticipate the treatment, which we assume away here), the \\(WW\\) comparison before the treatment should be null, therefore giving a zero effect of the placebo treatment “will receive the treatment in the future.” Example 1.12 When the allocation rule defining \\(D_i\\) is the eligibility rule that we have used so far, we have already seen that Assumption 1.7 does not hold and the placebo test should not pass either. One way of generating Assumption 1.7 from the eligibility rule that we are using is to mute the persistence in outcome dynamics. For example, one could set \\(\\rho=0\\) and \\(\\sigma^2_{\\mu}=0\\). param &lt;- c(8,0,.28,1500,0,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) param ## barmu sigma2mu sigma2U barY rho ## 8.00 0.00 0.28 1500.00 0.00 ## theta sigma2epsilon sigma2eta delta baralpha ## 0.01 0.05 0.05 0.05 0.10 In that case, outcomes are not persistent and Assumption 1.7 holds: \\[\\begin{align*} \\esp{y_i^0|D_i=1} &amp; = \\esp{\\mu_i+\\delta+U_i^0|y_i^B\\leq\\bar{y}}\\\\ &amp; = \\esp{\\bar{\\mu}+\\delta+\\epsilon_i|\\bar{\\mu}+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\bar{\\mu} + \\delta + \\esp{\\epsilon_i|\\bar{\\mu}+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\bar{\\mu} + \\delta + \\esp{\\epsilon_i|\\bar{\\mu}+U_i^B&gt;\\bar{y}}\\\\ &amp; = \\esp{\\mu_i+\\delta+U_i^0|y_i^B&gt;\\bar{y}}\\\\ &amp; = \\esp{y_i^0|D_i=0}, \\end{align*}\\] where the second equality follows from \\(\\sigma^2_{\\mu}=0\\) and \\(\\rho=0\\) and the fourth from \\(\\epsilon_i \\Ind U_i^B\\). Another direct way to see this is to use the formula for selection bias that we have derived above. It is easy to see that with \\(\\rho=0\\) and \\(\\sigma^2_{\\mu}=0\\), \\(\\Delta^y_{SB}=0\\). To be sure, we can compute \\(\\Delta^y_{SB}\\) with the new parameter values: \\(\\Delta^y_{SB}=\\) 0. As a consequence, \\(\\Delta^y_{TT}=\\) 0.18 \\(=\\) 0.18 \\(=\\Delta^y_{WW}\\). Remark. You might have noticed that the value of \\(\\Delta^y_{TT}\\) is different than before. It is normal, since it depends on the values of parameters, and especially on \\(\\sigma_{\\mu}^2\\) and \\(\\rho\\). Let’s see how these quantities behave in the sample. set.seed(1234) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) We can see that \\(\\hat{\\esp{Y_i^0|D_i=1}}=\\) 8.038 \\(\\approx\\) 8.055 \\(=\\hat{\\esp{Y_i^0|D_i=0}}\\). This means that \\(WW\\) should be close to \\(TT\\): \\(\\hat{\\Delta^y_{TT}}=\\) 0.198 \\(\\approx\\) 0.182 \\(=\\hat{\\Delta^y_{WW}}\\). Note that \\(\\hat{WW}\\) in the sample is not exactly, but only approximately, equal to \\(TT\\) in the population and in the sample. This is an instance of the Fundamental Problem of Statistical Inference that we will study in the next chapter. Under these restrictions, the placebo test would unfortunately conclude against Assumption 1.7 even though it is valid: \\[\\begin{align*} \\esp{y_i^B|D_i=1} &amp; = \\esp{\\mu_i+ U_i^B|y_i^B\\leq\\bar{y}}\\\\ &amp; = \\esp{\\bar{\\mu}+U_i^B|\\bar{\\mu}+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\bar{\\mu} + \\esp{U_i^B|\\bar{\\mu}+U_i^B\\leq\\bar{y}}\\\\ &amp; \\neq \\bar{\\mu} + \\esp{U_i^B|\\bar{\\mu}+U_i^B&gt;\\bar{y}}\\\\ &amp; = \\esp{\\mu_i+U_i^0|y_i^B&gt;\\bar{y}}\\\\ &amp; = \\esp{y_i^B|D_i=0}. \\end{align*}\\] In the sample, we indeed have that \\(\\hat{\\esp{Y_i^B|D_i=1}}=\\) 7.004 \\(\\neq\\) 8.072 \\(=\\hat{\\esp{Y_i^B|D_i=0}}\\). The reason for the failure of the placebo test to conclude that \\(Ww\\) is actually correct is that the \\(U_i^B\\) shock enters both into the selection equation and the outcome equation for \\(y_i^B\\), generating a wage at period \\(B\\) between the outcomes of the treated and of the untreated. Since it is not persistent, this wedge does not generate selection bias. This wedge would not be detected if we could perform it further back in time, before the selection period. Another way to make Assumption 1.7 work is to generate a new allocation rule where all the determinants of treatment intake are indeed orthogonal to potential outcomes and to outcomes before the treatment. Let’s assume for example that \\(D_i=\\uns{V_i\\leq\\bar{y}}\\), with \\(V_i\\sim\\mathcal{N}(\\bar{\\mu},\\sigma^2_{\\mu}+\\sigma^2_{U})\\) and \\(V_i\\Ind(Y_i^0,Y_i^1,Y_i^B,\\mu_i,\\eta_i)\\). In that case, Assumption 1.7 holds and the placebo test does work. Indeed, we have: \\[\\begin{align*} \\Delta^y_{TT} &amp; = \\esp{Y_i^1-Y_i^0|D_i=1} \\\\ &amp; = \\esp{\\alpha_i|D_i=1} \\\\ &amp; = \\esp{\\bar{\\alpha}+\\theta\\mu_i+\\eta_i|V_i\\leq\\bar{y}}\\\\ &amp; = \\bar{\\alpha}+\\theta\\bar{\\mu} \\\\ &amp; = \\Delta^y_{ATE} \\\\ \\Delta^y_{WW} &amp; = \\esp{Y_i|D_i=1} - \\esp{Y_i|D_i=0} \\\\ &amp; = \\esp{Y^1_i|D_i=1} - \\esp{Y^0_i|D_i=0} \\\\ &amp; = \\esp{Y^1_i|V_i\\leq\\bar{y}} - \\esp{Y^0_i|V_i&gt;\\bar{y}} \\\\ &amp; = \\esp{Y^1_i} - \\esp{Y^0_i} \\\\ &amp; = \\Delta^y_{ATE} \\end{align*}\\] \\(ATE\\) is the Average Treatment Effect in the population. It is the expected effect of the treatment on all the members of the population, not only on the treated. When the treatment is randomly allocated, both \\(TT\\) and \\(ATE\\) are equal, since the treated are a random subset of the overall population. I prefer to use \\(ATE\\) for my definition of the \\(R\\) function in order not to erase the definition of the \\(TT\\) function: delta.y.ate &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]) } In the population, \\(WW\\) identifies \\(TT\\): \\(\\Delta^y_{TT}=\\) 0.18 \\(=\\Delta^y_{WW}\\). Let’s see how these quantities behave in the sample: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In the sample, the counterfactual is well approximated by the outcomes of the untreated: \\(\\hat{\\esp{Y_i^0|D_i=1}}=\\) 8.085 \\(\\approx\\) 8.054 \\(=\\hat{\\esp{Y_i^0|D_i=0}}\\). As a consequence, \\(WW\\) should be close to \\(TT\\): \\(\\hat{\\Delta^y_{TT}}=\\) 0.168 \\(\\approx\\) 0.199 \\(=\\hat{\\Delta^y_{WW}}\\). The placebo test is also valid in that case: \\(\\hat{\\esp{Y_i^B|D_i=1}}=\\) 7.95 \\(\\approx\\) 7.99 \\(=\\hat{\\esp{Y_i^B|D_i=0}}\\). 1.4.2 The before/after comparison, temporal confounders and time trend bias The before/after comparison (\\(BA\\)) is also very intuitive: it consists in looking at how the outcomes of the treated have changed over time and to attribute this change to the effect of the treatment. The problem is that other changes might have affected outcomes in the absence of the treatment, thereby biasing \\(BA\\). The bias of \\(BA\\) is called time-trend bias. It is due to confounders that affect the outcomes of the treated over time. This section defines the \\(BA\\) estimator, derives its bias, describes the role of the confounders and states conditions under which \\(BA\\) identifies \\(TT\\). Example 1.13 Before computing any estimates, we need to reset all our parameter values and generated sample it their usual values: param &lt;- c(8,.5,.28,1500) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;) set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 l &lt;- length(param) param &lt;- c(param,0.9,0.01,0.05,0.05,0.05,0.1) names(param)[(l+1):length(param)] &lt;- c(&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) 1.4.2.1 The before/after comparison The before/after estimator (\\(BA\\)) compares the outcomes of the treated after taking the treatment to the outcomes of the treated before taking the treatment. It is also sometimes called a “pre-post comparison.” Definition 1.8 (Before/after comparison) The before/after comparison is the difference between the expected outcomes in the treated group after the treatment and the expected outcomes in the same group before the treatment: \\[\\begin{align*} \\Delta^Y_{BA} &amp; = \\esp{Y_i|D_i=1}-\\esp{Y^B_i|D_i=1}. \\end{align*}\\] Example 1.14 In the population, the \\(BA\\) estimator has the following shape: \\[\\begin{align*} \\Delta^y_{BA} &amp; = \\esp{y_i|D_i=1}-\\esp{y^B_i|D_i=1}\\\\ &amp; = \\esp{y^1_i-y^B_i|D_i=1}\\\\ &amp; = \\esp{\\alpha_i|D_i=1} + \\delta + (\\rho-1)\\esp{U_i^B|\\mu_i+U_i^B\\leq\\bar{y}}\\\\ &amp; = \\Delta^y_{TT} + \\delta + (1-\\rho)\\left(\\frac{\\sigma^2_{U}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right). \\end{align*}\\] In order to compute \\(BA\\) in the population, we can again use a R function, combining the value of \\(TT\\) and that of the second part of the formula, that we are going to denote \\(TB\\) for reasons that are going to become clear in a bit. delta.y.tb &lt;- function(param){ return(param[&quot;delta&quot;] +(1-param[&quot;rho&quot;])*((param[&quot;sigma2U&quot;])/sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) *dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))) /pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))) } delta.y.ba &lt;- function(param){ return(delta.y.tt(param)+ delta.y.tb(param)) } The value of \\(BA\\) in the population is thus \\(\\Delta^y_{BA}=\\) 0.265. Remember that the true value of \\(TT\\) in the population is 0.172. In the sample, the value of \\(BA\\) is \\(\\hat{\\Delta^y_{BA}}=\\) 0.267. Remember that the value of \\(TT\\) in the sample is \\(\\Delta^y_{TT_s}=\\) 0.168. 1.4.2.2 Time trend bias When we form the before/after comparison, we do not recover the \\(TT\\) parameter. Instead, we recover \\(TT\\) plus a bias term, called time trend bias: \\[\\begin{align*} \\Delta^Y_{BA} &amp; =\\Delta^Y_{TT}+\\Delta^Y_{TB}. \\end{align*}\\] Definition 1.9 (Time trend bias) Time trend bias is the difference between the before/after comparison and the treatment on the treated parameter: \\[\\begin{align*} \\Delta^Y_{TB} &amp; = \\Delta^Y_{BA}-\\Delta^Y_{TT} . \\end{align*}\\] \\(BA\\) uses the expected outcome in the treated group before the treatment as a proxy for the expected counterfactual outcome in the absence of the treatment in the same group. \\(TB\\) is due to the fact that \\(BA\\) uses an imperfect proxy for the counterfactual expected outcome of the treated: Theorem 1.4 Time trend bias is the difference between the counterfactual expected potential outcome in the absence of the treatment among the treated and the expected outcome before the treatment in the same group. \\[\\begin{align*} \\Delta^Y_{TB} &amp; = \\esp{Y_i^0|D_i=1}-\\esp{Y_i^B|D_i=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{TB} &amp; = \\Delta^Y_{BA}-\\Delta^Y_{TT} \\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{Y^B_i|D_i=1}-\\esp{Y_i^1-Y_i^0|D_i=1}\\\\ &amp; = \\esp{Y_i^0|D_i=1}-\\esp{Y_i^B|D_i=1}. \\end{align*}\\] The first and second equalities stem from the definition of both parameters. The third equality stems from using the switching equation: \\(Y_i=Y_i^1D_i+Y_i^0(1-D_i)\\), so that \\(\\esp{Y_i|D_i=1}=\\esp{Y^1_i|D_i=1}\\). Example 1.15 In the population, \\(TB\\) is equal to \\(\\Delta^y_{TB}=\\Delta^y_{BA}-\\Delta^y_{TT}=\\) 0.265 \\(-\\) 0.172 \\(=\\) 0.093. We could have computed this result using Theorem1.4: \\[\\begin{align*} \\Delta^y_{TB} &amp; = \\esp{y_i^0|D_i=1}-\\esp{y_i^B|D_i=1} \\\\ &amp; = \\delta + (1-\\rho)\\left(\\frac{\\sigma^2_{U}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\sigma^2_{U}}}\\right)}\\right). \\end{align*}\\] Using the R function that we have defined previously, this approach gives \\(\\Delta^y_{TB}=\\) 0.093. In the sample \\(\\hat{\\Delta^y_{BA}}=\\) 0.267 while \\(\\hat{\\Delta^y_{TT}}=\\) 0.168, so that \\(\\hat{\\Delta^y_{TB}}=\\) 0.099. Time trend bias emerges because we are using a bad proxy for the counterfactual average outcomes of the treated. The average outcome of the treated before the treatment takes place is \\(\\hat{\\esp{y_i^B|D_i=1}}=\\) 6.807 while the true counterfactual average outcome for the treated after the treatment is \\(\\hat{\\esp{y_i^0|D_i=1}}=\\) 6.906. Outcomes would have increased in the treatment group even in the absence of the treatment. As a consequence, the \\(BA\\) comparison overestimates the true effect of the treatment. \\(TB\\) estimated using Theorem 1.4 is equal to: \\(\\hat{\\Delta^y_{TB}}=\\) 6.906 \\(-\\) 6.807 \\(=\\) 0.099. This can be seen on Figure 1.6: the triangle in period 2 is higher than in period 1. 1.4.2.3 Temporal confounders Temporal confounders make the outcomes of the treated change at the same time as the treatment status changes, thereby confounding the effect of the treatment. Temporal confounders are responsible for time trend bias. Over time, there are other things that change than the treatment status. For example, maybe sick individuals naturally recover, and thus their counterfactual health status is better than ther health status before taking the treatment. As a results, \\(BA\\) might overstimate the effect of the treatment. It might also be that the overall level of health in the country has increased, because of increasing GDP, for example. Example 1.16 In our example, \\(\\delta\\) and \\(U_i^B\\) are the confounders. \\(\\delta\\) captures the overall changes in outcomes over time (business cycle, general improvement of health status). \\(U^B_i\\) captures the fact that transitorily sicker individuals tend at the same time to receive the treatment and also to recover naturally. The \\(BA\\) comparison incorrectly attributes both of these changes to the effect of the treatment. We can compute the relative contributions of both sources to the overall time-trend bias in the population. \\(\\delta\\) contributes for 0.05 while \\(U^B_i\\) contributes for 0.043. 1.4.2.4 When does \\(BA\\) identify \\(TT\\)? Are there conditions under which \\(BA\\) actually identifies \\(TT\\)? The answer is yes, when there are no temporal confounders. When that is the case, the variation of outcomes over time is only due to the treatment and it identifies the treatment effect. More formally, we make the following assumption: Definition 1.10 (No time trend bias) We assume the following: \\[\\begin{align*} \\esp{Y_i^0|D_i=1} &amp; = \\esp{Y_i^B|D_i=1}. \\end{align*}\\] Under Assumption 1.10, the expected counterfactual outcome of the treated is equal to the expected potential outcome of the untreated in the absence of the treatment. This yields to the following result: Theorem 1.5 Under Assumption 1.10, \\(BA\\) identifies the \\(TT\\) parameter: \\[\\begin{align*} \\Delta^Y_{BA} &amp; = \\Delta^Y_{TT}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{BA} &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i^B|D_i=1}\\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^B|D_i=1}\\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^0|D_i=1} \\\\ &amp; = \\Delta^Y_{TT}, \\end{align*}\\] where the second equation uses the switching equation and the third uses Assumption 1.10. Under Assumption 1.10 the outcomes of the treated before the treatment takes place are a good proxy for the counterfactual. As a consequence, \\(BA\\) identifies \\(TT\\). Under Assumption 1.10is very unlikely to hold in real life. Indeed, it requires tha nothing happens to the outcomes of the treated in the absence of the treatment. Assumption 1.10 rules out economy-wide shocks but also mean-reversion, such as when sick people naturally recover from an illness. A good way to test for the validity of Assumption 1.10 is to perform a placebo test. Two of these tests are possible. One placebo test would be to apply the \\(BA\\) estimator between two pre-treatment periods where nothing should happen since the treatment status does not vary and, by assumption, nothing else should vary. A second placebo test would be to apply the \\(BA\\) estimator to a group that does not receive the treatment. The untreated group is a perfectly suitable candidate for that. Assumption 1.10 does not imply that there should be no change in the untreated outcomes, but detecting such a change would cast a serious doubt on the validity of Assumption 1.10. Example 1.17 One way to generate a population in which Assumption 1.10 holds is to shut down the two sources of confounders in our original model by setting both \\(\\delta=0\\) and \\(\\rho=1\\). param &lt;- c(8,0.5,.28,1500,1,0.01,0.05,0.05,0,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) param ## barmu sigma2mu sigma2U barY rho ## 8.00 0.50 0.28 1500.00 1.00 ## theta sigma2epsilon sigma2eta delta baralpha ## 0.01 0.05 0.05 0.00 0.10 In that case, according to the formula we have derived for \\(TB\\), we have: \\(\\Delta^y_{TB}=\\) 0. Let’s see how these quantities behave in the sample: set.seed(1234) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In the sample, the value of \\(BA\\) is \\(\\hat{\\Delta^y_{BA}}=\\) 0.173 while the value of \\(TT\\) in the sample is \\(\\Delta^y_{TT_s}=\\) 0.168. We cannot perform a placebo test using two periods of pre-treatment outcomes for the treated since we have generated only one period of pre-treatment outcome. We will be able to perform this test later in the DID lecture. We can perfom the placebo test that applies the \\(BA\\) estimator to the untreated. The value of \\(BA\\) for the untreated is \\(\\hat{\\Delta^y_{BA|D=0}}=\\) 0.007, which is reasonably close to zero. "],["FPSI.html", "Chapter 2 Fundamental Problem of Statistical Inference 2.1 What is sampling noise? Definition and illustration 2.2 Estimating sampling noise", " Chapter 2 Fundamental Problem of Statistical Inference The Fundamental Problem of Statistical Inference (FPSI) states that, even if we have an estimator \\(E\\) that identifies \\(TT\\) in the population, we cannot observe \\(E\\) because we only have access to a finite sample of the population. The only thing that we can form from the sample is a sample equivalent \\(\\hat{E}\\) to the population quantity \\(E\\), and \\(\\hat{E}\\neq E\\). For example, the sample analog to \\(WW\\) is the difference in means between treated and untreated units \\(\\hat{WW}\\). As we saw in the last lecture, \\(\\hat{WW}\\) is never exactly equal to \\(WW\\). Why is \\(\\hat{E}\\neq E\\)? Because a finite sample is never perfectly representative of the population. In a sample, even in a random sample, the distribution of the observed and unobserved covariates deviates from the true population one. As a consequence, the sample value of the estimator is never precisely equal to the population value, but fluctuates around it with sampling noise. The main problem with the FPSI is that if we find an effect of our treatment, be it small or large, we cannot know whether we should attribute it to the treatment or to the bad or good luck of sampling noise. What can we do to deal with the FPSI? I am going to argue that there are mainly two things that we might want to do: estimating the extent of sampling noise and decreasing sampling noise. Estimating sampling noise means measuring how much variability there is in our estimate \\(\\hat{E}\\) due to the sampling procedure. This is very useful because it enables us to form a confidence interval that gauges how far from \\(\\hat{E}\\) the true value \\(E\\) might be. It is a measure of the precision of our estimation and of the extent to which sampling noise might drive our results. Estimating sampling noise is very hard because we have only access to one sample and we would like to know the behavior of our estimator over repeated samples. We are going to learn four ways to estimate the extent of sampling noise using data from one sample. Because sampling noise is such a nuisance and makes our estimates imprecise, we would like to be able to make it as small as possible. We are going to study three ways of decreasing sampling noise, two that take place before collecting the data (increasing sample size, stratifying) and one that takes place after (conditioning). Maybe you are surprised not to find statistical significance tests as an important answer to the FPSI. I argue in this lecture that statistical tests are misleading tools that make us overestimate the confidence in our results and underestimate the scope of sampling noise. Statistical tests are not meant to be used for scientific research, but were originally designed to make decisions in industrial settings where the concept of successive sampling made actual sense. Statistical tests also generate collective behaviors such as publication bias and specification search that undermine the very foundations of science. A general movement in the social sciences, but also in physics, is starting to ban the reporting of p-values. 2.1 What is sampling noise? Definition and illustration In this section, I am going to define sampling noise and illustrate it with a numerical example. In Section 2.1.1, I define sampling noise. In section 2.1.2, I illustrate how sampling noise varies when one is interested in the population treatment effect. In section 2.1.3, I illustrate how sampling noise varies when one is interesetd in the sample treatment effect. Finally, in section 2.1.4, I show how confidence intervals can be built from an estimate of sampling noise. 2.1.1 Sampling noise, a definition Sampling noise measures how much sampling variability moves the sample estimator \\(\\hat{E}\\) around. One way to define it more rigorously is to make it equal to the width of a confidence interval: Definition 2.1 (Sampling noise) Sampling noise is the width of the symmetric interval around TT within which \\(\\delta*100\\)% of the sample estimators fall, where \\(\\delta\\) is the confidence level. As a consequence, sampling noise is equal to \\(2\\epsilon\\) where \\(\\epsilon\\) is such that: \\[\\begin{align*} \\Pr(|\\hat{E}-TT|\\leq\\epsilon) &amp;= \\delta. \\end{align*}\\] This definition tries to capture the properties of the distribution of \\(\\hat{E}\\) using only one number. As every simplification, it leaves room for dissatisfaction, exactly as a 2D map is a convenient albeit arbitrary betrayal of a 3D phenomenon. For example, there is nothing sacred about the symmetry of the interval. It is just extremely convenient. One might prefer an interval that is symmetric in tail probabilities instead. Feel free to explore with different concepts if you like. A related concept to that of sampling noise is that of precision: the smaller the sampling noise, the higher the precision. Precision can be defined for example as the inverse of sampling noise \\(\\frac{1}{2\\epsilon}\\). Finally, a very useful concept is that of signal to noise ratio. It is not used in economics, but physicists use this concept all the time. The signal to noise ratio measures the treatment effect in multiple of the sampling noise. If they are of the same order of magnitude, we have a lot of noise and little confidence in our estimates. If the signal is much larger than the noise, we tend to have a lot of confidence in our parameter estimates. The signal to noise ratio can be computed as follows: \\(\\frac{E}{2\\epsilon}\\) or \\(\\frac{\\hat{E}}{2\\epsilon}\\). Remark. A very striking result is that the signal to noise ratio of a result that is marginally significant at the 5% level is very small, around one half, meaning that the noise is generally double the signal in these results. We will derive this result after studying how to estimate sampling noise with real data. There are two distinct ways of understanding sampling noise, depending on whether we are after the population treatment effect (\\(\\Delta^Y_{TT}\\)) or the sample treatment effect (\\(\\Delta^Y_{TT_s}\\)). Sampling noise for the population treatment effect stems from the fact that the sample is not perfectly representative of the population. The sample differs from the population and thus the sample estimates differs from the population estimate. Sampling noise for the sample parameter stems from the fact that the control group is not a perfect embodiment of the counterfactual. Discrepancies between treated and control samples are going to generate differences between the \\(WW\\) estimate and the \\(TT\\) effect in the sample. 2.1.2 Sampling noise for the population treatment effect Sampling noise for the population treatment effect stems from the fact that the sample is not perfectly representative of the population. Example 2.1 In order to assess the scope of sampling noise for our population treatment effect estimate, let’s first draw a sample. In order to be able to do that, I first have to define the parameter values: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) param ## barmu sigma2mu sigma2U barY rho ## 8.00 0.50 0.28 1500.00 0.90 ## theta sigma2epsilon sigma2eta delta baralpha ## 0.01 0.05 0.05 0.05 0.10 set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) delta.y.ate &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]) } In this sample, the \\(WW\\) estimator yields an estimate of \\(\\hat{\\Delta^y_{WW}}=\\) 0.133. Despite random assignment, we have \\(\\hat{\\Delta^y_{WW}}\\neq\\Delta^y_{TT}=\\) 0.18, an instance of the FPSI. In order to see how sampling noise varies, let’s draw another sample. In order to do so, I am going to choose a different seed to initialize the pseudo-random number generator in R. set.seed(12345) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In this sample, the \\(WW\\) estimator yields an estimate of \\(\\hat{\\Delta^y_{WW}}=\\) 0.179. Again, despite random assignment, we have \\(\\hat{\\Delta^y_{WW}}\\neq\\Delta^y_{TT}=\\) 0.18, an instance of the FPSI. Furthermore, the estimate of the population treatment effect in this sample differs from the previous one, a consequence of sampling noise. Let’s now visualize the extent of sampling noise by repeating the procedure multiple times with various sample sizes. This is called Monte Carlo replications: in each replication, I choose a sample size, draw one sample from the population and compute the \\(\\hat{WW}\\) estimator. At each replication, the sample I’m using is different, reflecting the actual sampling process and enabling me to gauge the extent of sampling noise. In order to focus on sampling noise alone, I am running the replications in the model in which selection into the treatment is independent on potential outcomes, so that \\(WW=TT\\) in the population. In order to speed up the process, I am using parallelized computing: I send each sample to a different core in my computer so that several samples can be run at the same time. You might want to adapt the program below to the number of cores you actually have using the ncpus variable in the beginning of the .Rmd file that generates this page.. In order to parallelize computations, I use the Snowfall package in R, that gives very simple and intuitive parallelization commands. In order to save time when generating the graph, I use the wonderful “cache” option of knitr: it stores the estimates from the code chunk and will not rerun it as long as the code inside the chunk has not been altered nor the code of the chunks that it depends on (parameter values, for example). monte.carlo.ww &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) return(c((1/sum(Ds))*sum(y*Ds)-(1/sum(1-Ds))*sum(y*(1-Ds)),var(y[Ds==1]),var(y[Ds==0]),mean(Ds))) } simuls.ww.N &lt;- function(N,Nsim,param){ simuls.ww &lt;- as.data.frame(matrix(unlist(lapply(1:Nsim,monte.carlo.ww,N=N,param=param)),nrow=Nsim,ncol=4,byrow=TRUE)) colnames(simuls.ww) &lt;- c(&#39;WW&#39;,&#39;V1&#39;,&#39;V0&#39;,&#39;p&#39;) return(simuls.ww) } sf.simuls.ww.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=ncpus) sim &lt;- as.data.frame(matrix(unlist(sfLapply(1:Nsim,monte.carlo.ww,N=N,param=param)),nrow=Nsim,ncol=4,byrow=TRUE)) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;,&#39;V1&#39;,&#39;V0&#39;,&#39;p&#39;) return(sim) } simuls.ww &lt;- lapply(N.sample,sf.simuls.ww.N,Nsim=Nsim,param=param) ## R Version: R version 4.1.1 (2021-08-10) par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww[[i]][,&#39;WW&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55)) abline(v=delta.y.ate(param),col=&quot;red&quot;) } Figure 2.1: Distribution of the \\(WW\\) estimator over replications of samples of different sizes Figure 2.1 is essential to understanding statistical inference and the properties of our estimators. We can see on Figure 2.1 that the estimates indeed move around at each sample replication. We can also see that the estimates seem to be concentrated around the truth. We also see that the estimates are more and more concentrated around the truth as sample size grows larger and larger. How big is sampling noise in all of these examples? We can compute it by using the replications as approximations to the true distribution of the estimator after an infinite number of samples has been drawn. Let’s first choose a confidence level and then compute the empirical equivalent to the formula in Definition 2.1. delta&lt;- 0.99 delta.2 &lt;- 0.95 samp.noise &lt;- function(estim,delta){ return(2*quantile(abs(delta.y.ate(param)-estim),prob=delta)) } samp.noise.ww &lt;- sapply(lapply(simuls.ww,`[`,,1),samp.noise,delta=delta) names(samp.noise.ww) &lt;- N.sample samp.noise.ww ## 100 1000 10000 1e+05 ## 1.09916429 0.39083801 0.11582492 0.03527744 Let’s also compute precision and the signal to noise ratio and put all of these results together in a nice table. precision &lt;- function(estim,delta){ return(1/samp.noise(estim,delta)) } signal.to.noise &lt;- function(estim,delta,param){ return(delta.y.ate(param)/samp.noise(estim,delta)) } precision.ww &lt;- sapply(lapply(simuls.ww,`[`,,1),precision,delta=delta) names(precision.ww) &lt;- N.sample signal.to.noise.ww &lt;- sapply(lapply(simuls.ww,`[`,,1),signal.to.noise,delta=delta,param=param) names(signal.to.noise.ww) &lt;- N.sample table.noise &lt;- cbind(samp.noise.ww,precision.ww,signal.to.noise.ww) colnames(table.noise) &lt;- c(&#39;Sampling noise&#39;, &#39;Precision&#39;, &#39;Signal to noise ratio&#39;) knitr::kable(table.noise,caption=paste(&#39;Sampling noise of $\\\\hat{WW}$ for the population treatment effect with $\\\\delta=$&#39;,delta,&#39;for various sample sizes&#39;,sep=&#39; &#39;),booktabs=TRUE,digits = c(2,2,2),align=c(&#39;c&#39;,&#39;c&#39;,&#39;c&#39;)) Table 2.1: Sampling noise of \\(\\hat{WW}\\) for the population treatment effect with \\(\\delta=\\) 0.99 for various sample sizes Sampling noise Precision Signal to noise ratio 100 1.10 0.91 0.16 1000 0.39 2.56 0.46 10000 0.12 8.63 1.55 1e+05 0.04 28.35 5.10 Finally, a nice way to summarize the extent of sampling noise is to graph how sampling noise varies around the true treatment effect, as shown on Figure 2.2. colnames(table.noise) &lt;- c(&#39;sampling.noise&#39;, &#39;precision&#39;, &#39;signal.to.noise&#39;) table.noise &lt;- as.data.frame(table.noise) table.noise$N &lt;- as.numeric(rownames(table.noise)) table.noise$TT &lt;- rep(delta.y.ate(param),nrow(table.noise)) ggplot(table.noise, aes(x=as.factor(N), y=TT)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 2.2: Sampling noise of \\(\\hat{WW}\\) (99% confidence) around \\(TT\\) for various sample sizes With \\(N=\\) 100, we can definitely see on Figure 2.2 that sampling noise is ridiculously large, especially compared with the treatment effect that we are trying to estimate. The signal to noise ratio is 0.16, which means that sampling noise is an order of magnitude bigger than the signal we are trying to extract. As a consequence, in 22.2% of our samples, we are going to estimate a negative effect of the treatment. There is also a 20.4% chance that we end up estimating an effect that is double the true effect. So how much can we trust our estimate from one sample to be close to the true effect of the treatment when \\(N=\\) 100? Not much. With \\(N=\\) 1000, sampling noise is still large: the signal to noise ratio is 0.46, which means that sampling noise is double the signal we are trying to extract. As a consequence, the chance that we end up with a negative treatment effect has decreased to 0.9% and that we end up with an effect double the true one is 1%. But still, the chances that we end up with an effect that is smaller than three quarters of the true effect is 25.6% and the chances that we end up with an estimator that is 25% bigger than the true effect is 26.2%. These are nontrivial differences: compare a program that increases earnings by 13.5% to one that increases them by 18% and another by 22.5%. They would have completely different cost/benefit ratios. But we at least trust our estimator to give us a correct idea of the sign of the treatment effect and a vague and imprecise idea of its magnitude. With \\(N=\\) 10^{4}, sampling noise is smaller than the signal, which is encouraging. The signal to noise ratio is 1.55. In only 1% of the samples does the estimated effect of the treatment become smaller than 0.125 or bigger than 0.247. We start gaining a lot of confidence in the relative magnitude of the effect, even if sampling noise is still responsible for economically significant variation. With \\(N=\\) 10^{5}, sampling noise has become trivial. The signal to noise ratio is 5.1, which means that the signal is now 5 times bigger than the sampling noise. In only 1% of the samples does the estimated effect of the treatment become smaller than 0.163 or bigger than 0.198. Sampling noise is not any more responsible for economically meaningful variation. 2.1.3 Sampling noise for the sample treatment effect Sampling noise for the sample parameter stems from the fact that the treated and control groups are not perfectly identical. The distribution of observed and unobserved covariates is actually different, because of sampling variation. This makes the actual comparison of means in the sample a noisy estimate of the true comparison that we would obtain by comparing the potential outcomes of the treated directly. In order to understand this issue well and to be able to illustrate it correctly, I am going to focus on the average treatment effect in the whole sample, not on the treated: \\(\\Delta^Y_{ATE_s}=\\frac{1}{N}\\sum_{i=1}^N(Y_i^1-Y_i^0)\\). This enables me to define a sample parameter that is independent of the allocation of \\(D_i\\). This is without important consequences since these two parameters are equal in the population when there is no selection bias, as we are assuming since the beginning of this lecture. Furthermore, if we view the treatment allocation generating no selection bias as a true random assignment in a Randomized Controlled Trial (RCT), then it is still possible to use this approach to estimate \\(TT\\) if we view the population over which we randomise as the population selected for receiving the treatment, as we will see in the lecture on RCTs. Example 2.2 In order to assess the scope of sampling noise for our sample treatment effect estimate, we first have to draw a sample: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In this sample, the treatment effect parameter is \\(\\Delta^y_{ATE_s}=\\) 0.171. The \\(WW\\) estimator yields an estimate of \\(\\hat{\\Delta^y_{WW}}=\\) 0.133. Despite random assignment, we have \\(\\Delta^y_{ATE_s}\\neq\\hat{\\Delta^y_{WW}}\\), an instance of the FPSI. In order to see how sampling noise varies, let’s draw a new treatment allocation, while retaining the same sample and the same potential outcomes. set.seed(12345) N &lt;-1000 Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In this sample, the treatment effect parameter is still \\(\\Delta^y_{ATE_s}=\\) 0.171. The \\(WW\\) estimator yields now an estimate of \\(\\hat{\\Delta^y_{WW}}=\\) 0.051. The \\(WW\\) estimate is different from our previous estimate because the treatment was allocated to a different random subset of people. Why is this second estimate so imprecise? It might because it estimates one of the two components of the average treatment effect badly, or both. The true average potential outcome with the treatment is, in this sample, \\(\\frac{1}{N}\\sum_{i=1}^Ny_i^1=\\) 8.207 while the \\(WW\\) estimate of this quantity is \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iy_i=\\) 8.113. The true average potential outcome without the treatment is, in this sample, \\(\\frac{1}{N}\\sum_{i=1}^Ny_i^0=\\) 8.036 while the \\(WW\\) estimate of this quantity is \\(\\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)y_i=\\) 8.062. It thus seems that most of the bias in the estimated effect stems from the fact that the treatment has been allocated to individuals with lower than expected outcomes with the treatment, be it because they did not react strongly to the treatment, or because they were in worse shape without the treatment. We can check which one of these two explanations is more important. The true average effect of the treatment is, in this sample, \\(\\frac{1}{N}\\sum_{i=1}^N(y_i^1-y^0_i)=\\) 0.171 while, in the treated group, this quantity is \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_i(y_i^1-y_i^0)=\\) 0.18. The true average potential outcome without the treatment is, in this sample, \\(\\frac{1}{N}\\sum_{i=1}^Ny^0_i=\\) 8.036 while, in the treated group, this quantity is \\(\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iy_i^0=\\) 7.933. The reason for the poor performance of the \\(WW\\) estimator in this sample is that individuals with lower counterfactual outcomes were included in the treated group, not that the treatment had lower effects on them. The bad counterfactual outcomes of the treated generates a bias of -0.103, while the bias due to heterogeneous reactions to the treatment is of 0.009. The last part of the bias is the one due to the fact that the individuals in the control group have slightly better counterfactual outcomes than in the sample: -0.026. The sum of these three terms yields the total bias of our \\(WW\\) estimator in this second sample: -0.12. Let’s now assess the overall effect of sampling noise on the estimate of the sample treatment effect for various sample sizes. In order to do this, I am going to use parallelized Monte Carlo simulations again. For the sake of simplicity, I am going to generate the same potential outcomes in each replication, using the same seed, and only choose a different treatment allocation. monte.carlo.ww.sample &lt;- function(s,N,param){ set.seed(1234) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) set.seed(s) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) return((1/sum(Ds))*sum(y*Ds)-(1/sum(1-Ds))*sum(y*(1-Ds))) } simuls.ww.N.sample &lt;- function(N,Nsim,param){ return(unlist(lapply(1:Nsim,monte.carlo.ww.sample,N=N,param=param))) } sf.simuls.ww.N.sample &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=ncpus) sim &lt;- sfLapply(1:Nsim,monte.carlo.ww.sample,N=N,param=param) sfStop() return(unlist(sim)) } simuls.ww.sample &lt;- lapply(N.sample,sf.simuls.ww.N.sample,Nsim=Nsim,param=param) monte.carlo.ate.sample &lt;- function(N,s,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) return(mean(alpha)) } par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww.sample[[i]],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55)) abline(v=monte.carlo.ate.sample(N.sample[[i]],1234,param),col=&quot;red&quot;) } Figure 2.3: Distribution of the \\(WW\\) estimator over replications of treatment allocation for samples of different sizes Let’s also compute sampling noise, precision and the signal to noise ratio in these examples. samp.noise.sample &lt;- function(i,delta,param){ return(2*quantile(abs(monte.carlo.ate.sample(1234,N.sample[[i]],param)-simuls.ww.sample[[i]]),prob=delta)) } samp.noise.ww.sample &lt;- sapply(1:4,samp.noise.sample,delta=delta,param=param) names(samp.noise.ww.sample) &lt;- N.sample precision.sample &lt;- function(i,delta,param){ return(1/samp.noise.sample(i,delta,param=param)) } signal.to.noise.sample &lt;- function(i,delta,param){ return(monte.carlo.ate.sample(1234,N.sample[[i]],param)/samp.noise.sample(i,delta,param=param)) } precision.ww.sample &lt;- sapply(1:4,precision.sample,delta=delta,param=param) names(precision.ww.sample) &lt;- N.sample signal.to.noise.ww.sample &lt;- sapply(1:4,signal.to.noise.sample,delta=delta,param=param) names(signal.to.noise.ww.sample) &lt;- N.sample table.noise.sample &lt;- cbind(samp.noise.ww.sample,precision.ww.sample,signal.to.noise.ww.sample) colnames(table.noise.sample) &lt;- c(&#39;Sampling noise&#39;, &#39;Precision&#39;, &#39;Signal to noise ratio&#39;) knitr::kable(table.noise.sample,caption=paste(&#39;Sampling noise of $\\\\hat{WW}$ for the sample treatment effect with $\\\\delta=$&#39;,delta,&#39;and for various sample sizes&#39;,sep=&#39; &#39;),booktabs=TRUE,align=c(&#39;c&#39;,&#39;c&#39;,&#39;c&#39;),digits=c(3,3,3)) Table 2.2: Sampling noise of \\(\\hat{WW}\\) for the sample treatment effect with \\(\\delta=\\) 0.99 and for various sample sizes Sampling noise Precision Signal to noise ratio 100 1.208 0.828 0.149 1000 0.366 2.729 0.482 10000 0.122 8.218 1.585 1e+05 0.033 30.283 5.453 Finally, let’s compare the extent of sampling noise for the population and the sample treatment effect parameters. colnames(table.noise.sample) &lt;- c(&#39;sampling.noise&#39;, &#39;precision&#39;, &#39;signal.to.noise&#39;) table.noise.sample &lt;- as.data.frame(table.noise.sample) table.noise.sample$N &lt;- as.numeric(rownames(table.noise.sample)) table.noise.sample$TT &lt;- sapply(N.sample,monte.carlo.ate.sample,s=1234,param=param) table.noise.sample$Type &lt;- &#39;TTs&#39; table.noise$Type &lt;- &#39;TT&#39; table.noise.tot &lt;- rbind(table.noise,table.noise.sample) table.noise.tot$Type &lt;- factor(table.noise.tot$Type) ggplot(table.noise.tot, aes(x=as.factor(N), y=TT,fill=Type)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw()+ theme(legend.position=c(0.85,0.88)) Figure 2.4: Sampling noise of \\(\\hat{WW}\\) (99% confidence) around \\(TT\\) and \\(TT_s\\) for various sample sizes Figure 2.3 and Table 2.2 present the results of the simulations of sampling noise for the sample treatment effect parameter. Figure 2.4 compares sampling noise for the population and sample treatment effects. For all practical purposes, the estimates of sampling noise for the sample treatment effect are extremely close to the ones we have estimated for the population treatment effect. I am actually surprised by this result, since I expected that keeping the potential outcomes constant over replications would decrease sampling noise. It seems that the variability in potential outcomes over replications of random allocations of the treatment in a given sample mimicks very well the sampling process from a population. I do not know if this result of similarity of sampling noise for the population and sample treatment effect is a general one, but considering them as similar or close seems innocuous in our example. 2.1.4 Building confidence intervals from estimates of sampling noise In real life, we do not observe \\(TT\\). We only have access to \\(\\hat{E}\\). Let’s also assume for now that we have access to an estimate of sampling noise, \\(2\\epsilon\\). How can we use these two quantities to assess the set of values that \\(TT\\) might take? One very useful device that we can use is the confidence interval. Confidence intervals are very useful because they quantify the zone within which we have a chance to find the true effect \\(TT\\): Theorem 2.1 (Confidence interval) For a given level of confidence \\(\\delta\\) and corresponding level of sampling noise \\(2\\epsilon\\) of the estimator \\(\\hat{E}\\) of \\(TT\\), the confidence interval \\(\\left\\{\\hat{E}-\\epsilon,\\hat{E}+\\epsilon\\right\\}\\) is such that the probability that it contains \\(TT\\) is equal to \\(\\delta\\) over sample replications: \\[\\begin{align*} \\Pr(\\hat{E}-\\epsilon\\leq TT\\leq\\hat{E}+\\epsilon) &amp; = \\delta. \\end{align*}\\] Proof. From the definition of sampling noise, we know that: \\[\\begin{align*} \\Pr(|\\hat{E}-TT|\\leq\\epsilon) &amp; = \\delta. \\end{align*}\\] Now: \\[\\begin{align*} \\Pr(|\\hat{E}-TT|\\leq\\epsilon) &amp; = \\Pr(TT-\\epsilon\\leq\\hat{E}\\leq TT+\\epsilon)\\\\ &amp; = \\Pr(-\\hat{E}-\\epsilon\\leq-TT\\leq -\\hat{E}+\\epsilon)\\\\ &amp; = \\Pr(\\hat{E}-\\epsilon\\leq TT\\leq\\hat{E}+\\epsilon), \\end{align*}\\] which proves the result. It is very important to note that confidence intervals are centered around \\(\\hat{E}\\) and not around \\(TT\\). When estimating sampling noise and building Figure 2.2, we have centered our intervals around \\(TT\\). The interval was fixed and \\(\\hat{E}\\) was moving across replications and \\(2\\epsilon\\) was defined as the length of the interval around \\(TT\\) containing a proportion \\(\\delta\\) of the estimates \\(\\hat{E}\\). A confidence interval cannot be centered around \\(TT\\), which is unknown, but is centered around \\(\\hat{E}\\), that we can observe. As a consequence, it is the interval that moves around across replications, and \\(\\delta\\) is the proportion of samples in which the interval contains \\(TT\\). Example 2.3 Let’s see how confidence intervals behave in our numerical example. N.plot &lt;- 40 plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test &lt;- sample(simuls.ww[[k]][,&#39;WW&#39;],N.plot) test &lt;- as.data.frame(cbind(test,rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta)),rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta.2)))) colnames(test) &lt;- c(&#39;WW&#39;,&#39;sampling.noise.1&#39;,&#39;sampling.noise.2&#39;) test$id &lt;- 1:N.plot plot.test &lt;- ggplot(test, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise.1/2, ymax=WW+sampling.noise.1/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise.2/2, ymax=WW+sampling.noise.2/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ #ylim(-0.5,1.2)+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test } plot.CI &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI) Figure 2.5: Confidence intervals of \\(\\hat{WW}\\) for \\(\\delta=\\) 0.99 (red) and 0.95 (blue) over sample replications for various sample sizes Figure 2.5 presents the 99% and 95% confidence intervals for 40 samples selected from our simulations. First, confidence intervals do their job: they contain the true effect most of the time. Second, the 95% confidence interval misses the true effect more often, as expected. For example, with \\(N=\\) 1000, the confidence intervals in samples 13 and 23 do not contain the true effect, but it is not far from their lower bound. Third, confidence intervals faithfully reflect what we can learn from our estimates at each sample size. With \\(N=\\) 100, the confidence intervals make it clear that the effect might be very large or very small, even strongly negative. With \\(N=\\) 1000, the confidence intervals suggest that the effect is either positive or null, but unlikely to be strongly negative. Most of the time, we get the sign right. With \\(N=\\) 10^{4}, we know that the true effect is bigger than 0.1 and smaller than 0.3 and most intervals place the true effect somewhere between 0.11 and 0.25. With \\(N=\\) 10^{5}, we know that the true effect is bigger than 0.15 and smaller than 0.21 and most intervals place the true effect somewhere between 0.16 and 0.20. 2.1.5 Reporting sampling noise: a proposal Once sampling noise is measured (and we’ll see how to get an estimate in the next section), one still has to communicate it to others. There are many ways to report sampling noise: Sampling noise as defined in this book (\\(2*\\epsilon\\)) The corresponding confidence interval The signal to noise ratio A standard error A significance level A p-value A t-statistic The main problem with all of these approaches is that they do not express sampling noise in a way that is directly comparable to the magnitude of the \\(TT\\) estimate. Other ways of reporting sampling noise such as p-values and t-stats are nonlinear transforms of sampling noise, making it difficult to really gauge the size of sampling noise as it relates to the magnitude of \\(TT\\). My own preference goes to the following format for reporting results: \\(TT \\pm \\epsilon\\). As such, we can readily compare the size of the noise to the sizee of the \\(TT\\) estimate. We can also form all the other ways of expressing sampling noise directly. Example 2.4 Let’s see how this approach behaves in our numerical example. test.all &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test &lt;- sample(simuls.ww[[k]][,&#39;WW&#39;],N.plot) test &lt;- as.data.frame(cbind(test,rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta)),rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta.2)))) colnames(test) &lt;- c(&#39;WW&#39;,&#39;sampling.noise.1&#39;,&#39;sampling.noise.2&#39;) test$id &lt;- 1:N.plot test.all[[k]] &lt;- test } With \\(N=\\) 100, the reporting of the results for sample 1 would be something like: “we find an effect of 0.37 \\(\\pm\\) 0.55.” Note how the choice of \\(\\delta\\) does not matter much for the result. The previous result was for \\(\\delta=0.99\\) while the result for \\(\\delta=0.95\\) would have been: “we find an effect of 0.37 \\(\\pm\\) 0.45.” The precise result changes with \\(\\delta\\), but the qualitative result stays the same: the magnitude of sampling noise is large and it dwarfs the treatment effect estimate. With \\(N=\\) 1000, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect of 0.25 \\(\\pm\\) 0.2.” With \\(\\delta=0.95\\): “we find an effect of 0.25 \\(\\pm\\) 0.15.” Again, although the precise quantitative result is affected by the choice of \\(\\delta\\), but hte qualitative message stays the same: sampling noise is of the same order of magnitude as the estimated treatment effect. With \\(N=\\) 10^{4}, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect of 0.19 \\(\\pm\\) 0.06.” With \\(\\delta=0.95\\): “we find an effect of 0.19 \\(\\pm\\) 0.04.” Again, see how the qualitative result is independent of the precise choice of \\(\\delta\\): sampling noise is almost one order of magnitude smaller than the treatment effect estimate. With \\(N=\\) 10^{5}, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect of 0.18 \\(\\pm\\) 0.02.” With \\(\\delta=0.95\\): “we find an effect of 0.18 \\(\\pm\\) 0.01.” Again, see how the qualitative result is independent of the precise choice of \\(\\delta\\): sampling noise is one order of magnitude smaller than the treatment effect estimate. Remark. What I hope the example makes clear is that my proposed way of reporting results gives the same importance to sampling noise as it gives to the treatment effect estimate. Also, comparing them is easy, without requiring a huge computational burden on our brain. Remark. One problem with the approach that I propose is when you have a non-symetric distribution of sampling noise, or when \\(TT \\pm \\epsilon\\) exceeds natural bounds on \\(TT\\) (such as if the effect cannot be bigger than one, for example). I think these issues are minor and rare and can be dealt with on a case by case basis. The advantage of having one simple and directly readable number comparable to the magnitude of the treatment effect is overwhelming and makes this approach the most natural and adequate, in my opinion. 2.1.6 Using effect sizes to normalize the reporting of treatment effects and their precision When looking at the effect of a program on an outcome, we depend on the scaling on that outcome to appreciate the relative size of the estimated treatment effect. It is often difficult to appreciate the relative importance of the size of an effect, even if we know the scale of the outcome of interest. One useful device to normalize the treatment effects is called Cohen’s \\(d\\), or effect size. The idea is to compare the magnitude of the treatment effect to an estimate of the usual amount of variation that the outcome undergoes in the population. The way to build Cohen’s \\(d\\) is by dividing the estimated treatment effect by the standard deviation of the outcome. I generally prefer to use the standard devaition of the outcome in the control group, so as not to include the additional amoiunt of variation due to the heterogeneity in treatment effects. Definition 2.2 (Cohen's $d$) Cohen’s \\(d\\), or effect size, is the ratio of the estimated treatment effect to the standard deviation of outcomes in the control group: \\[ d = \\frac{\\hat{TT}}{\\sqrt{\\frac{1}{N^0}\\sum_{i=1}^{N^0}(Y_i-\\bar{Y^0})^2}} \\] where \\(\\hat{TT}\\) is an estimate of the treatment effect, \\(N^0\\) is the number of individuals in the treatment group and \\(\\bar{Y^0}\\) is the average outcome in the treatment group. Cohen’s \\(d\\) can be interpreted in terms of magnitude of effect size: It is generally considered that an effect is large when its \\(d\\) is larger than 0.8. An effect size around 0.5 is considered medium An effect size around 0.2 is considered to be small An effect size around 0.02 is considered to be very small. There probably could be a rescaling of these terms, but that is the actual state of the art. What I like about effect sizes is that they encourage an interpretation of the order of magnitude of the treatment effect. As such, they enable to include the information on precision by looking at which orders of magnitude are compatible with the estimated effect at the estimated precision level. Effect sizes and orders of magnitude help make us aware that our results might be imprecise, and that the precise value that we have estimated is probably not the truth. What is important is the range of effect sizes compatible with our results (both point estimate and precision). Example 2.5 Let’s see how Cohen’s \\(d\\) behaves in our numerical example. The value of Cohen’s \\(d\\) (or effect size) in the population is equal to: \\[\\begin{align*} ES &amp; = \\frac{TT}{\\sqrt{V^0}} = \\frac{\\bar{\\alpha}+\\theta\\bar{\\mu}}{\\sqrt{\\sigma^2_{\\mu}+\\rho^2\\sigma^2_{U}+\\sigma^2_{\\epsilon}}} \\end{align*}\\] We can write a function to compute this parameter, as well as functions to implement its estimator in the simulated samples: V0 &lt;- function(param){ return(param[&quot;sigma2mu&quot;]+param[&quot;rho&quot;]^2*param[&quot;sigma2U&quot;]+param[&quot;sigma2epsilon&quot;]) } ES &lt;- function(param){ return(delta.y.ate(param)/sqrt(V0(param))) } samp.noise.ES &lt;- function(estim,delta,param=param){ return(2*quantile(abs(delta.y.ate(param)/sqrt(V0(param))-estim),prob=delta)) } for (i in 1:4){ simuls.ww[[i]][,&#39;ES&#39;] &lt;- simuls.ww[[i]][,&#39;WW&#39;]/sqrt(simuls.ww[[i]][,&#39;V0&#39;]) } The true effect size in the population is thus 0.2. It is considered to be small according to the current classification, although I’d say that a treatment able to move the outcomes by 20% of their usual variation is a pretty effective treatment, and this effect should be labelled at least medium. Let’s stick with the classification though. In our example, the effect size does not differ much from the treatment effect since the standard deviation of outcomes in the control group is pretty close to one: it is equal to 0.88. Let’s now build confidence intervals for the effect size and try to comment on the magnitudes of these effects using the normalized classification. N.plot.ES &lt;- 40 plot.list.ES &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.ES &lt;- sample(simuls.ww[[k]][,&#39;ES&#39;],N.plot) test.ES &lt;- as.data.frame(cbind(test.ES,rep(samp.noise.ES(simuls.ww[[k]][,&#39;ES&#39;],delta=delta,param=param)),rep(samp.noise.ES(simuls.ww[[k]][,&#39;ES&#39;],delta=delta.2,param=param)))) colnames(test.ES) &lt;- c(&#39;ES&#39;,&#39;sampling.noise.ES.1&#39;,&#39;sampling.noise.ES.2&#39;) test.ES$id &lt;- 1:N.plot.ES plot.test.ES &lt;- ggplot(test.ES, aes(x=as.factor(id), y=ES)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=ES-sampling.noise.ES.1/2, ymax=ES+sampling.noise.ES.1/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=ES-sampling.noise.ES.2/2, ymax=ES+sampling.noise.ES.2/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ #ylim(-0.5,1.2)+ xlab(&quot;Sample id&quot;)+ ylab(&quot;Effect Size&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list.ES[[k]] &lt;- plot.test.ES } plot.CI.ES &lt;- plot_grid(plot.list.ES[[1]],plot.list.ES[[2]],plot.list.ES[[3]],plot.list.ES[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI.ES) Figure 2.6: Confidence intervals of \\(\\hat{ES}\\) for \\(\\delta=\\) 0.99 (red) and 0.95 (blue) over sample replications for various sample sizes Figure 2.6 presents the 99% and 95% confidence intervals for the effect size estimated in 40 samples selected from our simulations. Let’s regroup our estimate and see how we could present their results. test.all.ES &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.ES &lt;- sample(simuls.ww[[k]][,&#39;ES&#39;],N.plot) test.ES &lt;- as.data.frame(cbind(test.ES,rep(samp.noise.ES(simuls.ww[[k]][,&#39;ES&#39;],delta=delta,param=param)),rep(samp.noise.ES(simuls.ww[[k]][,&#39;ES&#39;],delta=delta.2,param=param)))) colnames(test.ES) &lt;- c(&#39;ES&#39;,&#39;sampling.noise.ES.1&#39;,&#39;sampling.noise.ES.2&#39;) test.ES$id &lt;- 1:N.plot.ES test.all.ES[[k]] &lt;- test.ES } With \\(N=\\) 100, the reporting of the results for sample 1 would be something like: “we find an effect size of 0.44 \\(\\pm\\) 0.66” with \\(\\delta=0,99\\). With \\(\\delta=0.95\\) we would say: “we find an effect of 0.44 \\(\\pm\\) 0.5.” All in all, our estimate is compatible with the treatment having a large positive effect size and a medium negative effect size. Low precision prevents us from saying much else. With \\(N=\\) 1000, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect size of 0.28 \\(\\pm\\) 0.22.” With \\(\\delta=0.95\\): “we find an effect size of 0.28 \\(\\pm\\) 0.17.” Our estimate is compatible with a medium positive effect or a very small positive or even negative effect (depending on the choice of \\(\\delta\\)). With \\(N=\\) 10^{4}, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect size of 0.22 \\(\\pm\\) 0.07.” With \\(\\delta=0.95\\): “we find an effect size of 0.22 \\(\\pm\\) 0.05.” Our estimate is thus compatible with a small effect of the treatment. We can rule out that the effect of the treatment is medium since the upper bound of the 99% confidence interval is equal to 0.28. We can also rule out that the effect of the treatment is very small since the lower bound of the 99% confidence interval is equal to 0.15. With this sample size, we have been able to reach a precision level sufficient enough to pin down the order of magnitude of the effect size of our treatment. There still remains a considerable amount of uncertainty about the true effect size, though: the upper bound of our confidence interval is almost double the lower bound. With \\(N=\\) 10^{5}, the reporting of the results for sample 1 with \\(\\delta=0.99\\) would be something like: “we find an effect size of 0.2 \\(\\pm\\) 0.02.” With \\(\\delta=0.95\\): “we find an effect size of 0.2 \\(\\pm\\) 0.02.” Here, the level of precision of our result is such that, first, it does not depend on the choice of \\(\\delta\\) in any meaningful way, and second, we can do more than pinpoint the order of magnitude of the effect size, we can start to zero in on its precise value. From our estimate, the true value of the effect size is really close to 0.2. It could be equal to 0.18 or 0.22, but not further away from 0.2 than that. Remember that is actually equal to 0.2. Remark. One issue with Cohen’s \\(d\\) is that its magnitude depends on the dispersion of the outcomes in the control group. That means that for the same treatment, and same value of the treatment effect, the effect size is larger in a population where oucomes are more homogeneous. This is not an attractive feature of a normalizing scale that its size depends on the particular application. One solution would be, for each outcome, to provide a standardized scale, using for example the estmated standard deviation in a reference population. This would be similar to the invention of the metric system, where a reference scale was agreed uppon once and for all. Remark. Cohen’s \\(d\\) is well defined for continuous outcomes. For discrete outcomes, the use of Cohen’s \\(d\\) poses a series of problems, and alternatives such as relative risk ratios and odds ratios have been proposed. I’ll comment on that in the last chapter. 2.2 Estimating sampling noise Gauging the extent sampling noise is very useful in order to be able to determine how much we should trust our results. Are they precise, so that the true treatment effect lies very close to our estimate? Or are our results imprecise, the true treatment effect maybe lying very far from our estimate? Estimating sampling noise is hard because we want to infer a property of our estimator over repeated samples using only one sample. In this lecture, I am going to introduce four tools that enable you to gauge sampling noise and to choose sample size. The four tools are Chebyshev’s inequality, the Central Limit Theorem, resampling methods and Fisher’s permutation method. The idea of all these methods is to use the properties of the sample to infer the properties of our estimator over replications. Chebyshev’s inequality gives an upper bound on the sampling noise and a lower bound on sample size, but these bounds are generally too wide to be useful. The Central Limit Theorem (CLT) approximates the distribution of \\(\\hat{E}\\) by a normal distribution, and quantifies sampling noise as a multiple of the standard deviation. Resampling methods use the sample as a population and draw new samples from it in order to approximate sampling noise. Fisher’s permutation method, also called randomization inference, derives the distribution of \\(\\hat{E}\\) under the assumption that all treatment effects are null, by reallocating the treatment indicator among the treatment and control group. Both the CLT and resampling methods are approximation methods, and their approximation of the true extent of sampling noise gets better and better as sample size increases. Fisher’s permutation method is exact-it is not an approximation-but it only works for the special case of the \\(WW\\) estimator in a randomized design. The remaining of this section is structured as follows. Section 2.2.1 introduces the assumptions that we will need in order to implement the methods. Section 2.2.2 presents the Chebyshev approach to gauging sampling noise and choosing sample size. Section 2.2.3 introduces the CLT way of approximating sampling noise and choosing sample size. Section 2.2.4 presents the resampling methods. Remark. I am going to derive the estimators for the precision only for the \\(WW\\) estimator. In the following lectures, I will show how these methods adapt to other estimators. 2.2.1 Assumptions In order to be able to use the theorems that power up the methods that we are going to use to gauge sampling noise, we need to make some assumptions on the properties of the data. The main assumptions that we need are that the estimator identifies the true effect of the treatment in the population, that the estimator is well-defined in the sample, that the observations in the sample are independently and identically distributed (i.i.d.), that there is no interaction between units and that the variances of the outcomes in the treated and untreated group are finite. We know from last lecture that for the \\(WW\\) estimator to identify \\(TT\\), we need to assume that there is no selection bias, as stated in Assumption 1.7. One way to ensure that this assumption holds is to use a RCT. In order to be able to form the \\(WW\\) estimator in the sample, we also need that there is at least one treated and one untreated in the sample: Hypothesis 2.1 (Full rank) We assume that there is at least one observation in the sample that receives the treatment and one observation that does not receive it: \\[\\begin{align*} \\exists i,j\\leq N \\text{ such that } &amp; D_i=1 \\&amp; D_j=0. \\end{align*}\\] One way to ensure that this assumption holds is to sample treated and untreated units. In order to be able to estimate the variance of the estimator easily, we assume that the observations come from random sampling and are i.i.d.: Hypothesis 2.2 (i.i.d. sampling) We assume that the observations in the sample are identically and independently distributed: \\[\\begin{align*} \\forall i,j\\leq N\\text{, }i\\neq j\\text{, } &amp; (Y_i,D_i)\\Ind(Y_j,D_j),\\\\ &amp; (Y_i,D_i)\\&amp;(Y_j,D_j)\\sim F_{Y,D}. \\end{align*}\\] We have to assume something on how the observations are related to each other and to the population. Identical sampling is natural in the sense that we are OK to assume that the observations stem from the same population model. Independent sampling is something else altogether. Independence means that the fates of two closely related individuals are assumed to be independent. This rules out two empirically relevant scenarios: The fates of individuals are related because of common influences, as for example the environment, etc, The fates of individuals are related because they directly influence each other, as for example on a market, but also for example because there are diffusion effects, such as contagion of deseases or technological adoption by imitation. We will address both sources of failure of the independence assumption in future lectures. Finally, in order for all our derivations to make sense, we need to assume that the outcomes in both groups have finite variances, otherwise sampling noise is going to be too extreme to be able to estimate it using the methods developed in this lecture: Hypothesis 2.3 (Finite variance of $\\hat{\\Delta^Y_{WW}}$) We assume that \\(\\var{Y^1|D_i=1}\\) and \\(\\var{Y^0|D_i=0}\\) are finite. 2.2.2 Using Chebyshev’s inequality Chebyshev’s inequality is a fundamental building block of statistics. It relates the sampling noise of an estimator to its variance. More precisely, it derives an upper bound on the samplig noise of an unbiased estimator: Theorem 2.2 (Chebyshev's inequality) For any unbiased estimator \\(\\hat{\\theta}\\), sampling noise level \\(2\\epsilon\\) and confidence level \\(\\delta\\), sampling noise is bounded from above: \\[\\begin{align*} 2\\epsilon \\leq 2\\sqrt{\\frac{\\var{\\hat{\\theta}}}{1-\\delta}}. \\end{align*}\\] Remark. The more general version of Chebyshev’s inequality that is generally presented is as follows: \\[\\begin{align*} \\Pr(|\\hat{\\theta}-\\esp{\\hat{\\theta}}|&gt;\\epsilon) &amp; \\leq \\frac{\\var{\\hat{\\theta}}}{\\epsilon^2}. \\end{align*}\\] The version I present in Theorem 2.2 is adapted to the bouding of sampling noise for a given confidence level, while this version is adapted to bounding the confidence level for a given level of sampling noise. In order to go from this general version to Theorem 2.2, simply remember that, for an unbiased estimator, \\(\\esp{\\hat{\\theta}}=\\theta\\) and that, by definition of sampling noise, \\(\\Pr(|\\hat{\\theta}-\\theta|&gt;\\epsilon)=1-\\delta\\). As a result, \\(1-\\delta\\leq\\var{\\hat{\\theta}}/\\epsilon^2\\), hence the result in Theorem 2.2. Using Chebyshev’s inequality, we can obtain an upper bound on the sampling noise of the \\(WW\\) estimator: Theorem 2.3 (Upper bound on the sampling noise of $\\hat{WW}$) Under Assumptions 1.7, 2.1 and 2.2, for a given confidence level \\(\\delta\\), the sampling noise of the \\(\\hat{WW}\\) estimator is bounded from above: \\[\\begin{align*} 2\\epsilon \\leq 2\\sqrt{\\frac{1}{N(1-\\delta)}\\left(\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}\\right)}\\equiv 2\\bar{\\epsilon}. \\end{align*}\\] Proof. See in Appendix A.1.1 Theorem 2.3 is a useful step forward for estimating sampling noise. Theorem 2.3 states that the actual level of sampling noise of the \\(\\hat{WW}\\) estimator (\\(2\\epsilon\\)) is never bigger than a quantity that depends on sample size, confidence level and on the variances of outcomes in the treated and control groups. We either know all the components of the formula for \\(2\\bar{\\epsilon}\\) or we can estimate them in the sample. For example, \\(\\Pr(D_i=1)\\), \\(\\var{Y_i^1|D_i=1}\\) and \\(\\var{Y_i^0|D_i=0}\\) by can be approximated by, respectively: \\[\\begin{align*} \\hat{\\Pr(D_i=1)} &amp; = \\frac{1}{N}\\sum_{i=1}^ND_i\\\\ \\hat{\\var{Y_i^1|D_i=1}} &amp; = \\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_i(Y_i-\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iY_i)^2\\\\ \\hat{\\var{Y_i^0|D_i=0}} &amp; = \\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)(Y_i-\\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)Y_i)^2. \\end{align*}\\] Using these approximations for the quantities in the formula, we can compute an estimate of the upper bound on sampling noise, \\(\\hat{2\\bar{\\epsilon}}\\). Example 2.6 Let’s write an R function that is going to compute an estimate for the upper bound of sampling noise for any sample: samp.noise.ww.cheb &lt;- function(N,delta,v1,v0,p){ return(2*sqrt((v1/p+v0/(1-p))/(N*(1-delta)))) } Let’s estimate this upper bound in our usual sample: set.seed(1234) N &lt;-1000 delta &lt;- 0.99 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) In our sample, for \\(\\delta=\\) 0.99, \\(\\hat{2\\bar{\\epsilon}}=\\) 1.35. How does this compare with the true extent of sampling noise when \\(N=\\) 1000? Remember that we have computed an estimate of sampling noise out of our Monte Carlo replications. In Table 2.2, we can read that sampling noise is actually equal to 0.39. The Chebyshev upper bound overestimates the extent of sampling noise by 245%. How does the Chebyshev upper bound fares overall? In order to know that, let’s compute the Chebyshev upper bound for all the simulated samples. You might have noticed that, when running the Monte Carlo simulations for the population parameter, I have not only recovered \\(\\hat{WW}\\) for each sample, but also the estimates of the components of the formula for the upper bound on sampling noise. I can thus easily compute the Chebyshev upper bound on sampling noise for each replication. for (k in (1:length(N.sample))){ simuls.ww[[k]]$cheb.noise &lt;- samp.noise.ww.cheb(N.sample[[k]],delta,simuls.ww[[k]][,&#39;V1&#39;],simuls.ww[[k]][,&#39;V0&#39;],simuls.ww[[k]][,&#39;p&#39;]) } par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww[[i]][,&#39;cheb.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))),xlim=c(0.25*min(simuls.ww[[i]][,&#39;cheb.noise&#39;]),max(simuls.ww[[i]][,&#39;cheb.noise&#39;]))) abline(v=table.noise[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } Figure 2.7: Distribution of the Chebyshev upper bound on sampling noise over replications of samples of different sizes (true sampling noise in red) Figure 2.7 shows that the upper bound works: it is always bigger than the true sampling noise. Figure 2.7 also shows that the upper bound is large: it generally is of an order of magnitude bigger than the true sampling noise, and thus offers a blurry and too pessimistic view of the precision of an estimator. Figure 2.8 shows that the average Chebyshev bound gives an inflated estimate of sampling noise. Figure 2.9 shows that the Chebyshev confidence intervals are clearly less precise than the true unknown ones. With \\(N=\\) 1000, the true confidence intervals generally reject large negative effects, whereas the Chebyshev confidence intervals do not rule out this possibility. With \\(N=\\) 10^{4}, the true confidence intervals generally reject effects smaller than 0.1, whereas the Chebyshev confidence intervals cannot rule out small negative effects. As a conclusion on Chebyshev estimates of sampling noise, their advantage is that they offer an upper bound on the noise: we can never underestimate noise if we use them. A downside of Chebyshev sampling noise estimates is their low precision, which makes it hard to pinpoint the true confidence intervals. for (k in (1:length(N.sample))){ table.noise$cheb.noise[k] &lt;- mean(simuls.ww[[k]]$cheb.noise) } ggplot(table.noise, aes(x=as.factor(N), y=TT)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=TT-cheb.noise/2, ymax=TT+cheb.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 2.8: Average Chebyshev upper bound on sampling noise over replications of samples of different sizes (true sampling noise in red) N.plot &lt;- 40 plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.cheb &lt;- simuls.ww[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;cheb.noise&#39;)] test.cheb &lt;- as.data.frame(cbind(test.cheb,rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.cheb) &lt;- c(&#39;WW&#39;,&#39;cheb.noise&#39;,&#39;sampling.noise&#39;) test.cheb$id &lt;- 1:N.plot plot.test.cheb &lt;- ggplot(test.cheb, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=WW-cheb.noise/2, ymax=WW+cheb.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.cheb } plot.CI &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI) Figure 2.9: Chebyshev confidence intervals of \\(\\hat{WW}\\) for \\(\\delta=\\) 0.99 over sample replications for various sample sizes (true confidence intervals in red) 2.2.3 Using the Central Limit Theorem The main problem with Chebyshev’s upper bound on sampling noise is that it is an upper bound, and thus it overestimates sampling noise and underestimates precision. One alternative to using Chebyshev’s upper bound is to use the Central Limit Theorem (CLT). In econometrics and statistics, the CLT is used to derive approximate values for the sampling noise of estimators. Because these approximations become more and more precise as sample size increases, we call them asymptotic approximations. Taken to its bare bones, the CLT states that the sum of i.i.d. random variables behaves approximately like a normal distribution when the sample size is large: Theorem 2.4 (Central Limit Theorem) Let \\(X_i\\) be i.i.d. random variables with \\(\\esp{X_i}=\\mu\\) and \\(\\var{X_i}=\\sigma^2\\), and define \\(Z_N=\\frac{\\frac{1}{N}\\sum_{i=1}^NX_i-\\mu}{\\frac{\\sigma}{\\sqrt{N}}}\\), then, for all \\(z\\) we have: \\[\\begin{align*} \\lim_{N\\rightarrow\\infty}\\Pr(Z_N\\leq z) &amp; = \\Phi(z), \\end{align*}\\] where \\(\\Phi\\) is the cumulative distribution function of the centered standardized normal. We say that \\(Z_N\\) converges in distribution to a standard normal random variable, and we denote: \\(Z_N\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,1)\\). The CLT is a beautiful result: the distribution of the average of realisations of any random variable that has finite mean and variance can be approximated by a normal when the sample size is large enough. The CLT is somehow limited though because not all estimators are sums. Estimators are generally more or less complex combinations of sums. In order to derive the asymptotic approximation for a lot of estimators that are combinations of sums, econometricians and statisticians complement the CLT with two other extremely powerful tools: Slutsky’s theorem and the Delta method. Slutsky’s theorem states that sums, products and ratios of sums that converge to a normal converge to the sum, product or ratio of these normals. The Delta method states that a function of a sum that converges to a normal converges to a normal whose variance is a quadratic form of the variance of the sum and of the first derivative of the function. Both of these tools are stated more rigorously in the appendix, but you do not need to know them for this class. The idea is for you to be aware of how the main approximations that we are going to use throughout this class have been derived. Let me now state the main result of this section: Theorem 2.5 (Asymptotic Estimate of Sampling Noise of WW) Under Assumptions 1.7, 2.1, 2.2 and 2.3, for a given confidence level \\(\\delta\\) and sample size \\(N\\), the sampling noise of \\(\\hat{WW}\\) can be approximated as follows: \\[\\begin{align*} 2\\epsilon &amp; \\approx 2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}} \\equiv 2\\tilde{\\epsilon}. \\end{align*}\\] Proof. See in Appendix A.1.2. Let’s write an R function that computes this formula: samp.noise.ww.CLT &lt;- function(N,delta,v1,v0,p){ return(2*qnorm((delta+1)/2)*sqrt((v1/p+v0/(1-p))/N)) } Example 2.7 Let’s see how the CLT performs in our example. In our sample, for \\(\\delta=\\) 0.99, the CLT estimate of sampling noise is \\(\\hat{2\\tilde{\\epsilon}}=\\) 0.35. How does this compare with the true extent of sampling noise when \\(N=\\) 1000? Remember that we have computed an estimate of sampling noise out of our Monte Carlo replications. In Table 2.1, we can read that sampling noise is actually equal to 0.39. The CLT approximation is pretty precise: it only underestimates the true extent of sampling noise by 11%. We can also compute the CLT approximation to sampling noise in all of our samples: for (k in (1:length(N.sample))){ simuls.ww[[k]]$CLT.noise &lt;- samp.noise.ww.CLT(N.sample[[k]],delta,simuls.ww[[k]][,&#39;V1&#39;],simuls.ww[[k]][,&#39;V0&#39;],simuls.ww[[k]][,&#39;p&#39;]) } par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww[[i]][,&#39;CLT.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))),xlim=c(min(simuls.ww[[i]][,&#39;CLT.noise&#39;]),max(simuls.ww[[i]][,&#39;CLT.noise&#39;]))) abline(v=table.noise[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } Figure 2.10: Distribution of the CLT approximation of sampling noise over replications of samples of different sizes (true sampling noise in red) Figure 2.10 shows that the CLT works: CLT-based estimates of sampling noise approximates true sampling noise well. CLT-based approximations of sampling noise are even impressively accurate: they always capture the exact order of magnitude of sampling noise, although there is a slight underestimation when \\(N=\\) 1000 and 10^{4} and a slight overestimation when \\(N=\\) 10^{5}. This success should not come as a surprise as all shocks in our model are normally distributed, meaning that the CLT results are more than an approximation, they are exact. Results might be less spectacular when estimating the effect of the treatment on the outcomes in levels rather than in logs. As a consequence, the average CLT-based estimates of sampling noise and of confidence intervals are pretty precise, as Figures 2.11 and 2.12 show. Let’s pause for a second at the beauty of what we have achieved using the CLT: by using only information from one sample, we have been able to gauge extremely precisely how the estimator would behave over sampling repetitions. for (k in (1:length(N.sample))){ table.noise$CLT.noise[k] &lt;- mean(simuls.ww[[k]]$CLT.noise) } ggplot(table.noise, aes(x=as.factor(N), y=TT)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=TT-CLT.noise/2, ymax=TT+CLT.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 2.11: Average CLT-based approximations of sampling noise over replications of samples of different sizes (true sampling noise in red) N.plot &lt;- 40 plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.CLT &lt;- simuls.ww[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;CLT.noise&#39;)] test.CLT &lt;- as.data.frame(cbind(test.CLT,rep(samp.noise(simuls.ww[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.CLT) &lt;- c(&#39;WW&#39;,&#39;CLT.noise&#39;,&#39;sampling.noise&#39;) test.CLT$id &lt;- 1:N.plot plot.test.CLT &lt;- ggplot(test.CLT, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=WW-CLT.noise/2, ymax=WW+CLT.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.CLT } plot.CI &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI) Figure 2.12: CLT-based confidence intervals of \\(\\hat{WW}\\) for \\(\\delta=\\) 0.99 over sample replications for various sample sizes (true confidence intervals in red) Remark. In proving the main result on the asymptotic distribution of \\(\\hat{WW}\\), we have also proved a very useful result: \\(\\hat{WW}\\) is the Ordinary Least Squares (OLS) estimator of \\(\\beta\\) in the regression \\(Y_i=\\alpha+\\beta D_i + U_i\\). This is pretty cool since we now can use our classical OLS estimator in our statistical package to estimate \\(\\hat{WW}\\). Let’s compute the OLS estimate of \\(WW\\) in our sample: ols.ww &lt;- lm(y~Ds) ww.ols &lt;- ols.ww$coef[[2]] We have \\(\\hat{WW}_{OLS}=\\) 0.13 \\(=\\) 0.13 \\(=\\hat{WW}\\). Remark. Another pretty cool consequence of Theorem 2.5 and of its proof is that the standard error of the OLS estimator of \\(\\hat{WW}\\) (\\(\\sigma_{\\beta}\\)) is related to the sampling noise of \\(\\hat{WW}\\) by the following formula: \\(2\\tilde{\\epsilon}=2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\sigma_{\\beta}\\). This implies that sampling noise is equal to 5 \\(\\sigma_{\\beta}\\) when \\(\\delta=\\) 0.99 and to 4 \\(\\sigma_{\\beta}\\) when \\(\\delta=\\) 0.95. It is thus very easy to move from estimates of the standard error of the \\(\\beta\\) coefficient to the extent of sampling noise. Remark. A last important consequence of Theorem 2.5 and of its proof is that the standard error of the OLS estimator of \\(\\hat{WW}\\) (\\(\\sigma_{\\beta}\\)) that we use is the heteroskedasticity-robust one. Using the RCM, we can indeed show that: \\[\\begin{align*} \\alpha &amp; = \\esp{Y_i^0|D_i=0} \\\\ \\beta &amp; = \\Delta^Y_{TT} \\\\ U_i &amp; = Y^0_i-\\esp{Y^0_i|D_i=0} + D_i(\\Delta^Y_i-\\Delta^Y_{TT}), \\end{align*}\\] Under Assumption 1.7, we have: \\[\\begin{align*} U_i &amp; = (1-D_i)(Y^0_i-\\esp{Y^0_i|D_i=0}) + D_i(Y_i^1-\\esp{Y^1_i|D_i=1}) \\end{align*}\\] There is heteroskedasticity because the outcomes of the treated and of the untreated have different variances: \\[\\begin{align*} \\var{U_i|D_i=d} &amp; = \\esp{U_i^2|D_i=d} \\\\ &amp; = \\esp{(Y^d_i-\\esp{Y^d_i|D_i=d})^2|D_i=d} \\\\ &amp; = \\var{Y_i^d|D_i=d} \\end{align*}\\] We do not want to assume homoskedasticity, since it would imply a constant treatment effect. Indeed, \\(\\var{Y_i^1|D_i=1} = \\var{Y_i^0|D_i=1}+\\var{\\alpha_i|D_i=1}\\). Remark. In order to estimate the heteroskedasticity robust standard error from the OLS regression, we can use the sandwich package in R Most available heteroskedasticity robust estimators based on the CLT can be written in the following way: \\[\\begin{align*} \\var{\\hat{\\Theta}_{OLS}} &amp; \\approx (X&#39;X)^{-1}X&#39;\\hat{\\Omega}X(X&#39;X)^{-1}, \\end{align*}\\] where \\(X\\) is the matrix of regressors and \\(\\hat{\\Omega}=\\diag(\\hat{\\sigma}^2_{U_1},\\dots,\\hat{\\sigma}^2_{U_N})\\) is an estimate the covariance matrix of the residuals \\(U_i\\). Here are various classical estimators for \\(\\hat{\\Omega}\\): \\[\\begin{align*} \\text{HC0:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\hat{U_i}^2 \\\\ \\text{HC1:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{N}{N-K}\\hat{U_i}^2 \\\\ \\text{HC2:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{\\hat{U_i}^2}{1-h_i} \\\\ \\text{HC3:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{\\hat{U_i}^2}{(1-h_i)^2}, \\end{align*}\\] where \\(\\hat{U}_i\\) is the residual from the OLS regression, \\(K\\) is the number of regressors, \\(h_i\\) is the leverage of observation \\(i\\), and is the \\(i^{\\text{th}}\\) diagonal element of \\(H=X(X&#39;X)^{-1}X&#39;\\). HC1 is the one reported by Stata when using the ‘robust’ option. Example 2.8 Using the sandwich package, we can estimate the heteroskedasticity-robust variance-covariance matrix and sampling noise as follows: ols.ww.vcov.HC0 &lt;- vcovHC(ols.ww, type = &quot;HC0&quot;) samp.noise.ww.CLT.ols &lt;- function(delta,reg,...){ return(2*qnorm((delta+1)/2)*sqrt(vcovHC(reg,...)[2,2])) } For \\(\\delta=\\) 0.99, sampling noise estimated using the “HC0” option is equal to 0.35. This is exactly the value we have estimated using our CLT-based formula (\\(\\hat{2\\tilde{\\epsilon}}=\\) 0.35). Remember that sampling noise is actually equal to 0.39. Other “HC” options might be better in small samples. For example, with the “HC1” option, we have an estimate for sampling noise of 0.35. What would have happened to our estimate of sampling noise if we had ignored heteroskedasticity? The default OLS standard error estimate yields an estimate for sampling noise of 0.36. 2.2.4 Using resampling methods The main intuition behind resampling methods is to use the sample as a population, to draw samples from it and compute our estimator on each of these samples in order to gauge its variability over sampling repetitions. There are three main methods of resampling that work that way: bootstrapping, radomization inference and subsampling. Bootstrapping draws samples with replacement, so that each sample has the same size as the original sample. Subsampling draws samples without replacement, thereby the samples are of a smaller size than the original one. Randomization inference keeps the same sample in all repetitions, but changes the allocation of the treatment. Why would we use resampling methods instead of CLT-based standard errors? There are several possible reasons: Asymptotic refinements: sometimes, resampling methods are more precise in small samples than the CLT-based asymptotic approaches. In that case, we say that resampling methods offer asymptotic refinements. Ease of computation: for some estimators, the CLT-based estimates of sampling noise are complex or cumbersome to compute, whereas resampling methods are only computationally intensive. Inexistence of CLT-based estimates of sampling noise: some estimators do not have any CLT-based estimates of sampling noise yet. That was the case for the Nearest-Neighbour Matching estimator (NNM) for a long time for example. It still is the case for the Synthetic Control Method estimator. Beware though that the bootstrap is not valid for all estimators. For example, it is possible to show that the bootstrap is invalid for NNM. Subsampling is valid for NNM though (see Abadie and Imbens, 2006). 2.2.4.1 Bootstrap The basic idea of the bootstrap is to use Monte Carlo replications to draw samples from the original sample with replacement. Then, at each replication, we compute the value of our estimator \\(\\hat{E}\\) on the new sample. Let’s call this new value \\(\\hat{E}^*_k\\) for bootstrap replication \\(k\\). Under certain conditions, the distribution of \\(\\hat{E}^*_k\\) approximates the distribution of \\(\\hat{E}\\) over sample repetitions very well, and all the more so as the sample size gets large. What are the conditions under which the bootstrap is going to provide an accurate estimation of the distribution of \\(\\hat{E}\\)? Horowitz (2001) reports on a very nice result by Mammen that makes these conditions clear: Theorem 2.6 (Mammen (1992)) Let \\(\\left\\{X_i:i=1,\\dots,N\\right\\}\\) be a random sample from a population. For a sequence of functions \\(g_N\\) and sequences of numbers \\(t_N\\) and \\(\\sigma_N\\), define \\(\\bar{g}_N=\\frac{1}{N}\\sum_{i=1}^Ng_N(X_i)\\) and \\(T_N=(\\bar{g}_N-t_N)/\\sigma_N\\). For the bootstrap sample \\(\\left\\{X^*_i:i=1,\\dots,N\\right\\}\\), define \\(\\bar{g}^*_N=\\frac{1}{N}\\sum_{i=1}^Ng_N(X^*_i)\\) and \\(T^*_N=(\\bar{g}^*_N-\\bar{g}_N)/\\sigma_N\\). Let \\(G_N(\\tau)=\\Pr(T_N\\leq\\tau)\\) and \\(G^*_N(\\tau)=\\Pr(T^*_N\\leq\\tau)\\), where this last probability distribution is taken over bootstrap sampling replications. Then \\(G^*_N\\) consistently estimates \\(G_N\\) if and only if \\(T_N\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,1)\\). Theorem 2.6 states that the bootstrap will offer a consistent estimation of the distribution of a given estimator if and only if this estimator is asymptotically normally distributed. It means that we could theoretically use the CLT-based asymptotic distribution to compute sampling noise. So, and it demands to be stronlgy emphasized, . How do we estimate sampling noise with the bootstrap? There are several ways to do so, but I am going to emphasize the most widespread here, that is known as the percentile method. Let’s define \\(E^*_{\\frac{1-\\delta}{2}}\\) and \\(E^*_{\\frac{1+\\delta}{2}}\\) as the corresponding quantiles of the bootstrap distribution of \\(\\hat{E}^*_k\\) over a large number \\(K\\) of replications. The bootstrapped sampling noise using the percentile method is simply the distance between these two quantities. Theorem 2.7 (Bootstrapped Estimate of Sampling Noise of WW) Under Assumptions 1.7, 2.1, 2.2 and 2.3, for a given confidence level \\(\\delta\\) and sample size \\(N\\), the sampling noise of \\(\\hat{WW}\\) can be approximated as follows: \\[\\begin{align*} 2\\epsilon &amp; \\approx E^*_{\\frac{1+\\delta}{2}}-E^*_{\\frac{1-\\delta}{2}} \\equiv 2\\tilde{\\epsilon}^b. \\end{align*}\\] Proof. The \\(WW\\) estimator can be written as a sum: \\[\\begin{align*} \\hat{\\Delta^Y_{WW}} &amp; = \\frac{1}{N}\\sum_{i=1}^N\\frac{\\left(Y_i-\\frac{1}{N}\\sum_{i=1}^NY_i\\right)\\left(D_i-\\frac{1}{N}\\sum_{i=1}^ND_i\\right)}{\\frac{1}{N}\\sum_{i=1}^N\\left(D_i-\\frac{1}{N}\\sum_{i=1}^ND_i\\right)^2}. \\end{align*}\\] Using Lemma A.5, we know that the \\(WW\\) estimator is asymptotically normal under Assumptions 1.7, ??, 2.2 and ??. Using Theorem 2.6 proves the result. Remark. With the bootstrap, we are not going to define the confidence interval using Theorem 2.1 but directly using \\(\\left\\{E^*_{\\frac{1-\\delta}{2}};E^*_{\\frac{1+\\delta}{2}}\\right\\}\\). Indeed, we have defined the bootstrapped estimator of sampling noise by using the asymetric confidence interval. We could have used the equivalent of Definition 2.1 on the bootstrapped samples to compute sampling noise using the symmetric confidence interval. Both are feasible and similar in large samples, since the asymptotic distribution is symmetric. One advantage of asymetric confidence intervals is that they might capture deviations from the normal distribution in small samples. These advantages are part of what we call asymptotic refinements. Rigorously, though, asymptotic refinements have not been proved to exist for the percentile method but only for the method bootstrapping asymptotically pivotal quantities. Remark. We say that a method brings asymptotic refinements if it increases the precision when estimating sampling noise and confidence intervals relative to the asymptotic CLT-based approximation. The bootstrap has been shown rigorously to bring asymptotic refinements when used to estimate the distribution of asymptotically pivotal statistic. An asymptotically pivotal statistic is a statistic that can be computed from the sample but that, asymptotically, converges to a quantity that does not depend on the sample, like for example a standard normal. Using Lemma A.5, we know for example that the following statistic is asymptotically normal: \\[\\begin{align*} T_N^{WW} &amp; = \\frac{\\hat{\\Delta^Y_{WW}}-\\Delta^Y_{TT}}{\\sqrt{\\frac{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}{N}}} \\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(0,1\\right). \\end{align*}\\] To build a confidence interval bootstrapping \\(T_N^{WW}\\), compute an estimator of \\(T_N^{WW}\\) for each bootstrapped sample, say \\(\\hat{T}_{N,k}^{WW*}\\). You can for example use the OLS estimator in the bootstrapped sample, with a heteroskedasticity-robust standard error estimator. Or you can compute the \\(WW\\) estimator by hand in the sample along with an estimator of its variance using the variance of the outcomes in the treated and control groups. You can then estimate the confidence interval as follows: \\(\\left\\{\\hat{\\Delta^Y_{WW}}-\\hat{\\sigma_{WW}}\\hat{T}^{WW*}_{N,\\frac{1-\\delta}{2}};\\hat{\\Delta^Y_{WW}}+\\hat{\\sigma_{WW}}\\hat{T}^{WW*}_{N,\\frac{1+\\delta}{2}}\\right\\}\\), where \\(\\hat{T}^{WW*}_{N,q}\\) iq the \\(q^{\\text{th}}\\) quantile of the distribution of \\(\\hat{T}_{N,k}^{WW*}\\) over sampling replications and \\(\\hat{\\sigma_{WW}}\\) is an estimate of the variance of \\(\\hat{\\Delta^Y_{WW}}\\) (either the CLT-based approximation of the bootstrapped one, see below). Remark. One last possibility to develop an estimator for sampling noise and confidence interval is to use the bootstrap in order to estimate the variance of the estimator \\(\\hat{E}\\), \\(\\hat{\\sigma^2_{E}}\\), and then use it to compute sampling noise. If \\(\\hat{E}\\) is asymptotically normally distributed, we have that sampling noise is equal to \\(2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\hat{\\sigma_{E}}\\). You can use the usual formula from Theore 2.1 to compute the confidence interval. The bootstrapped variance of \\(\\hat{E}\\), \\(\\hat{\\sigma^2_{E}}\\), is simply the variance of \\(\\hat{E}^*_k\\) over bootstrap replications. Example 2.9 In the numerical example, I am going to derive the bootstrapped confidence intervals and sampling noise for the percentile method. Let’s first put the dataset from our example in a nice data frame format so that resampling is made easier. We then define a function taking a number of bootstrapped replications and spitting out sampling noise and confidence intervals. data &lt;- as.data.frame(cbind(y,Ds,yB)) boot.fun.ww.1 &lt;- function(seed,data){ set.seed(seed,kind=&quot;Wichmann-Hill&quot;) data &lt;- data[sample(nrow(data),replace = TRUE),] ols.ww &lt;- lm(y~Ds,data=data) ww &lt;- ols.ww$coef[[2]] return(ww) } boot.fun.ww &lt;- function(Nboot,data){ #sfInit(parallel=TRUE,cpus=8) boot &lt;- lapply(1:Nboot,boot.fun.ww.1,data=data) #sfStop() return(unlist(boot)) } boot.CI.ww &lt;- function(boot,delta){ return(c(quantile(boot,prob=(1-delta)/2),quantile(boot,prob=(1+delta)/2))) } boot.samp.noise.ww &lt;- function(boot,delta){ return(quantile(boot,prob=(1+delta)/2)-quantile(boot,prob=(1-delta)/2)) } Nboot &lt;- 500 ww.boot &lt;- boot.fun.ww(Nboot,data) ww.CI.boot &lt;- boot.CI.ww(ww.boot,delta) ww.samp.noise.boot &lt;- boot.samp.noise.ww(ww.boot,delta) Over 500 replications, the 99% bootstrapped confidence interval using the percentile method is \\(\\left\\{-0.027;0.295\\right\\}\\). As a consequence, the bootstrapped estimate of 99% sampling noise is of 0.321. Remember that, with \\(N=\\) 1000, sampling noise is actually equal to 0.39. In order to assess the global precision of bootstrapping, we are going to resort to Monte Carlo simulations. For each Monte Carlo sample, we are going to estimate sampling noise and confidence intervals using the bootstrap. As you can imagine, this is going to prove rather computationally intensive. I cannot use parallelization twice: I have to choose whether to parallelize the Monte Carlo simulations or the bootstrap simulations. I have choosen to parallelize the outer loop, so that a given job takes longer on each cluster. monte.carlo.ww.boot &lt;- function(s,N,param,Nboot,delta){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) data &lt;- as.data.frame(cbind(y,Ds,yB)) ww.boot &lt;- boot.fun.ww(Nboot,data) ww.CI.boot &lt;- boot.CI.ww(ww.boot,delta) ww.samp.noise.boot &lt;- boot.samp.noise.ww(ww.boot,delta) return(c((1/sum(Ds))*sum(y*Ds)-(1/sum(1-Ds))*sum(y*(1-Ds)),var(y[Ds==1]),var(y[Ds==0]),mean(Ds),ww.CI.boot[[1]],ww.CI.boot[[2]],ww.samp.noise.boot)) } sf.simuls.ww.N.boot &lt;- function(N,Nsim,Nboot,delta,param){ sfInit(parallel=TRUE,cpus=2*ncpus) sfExport(&quot;boot.fun.ww&quot;,&quot;boot.CI.ww&quot;,&quot;boot.samp.noise.ww&quot;,&quot;boot.fun.ww.1&quot;) sim &lt;- as.data.frame(matrix(unlist(sfLapply(1:Nsim,monte.carlo.ww.boot,N=N,Nboot=Nboot,delta=delta,param=param)),nrow=Nsim,ncol=7,byrow=TRUE)) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;,&#39;V1&#39;,&#39;V0&#39;,&#39;p&#39;,&#39;boot.lCI&#39;,&#39;boot.uCI&#39;,&#39;boot.samp.noise&#39;) return(sim) } simuls.ww.boot &lt;- lapply(N.sample,sf.simuls.ww.N.boot,Nsim=Nsim,param=param,Nboot=Nboot,delta=delta) We can now graph our bootstrapped estimate of sampling noise in all of our samples, the average bootstrapped estimates of sampling noise and of confidence intervals, in Figures 2.13, 2.14 and 2.15 show. par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww.boot[[i]][,&#39;boot.samp.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))),xlim=c(min(simuls.ww.boot[[i]][,&#39;boot.samp.noise&#39;]),max(simuls.ww.boot[[i]][,&#39;boot.samp.noise&#39;]))) abline(v=table.noise[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } Figure 2.13: Distribution of the bootstrapped approximation of sampling noise over replications of samples of different sizes (true sampling noise in red) for (k in (1:length(N.sample))){ table.noise$boot.noise[k] &lt;- mean(simuls.ww.boot[[k]]$boot.samp.noise) } ggplot(table.noise, aes(x=as.factor(N), y=TT)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=TT-boot.noise/2, ymax=TT+boot.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 2.14: Average bootstrapped approximations of sampling noise over replications of samples of different sizes (true sampling noise in red) N.plot &lt;- 40 plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.boot &lt;- simuls.ww.boot[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;boot.lCI&#39;,&#39;boot.uCI&#39;)] test.boot &lt;- as.data.frame(cbind(test.boot,rep(samp.noise(simuls.ww.boot[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.boot) &lt;- c(&#39;WW&#39;,&#39;boot.lCI&#39;,&#39;boot.uCI&#39;,&#39;sampling.noise&#39;) test.boot$id &lt;- 1:N.plot plot.test.boot &lt;- ggplot(test.boot, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=boot.lCI, ymax=boot.uCI), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.boot } plot.CI &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI) Figure 2.15: Bootstrapped confidence intervals of \\(\\hat{WW}\\) for \\(\\delta=\\) 0.99 over sample replications for various sample sizes (true confidence intervals in red) TO DO: COMMENT AND USE PIVOTAL TEST STATISTIC 2.2.4.2 Randomization inference Randomization inference (a.k.a. Fisher’s permutation approach) tries to mimick the sampling noise due to the random allocation of the treatment vector, as we have seen in Section 2.1.3. In practice, the idea is simply to look at how the treatment effect that we estimate varies when we visit all the possible allocations of the treament dummy in the sample. For each new allocation, we are going to compute the with/without estimator using the observed outcomes and the newly allocated treatment dummy. It means that some actually treated observations are going to enter into the computation of the control group mean, while some actually untreated observations are going to enter into the computation of the treatment group mean. As a consequence, the resulting distribution will be centered at zero. Under the assumption of a constant treatment effect, the distribution of the parameter obtained using randomization inference will be an exact estimation of sampling noise for the sample treatment effect. Notice how beautilful the result is: randomization inference yields an measure of sampling noise. The resulting estimate of sampling noise is not an approximation that is going to become better as sample size increases. No, it is the value of sampling noise in the sample. There are two ways to compute a confidence interval using Fisher’s permutation approach. One is to form symmetric intervals using our estimate of sampling noise as presented in Section 2.1.4. Another approach is to directly use the quantiles of the distribution of the parameter centered around the estimated treatment effect, in the same spirit as bootstrapped confidence intervals using the percentile approach. This last approach accomodates possible asymetries in the finite sample distribution of the treatment effect. Computing the value of the treatment effect for all possible treatment allocations can take a lot of time with large samples. That’s why we in general compute the test statistic for a reasonably large number of random allocations. Remark. Fisher’s original approach is slightly different from the one I delineate here. Fisher wanted to derive a test statistic for whether the treatment effect was zero, not to estimate sampling noise. Under the null that the treatment has absolutely no effect whatsoever on any unit, any test statistic whose value should be zero if the two distributions where identical can be computed on the actual sample and its distribution can be derived using Fisher’s permutation approach. The test statistic can be the difference in means, standard deviations, medians, ranks, the T-stat, the Kolmogorov-Smirnov test statistic or any other test statistic that you might want to compute. Comparing the actual value of the test statistic to its distribution under the null gives a p-value for the validity of the null. Remark. Imbens and Rubin propose a more complex procedure to derive the confidence interval for the treatment effect using randomization inference. They propose to compute Fisher’s p-value for different values of the treatment effect, and to set the confidence interval as the values of the treatment effect under and above which the p-value is smaller than \\(\\delta\\). When using the with/without estimator as the test statistic, the two approches should be equivalent. Is is possible that the estimates using statistics less influenced by outliers are more precise though. Remark. Note that we pay two prices for having an exact estimation of sampling noise: We have to assume that the treatment effect is constant, e.g. we have to assume homoskedasticity. This is in general not the case. Whether this is in general a big issue depends on how large the difference is between homoskedastic and heteroskedastic standard errors. One way around this issue would be to add a small amount of noise to the observations that are in the group with the lowest variance. Whether this would work in practice is still to be demonstrated. We have to be interested only in the sampling noise of the sample treatment effect. The sampling noise of the population treatment effect is not estimated using Fisher’s permutation approach. As we have seen in Section 2.1.3, there is no practical difference between these two sampling noises in our example. Whether this is the case in general deserves further investigation. Example 2.10 In practice, randomization inference is very close to a bootstrap procedure, except that instead of resampling with replacement from the original sample, we only change the vector of treatment allocation at each replication. fisher.fun.ww.1 &lt;- function(seed,data){ set.seed(seed,kind=&quot;Wichmann-Hill&quot;) data$D &lt;- rbinom(nrow(data),1,mean(data$Ds)) ols.ww &lt;- lm(y~D,data=data) ww &lt;- ols.ww$coef[[2]] return(ww) } fisher.fun.ww &lt;- function(Nfisher,data,delta){ fisher &lt;- unlist(lapply(1:Nfisher,fisher.fun.ww.1,data=data)) ols.ww &lt;- lm(y~Ds,data=data) ww &lt;- ols.ww$coef[[2]] fisher &lt;- fisher+ ww fisher.CI.ww &lt;- c(quantile(fisher,prob=(1-delta)/2),quantile(fisher,prob=(1+delta)/2)) fisher.samp.noise.ww &lt;- quantile(fisher,prob=(1+delta)/2)-quantile(fisher,prob=(1-delta)/2) return(list(fisher,fisher.CI.ww,fisher.samp.noise.ww)) } Nfisher &lt;- 500 ww.fisher &lt;- fisher.fun.ww(Nfisher,data,delta) Over 500 replications, the 99% confidence interval based on Fisher’s permutation approach is \\(\\left\\{-0.052;0.3\\right\\}\\). As a consequence, the bootstrapped estimate of 99% sampling noise is of 0.352. Remember that, with \\(N=\\) 1000, sampling noise is actually equal to 0.39. In order to assess the global precision of Fisher’s permutation method, we are going to resort to Monte Carlo simulations. monte.carlo.ww.fisher &lt;- function(s,N,param,Nfisher,delta){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) data &lt;- as.data.frame(cbind(y,Ds,yB)) ww.fisher &lt;- fisher.fun.ww(Nfisher,data,delta) return(c((1/sum(Ds))*sum(y*Ds)-(1/sum(1-Ds))*sum(y*(1-Ds)),var(y[Ds==1]),var(y[Ds==0]),mean(Ds),ww.fisher[[2]][1],ww.fisher[[2]][2],ww.fisher[[3]])) } sf.simuls.ww.N.fisher &lt;- function(N,Nsim,Nfisher,delta,param){ sfInit(parallel=TRUE,cpus=2*ncpus) sfExport(&quot;fisher.fun.ww&quot;,&quot;fisher.fun.ww.1&quot;) sim &lt;- as.data.frame(matrix(unlist(sfLapply(1:Nsim,monte.carlo.ww.fisher,N=N,Nfisher=Nfisher,delta=delta,param=param)),nrow=Nsim,ncol=7,byrow=TRUE)) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;,&#39;V1&#39;,&#39;V0&#39;,&#39;p&#39;,&#39;fisher.lCI&#39;,&#39;fisher.uCI&#39;,&#39;fisher.samp.noise&#39;) return(sim) } simuls.ww.fisher &lt;- lapply(N.sample,sf.simuls.ww.N.fisher,Nsim=Nsim,param=param,Nfisher=Nfisher,delta=delta) We can now graph our bootstrapped estimate of sampling noise in all of our samples, the average bootstrapped estimates of sampling noise and of confidence intervals, as Figures 2.16, 2.17 and 2.18 show. The results are pretty good. On average, estimates of sampling noise using Randomization Inference are pretty accurate, as Figure 2.17 shows. It seems that sampling noise is underestimated by Randomization Inference when \\(N=\\) 1000, without any clear reason why. par(mfrow=c(2,2)) for (i in 1:4){ hist(simuls.ww.fisher[[i]][,&#39;fisher.samp.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))),xlim=c(min(simuls.ww.fisher[[i]][,&#39;fisher.samp.noise&#39;]),max(simuls.ww.fisher[[i]][,&#39;fisher.samp.noise&#39;]))) abline(v=table.noise[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } Figure 2.16: Distribution of the estimates of sampling noise using Randomization Inference over replications of samples of different sizes (true sampling noise in red) for (k in (1:length(N.sample))){ table.noise$fisher.noise[k] &lt;- mean(simuls.ww.fisher[[k]]$fisher.samp.noise) } ggplot(table.noise, aes(x=as.factor(N), y=TT)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=TT-sampling.noise/2, ymax=TT+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=TT-fisher.noise/2, ymax=TT+fisher.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 2.17: Average estimates of sampling noise using Randomization Inference over replications of samples of different sizes (true sampling noise in red) N.plot &lt;- 40 plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.fisher &lt;- simuls.ww.fisher[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;fisher.lCI&#39;,&#39;fisher.uCI&#39;)] test.fisher &lt;- as.data.frame(cbind(test.fisher,rep(samp.noise(simuls.ww.fisher[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.fisher) &lt;- c(&#39;WW&#39;,&#39;fisher.lCI&#39;,&#39;fisher.uCI&#39;,&#39;sampling.noise&#39;) test.fisher$id &lt;- 1:N.plot plot.test.fisher &lt;- ggplot(test.fisher, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=fisher.lCI, ymax=fisher.uCI), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.fisher } plot.CI &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI) Figure 2.18: Confidence intervals of \\(\\hat{WW}\\) for \\(\\delta=\\) 0.99 estimated using Randomization Inference over sample replications for various sample sizes (true confidence intervals in red) TO DO: ALTERNATIVE APPROACH USING p-VALUES 2.2.4.3 Subsampling TO DO: ALL "],["RCT.html", "Chapter 3 Randomized Controlled Trials 3.1 Brute Force Design 3.2 Self-Selection design 3.3 Eligibility design 3.4 Encouragement Design", " Chapter 3 Randomized Controlled Trials The most robust and rigorous method that has been devised by social scientists to estimate the effect of an intervention on an outcome is the Randomized Controlled Trial (RCT). RCTs are used extensively in the field to evaluate a wide array of programs, from development, labor and education interventions to environmental nudges to website and search engine features. The key feature of an RCT is the introduction by the researcher of randomness in the allocation of the treatment. Individuals with \\(R_i=1\\), where \\(R_i\\) denotes the outcome of a random event, such as a coin toss, have a higher probability of receiving the treatment. Potential outcomes have the same distribution in both \\(R_i=1\\) and \\(R_i=0\\) groups. If we observe different outcomes between the treatment and control group, it has to be because of the causal effect of the treatment, since both groups only differ by the proportion of treated and controls. The most attractive feature of RCTs is that researchers enforce the main identification assumption (we do not have to assume that it holds, we can make sure that it does). This property of RCTs distinguishes them from all the other methods that we are going to learn in this class. In this lecture, we are going to study how to estimate the effect of an intervention on an outcome using RCTs. We are especially going to study the various types of designs and what can be recovered from them using which technique. For each design, we are going to detail which treatment effect it enables us to identify, how to obtain a sample estimate of this treatment effect and how to estimate the associated sampling noise. The main substantial difference between these four designs are the types of treatment effect parameters that they enable us to recover. Sections 3.1 to 3.4 of this lecture introduces the four designs and how to analyze them. Unfortunately, RCTs are not bullet proof. They suffer from problems that might make their estimates of causal effects badly biased. Section ?? surveys the various threats and what we can do to try to minimize them. 3.1 Brute Force Design In the Brute Force Design, eligible individuals are randomly assigned to the treatment irrespective of their willingness to accept it and have to comply with the assignment. This is a rather dumb procedure but it is very easy to analyze and that is why I start with it. With the Brute Force Design, you can recover the average effect of the treatment on the whole population. This parameter is generally called the Average Treatment Effect (ATE). In this section, I am going to detail the assumptions required for the Brute Force Design to identify the ATE, how to form an estimator of the ATE and how to estimate its sampling noise. 3.1.1 Identification In the Brute Force Design, we need two assumptions for the ATE to be identified in the population: Independence and Brute Force Validity. Definition 3.1 (Independence) We assume that the allocation of the program is independent of potential outcomes: \\[\\begin{align*} R_i\\Ind(Y_i^0,Y_i^1). \\end{align*}\\] Here, \\(\\Ind\\) codes for independence or random variables. Independence can be enforced by the randomized allocation. We need a second assumption for the Brute Force Design to work: Definition 3.2 (Brute Force Validity) We assume that the randomized allocation of the program is mandatory and does not interfere with how potential outcomes are generated: \\[\\begin{align*} Y_i &amp; = \\begin{cases} Y_i^1 &amp; \\text{ if } R_i=1 \\\\ Y_i^0 &amp; \\text{ if } R_i=0 \\end{cases} \\end{align*}\\] with \\(Y_i^1\\) and \\(Y_i^0\\) the same potential outcomes as defined in Lecture~0 with a routine allocation of the treatment. Under both Idependence and Brute Force Validity, we have the follwing result: Theorem 3.1 (Identification in the Brute Force Design) Under Assumptions 3.1 and 3.2, the WW estimator identifies the Average Effect of the Treatment (ATE): \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\Delta^Y_{ATE}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\esp{Y_i|R_i=1} - \\esp{Y_i|R_i=0} \\\\ \\Delta^Y_{ATE} &amp; = \\esp{Y_i^1-Y_i^0}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{WW} &amp; = \\esp{Y_i|R_i=1} - \\esp{Y_i|R_i=0} \\\\ &amp; = \\esp{Y^1_i|R_i=1} - \\esp{Y^0_i|R_i=0} \\\\ &amp; = \\esp{Y_i^1}-\\esp{Y_i^0}\\\\ &amp; = \\esp{Y_i^1-Y_i^0}, \\end{align*}\\] where the first equality uses Assumption 3.2, the second equality Assumption 3.1 and the last equality the linearity of the expectation operator. Remark. As you can see from Theorem 3.1, ATE is the average effect of the treatment on the whole population, those who would be eligible for it and those who would not. ATE differs from TT because the effect of the treatment might be correlated with treatment intake. It is possible that the treatment has a bigger (resp. smaller) effect on treated individuals. In that case, ATE is higher (resp. smaller) than TT. Remark. Another related design is the Brute Force Design among Eligibles. In this design, you impose the treatment status only among eligibles, irrespective of whether they want the treatment or not. It can be operationalized using the selection rule used in Section 3.2. Example 3.1 Let’s use the example to illustrate the concept of ATE. Let’s generate data with our usual parameter values without allocating the treatment yet: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) In the sample, the ATE is the average difference between \\(y_i^1\\) and \\(y_i^0\\), or – the expectation operator being linear – the difference between average \\(y_i^1\\) and average \\(y_i^0\\). In our sample, the former is equal to 0.179 and the latter to 0.179. In the population, the ATE is equal to: \\[\\begin{align*} \\Delta^y_{ATE} &amp; = \\esp{Y_i^1-Y_i^0} \\\\ &amp; = \\esp{\\alpha_i} \\\\ &amp; = \\bar{\\alpha}+\\theta\\bar{\\mu}. \\end{align*}\\] Let’s write a function to compute the value of the ATE and of TT (we derived the formula for TT in the previous lecture): delta.y.ate &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]) } delta.y.tt &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;theta&quot;]*((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } In the population, with our parameter values, \\(\\Delta^y_{ATE}=\\) 0.18 and \\(\\Delta^y_{TT}=\\) 0.172. In our case, selection into the treatment is correlated with lower outcomes, so that \\(TT\\leq ATE\\). In order to implement the Brute Force Design in practice in a sample, we simply either draw a coin repeatedly for each member of the sample, assigning for example, all “heads” to the treatment and all “tails” to the control. Because it can be a little cumbersome, it is possible to replace the coin toss by a pseudo-Random Number Generator (RNG), which is is an algorithm that tries to mimic the properties of random draws. When generating the samples in the numerical exmples, I actually use a pseudo-RNG. For example, we can draw from a uniform distribution on \\([0,1]\\) and allocate to the treatment all the individuals whose draw is smaller than 0.5: \\[\\begin{align*} R_i^* &amp; \\sim \\mathcal{U}[0,1]\\\\ R_i &amp; = \\begin{cases} 1 &amp; \\text{ if } R_i^*\\leq .5 \\\\ 0 &amp; \\text{ if } R_i^*&gt; .5 \\end{cases} \\end{align*}\\] The advantage of using a uniform law is that you can set up proportions of treated and controls easily. Example 3.2 In our numerical example, the following R code generates two random groups, one treated and one control, and imposes the Assumption of Brute Force Validity: # randomized allocation of 50% of individuals Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) Remark. It is interesting to stop for one minute to think about how the Brute Force Design solves the FPCI. First, with the ATE, the counterfactual problem is more severe than in the case of the TT. In the routine mode of the program, where only eligible individuals receive the treatment, both parts of the ATE are unobserved: \\(\\esp{Y_i^1}\\) is unobserved since we only observe the expected value of outcomes for the treated \\(\\esp{Y_i^1|D_i=1}\\), and they do not have to be the same. \\(\\esp{Y_i^0}\\) is unobserved since we only observe the expected value of outcomes for the untreated \\(\\esp{Y_i^0|D_i=0}\\), and they do not have to be the same. What the Brute Force Design does, is that it allocates randomly one part of the sample to the treatment, so that we see \\(\\esp{Y_i^1|R_i=1}=\\esp{Y_i^1}\\) and one part to the control so that we see \\(\\esp{Y_i^0|R_i=0}=\\esp{Y_i^0}\\). 3.1.2 Estimating ATE 3.1.2.1 Using the WW estimator In order to estimate ATE in a sample where the treatment has been randomized using a Brute Force Design, we simply use the sample equivalent of the With/Without estimator: \\[\\begin{align*} \\hat{\\Delta}^Y_{WW} &amp; = \\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N Y_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N Y_i(1-R_i). \\end{align*}\\] Example 3.3 In our numerical example, the WW estimator can be computed as follows in the sample: delta.y.ww &lt;- mean(y[R==1])-mean(y[R==0]) The WW estimator of the ATE in the sample is equal to 0.156. Let’s recall that the true value of ATE is 0.18 in the population and 0.179 in the sample. We can also see in our example how the Brute Force Design approximates the counterfactual expectation \\(\\esp{y_i^1}\\) and its sample equivalent mean \\(\\frac{1}{\\sum_{i=1}^N}\\sum_{i=1}^N y^1_i\\) by the observed mean in the treated sample \\(\\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N y_iR_i\\). In our example, the sample value of the counterfactual mean potential outcome \\(\\frac{1}{\\sum_{i=1}^N}\\sum_{i=1}^N y^1_i\\) is equal to 8.222 and the sample value of its observed counterpart is 8.209. Similarly, the sample value of the counterfactual mean potential outcome \\(\\frac{1}{\\sum_{i=1}^N}\\sum_{i=1}^N y^0_i\\) is equal to 8.043 and the sample value of its observed counterpart is 8.054. 3.1.2.2 Using OLS As we have seen in Lecture 0, the WW estimator is numerically identical to the OLS estimator of a linear regression of outcomes on treatment: The OLS coefficient \\(\\beta\\) in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + U_i \\end{align*}\\] is the WW estimator. Example 3.4 In our numerical example, we can run the OLS regression as follows: reg.y.R.ols &lt;- lm(y~R) \\(\\hat{\\Delta}^y_{OLS}=\\) 0.156 which is exactly equal, as expected, to the WW estimator: 0.156. 3.1.2.3 Using OLS conditioning on covariates The advantage of using OLS other the direct WW comparison is that it gives you a direct estimate of sampling noise (see next section) but also that it enables you to condition on additional covariates in the regression: The OLS coefficient \\(\\beta\\) in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + \\gamma&#39; X_i + U_i \\end{align*}\\] is a consistent (and even unbiased) estimate of the ATE. proof needed, especially assumption of linearity. Also, is interaction between \\(X_i\\) and \\(R_i\\) needed? Example 3.5 In our numerical example, we can run the OLS regression conditioning on \\(y_i^B\\) as follows: reg.y.R.ols.yB &lt;- lm(y~R + yB) \\(\\hat{\\Delta}^y_{OLSX}=\\) 0.177. Note that \\(\\hat{\\Delta}^y_{OLSX}\\neq\\hat{\\Delta}^y_{WW}\\). There is no numerical equivalence between the two estimators. Remark. Why would you want to condition on covariates in an RCT? Indeed, covariates should be balanced by randomization and thus there does not seem to be a rationale for conditioning on potential confounders, since there should be none. The main reason why we condition on covariates is to decrease sampling noise. Remember that sampling noise is due to imbalances between confounders in the treatment and control group. Since these imbalances are not systematic, the WW estimator is unbiased. We can also make the bias due to these unbalances as small as we want by choosing an adequate sample size (the WW estimator is consistent). But for a given sample size, these imbalances generate sampling noise around the true ATE. Conditioning on covariates helps decrease sampling noise by accounting for imbalances due to observed covariates. If observed covariates explain a large part of the variation in outcomes, conditioning on them is going to prevent a lot of sampling noise from occuring. Example 3.6 In order to make the gains in precision from conditioning on covariates apparent, let’s use Monte Carlo simulations of our numerical example. monte.carlo.brute.force.ww &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # randomized allocation of 50% of individuals Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) reg.y.R.ols &lt;- lm(y~R) return(c(reg.y.R.ols$coef[2],sqrt(vcovHC(reg.y.R.ols,type=&#39;HC2&#39;)[2,2]))) } simuls.brute.force.ww.N &lt;- function(N,Nsim,param){ simuls.brute.force.ww &lt;- as.data.frame(matrix(unlist(lapply(1:Nsim,monte.carlo.brute.force.ww,N=N,param=param)),nrow=Nsim,ncol=2,byrow=TRUE)) colnames(simuls.brute.force.ww) &lt;- c(&#39;WW&#39;,&#39;se&#39;) return(simuls.brute.force.ww) } sf.simuls.brute.force.ww.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=2*ncpus) sfLibrary(sandwich) sim &lt;- as.data.frame(matrix(unlist(sfLapply(1:Nsim,monte.carlo.brute.force.ww,N=N,param=param)),nrow=Nsim,ncol=2,byrow=TRUE)) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;,&#39;se&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.brute.force.ww &lt;- lapply(N.sample,sf.simuls.brute.force.ww.N,Nsim=Nsim,param=param) names(simuls.brute.force.ww) &lt;- N.sample monte.carlo.brute.force.ww.yB &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # randomized allocation of 50% of individuals Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) reg.y.R.yB.ols &lt;- lm(y~R + yB) return(c(reg.y.R.yB.ols$coef[2],sqrt(vcovHC(reg.y.R.yB.ols,type=&#39;HC2&#39;)[2,2]))) } simuls.brute.force.ww.yB.N &lt;- function(N,Nsim,param){ simuls.brute.force.ww.yB &lt;- as.data.frame(matrix(unlist(lapply(1:Nsim,monte.carlo.brute.force.ww.yB,N=N,param=param)),nrow=Nsim,ncol=2,byrow=TRUE)) colnames(simuls.brute.force.ww.yB) &lt;- c(&#39;WW&#39;,&#39;se&#39;) return(simuls.brute.force.ww.yB) } sf.simuls.brute.force.ww.yB.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=2*ncpus) sfLibrary(sandwich) sim &lt;- as.data.frame(matrix(unlist(sfLapply(1:Nsim,monte.carlo.brute.force.ww.yB,N=N,param=param)),nrow=Nsim,ncol=2,byrow=TRUE)) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;,&#39;se&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.brute.force.ww.yB &lt;- lapply(N.sample,sf.simuls.brute.force.ww.yB.N,Nsim=Nsim,param=param) names(simuls.brute.force.ww.yB) &lt;- N.sample Figure 3.1: Distribution of the \\(WW\\) and \\(OLSX\\) estimators in a Brute Force design over replications of samples of different sizes Figure 3.1 shows that the gains in precision from conditioning on \\(y_i^B\\) are spectacular in our numerical example. They basically correspond to a gain in one order of magnitude of sample size: the precision of the \\(OLSX\\) estimator conditioning on \\(y_i^B\\) with a sample size of 100 is similar to the precision of the \\(OLS\\) estimator not conditioning on \\(y_i^B\\) with a sample size of \\(1000\\). This large gain in precision is largely due to the fact that \\(y_i\\) and \\(y_i^B\\) are highly correlated. Not all covariates perform so well in actual samples in the social sciences. Remark. The ability to condition on covariates in order to decrease sampling noise is a blessing but can also be a curse when combined with significance testing. Indeed, you can now see that you can run a lot of regressions (with and without some covariates, interactions, etc) and maybe report only the statistically significant ones. This is a bad practice that will lead to publication bias and inflated treatment effects. Several possibilities in order to avoid that: Pre-register your analysis and explain which covariates you are going to use (with which interactions, etc) so that you cannot cherry pick your favorite results ex-post. Use a stratified design for your RCT (more on this in Lecture 6) so that the important covariates are already balanced between treated and controls. If unable to do all of the above, report results from regressions without controls and with various sets of controls. We do not expect the various treatment effect estimates to be the same (they cannot be, otherwise, they would have similar sampling noise), but we expect the following pattern: conditioning should systematically decrease sampling noise, not increase the treatment effect estimate. If conditioning on covariates makes a treatment effect significant, pay attention to why: is it because of a decrease in sampling noise (expected and OK) or because of an increase in treatment effect (beware specification search). Revise that especially in light of Chapter ?? Remark. You might not be happy with the assumption of linearity needed to use OLS to control for covariates. I have read somewhere (forgot where) that this should not be much of a problem since covariates are well balanced between groups by randomization, and thus a linear first approximation to the function relating \\(X_i\\) to \\(Y_i\\) should be fine. I tend not to buy that argument much. I have to run simulations with a non linear relation between outcomes and controls and see how linear OLS performs. If you do not like the linearity assumption, you can always use any of the nonparametric observational methods presented in Chapter ??. 3.1.3 Estimating Sampling Noise In order to estimate sampling noise, you can either use the CLT-based approach or resampling, either using the bootstrap or randomization inference. In Section 2.2, we have already discussed how to estimate sampling noise when using the WW estimator that we are using here. We are going to use the default and heteroskedasticity-robust standard errors from OLS, which are both CLT-based. Only the heteroskedasticity-robust standard errors are valid under the assumptions that we have made so far. Homoskedasticity would require constant treatment effects. Heteroskedasticity being small in our numerical example, that should not matter much, but it could in other applications. Example 3.7 Let us first estimate sampling noise for the simple WW estimator without control variables, using the OLS estimator. sn.BF.simuls &lt;- 2*quantile(abs(simuls.brute.force.ww[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.ate(param)),probs=c(0.99)) sn.BF.OLS.hetero &lt;- 2*qnorm((delta+1)/2)*sqrt(vcovHC(reg.y.R.ols,type=&#39;HC2&#39;)[2,2]) sn.BF.OLS.homo &lt;- 2*qnorm((delta+1)/2)*sqrt(vcov(reg.y.R.ols)[2,2]) The true value of the 99% sampling noise with a sample size of 1000 and no control variables is stemming from the simulations is 0.274. The 99% sampling noise estimated using heteroskedasticity robust OLS standard errors is 0.295. The 99% sampling noise estimated using default OLS standard errors is 0.294. Let us now estimate sampling noise for the simple WW estimator conditioning on \\(y_i^B\\), using the OLS estimator. sn.BF.simuls.yB &lt;- 2*quantile(abs(simuls.brute.force.ww.yB[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.ate(param)),probs=c(0.99)) sn.BF.OLS.hetero.yB &lt;- 2*qnorm((delta+1)/2)*sqrt(vcovHC(reg.y.R.ols.yB,type=&#39;HC2&#39;)[2,2]) sn.BF.OLS.homo.yB &lt;- 2*qnorm((delta+1)/2)*sqrt(vcov(reg.y.R.ols.yB)[2,2]) The true value of the 99% sampling noise with a sample size of 1000 and with control variables stemming from the simulations is 0.088. The 99% sampling noise estimated using heteroskedasticity robust OLS standard errors is 0.092. The 99% sampling noise estimated using default OLS standard errors is 0.091. Let’s see how all of this works on average. Figure 3.2 shows that overall the sampling nois eis much lower with \\(OLSX\\) than with \\(WW\\), as expected from Figure 3.1. The CLT-based estimator of sampling noise accounting for heteroskedasticity (in blue) recovers true sampling noise (in red) pretty well. Figure 3.3 shows that the CLT-based estimates of sampling noise are on point, except for \\(N=10000\\), where the CLT slightly overestimates true sampling noise. Figure 3.4 shows what happens when conditioning on \\(Y^B\\) in a selection of 40 samples. The reduction in samplong noise is pretty drastic here. for (k in (1:length(N.sample))){ simuls.brute.force.ww[[k]]$CLT.noise &lt;- 2*qnorm((delta+1)/2)*simuls.brute.force.ww[[k]][,&#39;se&#39;] simuls.brute.force.ww.yB[[k]]$CLT.noise &lt;- 2*qnorm((delta+1)/2)*simuls.brute.force.ww.yB[[k]][,&#39;se&#39;] } samp.noise.ww.BF &lt;- sapply(lapply(simuls.brute.force.ww,`[`,,1),samp.noise,delta=delta) precision.ww.BF &lt;- sapply(lapply(simuls.brute.force.ww,`[`,,1),precision,delta=delta) names(precision.ww.BF) &lt;- N.sample signal.to.noise.ww.BF &lt;- sapply(lapply(simuls.brute.force.ww,`[`,,1),signal.to.noise,delta=delta,param=param) names(signal.to.noise.ww.BF) &lt;- N.sample table.noise.BF &lt;- cbind(samp.noise.ww.BF,precision.ww.BF,signal.to.noise.ww.BF) colnames(table.noise.BF) &lt;- c(&#39;sampling.noise&#39;, &#39;precision&#39;, &#39;signal.to.noise&#39;) table.noise.BF &lt;- as.data.frame(table.noise.BF) table.noise.BF$N &lt;- as.numeric(N.sample) table.noise.BF$ATE &lt;- rep(delta.y.ate(param),nrow(table.noise.BF)) for (k in (1:length(N.sample))){ table.noise.BF$CLT.noise[k] &lt;- mean(simuls.brute.force.ww[[k]]$CLT.noise) } table.noise.BF$Method &lt;- rep(&quot;WW&quot;,nrow(table.noise.BF)) samp.noise.ww.BF.yB &lt;- sapply(lapply(simuls.brute.force.ww.yB,`[`,,1),samp.noise,delta=delta) precision.ww.BF.yB &lt;- sapply(lapply(simuls.brute.force.ww.yB,`[`,,1),precision,delta=delta) names(precision.ww.BF.yB) &lt;- N.sample signal.to.noise.ww.BF.yB &lt;- sapply(lapply(simuls.brute.force.ww.yB,`[`,,1),signal.to.noise,delta=delta,param=param) names(signal.to.noise.ww.BF.yB) &lt;- N.sample table.noise.BF.yB &lt;- cbind(samp.noise.ww.BF.yB,precision.ww.BF.yB,signal.to.noise.ww.BF.yB) colnames(table.noise.BF.yB) &lt;- c(&#39;sampling.noise&#39;, &#39;precision&#39;, &#39;signal.to.noise&#39;) table.noise.BF.yB &lt;- as.data.frame(table.noise.BF.yB) table.noise.BF.yB$N &lt;- as.numeric(N.sample) table.noise.BF.yB$ATE &lt;- rep(delta.y.ate(param),nrow(table.noise.BF.yB)) for (k in (1:length(N.sample))){ table.noise.BF.yB$CLT.noise[k] &lt;- mean(simuls.brute.force.ww.yB[[k]]$CLT.noise) } table.noise.BF.yB$Method &lt;- rep(&quot;OLSX&quot;,nrow(table.noise.BF)) table.noise.BF.tot &lt;- rbind(table.noise.BF,table.noise.BF.yB) table.noise.BF.tot$Method &lt;- factor(table.noise.BF.tot$Method,levels=c(&quot;WW&quot;,&quot;OLSX&quot;)) ggplot(table.noise.BF.tot, aes(x=as.factor(N), y=ATE,fill=Method)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=ATE-sampling.noise/2, ymax=ATE+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=ATE-CLT.noise/2, ymax=ATE+CLT.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw()+ theme(legend.position=c(0.85,0.88)) Figure 3.2: Average CLT-based approximations of sampling noise in the Brute Force design for \\(WW\\) and \\(OLSX\\) over replications of samples of different sizes (true sampling noise in red) par(mfrow=c(2,2)) for (i in 1:length(simuls.brute.force.ww)){ hist(simuls.brute.force.ww[[i]][,&#39;CLT.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))[WW]),xlim=c(min(table.noise.BF[i,colnames(table.noise)==&#39;sampling.noise&#39;],min(simuls.brute.force.ww[[i]][,&#39;CLT.noise&#39;])),max(table.noise.BF[i,colnames(table.noise)==&#39;sampling.noise&#39;],max(simuls.brute.force.ww[[i]][,&#39;CLT.noise&#39;])))) abline(v=table.noise.BF[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } par(mfrow=c(2,2)) for (i in 1:length(simuls.brute.force.ww.yB)){ hist(simuls.brute.force.ww.yB[[i]][,&#39;CLT.noise&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(2*bar(epsilon))[OLSX]),xlim=c(min(table.noise.BF.yB[i,colnames(table.noise)==&#39;sampling.noise&#39;],min(simuls.brute.force.ww.yB[[i]][,&#39;CLT.noise&#39;])),max(table.noise.BF.yB[i,colnames(table.noise)==&#39;sampling.noise&#39;],max(simuls.brute.force.ww.yB[[i]][,&#39;CLT.noise&#39;])))) abline(v=table.noise.BF.yB[i,colnames(table.noise)==&#39;sampling.noise&#39;],col=&quot;red&quot;) } Figure 3.3: Distribution of the CLT approximation of sampling noise in the Brute Force design for \\(WW\\) and \\(OLSX\\) over replications of samples of different sizes (true sampling noise in red) N.plot &lt;- 40 plot.list &lt;- list() limx &lt;- list(c(-0.65,1.25),c(-0.1,0.5),c(0,0.30),c(0,0.25)) for (k in 1:length(N.sample)){ set.seed(1234) test.CLT.BF &lt;- simuls.brute.force.ww[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;CLT.noise&#39;)] test.CLT.BF &lt;- as.data.frame(cbind(test.CLT.BF,rep(samp.noise(simuls.brute.force.ww[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.CLT.BF) &lt;- c(&#39;WW&#39;,&#39;CLT.noise&#39;,&#39;sampling.noise&#39;) test.CLT.BF$id &lt;- 1:N.plot plot.test.CLT.BF &lt;- ggplot(test.CLT.BF, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=WW-CLT.noise/2, ymax=WW+CLT.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ ylim(limx[[k]][1],limx[[k]][2])+ xlab(&quot;Sample id&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.CLT.BF } plot.CI.BF &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI.BF) plot.list &lt;- list() for (k in 1:length(N.sample)){ set.seed(1234) test.CLT.BF.yB &lt;- simuls.brute.force.ww.yB[[k]][sample(N.plot),c(&#39;WW&#39;,&#39;CLT.noise&#39;)] test.CLT.BF.yB &lt;- as.data.frame(cbind(test.CLT.BF.yB,rep(samp.noise(simuls.brute.force.ww.yB[[k]][,&#39;WW&#39;],delta=delta),N.plot))) colnames(test.CLT.BF.yB) &lt;- c(&#39;WW&#39;,&#39;CLT.noise&#39;,&#39;sampling.noise&#39;) test.CLT.BF.yB$id &lt;- 1:N.plot plot.test.CLT.BF.yB &lt;- ggplot(test.CLT.BF.yB, aes(x=as.factor(id), y=WW)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=WW-sampling.noise/2, ymax=WW+sampling.noise/2), width=.2,position=position_dodge(.9),color=&#39;red&#39;) + geom_errorbar(aes(ymin=WW-CLT.noise/2, ymax=WW+CLT.noise/2), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=delta.y.ate(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ ylim(limx[[k]][1],limx[[k]][2])+ xlab(&quot;Sample id&quot;)+ ylab(&quot;OLSX&quot;)+ theme_bw()+ ggtitle(paste(&quot;N=&quot;,N.sample[k])) plot.list[[k]] &lt;- plot.test.CLT.BF.yB } plot.CI.BF.yB &lt;- plot_grid(plot.list[[1]],plot.list[[2]],plot.list[[3]],plot.list[[4]],ncol=1,nrow=length(N.sample)) print(plot.CI.BF.yB) Figure 3.4: CLT-based confidence intervals of \\(\\hat{WW}\\) and \\(\\hat{OLSX}\\) for \\(\\delta=\\) 0.99 over sample replications for various sample sizes (true confidence intervals in red) 3.2 Self-Selection design In a Self-Selection design, individuals are randomly assigned to the treatment after having expressed their willingness to receive it. This design is able to recover the average effect of the Treatment on the Treated (TT). In order to explain this design clearly, and especially to make it clear how it differs from the following one (randomization after eligibility), I have to introduce a slightly more complex selection rule that we have seen so far, one that includes self-selection, take-up decisions by agents. We are going to assume that there are two steps in agents’ participation process: Eligibility: agents’ eligibility is assessed first, giving rise to a group of eligible individuals (\\(E_i=1\\)) and a group of non eligible individuals (\\(E_i=0\\)). Self-selection: eligible agents can then decide whether they want to take-up the proposed treatment or not. \\(D_i=1\\) for those who do. \\(D_i=0\\) for those who do not. By convention, ineligibles have \\(D_i=0\\). Example 3.8 In our numerical example, here are the equations operationalizing these notions: \\[\\begin{align*} E_i &amp; = \\uns{y_i^B\\leq\\bar{y}} \\\\ D_i &amp; = \\uns{\\underbrace{\\bar{\\alpha}+\\theta\\bar{\\mu}-C_i}_{D_i^*}\\geq0 \\land E_i=1} \\\\ C_i &amp; = \\bar{c} + \\gamma \\mu_i + V_i\\\\ V_i &amp; \\sim \\mathcal{N}(0,\\sigma^2_V) \\end{align*}\\] Eligibility is still decided based on pre-treatment outcomes being smaller than a threshold level \\(\\bar{y}\\). Self-selection among eligibles is decided by the net utility of the treatment \\(D_i^*\\) being positive. Here, the net utility is composed of the average gain from the treatment (assuming agents cannot foresee their idiosyncratic gain from the treatment) \\(\\bar{\\alpha}+\\theta\\bar{\\mu}\\) minus the cost of participation \\(C_i\\). The cost of participation in turn depends on a constant, on \\(\\mu_i\\) and on a random shock orthogonal to everything else \\(V_i\\). This cost might represent the administrative cost of applying for the treatment and the opportunity cost of participating into the treatment (foregone earnings and/or cost of time). Conditional on eligiblity, self-selection is endogenous in this model since both the gains and the cost of participation depend on \\(\\mu_i\\). Costs depend on \\(\\mu_i\\) since most productive people may face lower administrative costs but a higher opportunity cost of time. Let’s choose some values for the new parameters: param &lt;- c(param,-6.25,0.9,0.5) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;barc&quot;,&quot;gamma&quot;,&quot;sigma2V&quot;) and let’s generate a new dataset: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dstar &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Ds &lt;- ifelse(Dstar&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) Let’s compute the value of the TT parameter in this new model: \\[\\begin{align*} \\Delta^y_{TT} &amp; = \\bar{\\alpha}+ \\theta\\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y} \\land \\bar{\\alpha}+\\theta\\bar{\\mu}-\\bar{c}-\\gamma\\mu_i-V_i\\geq0} \\end{align*}\\] To compute the expectation of a doubly censored normal, I use the package tmvtnorm. \\[\\begin{align*} (\\mu_i,y_i^B,D_i^*) &amp; = \\mathcal{N}\\left(\\bar{\\mu},\\bar{\\mu},\\bar{\\alpha}+(\\theta-\\gamma)\\bar{\\mu}-\\bar{c}, \\left(\\begin{array}{ccc} \\sigma^2_{\\mu} &amp; \\sigma^2_{\\mu} &amp; -\\gamma\\sigma^2_{\\mu} \\\\ \\sigma^2_{\\mu} &amp; \\sigma^2_{\\mu} + \\sigma^2_{U} &amp; -\\gamma\\sigma^2_{\\mu} \\\\ -\\gamma\\sigma^2_{\\mu} &amp; -\\gamma\\sigma^2_{\\mu} &amp; \\gamma^2\\sigma^2_{\\mu}+\\sigma^2_{V} \\end{array} \\right) \\right) \\end{align*}\\] mean.mu.yB.Dstar &lt;- c(param[&#39;barmu&#39;],param[&#39;barmu&#39;],param[&#39;baralpha&#39;]- param[&#39;barc&#39;]+(param[&#39;theta&#39;]-param[&#39;gamma&#39;])*param[&#39;barmu&#39;]) cov.mu.yB.Dstar &lt;- matrix(c(param[&#39;sigma2mu&#39;],param[&quot;sigma2mu&quot;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;], param[&quot;sigma2mu&quot;],param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;], -param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;],param[&quot;sigma2mu&quot;]*(param[&#39;gamma&#39;])^2+param[&#39;sigma2V&#39;]),3,3,byrow=TRUE) lower.cut &lt;- c(-Inf,-Inf,0) upper.cut &lt;- c(Inf,log(param[&#39;barY&#39;]),Inf) moments.cut &lt;- mtmvnorm(mean=mean.mu.yB.Dstar,sigma=cov.mu.yB.Dstar,lower=lower.cut,upper=upper.cut) delta.y.tt &lt;- param[&#39;baralpha&#39;]+ param[&#39;theta&#39;]*moments.cut$tmean[1] delta.y.ww.self.select &lt;- mean(y[R==1 &amp; Ds==1])-mean(y[R==0 &amp; Ds==1]) The value of \\(\\Delta^y_{TT}\\) in our illustration is now 0.17. 3.2.1 Identification In a Self-Selection design, identification requires two assumptions: Definition 3.3 (Independence Among Self-Selected) We assume that the randomized allocation of the program among applicants is well done: \\[\\begin{align*} R_i\\Ind(Y_i^0,Y_i^1)|D_i=1. \\end{align*}\\] Independence can be enforced by the randomized allocation of the treatment among the eligible applicants. We need a second assumption: Definition 3.4 (Self-Selection design Validity) We assume that the randomized allocation of the program does not interfere with how potential outcomes and self-selection are generated: \\[\\begin{align*} Y_i &amp; = \\begin{cases} Y_i^1 &amp; \\text{ if } (R_i=1 \\text{ and } D_i=1) \\\\ Y_i^0 &amp; \\text{ if } (R_i=0 \\text{ and } D_i=1) \\text{ or } D_i=0 \\end{cases} \\end{align*}\\] with \\(Y_i^1\\), \\(Y_i^0\\) and \\(D_i\\) the same potential outcomes and self-selection decisions as in a routine allocation of the treatment. Under these assumptions, we have the following result: Theorem 3.2 (Identification in a Self-Selection design) Under Assumptions 3.3 and 3.4, the WW estimator among the self-selected identifies TT: \\[\\begin{align*} \\Delta^Y_{WW|D=1} &amp; = \\Delta^Y_{TT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{WW|D=1} &amp; = \\esp{Y_i|R_i=1,D_i=1} - \\esp{Y_i|R_i=0,D_i=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{WW|D=1} &amp; = \\esp{Y_i|R_i=1,D_i=1} - \\esp{Y_i|R_i=0,D_i=1} \\\\ &amp; = \\esp{Y^1_i|R_i=1,D_i=1} - \\esp{Y^0_i|R_i=0,D_i=1} \\\\ &amp; = \\esp{Y_i^1|D_i=1}-\\esp{Y_i^0|D_i=1}\\\\ &amp; = \\esp{Y_i^1-Y_i^0|D_i=1}, \\end{align*}\\] where the second equality uses Assummption3.4, the third equality Assumption 3.3 and the last equality the linearity of the expectation operator. Remark. The key intuitions for how the Self-Selection design solves the FPCI are: By allowing for eligibilty and self-selection, we identify the agents that would benefit from the treatment in routine mode (the treated). By randomly denying the treatment to some of the treated, we can estimate the counterfactual outcome of the treated by looking at the counterfactual outcome of the denied applicants: \\(\\esp{Y_i^0|D_i=1}=\\esp{Y_i|R_i=0,D_i=1}\\). Remark. In practice, we use a pseudo-RNG to generate a random allocation among applicants: \\[\\begin{align*} R_i^* &amp; \\sim \\mathcal{U}[0,1]\\\\ R_i &amp; = \\begin{cases} 1 &amp; \\text{ if } R_i^*\\leq .5 \\land D_i=1\\\\ 0 &amp; \\text{ if } R_i^*&gt; .5 \\land D_i=1 \\end{cases} \\end{align*}\\] Example 3.9 In our numerical example, the following R code generates two random groups, one treated and one control, and imposes the Assumption of Self-Selection design Validity: #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; Ds==1,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) 3.2.2 Estimating TT 3.2.2.1 Using the WW Estimator As in the case of the Brute Force Design, we can use the WW estimator to estimate the effect of the program with a Self-Selection design, except that this time the WW estimator is applied among applicants to the program only: \\[\\begin{align*} \\hat{\\Delta}^Y_{WW|D=1} &amp; = \\frac{1}{\\sum_{i=1}^N D_iR_i}\\sum_{i=1}^N Y_iD_iR_i-\\frac{1}{\\sum_{i=1}^N D_i(1-R_i)}\\sum_{i=1}^N D_iY_i(1-R_i). \\end{align*}\\] Example 3.10 In our numerical example, we can form the WW estimator among applicants: delta.y.ww.self.select &lt;- mean(y[R==1 &amp; Ds==1])-mean(y[R==0 &amp; Ds==1]) WW among applicants is equal to 0.085. It is actually rather far from the true value of 0.17, which reminds us that unbiasedness does not mean that a given sample will not suffer from a large bias. We just drew a bad sample where confounders are not very well balanced. 3.2.2.2 Using OLS As in the Brute Force Design with the ATE, we can estimate the TT parameter with a Self-Selection design using the OLS estimator. In the following regression run among applicants only (with \\(D_i=1\\)), \\(\\beta\\) estimates TT: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + U_i. \\end{align*}\\] As a matter of fact, the OLS estimator without control variables is numerically equivalent to the WW estimator. Example 3.11 In our numerical example, here is the OLS regression: reg.y.R.ols.self.select &lt;- lm(y[Ds==1]~R[Ds==1]) The value of the OLS estimator is 0.085, which is identical to the WW estimator among applicants. 3.2.2.3 Using OLS Conditioning on Covariates We might want to condition on covariates in order to reduce the amount of sampling noise. Parametrically, we can run the following OLS regression among applicants (with \\(D_i=1\\)): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + \\gamma&#39; X_i + U_i. \\end{align*}\\] \\(\\beta\\) estimates the TT. Needed: proof. Especially check whether we need to center covariates at the mean of the treatment group. I think so. We can also use Matching to obtain a nonparametric estimator. Example 3.12 Let us first compute the OLS estimator conditioning on \\(y_i^B\\): reg.y.R.yB.ols.self.select &lt;- lm(y[Ds==1] ~ R[Ds==1] + yB[Ds==1]) Our estimate of TT after conditioning on \\(y_i^B\\) is 0.145. Conditioning on \\(y_i^B\\) has been able to solve part of the bias of the WW problem estimator. Let’s now check whether conditioning on OLS has brought an improvement in terms of decreased sampling noise. monte.carlo.self.select.ww &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dstar &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Ds &lt;- ifelse(Dstar&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; Ds==1,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) return(mean(y[R==1 &amp; Ds==1])-mean(y[R==0 &amp; Ds==1])) } simuls.self.select.ww.N &lt;- function(N,Nsim,param){ simuls.self.select.ww &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.self.select.ww,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.self.select.ww) &lt;- c(&#39;WW&#39;) return(simuls.self.select.ww) } sf.simuls.self.select.ww.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.self.select.ww,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.self.select.ww &lt;- lapply(N.sample,sf.simuls.self.select.ww.N,Nsim=Nsim,param=param) names(simuls.self.select.ww) &lt;- N.sample monte.carlo.self.select.yB.ww &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dstar &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Ds &lt;- ifelse(Dstar&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; Ds==1,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) reg.y.R.yB.ols.self.select &lt;- lm(y[Ds==1] ~ R[Ds==1] + yB[Ds==1]) return(reg.y.R.yB.ols.self.select$coef[2]) } simuls.self.select.yB.ww.N &lt;- function(N,Nsim,param){ simuls.self.select.yB.ww &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.self.select.yB.ww,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.self.select.yB.ww) &lt;- c(&#39;WW&#39;) return(simuls.self.select.yB.ww) } sf.simuls.self.select.yB.ww.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.self.select.yB.ww,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;WW&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.self.select.yB.ww &lt;- lapply(N.sample,sf.simuls.self.select.yB.ww.N,Nsim=Nsim,param=param) names(simuls.self.select.yB.ww) &lt;- N.sample par(mfrow=c(2,2)) for (i in 1:length(simuls.self.select.ww)){ hist(simuls.self.select.ww[[i]][,&#39;WW&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt,col=&quot;red&quot;) } par(mfrow=c(2,2)) for (i in 1:length(simuls.self.select.yB.ww)){ hist(simuls.self.select.yB.ww[[i]][,&#39;WW&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt,col=&quot;red&quot;) } Figure 3.5: Distribution of the \\(WW\\) and \\(OLSX\\) estimator in a Self-Selection design over replications of samples of different sizes Figure 3.5 shows that, in our example, conditioning on covariates improves precision by the same amount as an increase in sample size by almost one order of magnitude. 3.2.3 Estimating Sampling Noise In order to estimate precision, we can either use the CLT, deriving sampling noise from the heteroskedasticity-robust standard error OLS estimates, or we can use some form of resampling as the bootstrap or randomization inference. Example 3.13 Let us derive the CLT-based estimates of sampling noise using the OLS standard errors without conditioning on covariates first. I’m using the sample size with \\(N=1000\\) as an example. sn.RASS.simuls &lt;- 2*quantile(abs(simuls.self.select.ww[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.tt),probs=c(0.99)) sn.RASS.OLS.homo &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.ols.self.select)[2,2]) sn.RASS.OLS.hetero &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.ols.self.select,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 0.548. 99% sampling noise estimated using default OLS standard errors is 0.578. 99% sampling noise estimated using heteroskedasticity robust OLS standard errors is 0.58. Conditioning on covariates: sn.RASS.simuls.yB &lt;- 2*quantile(abs(simuls.self.select.yB.ww[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.tt),probs=c(0.99)) sn.RASS.OLS.homo.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.yB.ols.self.select)[2,2]) sn.RASS.OLS.hetero.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.yB.ols.self.select,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 0.295. 99% sampling noise estimated using default OLS standard errors is 0.294. 99% sampling noise estimated using heteroskedasticity robust OLS standard errors is 0.299. 3.3 Eligibility design In an Eligibility design, we randomly select two groups among the eligibles. Members of the treated group are informed that they are eligible to the program and are free to self-select into it. Members of the control group are not enformed that they are eligible and cannot enroll into the program. In an Eligibility design, we can still recover the TT despite the fact that we have not randomized access to the programs among the applicants. This is the magic of instrumental variables. Let us detail the mechanics of this beautiful result. 3.3.1 Identification In order to state the identification results in the Randomization After Eligibility design rigorously, I need to define new potential outcomes: \\(Y_i^{d,r}\\) is the value of the outcome \\(Y\\) when individual \\(i\\) belongs to the program group \\(d\\) (\\(d\\in\\left\\{0,1\\right\\}\\)) and has been randomized in group \\(r\\) (\\(r\\in\\left\\{0,1\\right\\}\\)). \\(D_i^r\\) is the value of the program participation decision when individual \\(i\\) has been assigned randomly to group \\(r\\). 3.3.1.1 Identification of TT In an Eligiblity design, we need three assumptions to ensure identification of the TT: Definition 3.5 (Independence Among Eligibles) We assume that the randomized allocation of the program among eligibles is well done: \\[\\begin{align*} R_i\\Ind(Y_i^{0,0},Y_i^{0,1},Y_i^{1,0},Y_i^{1,1},D_i^1,D_i^0)|E_i=1. \\end{align*}\\] Independence can be enforced by the randomized allocation of information about eligibility among the eligibles. We need a second assumption: Definition 3.6 (Randomization After Eligibility Validity) We assume that no eligibles that has been randomized out can take the treatment and that the randomized allocation of the program does not interfere with how potential outcomes and self-selection are generated: \\[\\begin{align*} D_i^0 &amp; = 0\\text{, } \\forall i, \\\\ D_i &amp; = D_i^1R_i+(1-R_i)D_i^0 \\\\ Y_i &amp; = \\begin{cases} Y_i^{1,1} &amp; \\text{ if } (R_i=1 \\text{ and } D_i=1) \\\\ Y_i^{0,1} &amp; \\text{ if } (R_i=1 \\text{ and } D_i=0) \\\\ Y_i^{0,0} &amp; \\text{ if } R_i=0 \\end{cases} \\end{align*}\\] with \\(Y_i^{1,1}\\), \\(Y_i^{0,1}\\), \\(Y_i^{0,0}\\), \\(D_i^1\\) and \\(D^0_i\\) the same potential outcomes and self-selection decisions as in a routine allocation of the treatment. We need a third assumption: Definition 3.7 (Exclusion Restriction of Eligibility) We assume that there is no direct effect of being informed about eligibliity to the program on outcomes: \\[\\begin{align*} Y_i^{1,1} &amp; = Y_i^{1,0}= Y_i^1\\\\ Y_i^{0,1} &amp; = Y_i^{0,0}= Y_i^0. \\end{align*}\\] Under these assumptions, we have the following result: Theorem 3.3 (Identification of TT With Randomization After Eligibility) Under Assumptions 3.5, 3.6 and 3.7, the Bloom estimator among eligibles identifies TT: \\[\\begin{align*} \\Delta^Y_{Bloom|E=1} &amp; = \\Delta^Y_{TT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{Bloom|E=1} &amp; = \\frac{\\Delta^Y_{WW|E=1}}{\\Pr(D_i=1|R_i=1,E_i=1)} \\\\ \\Delta^Y_{WW|E=1} &amp; =\\esp{Y_i|R_i=1,E_i=1}-\\esp{Y_i|R_i=0,E_i=1}. \\end{align*}\\] Proof. I keep the conditioning on \\(E_i=1\\) implicit all along to save notation. \\[\\begin{align*} \\esp{Y_i|R_i=1} &amp; = \\esp{Y_i^{1,1}D_i+Y_i^{0,1}(1-D_i)|R_i=1} \\\\ &amp; = \\esp{Y_i^0+D_i(Y_i^1-Y_i^0)|R_i=1} \\\\ &amp; = \\esp{Y_i^0|R_i=1}+\\esp{Y_i^1-Y_i^0|D_i=1,R_i=1}\\Pr(D_i=1|R_i=1)\\\\ &amp; = \\esp{Y_i^0}+\\esp{Y_i^1-Y_i^0|D_i=1}\\Pr(D_i=1|R_i=1), \\end{align*}\\] where the first equality uses Assumption 3.6, the second equality Assumption 3.7 and the last equality Assumption 3.5 and the fact that \\(D_i=1\\Rightarrow R_i=1\\). Using the same reasoning, we also have: \\[\\begin{align*} \\esp{Y_i|R_i=0} &amp; = \\esp{Y_i^{1,0}D_i+Y_i^{0,0}(1-D_i)|R_i=0} \\\\ &amp; = \\esp{Y_i^0|R_i=0} \\\\ &amp; = \\esp{Y_i^0}. \\end{align*}\\] A direct application of the formula for the Bloom estimator proves the result. 3.3.1.2 Identification of ITE The previous proof does not give a lot of intuition of how TT is identified in the Randomization After Eligibility design. In order to gain more insight, we are going to decompose the Bloom estimator, and have a look at its numerator. The numerator of the Bloom estimator is a With/Without comparison, and it identifies, under fairly light conditions, another causal effect, the Intention to Treat Effect (ITE). Let me first define the ITE: Definition 3.8 (Intention to Treat Effect) In a Randomization After Eligibility design, the Intention to Treat Effect (ITE) is the effect of receiving information about eligiblity among eligibles: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|E_i=1}. \\end{align*}\\] Receiving information about eligibility has two impacts, in the general framework that we have delineated so far: first, it triggers some individuals into the treatment (those for which \\(D_i^1\\neq0\\)); second, it might have a direct effect on outcomes (\\(Y_i^{d,1}\\neq Y_i^{d,0}\\)). This second effect is the effect of annoucing eligiblity that does not goes through participation into the program. For example, it is possible that announcing eligibility to a retirement program makes me save more for retirement, even if I end up not taking up the proposed program. The two causal channels that are at work within the ITE can be seen more clearly after some manipulations: \\[\\begin{align} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1,1}D^1_i+Y_i^{0,1}(1-D_i^1)-(Y_i^{1,0}D^0_i+Y_i^{0,0}(1-D_i^0))|E_i=1}\\nonumber \\\\ &amp; = \\esp{Y_i^{1,1}D^1_i+Y_i^{0,1}(1-D_i^1)-(Y_i^{0,0}(D_i^1+1-D_i^1))|E_i=1}\\nonumber \\\\ &amp; = \\esp{(Y_i^{1,1}-Y_i^{0,0})D^1_i+(Y_i^{0,1}-Y_i^{0,0})(1-D_i^1)|E_i=1}\\nonumber \\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{0,0}|D^1_i=1,E_i=1}\\Pr(D^1_i=1|E_i=1)\\nonumber \\\\ &amp; \\phantom{=}+\\esp{Y_i^{0,1}-Y_i^{0,0}|D_i^1=0,E_i=1}\\Pr(D_i^1=0|E_i=1),\\tag{3.1} \\end{align}\\] where the first equality follows from Assumption 3.6 and the second equality uses the fact that \\(D_i^0=0\\), \\(\\forall i\\). We can now see that the ITE is composed of two terms: the first term captures the effect of announcing eligibility on those who decide to participate into the program; the second term captures the effect of announcing eligibility on those who do not participate into the program. Both of these effects are weighted by the respective proportions of those reacting to the eligibility annoucement by participating and by not participating respectively. Now, in order to see how the ITE “contains” the TT, we can use the following theorem: Theorem 3.4 (From ITE to TT) Under Assumptions 3.5, 3.6 and 3.7, ITE is equal to TT multiplied by the proportion of individuals taking up the treatment after eligibility has been announced: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\Delta^Y_{TT}\\Pr(D^1_i=1|E_i=1). \\end{align*}\\] Proof. Under Assumption 3.7, Equation (3.1) becomes: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1}-Y_i^{0}|D^1_i=1,E_i=1}\\Pr(D^1_i=1|E_i=1) \\\\ &amp; \\phantom{=}+\\esp{Y_i^{0}-Y_i^{0}|D_i^1=0,E_i=1}\\Pr(D_i^1=0|E_i=1)\\\\ &amp; = \\esp{D_i^1(Y_i^{1}-Y_i^{0})|R_i=1,E_i=1} \\\\ &amp; = \\esp{Y_i^{1}-Y_i^{0}|D_i^1=1,R_i=1,E_i=1}\\Pr(D^1_i=1|R_i=1,E_i=1) \\\\ &amp; = \\esp{Y_i^{1}-Y_i^{0}|D_i=1,E_i=1}\\Pr(D^1_i=1|E_i=1), \\end{align*}\\] where the first equality follows from Assumption 3.7, the second from Bayes’ rule and Assumptions 3.5, the third from Bayes’ rule and the last from the fact that \\(D_i^1=1,R_i=1\\Leftrightarrow D_i=1\\). The previous theorem shows that Assumption 3.7 shuts down any direct effect of the announcement of eligibility on outcomes. As a consequence of this assumption, the only impact that an eligibility annoucement has on outcomes is through participation into the program. Hence, the ITE is equal to TT multiplied by the proportion of people taking up the treatment when eligibility is announced. In order to move from the link between TT and ITE to the mechanics of the Bloom estimator, we need two additional identification results. The first result shows that ITE can be identified under fairly light conditions by a WW estimator. The second result shows that the proportion of people taking up the treatment when eligiblity is announced is also easily estimated from the data. Theorem 3.5 (Identification of ITE with Randomization After Eligibility) Under Assumptions 3.5 and 3.6, ITE is identified by the With/Without comparison among eligibles: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\Delta^Y_{WW|E=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{WW|E=1} &amp; =\\esp{Y_i|R_i=1,E_i=1}-\\esp{Y_i|R_i=0,E_i=1} \\\\ &amp; = \\esp{Y_i^{D_i^1,1}|R_i=1,E_i=1}-\\esp{Y_i^{D_i^0,0}|R_i=0,E_i=1} \\\\ &amp; = \\esp{Y_i^{D_i^1,1}|E_i=1}-\\esp{Y_i^{D_i^0,0}|E_i=1}, \\end{align*}\\] where the second equality follows from Assumption 3.6 and the third from Assumption 3.5. Theorem 3.6 (Identification of $\\Pr(D^1_i=1|E_i=1)$) Under Assumptions 3.5 and 3.6, \\(\\Pr(D^1_i=1|E_i=1)\\) is identified by the proportion of people taking up the offered treatment when informed about their eligibility status: \\[\\begin{align*} \\Pr(D^1_i=1|E_i=1) &amp; = \\Pr(D_i=1|R_i=1,E_i=1). \\end{align*}\\] Proof. \\[\\begin{align*} \\Pr(D_i=1|R_i=1,E_i=1) &amp; =\\Pr(D^1_i=1|R_i=1,E_i=1) \\\\ &amp; = \\Pr(D^1_i=1|E_i=1), \\end{align*}\\] where the first equality follows from Assumption 3.6 and the second from Assumption 3.5. Corollary 3.1 (Bloom estimator and ITE) It follows from Theorems 3.5 and 3.6 that, under Assumptions 3.5 and 3.6, the Bloom estimator is equal to the ITE divided by the propotion of agents taking up the program when eligible: \\[\\begin{align*} \\Delta^Y_{Bloom|E=1} &amp; = \\frac{\\Delta^Y_{ITE}}{\\Pr(D^1_i=1|E_i=1)}. \\end{align*}\\] As a consequence of Corollary 3.1, we see that the Bloom estimator reweights the ITE, the effect of receiving information about eligibility, by the proportion of people reacting to the eligibility by participating in the program. From Theorem 3.4, we know that this ratio will be equal to TT if the Assumption 3.7 also holds, so that all the impact of the eligibility annoucement stems from entering the program. The eligibility annoucement serves as an instrument for program participation. Remark. The design using Randomization After Eligibility seems like magic. You do not assign randomly the program, but information about the eligiblity status, but you can recover the effect of the program anyway. How does this magic work? Randomization After Eligibility is also less intrusive than Self-Selection design. With the latter design, you have to actively send away individuals that have expressed an interest for entering the program. This is harsh. With Randomization After Eligibility, you do not have to send away people expressing interest after being informed. And it seems that you are not paying a price for that, since you are able to recover the same TT parameter. Well, actually, you are going to pay a price in terms of larger sampling noise. The intuition for all that can be delineated using the very same apparatus that we have developed so far. So here goes. Under the assumptions made so far, it is easy to show that (omitting the conditioning on \\(E_i=1\\) for simplicity): \\[\\begin{align*} \\Delta^Y_{WW|E=1} &amp; = \\esp{Y_i^{1,1}|D_i^1=1,R_i=1}\\Pr(D^1_i=1|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{0,0}|D_i^1=1,R_i=0}\\Pr(D^1_i=1|R_i=0) \\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0,1}|D_i^1=0,R_i=1}\\Pr(D^1_i=0|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{0,0}|D_i^1=0,R_i=0}\\Pr(D^1_i=0|R_i=0). \\end{align*}\\] The first part of the equation is due to the difference in outcomes between the two treatment arms for people that take up the program when eligibility is announced. The second part is due to the difference in outcomes between the two treatment arms for people that do not take up the program when eligibility is announced. This second part cancels out under Assumption 3.5 and 3.7. But this cancelling out only happens in the population. In a given sample, the sample equivalents to the two members of the second part of the equation do not have to be equal, and thus they do not cancel out, generating additional sampling noise compared to the Self-Selection design. Indeed, in the Self-Selection design, you observe the population with \\(D_i^1=1\\) in both the treatment and control arms (you actually observe this population before randomizing the treatment within it), and you can enforce that the effect on \\(D_i^1=0\\) should be zero, under your assumptions. In an Eligibility design, you do not observe the population with \\(D_i^1=1\\) in the control arm, and you cannot enforce the equality of the outcomes for those with \\(D_i^1=0\\) present in both arms. You have to rely on the sampling estimates to make this cancellation, and that generates sampling noise. Remark. In practice, we use a pseudo-RNG to allocate the randomized annoucement of the eligibility status: \\[\\begin{align*} R_i^* &amp; \\sim \\mathcal{U}[0,1]\\\\ R_i &amp; = \\begin{cases} 1 &amp; \\text{ if } R_i^*\\leq .5 \\land E_i=1\\\\ 0 &amp; \\text{ if } R_i^*&gt; .5 \\land E_i=1 \\end{cases} \\\\ D_i &amp; = \\uns{\\bar{\\alpha}+\\theta\\bar{\\mu}-C_i\\geq0 \\land E_i=1 \\land R_i=1} \\end{align*}\\] Example 3.14 In our numerical example, we can actually use the same sample as we did for Self-Selection design. I have to generate it again, though, since I am going to allocate \\(R_i\\) differently. set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dindex &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Dstar &lt;- ifelse(Dindex&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) The value of TT in our example is the same as the one in the Self-Selection design case. TT in the population is equal to 0.17. Let’s now compute the value of ITE in the population. In our model, exclusion restriction holds, so that we can use the fact that \\(ITE=TT\\Pr(D^1_i=1|E_i=1)\\). We thus only need to compute \\(\\Pr(D^1_i=1|E_i=1)\\): \\[\\begin{align*} \\Pr(D^1_i=1|E_i=1) &amp; = \\Pr(D_i^*\\geq0|y_i^B\\leq\\bar{y}). \\end{align*}\\] I can again use the package tmvtnorm to compute that probability. It is indeed equal to \\(1-\\Pr(D_i^*&lt;0|y_i^B\\leq\\bar{y})\\), where \\(\\Pr(D_i^*&lt;0|y_i^B\\leq\\bar{y})\\) is the cumulative density of \\(D_i^*\\) conditional on \\(y_i^B\\leq\\bar{y}\\), the marginal cumulative of the third variable of the truncated trivariate normal \\((\\mu_i,y_i^B,D_i^*)\\) where the first variable is not truncated and the second one is truncated at \\(\\bar{y}\\). lower.cut &lt;- c(-Inf,-Inf,-Inf) upper.cut &lt;- c(Inf,log(param[&#39;barY&#39;]),Inf) prD1.elig &lt;- 1-ptmvnorm.marginal(xn=0,n=3,mean=mean.mu.yB.Dstar,sigma=cov.mu.yB.Dstar,lower=lower.cut,upper=upper.cut) delta.y.ite &lt;- delta.y.tt*prD1.elig \\(\\Pr(D^1_i=1|E_i=1)=\\) 0.459. As a consequence, ITE in the population is equal to 0.17 * 0.459 \\(\\approx\\) 0.078. In the sample, the value of ITE and TT are equal to: delta.y.tt.sample &lt;- mean(y1[E==1 &amp; Dstar==1]-y0[E==1 &amp; Dstar==1]) delta.y.ite.sample &lt;- delta.y.tt.sample*mean(Dstar[E==1]) \\(\\Delta^y_{ITE_s}=\\) 0.068 and \\(\\Delta^y_{TT_s}=\\) 0.187. Now, we can allocate the randomized treatment and let potential outcomes be realized: #random allocation among eligibles Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; E==1,1,0) Ds &lt;- ifelse(Dindex&gt;=0 &amp; E==1 &amp; R==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) 3.3.2 Estimating the ITE and the TT In general, we start the analysis of an Eligibility design by estimating the ITE. Then, we provide the TT by dividing the ITE by the proportion of participants among the eligibles. Actually, this procedure is akin to an instrumental variables estimator and we will see that the Bloom estimator is actually an IV estimator. The ITE estimation step corresponds to the reduced form in a classical IV approach. Estimation of the proportion of participants is the first stage in a IV approach. Estimation of the TT corresponds to the structural equation step of an IV procedure. 3.3.2.1 Estimating the ITE Estimation of the ITE relies on the WW estimator, in general implemented using OLS. It is similar to the estimation of ATE and TT in the Brute Force and Self-Selection designs. 3.3.2.1.1 Using the WW estimator Estimation of the ITE can be based on the WW estimator among eligibles. \\[\\begin{align*} \\hat{\\Delta}^Y_{WW|E=1} &amp; = \\frac{1}{\\sum_{i=1}^N E_iR_i}\\sum_{i=1}^N Y_iE_iR_i-\\frac{1}{\\sum_{i=1}^N E_i(1-R_i)}\\sum_{i=1}^N E_iY_i(1-R_i). \\end{align*}\\] Example 3.15 In our numerical example, we can form the WW estimator among eligibles: delta.y.ww.elig &lt;- mean(y[R==1 &amp; E==1])-mean(y[R==0 &amp; E==1]) WW among eligibles is equal to 0.069. 3.3.2.1.2 Using OLS As we have already seen before, the WW estimator is equivalent to OLS with one constant and no control variables. As a consequence, we can estimate the ITE using the OLS estimate of \\(\\beta\\) in the following regression run on the sample with \\(E_i=1\\): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + U_i. \\end{align*}\\] By construction, \\(\\hat{\\beta}_{OLSR|E=1}=\\hat{\\Delta}^Y_{WW|E=1}\\). Example 3.16 In our numerical example, we can form the WW estimator among eligibles: reg.y.ols.elig &lt;- lm(y[E==1]~R[E==1]) delta.y.ols.elig &lt;- reg.y.ols.elig$coef[2] \\(\\hat{\\beta}_{OLSR|E=1}\\) is equal to 0.069. Remember that ITE in the population is equal to 0.078. 3.3.2.1.3 Using OLS conditioning on covariates Again, as in the previous designs, we can compute ITE by using OLS conditional on covariates. Parametrically, we can run the following OLS regression among eligibles (with \\(E_i=1\\)): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta R_i + \\gamma&#39; X_i + U_i. \\end{align*}\\] The OLS estimate of \\(\\beta\\) estimates the ITE. Again: Needed: proof. Especially check whether we need to center covariates at the mean of the treatment group. I think so. We can also use Matching to obtain a nonparametric estimator. Example 3.17 Let us compute the OLS estimator conditioning on \\(y_i^B\\): reg.y.R.yB.ols.elig &lt;- lm(y[E==1] ~ R[E==1] + yB[E==1]) Our estimate of ITE after conditioning on \\(y_i^B\\) is 0.065. I do not have time to run the simulations, but it is highly likely that the sampling noise is lower after conditioning on \\(y_i^B\\). I do not have time to run the simulations, but it is highly likely that the sampling noise is lower after conditioning on \\(y_i^B\\). 3.3.2.2 Estimating TT We can estimate TT either using the Bloom estimator, or using the IV estimator, which is equivalent to a Bloom estimator in the Eligibility design. 3.3.2.2.1 Using the Bloom estimator Using the Bloom estimator, we simply compute the numerator of the Bloom estimator and divide it by the estimated proportion of eligible individuals with \\(R_i=1\\) that have chosen to take the program. \\[\\begin{align*} \\hat{\\Delta}^Y_{WW|D=1} &amp; = \\frac{\\frac{1}{\\sum_{i=1}^N E_iR_i}\\sum_{i=1}^N Y_iE_iR_i-\\frac{1}{\\sum_{i=1}^N E_i(1-R_i)}\\sum_{i=1}^N E_iY_i(1-R_i)}{\\frac{1}{\\sum_{i=1}^N E_iR_i}\\sum_{i=1}^N D_iE_iR_i}. \\end{align*}\\] Example 3.18 Let’s see how the Boom estimator works in our example. The numerator of the Bloom estimator is the ITE that we have just computed: 0.069. The denominator of the Bloom estimator is equal to the proportion of eligible individuals with \\(R_i=1\\) that have chosen to take the program: 0.342. delta.y.R.bloom.elig &lt;- (mean(y[R==1 &amp; E==1])-mean(y[R==0 &amp; E==1]))/mean(Ds[R==1 &amp; E==1]) The resulting estimate of TT is 0.203. It is rather far from the population or sample estimates: 0.17 and 0.187 respectively. What happened? The error seems to come from noise in the denominator of the Bloom estimator. In the ITE estimation, the true ITEs in the population and sample are 0.078 and 0.068 respectively and our estimate is equal to 0.069, so that’s fine. In the denominator, the proportion of randomized eligibles that take the program is equal to 0.342 while the true proportions in the population and in the sample are 0.459 and 0.364 respectively. So we do not have enough invited eligibles getting into the program, and the ones who do have unusually large outcomes. These two sampling errors combine to blow up the estimate of TT. 3.3.2.2.2 Using IV There is a very useful results, similar to the one stating that the WW estimator is equivalent to an OLS estimator: in the Eligiblity design, the Bloom estimator is equivalent to an IV estimator: Theorem 3.7 (Bloom is IV) Under the assumption that there is at least one individual with \\(R_i=1\\) and with \\(D_i=1\\), the coefficient \\(\\beta\\) in the following regression estimated among eligibles using \\(R_i\\) as an IV \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta D_i + U_i \\end{align*}\\] is the Bloom estimator in the Eligibility Design: \\[\\begin{align*} \\hat{\\beta}_{IV} &amp; = \\frac{\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_i\\left(Y_i-\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_iY_i\\right)\\left(R_i-\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_iR_i\\right)}{\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_i\\left(D_i-\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_iD_i\\right)\\left(R_i-\\frac{1}{\\sum_{i=1}^N E_i}\\sum_{i=1}^NE_iR_i\\right)} \\\\ &amp; = \\frac{\\frac{1}{\\sum_{i=1}^N E_iR_i}\\sum_{i=1}^N Y_iR_iE_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)E_i}\\sum_{i=1}^N Y_i(1-R_i)E_i}{\\frac{1}{\\sum_{i=1}^N E_iR_i}\\sum_{i=1}^N D_iR_iE_i}. \\end{align*}\\] Proof. The proof is straightforward using Theorem 3.15 below and setting \\(D_i=0\\) when \\(R_i=0\\). Example 3.19 In our numerical example, we have: reg.y.R.2sls.elig &lt;- ivreg(y[E==1]~Ds[E==1]|R[E==1]) \\(\\hat{\\beta}_{IV}=\\) 0.203 which is indeed equal to the Bloom estimator (\\(\\hat{\\Delta}^y_{Bloom}=\\) 0.203). 3.3.2.2.3 Using IV conditional on covariates We can improve on the precision of our 2SLS estimator by conditioning on observed covariates. Parametrically estimating the following equation with \\(R_i\\) and \\(X_i\\) as instruments on the sample with \\(E_i=1\\): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta D_i + \\gamma&#39; X_i + U_i. \\end{align*}\\] Proof? Do we need to center covariates to their mean in the treatment group? Nonparametric estimation using Frolich’s Wald matching estimator.} Example 3.20 In our numerical example, we have: reg.y.R.yB.2sls.elig &lt;- ivreg(y[E==1] ~ Ds[E==1] + yB[E==1] | R[E==1] + yB[E==1]) As a consequence, \\(\\hat{\\Delta}^y_{Bloom(X)}=\\) 0.191. Does conditioning on covariates improve precision? Let’s run some Monte-Carlo somulations in order to check for that. monte.carlo.elig &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dindex &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Dstar &lt;- ifelse(Dindex&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; E==1,1,0) Ds &lt;- ifelse(Dindex&gt;=0 &amp; E==1 &amp; R==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) reg.y.R.2sls.elig &lt;- ivreg(y[E==1]~Ds[E==1]|R[E==1]) return(reg.y.R.2sls.elig$coef[2]) } simuls.elig.N &lt;- function(N,Nsim,param){ simuls.elig &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.elig,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.elig) &lt;- c(&#39;Bloom&#39;) return(simuls.elig) } sf.simuls.elig.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sfLibrary(AER) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.elig,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;Bloom&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) N.sample &lt;- c(1000,10000,100000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.elig &lt;- lapply(N.sample,sf.simuls.elig.N,Nsim=Nsim,param=param) names(simuls.elig) &lt;- N.sample monte.carlo.elig.yB &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dindex &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Dstar &lt;- ifelse(Dindex&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; E==1,1,0) Ds &lt;- ifelse(Dindex&gt;=0 &amp; E==1 &amp; R==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) reg.y.R.yB.2sls.elig &lt;- ivreg(y[E==1] ~ Ds[E==1] + yB[E==1] | R[E==1] + yB[E==1]) return(reg.y.R.yB.2sls.elig$coef[2]) } simuls.elig.yB.N &lt;- function(N,Nsim,param){ simuls.elig.yB &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.elig.yB,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.elig.yB) &lt;- c(&#39;Bloom&#39;) return(simuls.elig.yB) } sf.simuls.elig.yB.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sfLibrary(AER) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.elig.yB,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;Bloom&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) N.sample &lt;- c(1000,10000,100000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.elig.yB &lt;- lapply(N.sample,sf.simuls.elig.yB.N,Nsim=Nsim,param=param) names(simuls.elig.yB) &lt;- N.sample par(mfrow=c(2,2)) for (i in 1:length(simuls.elig)){ hist(simuls.elig[[i]][,&#39;Bloom&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yBloom)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt,col=&quot;red&quot;) } par(mfrow=c(2,2)) for (i in 1:length(simuls.elig.yB)){ hist(simuls.elig.yB[[i]][,&#39;Bloom&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yBloom)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt,col=&quot;red&quot;) } Figure 3.6: Distribution of the \\(Bloom\\) and \\(Bloom(X)\\) estimators with randomization after eligibility over replications of samples of different sizes We can take three things from Figure 3.6: Problems with the IV estimator appear with \\(N=100\\) (probably because there are some samples where no one is treated). Sampling noise from randomization after eligibility is indeed larger than sampling noise from Self-Selection design. Conditioning on covariates helps. 3.3.3 Estimating sampling noise As always, we can estimate samling noise either using the CLT or resampling methods. Using the CLT, we can derive the following formula for the distribution of the Bloom estimator: Theorem 3.8 (Asymptotic Distribution of $\\hat{\\Delta}^Y_{Bloom}$) Under Assumptions 3.5, 3.6 and 3.7 and assuming that there is at least one individual with \\(R_i=1\\) and one individual with \\(D_i=1\\), we have (keeping the conditioning on \\(E_i=1\\) implicit): \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{Bloom}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{1}{(p^{D}_1)^2}\\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\var{Y_i|R_i=0}}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\var{Y_i|R_i=1}}{p^R}\\right]\\right), \\end{align*}\\] with \\(p^D=\\Pr(D_i=1)\\), \\(p^R=\\Pr(R_i=1)\\) and \\((p^{D}_1=\\Pr(D_i=1|R_i=1)\\). Proof. The proof is immediate using Theorem 3.16, setting \\(p^{AT}=0\\). Remark. Theorem 3.8 shows that there is a price to pay for not randomizing after self-selection. This price is a decrease in precision. The variance of the estimator is weighted by \\(\\frac{1}{(\\Pr(D_i=1|R_i=1))^2}\\). This means that the effective sample size is equal to the number of individuals that take up the treatment when offered. We generaly call these individuals “compliers,” since they comply with the treatment assignment. Sampling noise is of the same order of magnitude as the number of compliers You might have very low precision despite a very large sample size if you have a very small proportion of compliers. Remark. In order to compute an estimate of the sampling noise of the Bloom estimator, we can either use the plug-in formula from Theorem 3.8 or use the IV standard errors robust to heteroskedasticity. Here is a simple function in order to compute the plug-in estimator: var.RAE.plugin &lt;- function(pD1,pD,pR,V0,V1,N){ return(((pD/pR)^2*(V0/(1-pR))+((1-pD)/(1-pR))^2*(V1/pR))/(N*pD1^2)) } Example 3.21 Let us derive the CLT-based estimates of sampling noise using both the plug-in estimator and the IV standard errors without conditioning on covariates first. For the sake of the example, I’m working with a sample of size \\(N=1000\\). sn.RAE.simuls &lt;- 2*quantile(abs(simuls.elig[[&#39;1000&#39;]][,&#39;Bloom&#39;]-delta.y.tt),probs=c(0.99)) sn.RAE.IV.plugin &lt;- 2*qnorm((.99+1)/2)*sqrt(var.RAE.plugin(pD1=mean(Ds[E==1 &amp; R==1]),pD=mean(Ds[E==1]),pR=mean(R[E==1]),V0=var(y[R==0 &amp; E==1]),V1=var(y[R==1 &amp; E==1]),N=length(y[E==1]))) sn.RAE.IV.homo &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.2sls.elig)[2,2]) sn.RAE.IV.hetero &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.2sls.elig,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 0.757. 99% sampling noise estimated using the plug-in estimator is 0.921. 99% sampling noise estimated using default IV standard errors is 1.069. 99% sampling noise estimated using heteroskedasticity robust IV standard errors is 0.92. Conditioning on covariates: sn.RAE.simuls.yB &lt;- 2*quantile(abs(simuls.elig.yB[[&#39;1000&#39;]][,&#39;Bloom&#39;]-delta.y.tt),probs=c(0.99)) sn.RAE.IV.homo.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.yB.2sls.elig)[2,2]) sn.RAE.IV.hetero.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.yB.2sls.elig,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 0.393. 99% sampling noise estimated using default IV standard errors is 0.457. 99% sampling noise estimated using heteroskedasticity robust IV standard errors is 0.454. Remark. Sampling noise in the Randomization After Eligibility design seems larger than sampling noise in the Self-Selection design. In the Self-Selection design, sampling noise with \\(N=1000\\) is equal to 0.55. In the Eligibility design, sampling noise with \\(N=1000\\) is equal to 0.76. Why such a difference? Both designs have the same effective sample size. In the Self-Selection design, the effective sample size \\(N^{SS}_e\\) is the number of eligible individuals that apply to take up the program: \\(N^{SS}_e=N\\Pr(D_i=1|E_i=1)\\Pr(E_i=1)\\). In our example, \\(N^{SS}_e=1000 *\\) 0.459 \\(*\\) 0.218 \\(=\\) 100. In the Eligibility design, the sample size on which the regressions are performed is \\(N^{E}\\), the number of eligible individuals: \\(N^{E}=N\\Pr(E_i=1)\\). In our example, \\(N^{E}=1000 *\\) 0.459 \\(=\\) 459. But the effective sample size for the Randomization After Eligibility design is actually equal to the one in the Self-Selection design because only compliers matter for the precision of the Bloom estimator, as Theorem 3.8 shows. Thus \\(N^{SS}_e=N^{E}_e\\). Why then is sampling noise much larger in the Randomization After Eligibility design? Probably because the Bloom estimator cannot enforce the fact that the impact of the program on non compliers is zero. It has to estimate the average outcome of non compliers in both treatment arms and hope that they cancel. In real samples, they won’t, increasing the size of sampling noise. 3.4 Encouragement Design In an Encouragement Design, we randomly select two groups among the eligibles, as in Randomization After Eligibility. Treated individuals randomly receive an encouragement to participate in the program and decide whether they want to comply with the encouragement and join the program. Individuals in the control group do not receive an encouragement, but they can still decide to self-select in the program. The Encouragement design differs from the Randomization After Eligibility design mainly by not barring entry into the programs to individuals in the control group. If successful, the encouragement generates a higher level of take up of the program in the treatment group than in the control group. Examples of encouragements are additional reminders that the program exists, help in subscribing the program, financial incentives for subscribing the program, etc. In an Encouragement Design, we can recover the causal effect of the treatment not on all the treated but on the treated whose participation into the program has been triggered by the encouragement. The individuals reacting to the encouragement by participating in the program are usually called compliers. The effect of the treatment on the compliers is called the Local Average Treatment Effect. The main identification result for Encouragement designs is that a Wald ratio (an IV estimator) recovers the LATE. It is due to Imbens and Angrist (1994). A key assumption for this result is exclusion restriction: there has to be zero impact of the encouragement on the outcome, except through participation in the treatment. A second key assumption is that no one individual is driven away from participating in the treatment because of the encouragement. This assumption is called monotonicity. Let’s detail these assumptions, the identification result and the estimation strategy. 3.4.1 Identification 3.4.1.1 Identification of the Local Average Treatment Effect Before stating the identification results, let’s go through some definitions and assumptions. We are going to denote \\(R_i=1\\) when individual \\(i\\) receives the encouragement and \\(R_i=0\\) when she does not. As in Section 3.3, we have four potential outcomes for \\(Y_i\\): \\(Y_i^{d,r}\\), \\((d,r)\\in\\left\\{0,1\\right\\}^2\\), where \\(d\\) denotes receiving the treatment and \\(r\\) receiving the encouragement. We also have two potential outcomes for \\(D_i\\): \\(D_i^{r}\\), \\(r\\in\\left\\{0,1\\right\\}\\). \\(D_i^{1}\\) indicates whether individual \\(i\\) takes the treatment when receving the encouragement and \\(D_i^{0}\\) whether she takes the treatment when not receiving the encouragement. These potential outcomes define four possible types of individuals, that I’m going to denote with the random variable \\(T_i\\): Always takers, who take up the program whether they receive the encouragement or not. They are such that \\(D_i^{1}=D_i^{0}=1\\). I denote them \\(T_i=a\\). Never takers, who do not take up the program whether they receive the encouragement or not. They are such that \\(D_i^{1}=D_i^{0}=0\\). I denote them \\(T_i=n\\). Compliers, who take up the program when they receive the encouragement and do not when they do not receive the encouragement. They are such that \\(D_i^{1}-D_i^{0}=1\\). I denote them \\(T_i=c\\). Defiers, who do not take up the program when they receive the encouragement and take it up when they do not receive the encouragement. They are such that \\(D_i^{1}-D_i^{0}=-1\\). I denote them \\(T_i=d\\). We are now ready to state the assumptions needed for identification of the LATE. Definition 3.9 (Encouragement Validity) We assume that the randomized allocation of the program does not interfere with how potential outcomes and self-selection are generated: \\[\\begin{align*} D_i &amp; = D_i^1R_i+(1-R_i)D_i^0 \\\\ Y_i &amp; = \\begin{cases} Y_i^{1,1} &amp; \\text{ if } (R_i=1 \\text{ and } D_i=1) \\\\ Y_i^{0,1} &amp; \\text{ if } (R_i=1 \\text{ and } D_i=0) \\\\ Y_i^{1,0} &amp; \\text{ if } (R_i=0 \\text{ and } D_i=1) \\\\ Y_i^{0,0} &amp; \\text{ if } (R_i=0 \\text{ and } D_i=0) \\end{cases} \\end{align*}\\] with \\(Y_i^{1,1}\\), \\(Y_i^{0,1}\\), \\(Y_i^{1,0}\\), \\(Y_i^{0,0}\\), \\(D_i^1\\) and \\(D^0_i\\) the same potential outcomes and self-selection decisions as in a routine allocation of the treatment. Definition 3.10 (Independence of Encouragement) We assume that the randomized allocation of the program is well done: \\[\\begin{align*} (Y_i^{1,1},Y_i^{0,1},Y_i^{0,0},Y_i^{1,0},D_i^1,D^0_i)\\Ind R_i|E_i=1. \\end{align*}\\] Definition 3.11 (Exclusion Restriction) We assume that the randomized allocation of the program does not alter potential outcomes: \\[\\begin{align*} Y_i^{d,r} &amp; = Y_i^d \\text{, }\\forall (r,d)\\in\\left\\{0,1\\right\\}^2. \\end{align*}\\] Definition 3.12 (First Stage) We assume that the encouragement does manage to increase participation: \\[\\begin{align*} \\Pr(D_i=1|R_i=1,E_i=1) &gt; \\Pr(D_i=1|R_i=0,E_i=1). \\end{align*}\\] Definition 3.13 (Monotonicity) We assume that the encouragement either increases participation for everyone or decreases participation for everyone: \\[\\begin{align*} \\text{ either } \\forall i\\text{, }D_i^1\\geq D_i^0 \\text{ or } \\forall i\\text{, }D_i^1\\leq D_i^0 . \\end{align*}\\] Assumption 3.13 means that we cannot have simultaneously individuals that are pushed by the encouragement into the treatment and individuals that are pushed out of the treatment. As a consequence, there cannot be compliers and defiers at the same time. There can only be compliers or defiers. For simplicity, in what follows, I assume that there are no defiers. This is without loss of generality, since, under Assumption 3.13, a redefinition of the treatment (\\(\\tilde{D}_i=-D_i\\)) moves the model in this section from one with only defiers to one with only compliers. Theorem 3.9 (Identification in an Encouragement Design) Under Assumptions 3.9, 3.10, 3.11, 3.12 and 3.13, the Wald estimator identifies the LATE: \\[\\begin{align*} \\Delta^Y_{Wald} &amp; = \\Delta^Y_{LATE}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{Wald} &amp; = \\frac{\\esp{Y_i|R_i=1,E_i=1} - \\esp{Y_i|R_i=0,E_i=1}}{\\Pr(D_i=1|R_i=1,E_i=1)-\\Pr(D_i=1|R_i=0,E_i=1)}\\\\ \\Delta^Y_{LATE} &amp; = \\esp{Y^1_i-Y^0_i|T_i=c,E_i=1}. \\end{align*}\\] Proof. See Section A.2.1. Remark. Theorem 3.9 is pretty amazing. It shows that there exists a set of assumptions under which we can use an encouragement design to recover the effect of the treatment (\\(D_i\\)) on outcomes, despite the fact that we have NOT randomized \\(D_i\\). The assumptions needed for that to happen are intuitive: The encouragement has to have no direct effect on the outcomes (Assumption 3.11) The encouragement has to have an effect on treatment uptake (Assumption 3.12) The encouragement does not generate two-way flows in and out of the treatment, but only a one-way flow (Assumption 3.13) Under these assumptions, the only way that we can see a difference in outcomes between those that receive the encouragement and those that do not is that the treatment has had an effect on those that have taken it because of the encouragement. It cannot be because of the encouragement itself, because of Assumption 3.11. It cannot be because some people with particularly low outcomes have exited the program because of the encouragement, Assumption 3.13 forbids it. And if we see no effect of the encouragement, it has to be that the treatment has no effect on the compliers as well, because Assumption 3.12 implies that they have received the treatment in the encouragement group and that they have not in the group without encouragement. Remark. Less nice with Theorem 3.9 is that we recover the effect only for a subgroup of individuals, the compliers. This raises two issues: The effect on the compliers (or LATE) is not the effect on the treated (TT). When the treatment is given in routine mode, without the encouragement, TT is actually equal to the effect on the always takers. There is nothing that tells us that the always takers react in the same way to the treatment as the compliers. As soon as the expected benefits of the treatment enter the decision of taking it up, always takers have larger treatment effects than compliers. The identity of the compliers is unobserved. We cannot decide to allocate the treatment only to the compliers because they are defined by their counterfactual response to the encouragement. In both treatment arms, we do not know who the compliers are. We know they are among those who take up the program in the group receiving the encouragement. But there are also always takers that take up the program in this group. We know that they are among those that do not take up the program in the group that does not receive the encouragement. But never takers behave in the same way in that group. The only way to direct the treatment at the compliers is to use the encouragement. So, we end up evaluating the effect of the encouragement itself and not of the program. In that case, we do not need Assumptions 3.11, 3.12 and 3.13, because they are not needed to identify the effect of the encouragement (see Section 3.4.1.2 below). In general, researchers believe that LATE tells them something about the magnitude of the effect beyond compliers. This is not warranted by the maths, but one can understand how a bayesian decision-maker may use the information from some subpopulation to infer what would happen to another. Comparing LATEs and TTs for similar treatments is an active area for reasearch. I know of no paper doing that extensively and nicely. To generalize from the LATE to the TT, we can make the assumption that the impact on always takers is equal to the impact on compliers, but that seems a little far-fetched. Angrist and Fernandez-Val propose to assume that the effect on compliers is equal to the effect on always takers conditional on some observed covariates. When outcomes are bounded (for example because they are between zero and one), we can try to bound the \\(TT\\) using the \\(LATE\\) (see Huber, Laffers and Mellace (2017)). Remark. If you see a connexion between the conditions for the Wald estimator to identify LATE and the assumptions behind an IV estimator, you’re correct. The Wald estimator is actually an IV estimator (see Theorem 3.15 below). 3.4.1.2 Identification of the Intention to Treat Effect In this section, we are going to delineate how to identify the Intention to Treat Effect (ITE) in an Encouragement design. In an Encouragement design, ITE is the effect of receiving the encouragement. It is defined in a similar manner as in a Randomization After Eligibility design (see Definition 3.8): \\(\\Delta^Y_{ITE} = \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|E_i=1}\\). Under Assumption 3.9, receiving the encouragement has several impacts: Some individuals (the compliers) decide to enter the program, Some individuals (the defiers) decide to exit the program, The encouragement might have a direct effect on outcomes (\\(Y_i^{d,1}\\neq Y_i^{d,0}\\)). This last effect is the effect of receiving the encouragement that does not goes through participation into the program. For example, it is possible that sending an encouragement to take up a retirement program makes me save more for retirement, even if I end up not taking up the proposed program. The two causal channels that are at work within the ITE can be seen more clearly when decomposing the ITE to make each type appear. We can do that because the four types define a partition of the sample space, that is a collection of mutually exclusive events whose union spans the whole space. As a consequence of that, conditioning on the union of the four types is the same thing as not conditioning on anything. Using this trick, we have: \\[\\begin{align} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|(T_i=a\\cup T_i=c\\cup T_i=d\\cup T_i=n)\\cap E_i=1}\\nonumber\\\\ &amp; = \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|T_i=a,E_i=1}\\Pr(T_i=a|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|T_i=c,E_i=1}\\Pr(T_i=c|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|T_i=d,E_i=1}\\Pr(T_i=d|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{D_i^1,1}-Y_i^{D_i^0,0}|T_i=n,E_i=1}\\Pr(T_i=n|E_i=1)\\nonumber\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=a,E_i=1}\\Pr(T_i=a|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{1,1}-Y_i^{0,0}|T_i=c,E_i=1}\\Pr(T_i=c|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0,1}-Y_i^{1,0}|T_i=d,E_i=1}\\Pr(T_i=d|E_i=1)\\nonumber\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0,1}-Y_i^{0,0}|T_i=n,E_i=1}\\Pr(T_i=n|E_i=1),\\tag{3.2} \\end{align}\\] where the first equality follows from the four types defining a partition of the sample space, the second equality from the usual rule of conditional expectations and the fact that types are disjoint events, and the third equality from Assumption 3.6. We can now see that ITE is composed of four terms: The effect of receiving the encouragment on the always takers. This effect is only the direct effect of the encouragement, and not the effect of the program since the always takers always take the program. This term cancels under Assumption 3.11, when there is no direct effect of the encouragement on outcomes. The effect of receiving the encouragement on compliers. This is both the effect of the encouragement and of the program. This is equal to the LATE under Assumption 3.11. The effect of receiving the encouragement on defiers. This is the difference between the direct effect of the encouragement and the effect of the program. This is equal to the opposite of the effect of the treatment on the defiers under Assumption 3.11. The effect of receiving the encouragement on never takers. This effect is only the direct effect of the encouragement, and not the effect of the program since the never takers never take the program. This term cancels under Assumption 3.11. All these effects are weighted by the respective proportions of the types in the population. ITE is linked to LATE. This link can be made clearer: Theorem 3.10 (From ITE to Compliers and Defiers) Under Assumptions 3.9 and 3.11, ITE is equal to the effect on compliers minus the effect on defiers weighted by their respective proportions in the population: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=c,E_i=1}\\Pr(T_i=c|E_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{1}-Y_i^{0}|T_i=d,E_i=1}\\Pr(T_i=d|E_i=1). \\end{align*}\\] Proof. Under Assumption 3.11, Equation (3.2) becomes: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1}-Y_i^{1}|T_i=a,E_i=1}\\Pr(T_i=a|E_i=1)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{1}-Y_i^{0}|T_i=c,E_i=1}\\Pr(T_i=c|E_i=1)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0}-Y_i^{1}|T_i=d,E_i=1}\\Pr(T_i=d|E_i=1)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0}-Y_i^{0}|T_i=n,E_i=1}\\Pr(T_i=n|E_i=1) \\end{align*}\\] which proves the result. The previous theorem shows that Assumption 3.11 shuts down any direct effect of receiving the encouragement on outcomes. As a consequence of this assumption, the only impact that receiving the encouragement has on outcomes is through participation into the program. Hence, ITE is equal to the impact of the program on those who react to the encouragement: the compliers and the defiers, weighted by their respective proportions. The problem with the result of Theorem 3.10 is that ITE contains two-way flows in and out of the program. If we want to know something about the effect of the program, and not only about the effect of the encouragement, we need to assume that defiers do not exist. That’s what Assumption 3.13 does, as the following theorem shows: Theorem 3.11 (From ITE to LATE) Under Assumptions 3.9, 3.11 and 3.13, ITE is equal to the LATE multiplied by the proportion of compliers in the population: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\Delta^Y_{LATE}\\Pr(T_i=c|E_i=1). \\end{align*}\\] Proof. The result is straighforward using Assumption 3.13 and Theorem 3.10. Indeed, Assumption 3.13 implies that \\(\\forall i\\), \\(D_i^1-D_i^0\\geq 0\\) (choosing only the first “either” statement, without loss of generality). As a consequence, \\(\\Pr(T_i=d|E_i=1)=\\Pr(D_i^1-D_i^0=-1|E_i=1)=0\\). In order to move from the link between LATE and ITE to the mechanics of the Wald estimator, we need two additional identification results. The first result shows that ITE can be identified under fairly light conditions by a WW estimator. The second result shows that the proportion of people taking up the treatment when eligiblity is announced is also easily estimated from the data. Theorem 3.12 (Identification of ITE in an Encouragement Design) Under Assumptions 3.9 and 3.10, ITE is identified by the With/Without comparison among eligibles: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\Delta^Y_{WW|E_i=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{WW|E=1} &amp; =\\esp{Y_i|R_i=1,E_i=1}-\\esp{Y_i|R_i=0,E_i=1} \\\\ &amp; = \\esp{Y_i^{D_i^1,1}|R_i=1,E_i=1}-\\esp{Y_i^{D_i^0,0}|R_i=0,E_i=1} \\\\ &amp; = \\esp{Y_i^{D_i^1,1}|E_i=1}-\\esp{Y_i^{D_i^0,0}|E_i=1}, \\end{align*}\\] where the second equality follows from Assumption 3.9 and the third from Assumption 3.10. Theorem 3.13 (Identification of the Proportion of Compliers) Under Assumptions 3.9, 3.10 and 3.13, the proportion of compliers is identified by the difference between the proportion of people taking up the program among those receiving the encouragement and the proportion of individuals taking up the program among those not receiving the encouragement: \\[\\begin{align*} \\Pr(T_i=c|E_i=1) &amp; = \\Pr(D_i=1|R_i=1,E_i=1)-\\Pr(D_i=1|R_i=0,E_i=1). \\end{align*}\\] Proof. \\[\\begin{align*} \\Pr(D_i=1|R_i=1,E_i=1) &amp; =\\Pr(D_i=1\\cap (T_i=a\\cup T_i=c\\cup T_i=d\\cup T_i=n)|R_i=1,E_i=1) \\\\ &amp; = \\Pr(D_i=1\\cap T_i=a|R_i=1,E_i=1)\\\\ &amp; \\phantom{=}+ \\Pr(D_i=1\\cap T_i=c|R_i=1,E_i=1)\\\\ &amp; \\phantom{=} +\\Pr(D_i=1\\cap T_i=d|R_i=1,E_i=1)\\\\ &amp; \\phantom{=} +\\Pr(D_i=1\\cap T_i=n|R_i=1,E_i=1)\\\\ &amp; = \\Pr(T_i=a|R_i=1,E_i=1)\\\\ &amp; \\phantom{=} +\\Pr(T_i=c|R_i=1,E_i=1)\\\\ &amp; = \\Pr(T_i=a|E_i=1)\\\\ &amp; \\phantom{=} +\\Pr(T_i=c|E_i=1), \\end{align*}\\] where the first equality follows the types being a partition of the sample space; the second equality from the fact that the types are disjoint sets; the third equality from the fact that \\(T_i=a|R_i=1 \\Rightarrow D_i=1\\) (so that \\(\\Pr(D_i=1\\cap T_i=a|R_i=1,E_i=1)=\\Pr(T_i=a|R_i=1,E_i=1)\\)), \\(T_i=c|R_i=1 \\Rightarrow D_i=1\\) (so that \\(\\Pr(D_i=1\\cap T_i=c|R_i=1,E_i=1)=\\Pr(T_i=c|R_i=1,E_i=1)\\)), \\(T_i=d|R_i=1 \\Rightarrow D_i=0\\) (so that \\(\\Pr(D_i=1\\cap T_i=d|R_i=1,E_i=1)=0\\)) and \\(T_i=n|R_i=1 \\Rightarrow D_i=0\\) (so that \\(\\Pr(D_i=1\\cap T_i=n|R_i=1,E_i=1)=0\\)); and the fourth equality from Assumption 3.10 and Lemma A.6. Corollary 3.2 (Wald estimator and ITE) It follows from Theorems 3.12 and 3.13 that, under Assumptions 3.9, 3.10 and 3.13, the Wald estimator is equal to the ITE divided by the propotion of compliers: \\[\\begin{align*} \\Delta^Y_{Wald|E=1} &amp; = \\frac{\\Delta^Y_{ITE}}{\\Pr(T_i=c|E_i=1)}. \\end{align*}\\] As a consequence of Corollary 3.2, we see that the Wald estimator reweights the ITE, the effect of receiving an encouragement, by the proportion of people reacting to the encouragement by participating in the program, the compliers. From Theorem 3.10, we know that this ratio will be equal to LATE if the Assumption 3.11 also holds, so that all the impact of the encouragement stems from entering the program. The encouragement serves as an instrument for program participation. Remark. The Encouragement design seems like magic. You do not assign randomly the program, but only an encouragement to take it, and you can recover the effect of the program anyway. The Encouragement design is less intrusive than the Self-Selection and Eligibility designs. In an Encouragement design, you do not have to refuse the program to agents in the control group. You pay two types of prices for that: You only recover LATE, not TT You have larger sampling noise. The intuition for this second point can be delineated using the very same apparatus that we have developed so far. So here goes. Under the assumptions made so far, it is easy to show that (omitting the conditioning on \\(E_i=1\\) for simplicity): \\[\\begin{align*} \\Delta^Y_{WW|E=1} &amp; = \\esp{Y_i^{1,1}|T_i=a,R_i=1}\\Pr(T_i=a,|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{1,0}|T_i=a,R_i=0}\\Pr(T_i=a,|R_i=0)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{1,1}|T_i=c,R_i=1}\\Pr(T_i=c|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{0,0}|T_i=c,R_i=0}\\Pr(T_i=c|R_i=0)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0,1}|T_i=d,R_i=1}\\Pr(T_i=d|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{1,0}|T_i=d,R_i=0}\\Pr(T_i=d|R_i=0)\\\\ &amp; \\phantom{=}+ \\esp{Y_i^{0,1}|T_i=n,R_i=1}\\Pr(T_i=n|R_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{0,0}|T_i=n,R_i=0}\\Pr(T_i=n|R_i=0). \\end{align*}\\] The four parts of the equation account for comparisons among each type between the two treatment arms. The parts due to always takers and never takers cancel out under Assumptions 3.10 and 3.11. But this cancelling out only happens in the population. In a given sample, the sample equivalents of the two members of each difference do not have to be equal, and thus they do not cancel out, generating sampling noise. Ideally, we would like to enforce that the effect of the encouragement on always takers and never takers is null, as Assumption 3.11 imposes, but that would require observing the type variable \\(T_i\\). Unfortunately, we cannot now the type of each individual in the sample, since it is defined counterfactually. Maybe someday we’ll be able to use prior responses to the encouragement to identify the type of each individual and thus improve the precision of the Wald estimator. Explain de Chaisemartin. Remark. what if we fear there are defiers. de Chaisemartin Remark. In practice, we use a pseudo-RNG to allocate the randomized annoucement of the encouragement: \\[\\begin{align*} R_i^* &amp; \\sim \\mathcal{U}[0,1]\\\\ R_i &amp; = \\begin{cases} 1 &amp; \\text{ if } R_i^*\\leq .5 \\land E_i=1\\\\ 0 &amp; \\text{ if } R_i^*&gt; .5 \\land E_i=1 \\end{cases} \\\\ D_i &amp; = \\uns{\\bar{\\alpha}+\\theta\\bar{\\mu}+\\psi R_i-C_i\\geq0 \\land E_i=1} \\end{align*}\\] \\(\\psi\\) denotes the increase in agents’ valuation of the program after receiving the encouragement. Example 3.22 Let’s see how the encouragement design works in our numerical example. Let’s choose a value for \\(\\psi\\) and add it to the vector of parameters. param &lt;- c(param,0.6) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;barc&quot;,&quot;gamma&quot;,&quot;sigma2V&quot;,&quot;psi&quot;) Let’s first compute the value of LATE in this new model. Let’s denote \\(D_i^{*0}=\\bar{\\alpha}+\\theta\\bar{\\mu}-C_i\\) the utility of agent \\(i\\) absent the encouragement, with \\(C_i=\\bar{c} + \\gamma \\mu_i + V_i\\). In order to be a complier, you have to have a utility of the program that is insufficient to make you apply for the program when you receive no encouragement (\\(D_i^{*0}&lt;0\\)) and a positive utility of applying to the treatment after receiving the encouragement (\\(D_i^{*0}+\\psi\\geq 0\\)). Compliers are thus such that \\(-\\psi\\leq D_i^{*0}&lt;0\\). LATE can thus be written as follows in our model: \\[\\begin{align*} \\Delta^y_{LATE} &amp; = \\bar{\\alpha}+ \\theta\\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y} \\land -\\psi\\leq D_i^{*0}&lt;0}, \\end{align*}\\] Using the same approach, we can also compute the proportion of compliers among eligibles. In our model, we indeed have: \\[\\begin{align*} \\Pr(T_i=c|E_i=1) &amp; = \\Pr(-\\psi\\leq D_i^{*0}&lt;0|\\mu_i+U_i^B\\leq\\bar{y}). \\end{align*}\\] Since all errors terms are normally distributed in our model, we can compute the package tmvtnorm to compute both LATE and the proportion of compliers among eligibles. \\[\\begin{align*} (\\mu_i,y_i^B,D_i^{*0}) &amp; \\sim \\mathcal{N}\\left(\\bar{\\mu},\\bar{\\mu},\\bar{\\alpha}+(\\theta-\\gamma)\\bar{\\mu}-\\bar{c}, \\left(\\begin{array}{ccc} \\sigma^2_{\\mu} &amp; \\sigma^2_{\\mu} &amp; -\\gamma\\sigma^2_{\\mu} \\\\ \\sigma^2_{\\mu} &amp; \\sigma^2_{\\mu} + \\sigma^2_{U} &amp; -\\gamma\\sigma^2_{\\mu} \\\\ -\\gamma\\sigma^2_{\\mu} &amp; -\\gamma\\sigma^2_{\\mu} &amp; \\gamma^2\\sigma^2_{\\mu}+\\sigma^2_{V} \\end{array} \\right) \\right) \\end{align*}\\] mean.mu.yB.Dstar &lt;- c(param[&#39;barmu&#39;],param[&#39;barmu&#39;],param[&#39;baralpha&#39;]- param[&#39;barc&#39;]+(param[&#39;theta&#39;]-param[&#39;gamma&#39;])*param[&#39;barmu&#39;]) cov.mu.yB.Dstar &lt;- matrix(c(param[&#39;sigma2mu&#39;],param[&quot;sigma2mu&quot;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;], param[&quot;sigma2mu&quot;],param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;], -param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;],-param[&#39;gamma&#39;]*param[&quot;sigma2mu&quot;],param[&quot;sigma2mu&quot;]*(param[&#39;gamma&#39;])^2+param[&#39;sigma2V&#39;]),3,3,byrow=TRUE) # late lower.cut &lt;- c(-Inf,-Inf,-param[&#39;psi&#39;]) upper.cut &lt;- c(Inf,log(param[&#39;barY&#39;]),0) moments.cut &lt;- mtmvnorm(mean=mean.mu.yB.Dstar,sigma=cov.mu.yB.Dstar,lower=lower.cut,upper=upper.cut) delta.y.late &lt;- param[&#39;baralpha&#39;]+ param[&#39;theta&#39;]*moments.cut$tmean[1] # proportion of compliers lower.cut &lt;- c(-Inf,-Inf,-Inf) upper.cut &lt;- c(Inf,log(param[&#39;barY&#39;]),Inf) pr.compliers &lt;- ptmvnorm.marginal(xn=0,n=3,mean=mean.mu.yB.Dstar,sigma=cov.mu.yB.Dstar,lower=lower.cut,upper=upper.cut)-ptmvnorm.marginal(xn=-param[&#39;psi&#39;],n=3,mean=mean.mu.yB.Dstar,sigma=cov.mu.yB.Dstar,lower=lower.cut,upper=upper.cut) delta.y.ite &lt;- delta.y.late*pr.compliers The value of \\(\\Delta^y_{LATE}\\) in the population is thus 0.173. The proportion of compliers among eligibles in the population is 0.272. As a consequence of Corollary 3.2, we can compute ITE as the product of LATE and the proportion of compliers. In our example, ITE is thus equal to 0.047 in the population. Now let’s simulate a new sample with the encouragement delivered randomly among eligibles. I’m also defining the potential outcomes \\(D^1_i\\) and \\(D^0_i\\) and the types \\(T_i\\) for later use. # I&#39;m changing the seed because with the usual one, I get a negative estimate of the treatment effect: lots of sampling noise! set.seed(12345) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation of encouragement among eligibles E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; E==1,1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dindex &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]+param[&quot;psi&quot;]*R-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Ds &lt;- ifelse(Dindex&gt;=0 &amp; E==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) D &lt;- Ds # types Dindex1 &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]+param[&quot;psi&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Dindex0 &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V D1 &lt;- ifelse(Dindex1&gt;=0 &amp; E==1,1,0) D0 &lt;- ifelse(Dindex0&gt;=0 &amp; E==1,1,0) AT &lt;- ifelse(D1==1 &amp; D0==1,1,0) NT &lt;- ifelse(D1==0 &amp; D0==0,1,0) Co &lt;- ifelse(D1==1 &amp; D0==0,1,0) # figures Ncompliers &lt;- sum(Co) NElig &lt;- sum(E) PrCoElig &lt;- Ncompliers/NElig LATEs &lt;- mean(alpha[Co==1]) ITEs &lt;- LATEs*PrCoElig In our sample of \\(N=\\) 1000 individuals, there are only 216 eligibles, and among them 67 compliers. The proportion of compliers among eligibles is thus 0.31. Sample size decreases fast in an encouragement design. The sample LATE is equal to 0.14. The sample ITE is equal to 0.044. 3.4.2 Estimating the Local Average Treatment Effect and the Intention to Treat Effect Classically, we present the results of an Encouragement design in three stages: We show the first stage regression of \\(D_i\\) on \\(R_i\\): this estimates the impact of the encouragement on participation into the program and estimates the proportion of compliers. We show the reduced form regression of \\(Y_i\\) on \\(R_i\\): this estimates the impact of the encouragement on outcomes, also called ITE. We finally show the structural regression of \\(Y_i\\) on \\(D_i\\) using \\(R_i\\) as an instrument, which estimates the LATE. 3.4.2.1 First stage regression The first stage regression is simply to get an estimate of the effect of the encouragement on participation into the program. If there is no effect of the encouragement on participation, we might as well stop there, since there will be no compliers and no effect to estimate. Note that if we observe an effect on the encouragement on outcomes without any effect on participation, we have to accept the fact that the encouragement might have had a direct effect on outcomes and thus that the exclusion restriction assumption does not hold. Let’s denote this effect of \\(R_i\\) on \\(D_i\\) \\(\\Delta^{D,R}_{TT}=\\esp{D_i^1-D_i^0|R_i=1,E_i=1}\\). It is a treatment on the treated since we want to estimate the effect of the cnouragement onthose who have received it. Actually, \\(\\Delta^{D,R}_{TT}\\) is also equal to \\(\\Delta^{D,R}_{ATE}\\), since those who have received the encouragement are a random sample of the eligibles. How to estimate the effect of \\(R_i\\) on \\(D_i\\)? When estimating the effect of the encouragement, we are in a Brute Force design among eligibles, so that the appropriate estimator is the With/Without estimator among eligibles: Theorem 3.14 (Identification of the First Stage Effect in an Encouragment Design) Under Assumptions 3.9 and 3.10, the WW estimator identifies the First Stage Effect (the effect of \\(R_i\\) on \\(D_i\\)): \\[\\begin{align*} \\Delta^{D,R}_{WW} &amp; = \\Delta^{D,R}_{TT}. \\end{align*}\\] Proof. This is a direct consequence of Theorem 3.1. As we have seen in Chapter 1, the WW estimator is identical to an OLS estimator: The OLS coefficient \\(\\beta\\) in the following regression: \\[\\begin{align*} D_i &amp; = \\alpha + \\beta R_i + U_i \\end{align*}\\] is thus the \\(WW\\) estimator. Finally, the advantage of using OLS other the direct WW comparison is that it gives you a direct estimate of sampling noise (see next section) but also that it enables you to condition on additional covariates in the regression: The OLS coefficient \\(\\beta\\) in the following regression: \\[\\begin{align*} D_i &amp; = \\alpha + \\beta R_i + \\gamma&#39; X_i + U_i \\end{align*}\\] is a consistent (and even unbiased) estimate of the ATE. Center covariates at mean? Example 3.23 In our numerical example, we can compare all these estimators. WW.D.R &lt;- mean(D[E==1 &amp; R==1])-mean(D[E==1 &amp; R==0]) reg.D.R.ols &lt;- lm(D[E==1]~R[E==1]) reg.D.R.ols.yB &lt;- lm(D[E==1]~R[E==1]+yB[E==1]) \\(\\hat{\\Delta}^{D,R}_{WW} =\\) 0.213, while \\(\\hat{\\Delta}^{D,R}_{OLS}=\\) 0.213 which is exactly equal, as expected, to the WW estimator. When controlling for \\(y^B_i\\), we have: \\(\\hat{\\Delta}^{D,R}_{OLS(y^B)}=\\) 0.233. Under monotonicity, \\(\\Delta^{D,R}_{TT}\\) is equal to the proportion of compliers among eligibles. Indeed, this is the proportion of eligibles that participate when receiving the encouragement and that does not participate when not receiving it. In our example, the proportion of compliers among eligibles is 0.272 in the population and 0.31 in the sample. We are thus underestimating the true proportino of compliers, which is going to make us overestimate the LATE. 3.4.2.2 Reduced form regression The reduced form regression aims at estimating the ITE, that is the impact of receiving the encouragement on outcomes. From Theorem 3.12, we know that the WW estimator among eligibles identifies the ITE in the population. As a consequence of now classical results, the OLS estimator without control variables is equivalent to the WW estimator and the OLS estimator conditioning on covariates might increase precision. Example 3.24 In our numerical example, we can compare all these estimators. WW.y.R &lt;- mean(y[E==1 &amp; R==1])-mean(y[E==1 &amp; R==0]) reg.y.R.ols &lt;- lm(y[E==1]~R[E==1]) reg.y.R.ols.yB &lt;- lm(y[E==1]~R[E==1]+yB[E==1]) \\(\\hat{\\Delta}^{y,R}_{WW} =\\) 0.179, while \\(\\hat{\\Delta}^{y,R}_{OLS}=\\) 0.179 which is exactly equal, as expected, to the WW estimator. When controlling for \\(y^B_i\\), we have: \\(\\hat{\\Delta}^{y,R}_{OLS(y^B)}=\\) 0.108. In our example, the ITE is 0.047 in the population and 0.044 in the sample. Without conditioning on \\(Y_i^B\\), we are thus overestimating the true ITE by a lot. The consequence is that we are going to overestimate the LATE as well. 3.4.2.3 Structural regression There are four ways to compute the LATE: We can directly compute the sample equivalent to the Wald estimator defined in Theorem 3.9. We can divide our estimate of the ITE by the proportion of compliers, as Corollary 3.2 suggests. We can run a regression of \\(Y\\) on \\(D\\) using \\(R\\) as an instrumental variable. We can run a regression of \\(Y\\) on \\(D\\) using \\(R\\) as an instrumental variable and controlling for some variables \\(X\\). It turns out that, in the absence of control variables, the first three estimators are fully equivalent. Corollary 3.2 has already shown that the first two approaches are equivalent in the population. Theorem 3.15 below shows that the Wald estimator is equivalent to an IV estimator. For simplicity, in all that follows, I am working only in the subgroup of eligible individuals. That means that I’m setting \\(E_i=1\\) for everyone, so that \\(N\\) is the number of eligible individuals. 3.4.2.3.1 Using the Wald estimator The empirical counterpart to the Wald estimator is the difference in mean outcomes between treatment and controls divided by the difference in participation rates between the two groups: \\[\\begin{align*} \\hat{\\Delta}^Y_{Wald} &amp; = \\frac{\\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N Y_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N Y_i(1-R_i)}{\\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N D_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N D_i(1-R_i)} \\end{align*}\\] Example 3.25 Let’s check how this works in our numerical example. mean.y.R.1 &lt;- mean(y[E==1 &amp; R==1]) mean.y.R.0 &lt;- mean(y[E==1 &amp; R==0]) mean.D.R.1 &lt;- mean(D[E==1 &amp; R==1]) mean.D.R.0 &lt;- mean(D[E==1 &amp; R==0]) delta.y.Wald &lt;- (mean.y.R.1-mean.y.R.0)/(mean.D.R.1-mean.D.R.0) The numerator of the Wald estimator is equal to 7.059 \\(-\\) 6.88 \\(=\\) 0.179. The denominator of the Wald estimator is equal to 0.704 \\(-\\) 0.491 \\(=\\) 0.213. Overall, the Wald estimator of the LATE is equal to 0.179 \\(\\div\\) 0.213 \\(=\\) 0.841. Remember that the true LATE is equal to 0.173. We are thus severely overestimating the LATE. We’ll understand why in the next section. 3.4.2.3.2 Using the ITE We know from Corollary 3.2 that dividing the ITE by the proportion of compliers gives the Wald estimator. From Theorem 3.12, we know that the ITE can be estimated using the sample equivalent to the With/Without estimator as follows: \\[\\begin{align*} \\hat{\\Delta}^{Y,R}_{WW} &amp; = \\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N Y_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N Y_i(1-R_i). \\end{align*}\\] From Theorem 3.13, we also know that the proportion of compliers can be estimated using the sample equivalent to the With/Without estimator as follows: \\[\\begin{align*} \\hat{\\Delta}^{D,R}_{WW} &amp; = \\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N D_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N D_i(1-R_i). \\end{align*}\\] Example 3.26 Let’s check that this unfolds in our numerical example. We already know that the estimated ITE is equal to 0.179, which is equal to the numerator of the Wald estimator. We also now that the proportion of compliers in our sample is equal to 0.213. As a consequence, again, the Wald estimator of the LATE is equal to 0.179 \\(\\div\\) 0.213 \\(=\\) 0.841. Without surprise, we obtain exactly the same results as when using the Wald estimator directly. The two approaches are numerically equivalent. Again, our estimator of the LATE, the Wald estimator, severelt overestimates the LATE. The Wald estimator is equal to 0.841 while the true LATE is equal to 0.173. What is the reason for this mistake? There are actually two: We are overestimating the ITE (truth: 0.047; estimate: 0.179). We are underestimating the proportion of compliers (truth: 0.272; estimate: 0.213). The combination of these two mistakes generates the large discrepancy that we see between our estimate of the LATE and its true value. This error comes for covariates that are not distributed identically in the treatment and control groups. Maybe controlling for some of them would improve our fit. In order to to that, we need the IV estimator. 3.4.2.3.3 Using the IV estimator A very useful result is that the Wald estimator can be computed as an IV estimator. The following theorem proves that point: Theorem 3.15 (Wald is IV) Under the assumption that there is at least one individual with \\(R_i=1\\) and \\(D_i=1\\), the coefficient \\(\\beta\\) in the following regression estimated using \\(R_i\\) as an IV: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta D_i + U_i \\end{align*}\\] is the Wald estimator: \\[\\begin{align*} \\hat{\\beta}_{IV} &amp; = \\frac{\\frac{1}{N}\\sum_{i=1}^N\\left(Y_i-\\frac{1}{N}\\sum_{i=1}^NY_i\\right)\\left(R_i-\\frac{1}{N}\\sum_{i=1}^NR_i\\right)}{\\frac{1}{N}\\sum_{i=1}^N\\left(D_i-\\frac{1}{N}\\sum_{i=1}^ND_i\\right)\\left(R_i-\\frac{1}{N}\\sum_{i=1}^NR_i\\right)} \\\\ &amp; = \\frac{\\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N Y_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N Y_i(1-R_i)}{\\frac{1}{\\sum_{i=1}^N R_i}\\sum_{i=1}^N D_iR_i-\\frac{1}{\\sum_{i=1}^N (1-R_i)}\\sum_{i=1}^N D_i(1-R_i)}\\\\ &amp; = \\hat{\\Delta}^Y_{Wald} \\end{align*}\\] Proof. See in section A.2.2 in the appendix. Theorem 3.15 is super powerful since it enables us to directly use the IV estimator to compute the Wald estimator. In order to do so, we’re going to use the estimator ivreg in the AER package. Example 3.27 Let’s see how the IV estimator performs in our numerical example. reg.y.R.2sls.encourage &lt;- ivreg(y[E==1]~Ds[E==1]|R[E==1]) beta.IV &lt;- reg.y.R.2sls.encourage$coef[2] \\(\\hat{\\beta}_{IV}=\\) 0.841, which is equal to the Wald estimator, as Theorem 3.15 predicted. 3.4.2.3.4 Using the IV estimator conditioning on covariates One nice thing about the IV estimator is that we can use it to control for additional covariates \\(X\\). Estimating the following equation with \\(R_i\\) and \\(X_i\\) as instruments: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta D_i + \\gamma&#39; X_i + U_i \\end{align*}\\] recovers \\(\\beta_{IV}(X)\\), which is an estimate of the LATE under linearity assumptions on the potential outcomes. Expand on that Center covariates at mean? Example 3.28 Let’s see how this work in our numerical example, when we condition on \\(y^B_i\\). reg.y.R.yB.2sls.encourage &lt;- ivreg(y[E==1] ~ Ds[E==1] + yB[E==1] | R[E==1] + yB[E==1]) beta.IV.yB &lt;- reg.y.R.yB.2sls.encourage$coef[2] \\(\\hat{\\beta}_{IV}(y^B)=\\) 0.464. Remember that the value of \\(\\Delta^y_{LATE}\\) in the population is thus 0.173. All of our estimators have overshoot. The worse are the ones not conditioning on \\(y^B\\). It seems that conditioning on \\(y^B\\) improves the estimator slightly. So part of the estimation error in the Wald estimator probably comes from an imbalance in \\(y_i^B\\) between the treatment and control groups. Let’s check that this is the case. reg.yB.R.ols.encourage &lt;- lm(yB[E==1] ~ R[E==1]) delta.yB.WW.R &lt;- reg.yB.R.ols.encourage$coef[2] The difference in \\(y_i^B\\) among treated and controls in our example is 0.075. This is enough to account for the bias on the ITE. Expand on that Remark. One key question that remains is that whether the structural parameter \\(\\beta(X)\\) is still equal to the ratio of the reduced form parameter and the first stage parameter obtained by running OLS conditionnal on \\(X\\). Example 3.29 Let’s examine what happens in our example. reg.y.R.yB.ols.encourage &lt;- lm(y[E==1] ~ R[E==1] + yB[E==1]) ITE.yB &lt;- reg.y.R.yB.ols.encourage$coef[2] reg.D.R.yB.ols.encourage &lt;- lm(D[E==1] ~ R[E==1] + yB[E==1]) prCo.yB &lt;- reg.D.R.yB.ols.encourage$coef[2] Wald.yB &lt;- ITE.yB/prCo.yB We find that the ITE conditional on \\(y^B_i\\) is equal to 0.108 while the proportion of compliers conditioning on \\(y_i^B\\) is equal to 0.233. Overall the ratio of these two, which we could call the Wald ratio after conditioning on \\(y_i^B\\) is equal to 0.464. This is actually equal to the IV estimator including \\(y_i^B\\) as a covariate: \\(\\hat{\\beta}_{IV}(y^B)=\\) 0.464. So running the reduced form and first stage regressions separately and dividing the coefficients on \\(R_i\\) recovers the LATE even when conditioning on covariates? That’s pretty neat and opens up the route for a variety of new estimation techniques called split sample estimators, developed by Angrist and Krueger. We’ll take more about them later. Remark. We might want to control nonparametrically on the covariates instead of imposing a linear regression. Frolich’s Wald matching estimator enables to do just that. Its implementation will become clearer after Chapter ??. Remark. The last thing we want to check is whether conditioning on covariates improve precision. It seems to be the case in our example with one dataset. Let’s see what happens over sampling repetitions. Example 3.30 Let’s run some Monte Carlo simulations for the sampling noise of IV with and without conditining on \\(y_i^B\\). Figure 3.7: Distribution of the \\(Wald\\) and \\(Wald(X)\\) estimator in an encouragement design over replications of samples of different sizes Comment on the results 3.4.3 Estimating sampling noise As always, we can estimate sampling noise either using the CLT or resampling methods. Using the CLT, we can derive the following formula for the distribution of the Bloom estimator: Theorem 3.16 shows the asymptotic distribution of \\(\\hat{\\Delta}^Y_{Wald}\\): Theorem 3.16 (Asymptotic Distribution of $\\hat{\\Delta}^Y_{Wald}$) Under Assumptions 3.9, 3.10, 3.11, 3.12, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{Wald}-\\Delta^Y_{LATE}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{1}{(p^D_1-p^D_0)^2}\\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\var{Y_i|R_i=0}}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\var{Y_i|R_i=1}}{p^R}\\right]\\right)\\\\ \\end{align*}\\] Adding Assumption 3.13, the variance of the Wald estimator can be further decomposed as follows: \\[\\begin{align*} \\sigma^2_{\\hat{\\Delta}^Y_{Wald}} &amp; = \\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\var{Y_i^0|T_i=C}}{p^C(1-p^R)}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\var{Y^1_i|T_i=C}}{p^Cp^R}\\\\ &amp; \\phantom{=} +\\frac{(p^{AT}(1-p^R)-p^{NT}p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2}\\left[p^{AT}\\var{Y_i^1|T_i=AT}+p^{NT}\\var{Y^0_i|T_i=NT}\\right] \\end{align*}\\] with \\(p^D=\\Pr(D_i=1)\\), \\(p^R=\\Pr(R_i=1)\\), \\(p^{D}_1=\\Pr(D_i=1|R_i=1)\\), \\(p^{D}_0=\\Pr(D_i=1|R_i=0)\\), \\(p^t=\\Pr(T_i=t)\\), with \\(t\\in\\left\\{AT,NT,C,D\\right\\}\\). Proof. See Section A.2.3. Remark. Theorem 3.16 shows that the effective sample size of an encouragement design is equal to the number of compliers. Indeed, the denominator of the variance of the Wald Estimatior depends on \\(p^D_1-p^D_0\\), which is an estimate of the proportion of compliers, under Assumption 3.13. Theorem 3.16 also shows that there is a price to pay for the fact that we cannot enforce the effect on always takers and never takers is actually zero. Indeed, as the second formula shows, it is not only the variance of the oucomes of the compliers that appears in the formula, but also the variances of the outcomes of the always takers and never takers, therefore increasing sampling noise. Remark. In order to compute the formula in Theorem 3.16, we can use a plug-in estimator or the IV standard error estimate robist to heteroskedasticity. Here is a simple function in order to compute the plug-in estimator: Example 3.31 Let us derive the CLT-based estimates of sampling noise using both the plug-in estimator and the IV standard errors without conditioning on covariates first. For the sake of the example, I’m working with a sample of size \\(N=1000\\). sn.Encourag.simuls &lt;- 2*quantile(abs(simuls.encourage[[&#39;1000&#39;]][,&#39;Wald&#39;]-delta.y.late),probs=c(0.99)) sn.Encourag.IV.plugin &lt;- 2*qnorm((.99+1)/2)*sqrt(var.Encourage.plugin(pD1=mean(D[E==1 &amp; R==1]),pD0=mean(D[E==1 &amp; R==0]),pD=mean(D[E==1]),pR=mean(R[E==1]),V0=var(y[R==0 &amp; E==1]),V1=var(y[R==1 &amp; E==1]),N=length(y[E==1]))) sn.Encourag.IV.homo &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.2sls.encourage)[2,2]) sn.Encourag.IV.hetero &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.2sls.encourage,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 1.166. 99% sampling noise estimated using the plug-in estimator is 2.124. 99% sampling noise estimated using default IV standard errors is 23.134. 99% sampling noise estimated using heteroskedasticity robust IV standard errors is 2.119. Conditioning on \\(y_i^B\\): sn.Encourag.simuls.yB &lt;- 2*quantile(abs(simuls.encourage.yB[[&#39;1000&#39;]][,&#39;Wald&#39;]-delta.y.late),probs=c(0.99)) sn.Encourag.IV.homo.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcov(reg.y.R.yB.2sls.encourage)[2,2]) sn.Encourag.IV.hetero.yB &lt;- 2*qnorm((.99+1)/2)*sqrt(vcovHC(reg.y.R.yB.2sls.encourage,type=&#39;HC2&#39;)[2,2]) True 99% sampling noise (from the simulations) is 0.705. 99% sampling noise estimated using default IV standard errors is 0.988. 99% sampling noise estimated using heteroskedasticity robust IV standard errors is 0.975. "],["NE.html", "Chapter 4 Natural Experiments 4.1 Instrumental Variables 4.2 Regression Discontinuity Designs 4.3 Difference In Differences", " Chapter 4 Natural Experiments Natural Experiments are situations due to the natural course of events that approximate the conditions of a randomized controlled trial. In the economists’ toolkit, we generally make a distinction between: Instrumental variables (IV), that rely on finding a plausibly exogeneous source of variation in treatment intake. Regression Discontinuity Designs (RDD), that exploit a discontinuity in the eligibility to the treatment. Difference In Differences (DID), that make use of the differential exposure of some groups to the treatment of interest over time. Remark. The term Natural Experiments seems to be mostly used by economists. It dates back to Haavelmo (1944)’s paper on the Probability Approach to Econometrics, where he makes a distinction between the experiments we’d like to make as social scientists and the experiments that Nature provides us with, that are in general a subset of the experiments we’d like to make. This raises the question of our ability to identify the relationships of interest from the variation that is present in the data, a traditional problem in classical econometrics that has echoes in treatment effect estimation, where we also try to identify treatment effect parameters. At the time of Haavelmo, and until the beginning of the 1990s, there was no real discussion of the plausibility of the identifying assumptions (or restrictions) required for identification of certain relations, outside of a discussion of their theoretical plausiblility. With the credibility revolution brought about by Angrist (1990)’s paper and summarized in Angrist and Krueger (2001)’s review paper, the notion of natural experiment made a come back, with the idea that we might be able to look for specific set of events produced by Nature that more credibly identify a relationship of interest, i.e. that closely approximate true experimental conditions. Remark. Outside of economics, Natural Experiments have also flourished, but without the term, and were compiled in the early textbook on research methods by Campbell (1966). Both Difference In Differences and Regression Discontinuity Designs have been actually developed outside of economics, mostly in education research. Instrumental Variables have had a separate history in economics and in genetics, were it is called the method of path coefficients. 4.1 Instrumental Variables Instrumental Variables rely on finding a plausibly exogeneous source of variation in treatment intake. In the simple case of a binary instrument, the identification and estimation parts are actually identical to Encouragements designs in RCTs, that we have already studied in Section 3.4. As a consequence, unless we make very strong assumptions, an IV design is going to recover a Local Average Treatment Effect. Our classical assumptions are going to show up again: Independence, Exclusion Restriction, Monotonicity. Remark. Examples of Instrumental Variables are: Distance to college or to school for studying the impact of college or school enrollement on education, earnings and other outcomes. Random draft lottery number for investigating the impact of military experience on earnings and other outcomes. Randomized encouragement to participate in order to study the impact of a program. Remark. The crucial part of an IV design is to justify the credibility of the exclusion restriction and independence assumptions. It is in general very difficult to justify these assumptions, especially the exclusion restriction assumption. In the examples above, one could argue that schools or colleges might be built where they are necessary, i.e. close to destitute populations, or, on the contrary, that they are built far from difficult neighbourhoods. As soon as distance to school becomes correlated with other determinants of schooling, such as parental income and education, the independence assumption is violated. Even if school placement is truly independent of potential education and earnings outcomes at first, parents, by choosing where to live, will sort themselves such as the parents that pay more attention to education end up located closer to school. As a consequence, the independence assumption might be violated again. Even when the instrument is truly random, such as a draft lottery number, and thus the independence assumption seems fine, the instrument may directly affect the outcomes by other ways than the treatment of interest. For example, receiving a low draft lottery number makes one more likely to be drafted. In response, one might decide to increase their length of stay in college in order to use the waiver for the draft reserved for students. If receiving a low draft lottery number increases the number of years of education, and in turn subsequent earnings, then the exclusion restriction assumption is violated. In this section, I’m going to denote \\(Z_i\\) a binary instrument that can either take value \\(0\\) or \\(1\\). In general, we try to reserve the value \\(1\\) for the instrument value that increases participation in the treatment of interest. In our examples, that would be when for example, the distance to college is low, the draft lottery number is low, or someone receives an encouragement to enter a program. 4.1.1 An example where Monotonicity does not hold Since Monotonicity is going to play such a particular role, and since we have already explored this assumption a little in Chapter 3, I am going to use as an example a model where the Monotonicity assumption actually does not hold. It will, I hope, help us understand better the way Monotonicity works and how it interacts with the other assumptions. The key component of the model that makes Monotonicity necessary is the fact that treatment effects are heterogeneous and correlated with participation in the treatment. We’ll see later that Monotonicity is unnecessary when treatment effects are orthogonal to take up. Example 4.1 Let’s see how we can generate a model without Monotonicity: \\[\\begin{align*} y_i^1 &amp; = y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i \\\\ y_i^0 &amp; = \\mu_i+\\delta+U_i^0 \\\\ U_i^0 &amp; = \\rho U_i^B+\\epsilon_i \\\\ y_i^B &amp; =\\mu_i+U_i^B \\\\ U_i^B &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_i &amp; = \\uns{y_i^B+\\kappa_i Z_i + V_i\\leq\\bar{y}} \\\\ \\kappa_i &amp; = \\begin{cases} -\\bar{\\kappa} &amp; \\text{ if } \\xi_i = 1 \\\\ \\underline{\\kappa} &amp; \\text{ if } \\xi_i = 0 \\end{cases} \\\\ \\xi &amp; \\sim\\mathcal{B}(p_{\\xi}) \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_i \\\\ (\\eta_i,\\omega_i) &amp; \\sim\\mathcal{N}(0,0,\\sigma^2_{\\eta},\\sigma^2_{\\omega},\\rho_{\\eta,\\omega}) \\\\ Z_i &amp; \\sim\\mathcal{B}(p_Z) \\\\ Z_i &amp; \\Ind (y_i^0,y_i^1,y_i^B,V_i) \\\\ \\xi_i &amp; \\Ind (y_i^0,y_i^1,y_i^B,V_i,Z_i) \\end{align*}\\] The key component of the model that generates a failure of Monotonicity is the coefficient \\(\\kappa_i\\), that determines how individuals’ participation into the program reacts to the instrument \\(Z_i\\). \\(\\kappa_i\\) is a coefficient whose value varies accross the population. In my simplified model, \\(\\kappa_i\\) can take only two values, \\(-\\bar{\\kappa}\\) or \\(\\underline{\\kappa}\\). When \\(-\\bar{\\kappa}\\) and \\(\\underline{\\kappa}\\) have opposite signs (let’s say \\(-\\bar{\\kappa}&lt;0\\) and \\(\\underline{\\kappa}&gt;0\\)), then individuals with \\(\\kappa_i=-\\bar{\\kappa}\\) are going to be more likely to enter the program when they receive an encouragement (when \\(Z_i=1\\)) while individuals with \\(\\kappa_i=\\underline{\\kappa}\\) will be less likely to enter the program when \\(Z_i=1\\). When \\(-\\bar{\\kappa}\\) and \\(\\underline{\\kappa}\\) have different signs, we have four types of reactions when the instrumental variable moves from \\(Z_i=0\\) to \\(Z_i=1\\), holding everything else constant. These four types of reactions define four types of individuals: Always takers (\\(T_i=a\\)): individuals that participate in the program both when \\(Z_i=0\\) and \\(Z_i=1\\). Never takers (\\(T_i=n\\)): individuals that do not participate in the program both when \\(Z_i=0\\) and \\(Z_i=1\\). Compliers (\\(T_i=c\\)): individuals that do not participate in the program when \\(Z_i=0\\) but that participate in the program when \\(Z_i=1\\) . Defiers (\\(T_i=d\\)): individuals that participate in the program when \\(Z_i=0\\) but that do not participate in the program when \\(Z_i=1\\) . In our model, these four types are a function of \\(y_i^B+V_i\\) and \\(\\kappa_i\\). In order to see this let’s define, as in Section 3.4, \\(D^z_i\\) the participation decision of individual \\(i\\) when the instrument is exogenously set to \\(Z_i=z\\), with \\(z\\in\\left\\{0,1\\right\\}\\). When \\(\\kappa_i=-\\bar{\\kappa}&lt;0\\), we have three types of reactions to the instrument. It turns out that each of type can be defined by where \\(y_i^B+V_i\\) lies with respect to a series of thresholds: Always takers (\\(T_i=a\\)) are such that \\(D^1_i=\\uns{y_i^B-\\bar{\\kappa} + V_i\\leq\\bar{y}}=1\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=1\\), so that they actually are such that: \\(y_i^B+V_i\\leq\\bar{y}\\). This is because \\(y_i^B+V_i\\leq\\bar{y} \\Rightarrow y_i^B+V_i\\leq\\bar{y}+\\bar{\\kappa}\\), when \\(\\bar{\\kappa}&gt;0\\). Never takers (\\(T_i=n\\)) are such that \\(D^1_i=\\uns{y_i^B-\\bar{\\kappa} + V_i\\leq\\bar{y}}=0\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=0\\), so that they actually are such that: \\(y_i^B+V_i&gt;\\bar{y}+\\bar{\\kappa}\\). This is because \\(y_i^B+V_i&gt;\\bar{y}+\\bar{\\kappa} \\Rightarrow y_i^B+V_i&gt;\\bar{y}\\), when \\(\\bar{\\kappa}&gt;0\\). Compliers (\\(T_i=c\\)) are such that \\(D^1_i=\\uns{y_i^B-\\bar{\\kappa} + V_i\\leq\\bar{y}}=1\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=0\\), so that they actually are such that: \\(\\bar{y}&lt;y_i^B+V_i\\leq\\bar{y}+\\bar{\\kappa}\\). When \\(\\kappa_i=\\underline{\\kappa}&gt;0\\), we have three types defined by where \\(V_i\\) lies with respect to a series of thresholds: Always takers (\\(T_i=a\\)) are such that \\(D^1_i=\\uns{y_i^B+\\underline{\\kappa} + V_i\\leq\\bar{y}}=1\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=1\\), so that they actually are such that: \\(y_i^B+V_i\\leq\\bar{y}-\\underline{\\kappa}\\). This is because \\(y_i^B+V_i\\leq\\bar{y}-\\underline{\\kappa} \\Rightarrow y_i^B+V_i\\leq\\bar{y}\\), when \\(\\underline{\\kappa}&gt;0\\). Never takers (\\(T_i=n\\)) are such that \\(D^1_i=\\uns{y_i^B-\\bar{\\kappa} + V_i\\leq\\bar{y}}=0\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=0\\), so that they actually are such that: \\(y_i^B+V_i&gt;\\bar{y}\\). This is because \\(y_i^B+V_i&gt;\\bar{y} \\Rightarrow y_i^B+V_i\\leq\\bar{y}-\\underline{\\kappa}\\), when \\(\\underline{\\kappa}&gt;0\\). Defiers (\\(T_i=d\\)) are such that \\(D^1_i=\\uns{y_i^B+\\underline{\\kappa} + V_i\\leq\\bar{y}}=0\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=1\\), so that they actually are such that: \\(\\bar{y}-\\underline{\\kappa}&lt;V_i+y_i^B\\leq\\bar{y}\\). Let’s visualize how this works in a plot. Before that, let’s generate some data according to this process. For that, let’s choose values for the new parameters. param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1,0.1,7.98,0.5,1,0.5,0.9,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;gamma&quot;,&quot;baryB&quot;,&quot;pZ&quot;,&quot;barkappa&quot;,&quot;underbarkappa&quot;,&quot;pxi&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) set.seed(1234) N &lt;-1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Z &lt;- rbinom(N,1,param[&quot;pZ&quot;]) xi &lt;- rbinom(N,1,param[&quot;pxi&quot;]) kappa &lt;- ifelse(xi==1,-param[&quot;barkappa&quot;],param[&quot;underbarkappa&quot;]) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[yB+kappa*Z+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta.omega$eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) We can now define the types variable \\(T_i\\): D1 &lt;- ifelse(yB+kappa+V&lt;=log(param[&quot;barY&quot;]),1,0) D0 &lt;- ifelse(yB+V&lt;=log(param[&quot;barY&quot;]),1,0) AT &lt;- ifelse(D1==1 &amp; D0==1,1,0) NT &lt;- ifelse(D1==0 &amp; D0==0,1,0) C &lt;- ifelse(D1==1 &amp; D0==0,1,0) D &lt;- ifelse(D1==0 &amp; D0==1,1,0) Type &lt;- ifelse(AT==1,&#39;a&#39;, ifelse(NT==1,&#39;n&#39;, ifelse(C==1,&#39;c&#39;, ifelse(D==1,&#39;d&#39;,&quot;&quot;)))) data.non.mono &lt;- data.frame(cbind(Type,C,NT,AT,D1,D0,Y,y,Y1,Y0,y0,y1,yB,alpha,U0,eta.omega$eta,epsilon,Ds,kappa,xi,Z,mu,UB)) #ggplot(data.non.mono, aes(x=V, y=yB),color(as.factor(Type))) + # geom_point(shape=1)+ # facet_grid(.~ as.factor(kappa)) plot(yB[AT==1 &amp; kappa==-param[&quot;barkappa&quot;]]+V[AT==1 &amp; kappa==-param[&quot;barkappa&quot;]],y[AT==1 &amp; kappa==-param[&quot;barkappa&quot;]],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&#39;yB+V&#39;,ylab=&quot;Outcomes&quot;) points(yB[NT==1 &amp; kappa==-param[&quot;barkappa&quot;]]+V[NT==1 &amp; kappa==-param[&quot;barkappa&quot;]],y[NT==1 &amp; kappa==-param[&quot;barkappa&quot;]],pch=1,col=&#39;blue&#39;) points(yB[C==1 &amp; kappa==-param[&quot;barkappa&quot;]]+V[C==1 &amp; kappa==-param[&quot;barkappa&quot;]],y[C==1 &amp; kappa==-param[&quot;barkappa&quot;]],pch=1,col=&#39;red&#39;) points(yB[D==1 &amp; kappa==-param[&quot;barkappa&quot;]]+V[D==1 &amp; kappa==-param[&quot;barkappa&quot;]],y[D==1 &amp; kappa==-param[&quot;barkappa&quot;]],pch=1,col=&#39;green&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) abline(v=log(param[&quot;barY&quot;])+param[&#39;barkappa&#39;],col=&#39;red&#39;) #abline(v=log(param[&quot;barY&quot;])-param[&#39;underbarkappa&#39;],col=&#39;red&#39;) text(x=c(log(param[&quot;barY&quot;]),log(param[&quot;barY&quot;])+param[&#39;barkappa&#39;]),y=c(5,5),labels=c(expression(bar(&#39;y&#39;)),expression(bar(&#39;y&#39;)+bar(kappa))),pos=c(2,4),col=c(&#39;red&#39;,&#39;red&#39;),lty=c(&#39;solid&#39;,&#39;solid&#39;)) legend(5,10.5,c(&#39;AT&#39;,&#39;NT&#39;,&#39;C&#39;,&#39;D&#39;),pch=c(1,1,1,1),col=c(&#39;black&#39;,&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;),ncol=1) title(expression(kappa=bar(kappa))) plot(yB[AT==1 &amp; kappa==param[&quot;underbarkappa&quot;]]+V[AT==1 &amp; kappa==param[&quot;underbarkappa&quot;]],y[AT==1 &amp; kappa==param[&quot;underbarkappa&quot;]],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&#39;yB+V&#39;,ylab=&quot;Outcomes&quot;) points(yB[NT==1 &amp; kappa==param[&quot;underbarkappa&quot;]]+V[NT==1 &amp; kappa==param[&quot;underbarkappa&quot;]],y[NT==1 &amp; kappa==param[&quot;underbarkappa&quot;]],pch=1,col=&#39;blue&#39;) points(yB[C==1 &amp; kappa==param[&quot;underbarkappa&quot;]]+V[C==1 &amp; kappa==param[&quot;underbarkappa&quot;]],y[C==1 &amp; kappa==param[&quot;underbarkappa&quot;]],pch=1,col=&#39;red&#39;) points(yB[D==1 &amp; kappa==param[&quot;underbarkappa&quot;]]+V[D==1 &amp; kappa==param[&quot;underbarkappa&quot;]],y[D==1 &amp; kappa==param[&quot;underbarkappa&quot;]],pch=1,col=&#39;green&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) #abline(v=log(param[&quot;barY&quot;])-param[&#39;barkappa&#39;],col=&#39;red&#39;) abline(v=log(param[&quot;barY&quot;])-param[&#39;underbarkappa&#39;],col=&#39;red&#39;) text(x=c(log(param[&quot;barY&quot;]),log(param[&quot;barY&quot;])-param[&#39;underbarkappa&#39;]),y=c(5,5),labels=c(expression(bar(&#39;y&#39;)),expression(bar(&#39;y&#39;)-underbar(kappa))),pos=c(2,2),col=c(&#39;red&#39;,&#39;red&#39;),lty=c(&#39;solid&#39;,&#39;solid&#39;)) legend(5,10.5,c(&#39;AT&#39;,&#39;NT&#39;,&#39;C&#39;,&#39;D&#39;),pch=c(1,1,1,1),col=c(&#39;black&#39;,&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;),ncol=1) title(expression(kappa=underbar(kappa))) Figure 4.1: Types As Figure 4.1 shows how the different types interact with \\(\\kappa_i\\). When \\(\\kappa_i=-\\bar{\\kappa}\\), individuals with \\(y_i^B+V_i\\) below \\(\\bar{y}\\) always take the program. Even when \\(Z_i=1\\) and \\(\\bar{\\kappa}\\) is subtracted from their index, it is still low enough so that they get to participate. When \\(y_i^B+V_i\\) is in between \\(\\bar{y}\\) and \\(\\bar{y}+\\bar{\\kappa}\\), the individuals are such that their index without subtracting \\(\\bar{\\kappa}\\) is above \\(\\bar{y}\\), but it is below \\(\\bar{y}\\) when \\(\\bar{\\kappa}\\) is subtracted from it. These individuals participate when \\(Z_i=1\\) and do not participate when \\(Z_i=0\\): they are compliers. Individuals such that \\(y_i^B+V_i\\) is above \\(\\bar{y}+\\bar{\\kappa}\\) will have an index above \\(\\bar{y}\\) whether we substract \\(\\bar{\\kappa}\\) from it or not. They are never takers. When \\(\\kappa_i=\\underline{\\kappa}\\), individuals with \\(y_i^B+V_i\\) below \\(\\bar{y}-\\underline{\\kappa}\\) always take the program. Even when \\(Z_i=0\\) and \\(\\underline{\\kappa}\\) is not subtracted from their index, it is still low enough so that they get to participate. When \\(y_i^B+V_i\\) is in between \\(\\bar{y}-\\underline{\\kappa}\\) and \\(\\bar{y}\\), the individuals are such that their index without adding \\(\\underline{\\kappa}\\) is below \\(\\bar{y}\\), but it is above \\(\\bar{y}\\) when \\(\\underline{\\kappa}\\) is added to it. These individuals participate when \\(Z_i=0\\) and do not participate when \\(Z_i=1\\): they are defiers. Individuals such that \\(y_i^B+V_i\\) is above \\(\\bar{y}\\) will have an index above \\(\\bar{y}\\) whether we add \\(\\underline{\\kappa}\\) from it or not. They are never takers. 4.1.2 Identification We need several assumptions for identification in an Instrumental Variable framework. We are going to explore two sets of assumption that secure the identification of two different parameters: The Average Treatment Effect on the Treated (\\(TT\\)): identification will happen through the assumption of independence of treatment effects from potential treatment choice The Local Average Treatment Effect (\\(LATE\\)) Hypothesis 4.1 (First Stage Full Rank) We assume that the instrument \\(Z_i\\) has a direct effect on treatment participation: \\[\\begin{align*} \\Pr(D_i=1|Z_i=1)\\neq\\Pr(D_i=1|Z_i=0). \\end{align*}\\] Example 4.2 Let’s see how this assumption works in our example. Let’s first compute the average values of \\(Y_i\\) and \\(D_i\\) as a function of \\(Z_i\\), for later use. means.IV &lt;- c(mean(Ds[Z==0]),mean(Ds[Z==1]),mean(y0[Z==0]),mean(y0[Z==1]),mean(y[Z==0]),mean(y[Z==1]),0,1) means.IV &lt;- matrix(means.IV,nrow=2,ncol=4,byrow=FALSE,dimnames=list(c(&#39;Z=0&#39;,&#39;Z=1&#39;),c(&#39;D&#39;,&#39;y0&#39;,&#39;y&#39;,&#39;Z&#39;))) means.IV &lt;- as.data.frame(means.IV) Figure 4.2: Proportion of participants as a function of \\(Z_i\\) Figure 4.2 shows that the proportion of treated when \\(Z_i=1\\) in our sample is equal to 0.53 while the proportion of treated when \\(Z_i=0\\) is equal to 0.28, in accordance with Assumption 4.1. In the population, the proportion of treated when \\(Z_i=1\\) depends on the value of \\(\\kappa_i\\). Let’s derive its value: \\[\\begin{align*} \\Pr(D_i=1|Z_i=1) &amp; = \\Pr(y_i^B+\\kappa_i Z_i + V_i\\leq\\bar{y}|Z_i=1) \\\\ &amp; = \\Pr(y_i^B+\\kappa_i + V_i\\leq\\bar{y}) \\\\ &amp; = \\Pr(y_i^B+ V_i\\leq\\bar{y}+\\bar{\\kappa}|\\xi_i=1)\\Pr(\\xi_i=1) + \\Pr(y_i^B+V_i\\leq\\bar{y}-\\underline{\\kappa}|\\xi_i=0)\\Pr(\\xi_i=0) \\\\ &amp; = \\Pr(y_i^B+ V_i\\leq\\bar{y}+\\bar{\\kappa})p_{\\xi} + \\Pr(y_i^B+ V_i\\leq\\bar{y}-\\underline{\\kappa})(1-p_{\\xi}) \\\\ &amp; = p_{\\xi}\\Phi\\left(\\frac{\\bar{y}+\\bar{\\kappa}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_{U}+\\sigma^2_{\\omega}}}\\right) + (1-p_{\\xi})\\Phi\\left(\\frac{\\bar{y}-\\underline{\\kappa}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_{U}+\\sigma^2_{\\omega}}}\\right) \\end{align*}\\] where the second equality follows from \\(Z_i\\) being independent of \\((y_i^0,y_i^1,y_i^B,V_i)\\), the third equality follows from \\(\\xi_i\\) being independent from \\((y_i^0,y_i^1,y_i^B,V_i,Z_i)\\) and the last equality follows from the formula for the cumulative of a normal distribution. The formula for \\(\\Pr(D_i=1|Z_i=0)\\) is the same except for \\(\\bar{\\kappa}\\) and \\(\\underline{\\kappa}\\) that are set to zero. Let’s write two functions to compute these probabilities: prob.D.Z.1 &lt;- function(param){ part.1 &lt;- param[&#39;pxi&#39;]*pnorm((log(param[&quot;barY&quot;])+param[&#39;barkappa&#39;]-param[&#39;barmu&#39;])/sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&quot;sigma2U&quot;]+param[&#39;sigma2omega&#39;])) part.2 &lt;- (1-param[&#39;pxi&#39;])*pnorm((log(param[&quot;barY&quot;])-param[&#39;underbarkappa&#39;]-param[&#39;barmu&#39;])/sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&quot;sigma2U&quot;]+param[&#39;sigma2omega&#39;])) return(part.1+part.2) } prob.D.Z.0 &lt;- function(param){ part.1 &lt;- param[&#39;pxi&#39;]*pnorm((log(param[&quot;barY&quot;])-param[&#39;barmu&#39;])/sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&quot;sigma2U&quot;]+param[&#39;sigma2omega&#39;])) part.2 &lt;- (1-param[&#39;pxi&#39;])*pnorm((log(param[&quot;barY&quot;])-param[&#39;barmu&#39;])/sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&quot;sigma2U&quot;]+param[&#39;sigma2omega&#39;])) return(part.1+part.2) } With these functions, we know that, in the population, \\(\\Pr(D_i=1|Z_i=1)=\\) 0.57 and \\(\\Pr(D_i=1|Z_i=0)=\\) 0.25, which is not far from what we have found in our sample. Our next set of assumptions imposes that the instrument has no direct effect on the outcome and that it is not correlated with all the potential outcomes. Let’s start with the exclusion restriction: Hypothesis 4.2 (Exclusion Restriction) We assume that there is no direct effect of \\(Z_i\\) on outcomes: \\[\\begin{align*} \\forall d,z \\in \\left\\{0,1\\right\\}\\text{, } Y_i^{d,z} = Y_i^d. \\end{align*}\\] Example 4.3 In our example, this assumption is automatically satisfied. Indeed, \\(y_i^{d,z}=y_i^0 + d(y_i^1-y_i^0)\\) which is parameterized as \\(y_i^{d,z}=\\mu_i+\\delta+U_i^0+d(\\bar{\\alpha}+\\theta\\mu_i+\\eta_i)\\). Since \\(y_i^{d,z}\\) does not depend on \\(z\\), we have \\(y_i^{d,z} = y_i^d\\), \\(\\forall d,z \\in \\left\\{0,1\\right\\}\\). The assumption would not be satisfied if \\(Z_i\\) entered the equations for \\(y_i^0\\) or \\(y_i^1\\). For example, if \\(Z_i\\) is the Vietnam draft lottery number (high or low) used by Angrist to study the impact of army experience on earnings, the exclusion restriction would not work if \\(Z_i\\) was directly influencing outcomes, independent of miitary experience, by example by generating a higher education level. In that case, we could have \\(E_i=\\alpha+\\beta Z_i + v_i\\), where \\(E_i\\) is education, and, for example, \\(y_i^0=\\mu_i+\\delta+\\lambda E_i+U_i^0\\). We then have \\(y_i^{d,z}=\\mu_i+\\delta +\\lambda(\\alpha+\\beta z + v_i) +U_i^0+d(\\bar{\\alpha}+\\theta\\mu_i+\\eta_i)\\) which depends on \\(z\\) and thus the exclusion restriction does not hold any more. Let us now state the independence assumption: Hypothesis 4.3 (Independence) We assume that \\(Z_i\\) is independent from the other determinants of \\(Y_i\\) and \\(D_i\\): \\[\\begin{align*} (Y_i^1,Y_i^0,D_i^1,D_i^0)\\Ind Z_i. \\end{align*}\\] Remark. Why do we say that independence from the potential outcomes is the same as independence from the other determinants of \\(Y_i\\) and \\(D_i\\)? Because the only sources of variation that remain in \\(Y_i^d\\) and \\(D_i^z\\) are the other sources of variations (that is not the treatment \\(D_i=d\\) nor the instrument variable \\(Z_i=z\\)). Example 4.4 In our example, this assumption is also satisfied. If we assumed that unobserved determinants of earnings contained in \\(U^0_i\\) are correlated with the instrument value, then we would have a problem. For example, if children that leave close to college have also rich parents, or parents that spend a lot of time with them, or parents with large networks, there probably is a correlation between distance to college and earnings in the absence of the program. For the draft lottery example, you might have that people with a high draft lottery number who have well-connected parents obtain discharges on special medical grounds. Is that a violation of the independence assumption? Actually no. Indeed, these individuals are simply going to become never takers (they avoid the draft whatever their lottery number). But \\(Z_i\\) is still independent from the level of connections of the parents. For the independence assumption to fail in the draft lottery number example, you would need that children of well-connected parents obtain lower lottery numbers because the lottery is rigged. In that case, since well-connected individuals would have had higher earnings even absent the lottery, there is a negative correlation between \\(y_i^0\\) and having a high draft lottery number (\\(Z_i\\)). The last assumption we need in order to identify the Local Average Treatment Effect is that of Monotonicity. We already know this assumption: Hypothesis 4.4 (Monotonicity) We assume that the instrument moves everyone in the population in the same direction: \\[\\begin{align*} \\forall i\\text{, either } D^1_i\\geq D_i^0 \\text{ or } D^1_i\\leq D_i^0. \\end{align*}\\] Without loss of generality, we generally assume that \\(\\forall i\\), \\(D^1_i\\geq D_i^0\\). As a consequence, there are no defiers. Example 4.5 In our example, this assumption is not satisfied. There are defiers, as Figure 4.1 shows, when \\(\\xi_i = 0\\) and thus \\(\\kappa_i=\\underline{\\kappa}\\). Indeed, in that case, for the individuals who are such that \\(\\bar{y}-\\underline{\\kappa}&lt;y_i^B+V_i\\leq\\bar{y}\\), we have \\(D^1_i=\\uns{y_i^B+\\underline{\\kappa} + V_i\\leq\\bar{y}}=0\\) and \\(D^0_i=\\uns{y_i^B + V_i\\leq\\bar{y}}=1\\). This would happen for example if some people would go to college less if their house is located closer to the college, maybe for example because they have a preference not to stay at their parents’ house. Remark. Why are defiers a problem for the instrumental variable strategy? Because the Intention to Treat Effect that measures the difference in expected outcomes at the two levels of the instrument is going to be characterized by two-way flows in and out of the program, as we have already seen with Theorem 3.10. This means that some treatment effects will have negative weights in the ITE formula. In that case, you might have a negative Intention to Treat Effect despite the treatment having positive effects for everyone, or you might under estimate the true effect of the treatment. This matters only when the treatment effects are heterogeneous. Example 4.6 Let us detail how non-monotonicity and the existence defiers act on the ITE in our example, since we now have defiers. The first very important thing to understand is that all the problems we have happend because treatment effects are heterogeneous AND they are correlated with the type of individuals: defiers and compliers do not have the same distribution of treatment effects and, case in point, they do not have the same average treatment effects. The average effects of the treatment on compliers and defiers are not the same. Let us first look at the distribution of treatment effects among compliers and defiers in the sample and in the population. In order to derive the distribution of \\(\\alpha_i\\) conditional on Type in the population, we need to derive the joint distribution of \\(\\alpha_i\\) and \\(y_i^B+V_i\\) and use the trmtvnorm package to recover its density when it is truncated. This distribution is normal and fully characterized by its mean and covariance matrix. \\[\\begin{align*} (\\alpha_i,y_i^B+V_i) &amp; \\sim \\mathcal{N}\\left(\\bar{\\alpha}+\\theta\\bar{\\mu},\\bar{\\mu}, \\left(\\begin{array}{cc} \\theta^2\\sigma^2_{\\mu}+\\sigma^2_{\\eta} &amp; (\\theta+\\gamma)\\sigma^2_{\\mu}+\\rho_{\\eta,\\omega}\\sigma^2_{\\eta}\\sigma^2_{\\omega}\\\\ (\\theta+\\gamma)\\sigma^2_{\\mu}+\\rho_{\\eta,\\omega}\\sigma^2_{\\eta}\\sigma^2_{\\omega} &amp; (1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}\\\\ \\end{array} \\right) \\right) \\end{align*}\\] Let us write a function to generate them. mean.alpha.yBV &lt;- c(param[&#39;baralpha&#39;]+param[&#39;theta&#39;]*param[&#39;barmu&#39;],param[&#39;barmu&#39;]) cov.alpha.yBV &lt;- matrix(c((param[&#39;theta&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2eta&#39;], (param[&#39;theta&#39;]+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], (param[&#39;theta&#39;]+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], (1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]),2,2,byrow=TRUE) # density of alpha for compliers lower.cut.comp &lt;- c(-Inf,log(param[&#39;barY&#39;])) upper.cut.comp &lt;- c(Inf,log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;]) d.alpha.compliers &lt;- function(x){ return(dtmvnorm.marginal(xn=x,n=1,mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.comp,upper=upper.cut.comp)) } # density of alpha for defiers lower.cut.def &lt;- c(-Inf,log(param[&#39;barY&#39;]-param[&#39;underbarkappa&#39;])) upper.cut.def &lt;- c(Inf,log(param[&#39;barY&#39;])) d.alpha.defiers &lt;- function(x){ return(dtmvnorm.marginal(xn=x,n=1,mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.def,upper=upper.cut.def)) } Let us now plot the empirical and theoretical distributions of the treatment effects for compliers and defiers. # building the data frame alpha.types &lt;- as.data.frame(cbind(alpha,C,D,AT,NT)) %&gt;% mutate( Type = ifelse(AT==1,&quot;Always Takers&quot;, ifelse(NT==1,&quot;Never Takers&quot;, ifelse(C==1,&quot;Compliers&quot;,&quot;Defiers&quot;))) ) %&gt;% mutate(Type = as.factor(Type)) ggplot(filter(alpha.types,Type==&quot;Compliers&quot; | Type==&quot;Defiers&quot;), aes(x=alpha, colour=Type)) + geom_density(linetype=&quot;dashed&quot;) + geom_function(fun = d.alpha.compliers, colour = &quot;red&quot;) + geom_function(fun = d.alpha.defiers, colour = &quot;blue&quot;) + ylab(&#39;density&#39;) + theme_bw() Figure 4.3: Distribution of treatment effects by Type in the sample (dashed line) and in the population (full line) Figure 4.3 shows that the two distributions are actually very similar in our example. The distribution for the compliers is slightly above that for the defiers, meaning that the defiers should have lower expected outcomes in the population. Let us check that by computing the average outcomes of compliers and defiers both in the sample and in the population. # sample means mean.alpha.compliers.samp &lt;- mean(alpha[C==1]) mean.alpha.defiers.samp &lt;- mean(alpha[D==1]) # population means mean.alpha.compliers.pop &lt;- mtmvnorm(mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.comp,upper=upper.cut.comp,doComputeVariance=FALSE)[[1]] mean.alpha.defiers.pop &lt;- mtmvnorm(mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.def,upper=upper.cut.def,doComputeVariance=FALSE)[[1]] In the population, the average treatment effect for compliers is equal to 0.17 and the average treatment effect for defiers is equal to 0.14. In the sample, the average treatment effect for compliers is equal to 0.2 and the average treatment effect for defiers is equal to 0.16. The difference between the treatment effect for compliers and defiers is a problem for the Wald estimator. Let’s look at how the Wald estimator behaves in the population (in order to avoid considerations due to sampling noise). By Theorem 3.10, the numerator of the Wald estimator is equal to the difference between the average treatment on compliers and the average treatment effect on defiers weighted by their respective proportions in the population. In order to be able to compute the Wald estimator, we need to compute the proportion of compliers and of defiers in the population. These proportions are equal to: \\[\\begin{align*} \\Pr(T_i=c) &amp; = \\Pr(\\bar{y}&lt; y_i^B+V_i\\leq\\bar{y}+\\bar{\\kappa}\\cap\\kappa_i=-\\bar{\\kappa}) \\\\ &amp; = \\Pr(\\bar{y}&lt; y_i^B+V_i\\leq\\bar{y}+\\bar{\\kappa})p_{\\xi} \\\\ \\Pr(T_i=d) &amp; = \\Pr(\\bar{y}-\\underline{\\kappa}&lt; y_i^B+V_i\\leq\\bar{y}\\cap\\kappa_i=\\underline{\\kappa}) \\\\ &amp; = \\Pr(\\bar{y}-\\underline{\\kappa}&lt; y_i^B+V_i\\leq\\bar{y})(1-p_{\\xi}), \\end{align*}\\] where the second equality follows from the fact that \\(\\xi\\) is independent from \\(y_i^B+V_i\\) and uses the fact that \\(\\Pr(A\\cap B)=\\Pr(A|B)\\Pr(B)\\). Since \\(y_i^B+V_i\\) is normally distributed and we know its mean and variance, these proportions can be computed as: \\[\\begin{align*} \\Pr(T_i=c) &amp; = p_{\\xi}\\left(\\Phi\\left(\\frac{\\bar{y}+\\bar{\\kappa}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right) -\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right)\\right) \\\\ \\Pr(T_i=d) &amp; = (1-p_{\\xi})\\left(\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right) -\\Phi\\left(\\frac{\\bar{y}-\\underline{\\kappa}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right)\\right). \\end{align*}\\] Let’s write functions to compute these objects: # proportion compliers Prop.Comp &lt;- function(param){ first &lt;- pnorm((log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;]-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) second &lt;- pnorm((log(param[&#39;barY&#39;])-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) return(param[&#39;pxi&#39;]*(first - second)) } # proportion defiers Prop.Def &lt;- function(param){ first &lt;- pnorm((log(param[&#39;barY&#39;])-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) second &lt;- pnorm((log(param[&#39;barY&#39;])-param[&#39;underbarkappa&#39;]-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) return((1-param[&#39;pxi&#39;])*(first - second)) } In our example, the proportion of compliers is equal to 0.33 and the proportion of defiers is equal to 0.01. As a consequence, the population value of the numerator of the Wald estimator is equal to 0.05. In the Wald estimator, this quantity is divided by the difference between the proportion of participants when \\(Z_i=1\\) and when \\(Z_i=0\\). We have already computed this quantity earlier, but it is nice to try to compute it in a different way using the types. The difference in the proportion of participants when \\(Z_i=1\\) and when \\(Z_i=0\\) is indeed equal to the difference in the proportion of compliers and the proportion of defiers. The difference between the proportion of compliers and the proportion of defiers is equal to 0.32, while the difference between the proportion of participants when \\(Z_i=1\\) and when \\(Z_i=0\\) is equal to 0.32. It is reassuring that we find the same thing (actually, full disclosure, I did not find the same thing at first, and this help me spot a mistake in the formulas for the proportions of participants: mistakes are normal and natural and that is how we learn and grow). So we are now equipped to compute the value of the Wald estimator in the population in our model without monotonicity. It is equal to 0.172. In practice, the bias of the Wald estimator is rather small for the average treatment effect on the compliers (remember that it is equal to 0.171). In order to understand why, it is useful to see that the bias of the Wald estimator for the average treatment effect on the compliers is equal to: \\[\\begin{align*} \\esp{\\Delta_i^Y|T_i=c}-\\Delta^Y_{Wald} &amp; = \\esp{\\Delta_i^Y|T_i=c} + (\\esp{\\Delta_i^Y|T_i=c}-\\esp{\\Delta_i^Y|T_i=d})\\frac{\\Pr(T_i=d)}{\\Pr(T_i=c)-\\Pr(T_i=d)}, \\end{align*}\\] where the equality follows from Theorem 3.10 and some algebra. In the absence of Monotonicity, when the impact on defiers is smaller than the impact of compliers, the Wald estimator is baised upward for the effect on the compliers (as it happens in our example). In a model in which the effect of the treatment is larger on defiers than on compliers, the Wald estimator is biased downwards for the effect on compliers because defiers make the outcome of the control group seem too good. In the extreme, when \\(\\esp{\\Delta_i^Y|T_i=d}&gt;\\esp{\\Delta_i^Y|T_i=c}(1+\\frac{\\Pr(T_i=c)-\\Pr(T_i=d)}{\\Pr(T_i=d)})\\), the Wald estimator can be negative whereas the effects on compliers and on defiers are both positive. This happens when the effect on defiers is \\(1+\\frac{\\Pr(T_i=c)-\\Pr(T_i=d)}{\\Pr(T_i=d)}\\) times larger than the effect on compliers. In our case, that means that the effect on defiers should be 26 times larger than the effect on compliers for the Wald estimator to be negative, that is to say the effect on defiers should be equal to 4.41, really much much much larger than the effect on compliers. From there, we are going to explore three strategies in order to identify some true effect of the treatment using the Wald estimator: The first strategy has been recently proposed by de Chaisemartin (2017). It is valid in a model without monotonicity. The second strategy assumes that the heterogeneity in treatment effects is uncorrelated to the treatment. The last strategy is due to Imbens and Angrist (1994) and assumes that Monotonicity holds. Let’s review these solutions in turn. 4.1.2.1 Identification without Monotonicity The approach delineated by de Chaisemartin (2017) does not assume away non-monotonicity. Clement instead assumes that we can divide the population of compliers in two-subpopulations: the compliers-defiers (\\(T_i=cd\\)) and the surviving-compliers (\\(T_i=sc\\)). The main assumption in Clement’s approach is that (i) the compliers-defiers are in the same proportion as the defiers and (ii) that the average effect of the treatment on the compliers defiers is equal as the average effect of the treatment on the defiers. These two assumptions can be formalized as follows: Hypothesis 4.5 (Compliers-defiers) We assume that there exists as subpopulation of compliers that are in the same proportion as the defiers and for whom the average effect of the treatment is equal as the average effect of the treatment on the defiers: \\[\\begin{align*} (T_i=c) &amp; = (T_i=cd)\\cup (T_i=sc) \\\\ \\Pr(T_i=cd) &amp; = \\Pr(T_i=d) \\\\ \\esp{Y^1_i-Y^0_i|T_i=cd} &amp; = \\esp{Y^1_i-Y^0_i|T_i=d}. \\end{align*}\\] The first equation in Assumption 4.5 imposes that the compliers-defiers and the surviving-compliers are a partition of the population of compliers. From Assumption 4.5, we can prove the following theorem: Theorem 4.1 (Identification of the effect on the surviving-compliers) Under Assumptions 4.1, 4.2, 4.3 and 4.5, the Wald estimator identifies the effect of the treatment on the surviving-compliers: \\[\\begin{align*} \\Delta^Y_{Wald} &amp; = \\Delta^Y_{sc}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{Wald} &amp; = \\frac{\\esp{Y_i|Z_i=1} - \\esp{Y_i|Z_i=0}}{\\Pr(D_i=1|Z_i=1)-\\Pr(D_i=1|Z_i=0)}\\\\ \\Delta^Y_{sc} &amp; = \\esp{Y^1_i-Y^0_i|T_i=sc}. \\end{align*}\\] Proof. Under Assumptions 4.2 and 4.3, Theorems 3.10 and 3.12 imply that the numerator of the Wald estimator is equal to \\(\\Delta^Y_{ITE}\\) with: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=c}\\Pr(T_i=c)-\\esp{Y_i^{1}-Y_i^{0}|T_i=d}\\Pr(T_i=d). \\end{align*}\\] Now, we have that the effect on compliers can be decomposed in the effect on surviving-compliers and the effect on compliers-defiers using the Law of Iterated Expectations and the fact that \\(T_i=sc \\Rightarrow T_i=c\\) and \\(T_i=cd \\Rightarrow T_i=c\\): \\[\\begin{align*} \\Delta^Y_{c} &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=sc}\\Pr(T_i=sc|T_i=c)+\\esp{Y_i^{1}-Y_i^{0}|T_i=cd}\\Pr(T_i=cd|T_i=c), \\end{align*}\\] Now, using the fact that \\(\\Pr(T_i=sc|T_i=c)\\Pr(T_i=c)=\\Pr(T_i=sc)\\) and \\(\\Pr(T_i=cd|T_i=c)\\Pr(T_i=c)=\\Pr(T_i=cd)\\) (because \\(\\Pr(A|B)\\Pr(B)=\\Pr(A\\cap B)\\) and \\(\\Pr(A\\cap B)=\\Pr(A)\\) if \\(A \\Rightarrow B\\)), we have: \\[\\begin{align*} \\Delta^Y_{ITE} &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=sc}\\Pr(T_i=sc)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1}-Y_i^{0}|T_i=cd}\\Pr(T_i=cd)-\\esp{Y_i^{1}-Y_i^{0}|T_i=d}\\Pr(T_i=d). \\end{align*}\\] The second part of the right-hand side of the above equation is equal to zero by virtue of Assumption 4.5. Now, under Assumptions 4.1, 4.2 and 4.3, we know, from the proof of Theorem 3.9, that \\(\\Pr(D_i=1|Z_i=1)-\\Pr(D_i=1|Z_i=0)=\\Pr(T_i=c)-\\Pr(T_i=d)\\). Under Assumption 4.5, we have \\(\\Pr(T_i=c)=\\Pr((T_i=cd)\\cup(T_i=sc))=\\Pr(T_i=cd)+\\Pr(T_i=sc)\\). Replacing \\(\\Pr(T_i=c)\\) gives \\(\\Pr(D_i=1|Z_i=1)-\\Pr(D_i=1|Z_i=0)=\\Pr(T_i=sc)\\). Dividing \\(\\Delta^Y_{ITE}\\) by \\(\\Pr(T_i=sc)\\) gives the result. Remark. de Chaisemartin (2017) shows in his Theorem 2.1 that the reciprocal of Theorem 4.1 is actually valid: if there exists surviving-compliers such that their effect is estimated by the Wald estimator and their proportion is equal to the denominator of the Wald estimator, then it has to be that there exists a sub-population of compliers-defiers that are in the same proportion as the defiers and have the same average treatment effect. Example 4.7 Let us now see if the conditions in de Chaisemartin (2017) are verified in our numerical example. I have bad news: they are not. It is not super easy to see why, but an intuitive explanation is that the average effect on the defiers in our model is taken conditional on \\(y^B_i+V_i\\in]\\bar{y}-\\underline{\\kappa},\\bar{y}]\\) while the effect on compliers is taken conditional on \\(y^B_i+V_i\\in]\\bar{y},\\bar{y}+\\bar{\\kappa}]\\). These two intervals do not overlap. Since the expected value of the treatment effect conditional on \\(y^B_i+V_i=v\\) is monotonous in \\(v\\) (because both variables come from a bivariate normal distribution), then all the effects on the defiers interval are either smaller or larger than all the effects on the compliers interval, making it impossible to find a sub-population of compliers that have the same average effect of the treatment as the defiers. More formally, it is possible to prove this result by using the concept of Marginal Treatment Effect developed by Heckman and Vytlacil (1999). I might devote a specific section of the book to the MTE and its derivations. For now, I let it as a possibility. What can we do then? Probably the best that we can do is to find \\(\\kappa^*\\) such that \\(\\Pr(\\bar{y}&lt;y_i^B+V\\leq\\bar{y}+\\kappa^*)p_{\\xi}=\\Pr(T_i=d)\\), that is the value such that the interval of values of \\(y_i^B+V\\) that are for compliers and closest to the interval for defiers and that contains the same proportion of compliers as there are defiers. This value is going to produce an average effect for compliers-defiers as close as possible to the average effect on defiers. It can be computed as follows: \\[\\begin{align*} \\kappa^* &amp; = \\bar{\\mu}-\\bar{y}+\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}} \\Phi^{-1}\\Bigg(\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right)\\\\ &amp; \\phantom{=}+\\frac{1-p_{\\xi}}{p_{\\xi}}\\left(\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right)-\\Phi\\left(\\frac{\\bar{y}-\\underline{\\kappa}-\\bar{\\mu}}{\\sqrt{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}}\\right)\\right)\\Bigg) \\end{align*}\\] Let’s write functions to compute \\(\\kappa^*\\), the implied proportion of compliers-defiers and the average effect of the treatment on compliers-defiers and on surviving-compliers: # kappa star KappaStar &lt;- function(param){ prop.def &lt;- Prop.Def(param) prop.below.bary &lt;- pnorm((log(param[&#39;barY&#39;])-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) st.dev.yB.V &lt;- sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]) return(param[&#39;barmu&#39;]-log(param[&#39;barY&#39;])+st.dev.yB.V*qnorm(prop.below.bary+prop.def/param[&#39;pxi&#39;])) } # proportion of compliers-defiers Prop.Comp.Def &lt;- function(param){ first &lt;- pnorm((log(param[&#39;barY&#39;])+KappaStar(param)-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) second &lt;- pnorm((log(param[&#39;barY&#39;])-param[&#39;barmu&#39;])/(sqrt((1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]))) return(param[&#39;pxi&#39;]*(first - second)) } # mean impact on compliers-defiers lower.cut.comp.def &lt;- c(-Inf,log(param[&#39;barY&#39;])) upper.cut.comp.def &lt;- c(Inf,log(param[&#39;barY&#39;])+KappaStar(param)) mean.alpha.comp.def.pop &lt;- mtmvnorm(mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.comp.def,upper=upper.cut.comp.def,doComputeVariance=FALSE)[[1]] # mean impact on surviving compliers lower.cut.surv.comp &lt;- c(-Inf,log(param[&#39;barY&#39;])+KappaStar(param)) upper.cut.surv.comp &lt;- c(Inf,log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;]) mean.alpha.surv.comp.pop &lt;- mtmvnorm(mean=mean.alpha.yBV,sigma=cov.alpha.yBV,lower=lower.cut.surv.comp,upper=upper.cut.surv.comp,doComputeVariance=FALSE)[[1]] The first have that \\(\\kappa^*=\\) 0.0452. For this value of \\(\\kappa^*\\), we have that \\(\\Pr(T_i=cd)=\\) 0.0128. As expected, this is very close to the proportion of compliers in the population: \\(\\Pr(T_i=d)=\\) 0.0128. Finally, the average treatment effect on the compliers-defiers is equal to: \\(\\Delta^y_{cd}=\\) 0.1457. As expected, but luckily enough, since it was absolutely not sure, it is very close to the to the average treatment effect on the defiers: \\(\\Delta^y_{d}=\\) 0.1445. So, in our model, Assumption 4.5 is almost satisfied, and so does Theorem 4.1. As a consequence, the Wald estimator is very close to the effect on the surviving-compliers. Indeed, the Wald estimator, in the population, is equal to \\(\\Delta^y_{Wald}=\\) 0.172156, while the average effect on surviving-compliers is equal to \\(\\Delta^y_{sc}=\\) 0.172108. 4.1.2.2 Identification under Independence of treatment effects Another way to get around the issue of Non-Monotonicity is simply to assume away any meaningful role for treatment effect heterogeneity. One approach to that would simply be to assume that treatment effects are constant across individuals. I leave to the reader to prove that in that case, the Wald estimator would recover the treatment effect under only Independence and Exclusion Restriction. We are going to use a slightly more general approach here by assuming that treatment effect heterogeneity is unrelated to the reaction to the instrument: Hypothesis 4.6 (Independent Treatment Effects) We assume that the treatment effect is independent from potential reactions to the instrument: \\[\\begin{align*} \\Delta^Y_i\\Ind (D^1_i,D^0_i). \\end{align*}\\] We can now prove that, under Assumption 4.6, the Wald estimator identifies the Average Treatment Effect (ATE), the average effect of the Treatment on the Treated (TT) and the average effect on compliers and on defiers. The first thing to know before we state the result is that, under Assumption 4.6, all these average treatment effects are equal to each other. This is a direct implication of the following lemma: Lemma 4.1 (Independence of Treatment Effects from Types) Under Assumption 4.6, the treatment effect is independent from types: \\[\\begin{align*} \\Delta^Y_i\\Ind T_i. \\end{align*}\\] Proof. Lemma (4.2) in Dawid (1979) states that if \\(X \\Ind Y|Z\\) and \\(U\\) is a function of \\(X\\), then \\(U \\Ind Y|Z\\). Since \\(T_i\\) is a function of \\((D^1_i,D^0_i)\\) under Assumption 4.6, Lemma 4.1 follows. A direct corollary of Lemma 4.1 is: Corollary 4.1 (Independence of Treatment Effects and Average Effects) Under Assumption 4.6, the Average Treatment Effect (ATE), the average effect of the Treatment on the Treated (TT) and the average effect on compliers and on defiers are all equal: \\[\\begin{align*} \\Delta^Y_{ATE} = \\Delta^Y_{TT(1)} = \\Delta^Y_{TT(0)} = \\Delta^Y_{c} = \\Delta^Y_{d}. \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{TT(z)} = \\esp{Y_i^1-Y_i^0|D_i=1,Z_i=z}. \\end{align*}\\] Proof. Using Lemma 4.1, we have that: \\[\\begin{align*} \\Delta^Y_{c} = \\Delta^Y_{d} = \\Delta^Y_{at} =\\Delta^Y_{nt}. \\end{align*}\\] Because \\(T_i\\) is a partition, we have \\(\\Delta^Y_{ATE}=\\Delta^Y_{c}\\Pr(T_i=c)+\\Delta^Y_{d}\\Pr(T_i=d)+\\Delta^Y_{at}\\Pr(T_i=at)+\\Delta^Y_{nt}\\Pr(T_i=nt)=\\Delta^Y_{c}\\) (since \\(\\Pr(T_i=c)+\\Pr(T_i=d)+\\Pr(T_i=at)+\\Pr(T_i=nt)=1\\)). Finally, we also have that \\(\\Delta^Y_{TT(1)}=\\Delta^Y_{c}\\Pr(T_i=c|D_i=1,Z_i=1)+\\Delta^Y_{at}\\Pr(T_i=at|D_i=1,Z_i=1)=\\Delta^Y_{c}\\) and \\(\\Delta^Y_{TT(0)}=\\Delta^Y_{d}\\Pr(T_i=d|D_i=1,Z_i=0)+\\Delta^Y_{at}\\Pr(T_i=at|D_i=1,Z_i=0)=\\Delta^Y_{c}\\), since \\((D_i=1)\\cap(Z_i=1)\\Rightarrow (T_i=c)\\cup(T_i=at)\\) and \\((D_i=1)\\cap(Z_i=0)\\Rightarrow (T_i=d)\\cup(T_i=at)\\). We are now equipped to state the final result of this section: Theorem 4.2 (Identification under Independent Treatment Effect) Under Assumptions 4.1, 4.2, 4.3 and 4.6, the Wald estimator identifies the average effect of the Treatment on the Treated: \\[\\begin{align*} \\Delta^Y_{Wald} &amp; = \\Delta^Y_{TT}. \\end{align*}\\] Proof. Using the formula for the Wald estimator, we have, for the two components of its numerator: \\[\\begin{align*} \\esp{Y_i|Z_i=1} &amp; = \\esp{Y_i^0+(Y_i^1-Y_i^0)D_i|Z_i=1} \\\\ &amp; = \\esp{Y_i^0|Z_i=1}+\\esp{\\Delta^Y_i|D_i=1,Z_i=1}\\Pr(D_i=1|Z_i=1)\\\\ &amp; = \\esp{Y_i^0|Z_i=1}+\\Delta^Y_{TT(1)}\\Pr(D_i=1|Z_i=1)\\\\ \\esp{Y_i|Z_i=0} &amp; = \\esp{Y_i^0+(Y_i^1-Y_i^0)D_i|Z_i=0} \\\\ &amp; = \\esp{Y_i^0|Z_i=0}+\\esp{\\Delta^Y_i|D_i=0,Z_i=1}\\Pr(D_i=1|Z_i=0)\\\\ &amp; = \\esp{Y_i^0|Z_i=0}+\\Delta^Y_{TT(0)}\\Pr(D_i=1|Z_i=0),\\\\ \\end{align*}\\] where the first equalities use Assumption 4.2. Now, under Assumption 4.6, Corollary 4.1 implies that \\(\\Delta^Y_{TT(0)}=\\Delta^Y_{TT(1)}=\\Delta^Y_{TT}\\). We thus have that the numerator of the Wald estimator is equal to: \\[\\begin{align*} \\esp{Y_i|Z_i=1}-\\esp{Y_i|Z_i=0} &amp; = \\Delta^Y_{TT}(\\Pr(D_i=1|Z_i=1)-\\Pr(D_i=1|Z_i=0))\\\\ &amp; \\phantom{=}+\\esp{Y_i^0|Z_i=1}-\\esp{Y_i^0|Z_i=0}. \\end{align*}\\] Assumption 4.3 implies that \\(\\esp{Y_i^0|Z_i=1}=\\esp{Y_i^0|Z_i=0}\\). Using Assumption 4.1 proves the result. 4.1.2.3 Identification under Monotonicity The classical approach to identification using instrumental variables is due to Imbens and Angrist (1994) and Angrist, Imbens and Rubin (1996). It rests on Assumption 4.4 or Monotonicity that we are now familiar with, that requires that the effect of the instrument on treatment participation moves everyone in the same direction. Remark. For the rest of the section, we will assume that \\(\\forall i\\), \\(D^1_i\\geq D_i^0\\). It is without loss of generality, since if the initial treatment does not comply with this requirement, you can simply redefine a new treatment equal to \\(-D_i\\). Under Monotonicity, there are no defiers. This is what the following lemma shows: Lemma 4.2 Under Assumption 4.4, there are no defiers a.s.: \\[\\begin{align*} \\Pr(T_i=c) &amp; = 0. \\end{align*}\\] Proof. Under Assumption 4.4, \\(\\forall i\\), \\(D^1_i\\geq D_i^0\\). As a consequence, \\(\\Pr(D^1_i &lt; D_i^0)=0\\). Since defiers are defined as \\(D^1_i &lt; D_i^0\\), the result follows. In the absence of defiers, the Wald estimator identifies the average effect of the treatment on the compliers, also called the Local Average Treatment Effect: Theorem 4.3 Under Assumptions 4.1, 4.2, 4.3 and 4.4, the Wald estimator identifies the average effect of the treatment on the compliers, also called the Local Average Treatment Effect: \\[\\begin{align*} \\Delta^Y_{Wald}&amp; = \\Delta^Y_{LATE}. \\end{align*}\\] Proof. Using Theorem 3.9 directly proves the result. Remark. The magic of the instrumental variables setting applies again. By moving the instrument, we are able to learn something about the causal effect of the treatment. Monotonicity is a very strong assumption though, as are Independence and Exclusion Restriction. They are very rarely met in practice. Even the case of RCTs with encouragement design, where Independence holds by design, might be affected by failures of Exclusion Restriction and/or Monotonicity. Example 4.8 Let’s see how monotonicity works in our example. First, we have to generate a model in which monotonicity holds. For that, we need to shut down heterogeneous reactions to the instrument. In practice, we are going to replace the participation equation in our model, which was characterized by a random coefficient, by the following one, which has a constant coefficient: \\[\\begin{align*} D_i &amp; = \\uns{y_i^B-\\bar{\\kappa} Z_i + V_i\\leq\\bar{y}} \\end{align*}\\] As a consequence, we have no more defiers and monotonicity holds. Let us now generate the data from the model with monotonicity: set.seed(12345) N &lt;-1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Z &lt;- rbinom(N,1,param[&quot;pZ&quot;]) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[yB-param[&quot;barkappa&quot;]*Z+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta.omega$eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) We can now define the types variable \\(T_i\\): D1 &lt;- ifelse(yB-param[&quot;barkappa&quot;]+V&lt;=log(param[&quot;barY&quot;]),1,0) D0 &lt;- ifelse(yB+V&lt;=log(param[&quot;barY&quot;]),1,0) AT &lt;- ifelse(D1==1 &amp; D0==1,1,0) NT &lt;- ifelse(D1==0 &amp; D0==0,1,0) C &lt;- ifelse(D1==1 &amp; D0==0,1,0) D &lt;- ifelse(D1==0 &amp; D0==1,1,0) Type &lt;- ifelse(AT==1,&#39;a&#39;, ifelse(NT==1,&#39;n&#39;, ifelse(C==1,&#39;c&#39;, ifelse(D==1,&#39;d&#39;,&quot;&quot;)))) data.mono &lt;- data.frame(cbind(Type,C,NT,AT,D1,D0,Y,y,Y1,Y0,y0,y1,yB,alpha,U0,eta.omega$eta,epsilon,Ds,Z,mu,UB)) The first thing we can check is that there are no defiers. For that, let’s count the number of individuals who have \\(T_i=1\\). It is equal to 0. One thing that helped me understand how the IV approach under monotonicity works is the following graph: plot(yB[AT==1]+V[AT==1],y[AT==1],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB+V&quot;,ylab=&quot;Outcomes&quot;) points(yB[NT==1]+V[NT==1],y[NT==1],pch=1,col=&#39;blue&#39;) points(yB[C==1 &amp; Ds==1]+V[C==1 &amp; Ds==1],y[C==1 &amp; Ds==1],pch=1,col=&#39;red&#39;) points(yB[C==1 &amp; Ds==0]+V[C==1 &amp; Ds==0],y[C==1 &amp; Ds==0],pch=1,col=&#39;green&#39;) abline(v=log(param[&quot;barY&quot;]),col=&quot;red&quot;) abline(v=log(param[&quot;barY&quot;])+param[&#39;barkappa&#39;],col=&quot;red&quot;) text(x=c(log(param[&quot;barY&quot;]),log(param[&quot;barY&quot;])+param[&#39;barkappa&#39;]),y=c(5,5),labels=c(expression(bar(&#39;y&#39;)),expression(bar(&#39;y&#39;)+bar(kappa))),pos=c(2,4),col=c(&quot;red&quot;,&quot;red&quot;)) legend(5,10.5,c(&#39;AT&#39;,&#39;NT&#39;,&#39;C|D=1&#39;,&#39;C|D=0&#39;),pch=c(1,1,1,1),col=c(&quot;black&quot;,&#39;blue&#39;,&quot;red&quot;,&#39;green&#39;),ncol=1) Figure 4.4: Types under Monotonicity What 4.4 shows is that the IV acts as a randomized controlled trial among compliers. Within the population of compliers, whether one receives the treatment or not is as good as random. If we actually knew who the compliers were, we could directly estimate the effect of the treatment by comparing the outcomes of the treated compliers to the outcomes of the untreated compliers. Actually, this approach, applied in our sample, yields an estimated treatment effect on the compliers of 0.14, whereas the simple comparison of participants and non participants would give an estimate of -0.93. In our sample, the average effect of the treatment on compliers is actually equal to 0.18. Let us finally check that Theorem 4.3 works in the population in our new model. We need to compute the various parts of the Wald estimator and the average effect of the treatment on the compliers. The key to understand the Wald estimator is to see that its numerator is composed of the difference between two means, with both means containing the average outcomes of always takers and never takers weighted by their respective proportions in the population, as shown in the proof of Theorem 4.3. These two means cancel out, leaving only the differences in the means of the compliers in and out of the treatment, weighted by their proportion in the population. The denominator of the Wald estimator simply provides an estimate of the proportion of compliers. In order to illustrate these intuitions in our example, I am going to use the formula for a truncated multivariate normal variable and the package tmvtnorm. The most important thing to notice here is that \\((y^0_i,y^1_i,y_i^B+V_i) \\sim \\mathcal{N}\\left(\\bar{\\mu}+\\delta,\\bar{\\mu}(1+\\theta)+\\delta+\\bar{\\alpha},\\bar{\\mu},\\mathbf{C}\\right)\\) with: \\[\\begin{align*} \\mathbf{C} &amp;= \\left(\\begin{array}{ccc} \\sigma^2_{\\mu}+\\rho^2\\sigma^2_{U} +\\sigma^2_{\\epsilon} &amp; (1+\\theta)\\sigma^2_{\\mu}+\\rho^2\\sigma^2_U + \\sigma^2_{\\epsilon} &amp; (1+\\gamma)\\sigma^2_{\\mu}+\\rho\\sigma^2_U \\\\ (1+\\theta)\\sigma^2_{\\mu}+\\rho^2\\sigma^2_U + \\sigma^2_{\\epsilon} &amp; (1+\\theta^2)\\sigma^2_{\\mu}+\\rho^2\\sigma^2_{U} +\\sigma^2_{\\epsilon} + \\sigma^2_{\\eta} &amp; (1+\\theta+\\gamma)\\sigma^2_{\\mu}+\\rho\\sigma^2_U+\\rho_{\\eta,\\omega}\\sigma^2_{\\eta}\\sigma^2_{\\omega} \\\\ (1+\\gamma)\\sigma^2_{\\mu}+\\rho\\sigma^2_U &amp; (1+\\theta+\\gamma)\\sigma^2_{\\mu}+\\rho\\sigma^2_U+\\rho_{\\eta,\\omega}\\sigma^2_{\\eta}\\sigma^2_{\\omega} &amp; (1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega} \\\\ \\end{array} \\right) \\end{align*}\\] We now simply have to derive the mean outcomes and proportions of each type in the population in order to form the Wald estimator. Let me first derive the joint distribution of the portential outcomes and the means and proportions of each type in the population. mean.y0.y1.yBV &lt;- c(param[&#39;barmu&#39;]+param[&#39;delta&#39;],param[&#39;barmu&#39;]*(1+param[&#39;theta&#39;])+param[&#39;delta&#39;]+param[&#39;baralpha&#39;],param[&#39;barmu&#39;]) cov.y0.y1.yBV &lt;- matrix(c(param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]^2*param[&#39;sigma2U&#39;]+param[&#39;sigma2epsilon&#39;], (1+param[&#39;theta&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]^2*param[&#39;sigma2U&#39;]+param[&#39;sigma2epsilon&#39;], (1+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]*param[&#39;sigma2U&#39;], (1+param[&#39;theta&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]^2*param[&#39;sigma2U&#39;]+param[&#39;sigma2epsilon&#39;], (1+param[&#39;theta&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]^2*param[&#39;sigma2U&#39;]+param[&#39;sigma2epsilon&#39;]+param[&#39;sigma2eta&#39;], (1+param[&#39;theta&#39;]+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]*param[&#39;sigma2U&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], (1+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]*param[&#39;sigma2U&#39;], (1+param[&#39;theta&#39;]+param[&#39;gamma&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rho&#39;]*param[&#39;sigma2U&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], (1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]),3,3,byrow=TRUE) # cuts #always takers lower.cut.at &lt;- c(-Inf,-Inf,-Inf) upper.cut.at &lt;- c(Inf,Inf,log(param[&#39;barY&#39;])) # compliers lower.cut.comp &lt;- c(-Inf,-Inf,log(param[&#39;barY&#39;])) upper.cut.comp &lt;- c(Inf,Inf,log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;]) # never takers lower.cut.nt &lt;- c(-Inf,-Inf,log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;]) upper.cut.nt &lt;- c(Inf,Inf,Inf) # means by types #always takers mean.y1.at.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.at,upper=upper.cut.at,doComputeVariance=FALSE)[[1]][[2]] mean.y0.at.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.at,upper=upper.cut.at,doComputeVariance=FALSE)[[1]][[1]] # never takers mean.y1.nt.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.nt,upper=upper.cut.nt,doComputeVariance=FALSE)[[1]][[2]] mean.y0.nt.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.nt,upper=upper.cut.nt,doComputeVariance=FALSE)[[1]][[1]] #compliers mean.y1.comp.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.comp,upper=upper.cut.comp,doComputeVariance=FALSE)[[1]][[2]] mean.y0.comp.pop &lt;- mtmvnorm(mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV,lower=lower.cut.comp,upper=upper.cut.comp,doComputeVariance=FALSE)[[1]][[1]] # Proportion of each types # always takers prop.at.pop &lt;- ptmvnorm.marginal(log(param[&#39;barY&#39;]),n=3,mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV)[[1]] # never takers prop.nt.pop &lt;- 1-ptmvnorm.marginal(log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;],n=3,mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV)[[1]] # compliers prop.comp.pop &lt;- ptmvnorm.marginal(log(param[&#39;barY&#39;])+param[&#39;barkappa&#39;],n=3,mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV)[[1]]-ptmvnorm.marginal(log(param[&#39;barY&#39;]),n=3,mean=mean.y0.y1.yBV,sigma=cov.y0.y1.yBV)[[1]] # LATE late.pop &lt;- mean.y1.comp.pop-mean.y0.comp.pop late.prop.comp.pop &lt;- late.pop*prop.comp.pop # Wald num.Wald.pop &lt;- (mean.y1.comp.pop*prop.comp.pop+mean.y1.at.pop*prop.at.pop+mean.y0.nt.pop*prop.nt.pop-(mean.y0.comp.pop*prop.comp.pop+mean.y1.at.pop*prop.at.pop+mean.y0.nt.pop*prop.nt.pop)) denom.Wald.pop &lt;- (prop.at.pop+prop.comp.pop-prop.at.pop) Wald.pop &lt;- num.Wald.pop/denom.Wald.pop We are now equipped to compute the Wald estimator in the population. Before that, let us compute the LATE. We have \\(\\Delta^Y_{LATE} =\\) 0.179. The Wald estimator is equal to \\(\\Delta^Y_{Wald} =\\) 0.179. They are obviously equal. This is because the numerator of the Wald is equal to the product of the LATE multiplied by the proportion of compliers (which is equal to 0.066). This is because the outcomes of never takers and always takers cancel out on each separate term of the numerator of the Wald estimator. Indeed, we have that the numerator of the Wald estimator is equal to: 0.066. 4.1.3 Estimation Estimation of the LATE under the IV assumptions closely follows the same steps that we have delineated in Section 3.4.2: First stage regression of \\(D_i\\) on \\(Z_i\\): this estimates the impact of the instrument on participation into the program and estimates the proportion of compliers. Reduced form regression of \\(Y_i\\) on \\(Z_i\\): this estimates the impact of the instrument on outcomes, a.k.a the ITE. Structural regression of \\(Y_i\\) on \\(D_i\\) using \\(Z_i\\) as an instrument, which estimates the LATE. Let’s take these three steps in turn. 4.1.3.1 First stage regression The first stage regression regresses \\(D_i\\) on \\(Z_i\\) and thus estimates the impact of the instrument on treatment participation, which is equal to the proportion of compliers. It can be run using the With/Without estimator or OLS (both are numerically equivalent as Lemma A.3 shows) or OLS conditioning on observed covariates. Example 4.9 Let’s see how these three approaches fare in our example. # WW first stage WW.First.Stage.IV &lt;- mean(Ds[Z==1])-mean(Ds[Z==0]) # Simple OLS OLS.D.Z.IV &lt;- lm(Ds~Z) OLS.First.Stage.IV &lt;- coef(OLS.D.Z.IV)[[2]] # OLS conditioning on yB OLS.D.Z.yB.IV &lt;- lm(Ds~Z+yB) OLSX.First.Stage.IV &lt;- coef(OLS.D.Z.yB.IV)[[2]] The WW estimator of the first stage impact of \\(Z_i\\) on \\(D_i\\) is equal to 0.374. The OLS estimator of the first stage impact of \\(Z_i\\) on \\(D_i\\) is equal to 0.374. The OLS estimator of the first stage impact of \\(Z_i\\) on \\(D_i\\) conditioning on \\(y^B_i\\) is equal to 0.339. Remember that the true proportion of compliers in the population in our model is equal to 0.366. 4.1.3.2 Reduced form regression The reduced form regression regresses \\(Y_i\\) on \\(Z_i\\) and thus estimates the impact of the instrument on outcomes, which is equal to the ITE. It can be run using the With/Without estimator or OLS (both are numerically equivalent as Lemma A.3 shows) or OLS conditioning on observed covariates. Example 4.10 Let’s see how these three approaches fare in our example. # WW reduced form WW.Reduced.Form.IV &lt;- mean(y[Z==1])-mean(y[Z==0]) # Simple OLS OLS.y.Z.IV &lt;- lm(y~Z) OLS.Reduced.Form.IV &lt;- coef(OLS.y.Z.IV)[[2]] # OLS conditioning on yB OLS.y.Z.yB.IV &lt;- lm(y~Z+yB) OLSX.Reduced.Form.IV &lt;- coef(OLS.y.Z.yB.IV)[[2]] The WW estimator of the reduced form impact of \\(Z_i\\) on \\(y_i\\) is equal to -0.029. The OLS estimator of the reduced form impact of \\(Z_i\\) on \\(y_i\\) is equal to -0.029. The OLS estimator of the reduced form impact of \\(Z_i\\) on \\(y_i\\) conditioning on \\(y^B_i\\) is equal to 0.058. Remember that the true ITE in the population in our model is equal to 0.066. 4.1.3.3 Structural regression The final step of the analysis is to estimate the impact of \\(D_i\\) on \\(Y_i\\) using \\(Z_i\\) as an instrument. This can be done either by directly using the Wald estimator, by dividing the estimate of the reduced form by the result of the first stage, or by directly using the IV estimator (which is equivalent to the Wald estimator as Theorem 3.15 shows) or the IV estimator conditional on covariates. Example 4.11 Let’s see how these four approaches fare in our example. # Wald structural form Wald.Structural.Form.IV &lt;- (mean(y[Z==1])-mean(y[Z==0]))/(mean(Ds[Z==1])-mean(Ds[Z==0])) # Simple IV TSLS.y.D.Z.IV &lt;- ivreg(y~Ds|Z) TSLS.Structural.Form.IV &lt;- coef(TSLS.y.D.Z.IV)[[2]] # IV conditioning on yB TSLS.y.D.Z.yB.IV &lt;- ivreg(y~Ds+yB|Z+yB) TSLSX.Structural.Form.IV &lt;- coef(TSLS.y.D.Z.yB.IV)[[2]] The Wald estimator of the LATE is equal to \\(\\hat{\\Delta}_{Wald}^{y}=\\) -0.078. The IV estimator of the LATE is equal to \\(\\hat{\\Delta}_{IV}^{y}=\\) -0.078, and is numerically identical to the Wald estimator, as expected. The IV estimator of the LATE conditioning on \\(y_i^B\\) is equal to 0.172. Remember that the true LATE in the population in our model is equal to 0.179. Remark. The last thing we might want to check is what the sampling noise of the IV estimator looks like and whether it is reduced by conditioning on observed covariates. Example 4.12 Let’s see how sampling noise moves in our example. Do it 4.1.4 Estimation of sampling noise Remark. The framework we have seen here as been extended to multivalued instruments or treatments by several papers. Imbens and Angrist (1994) extend the framework to an ordered instrument. They show that the 2SLS estimator is a weighted average of LATEs for each values of the instrument, with positive weights summing to one. Angrist and Imbens (1995) extend the framework to he case where the treatment is an ordered discrete variable and there are multiple dichotomous instruments. They again show that the 2SLS estimator is a weighted average of LATEs with positive weights summing to one. Heckman and Vytlacil (1999) extend the framework to a case with a continuous instrument and show that one can the define a Marginal Treatment Effect (or MTE) that is equal to the effect of the treatment on individuals that have the same unobserved propensity to take the treatment. They show that the MTE can be identified by a limiting form of Wald estimator that they call a Local Instrumental Variable estimator. They also show that average treatment effect parameters such as TT, ATE and LATE are all weighted averages of the MTE, with positive weights summing to one. Under strong support conditions on the side of the instrument, one can thus in principle recover all treatment effect parameters with a continuous instrument. Remark. One important concern with the first stage regression is that of weak instruments. When Assumption 4.1 does not hold and the impact on the instrument on take up is actually zero in the population, the Wald estimator is not well-defined. Expand 4.2 Regression Discontinuity Designs Regression Discontinuity Designs emerge in situations where there is a discontinuity in the probability of receiving the treatment. If there is also a discontinuity in outcomes, it is interpreted as the effect of the treatment. We distinguish two RD Designs: Sharp Designs (the probability of receiving the treatment moves from 0 to 1 at the discontinuity, Fuzzy Designs (the probability of receiving the treatment moves from values strictly between 0 and 1 at the discontinuity. Let’s examine both of these configurations in turn. 4.2.1 Sharp Regression Discontinuity Designs In Sharp Regression Discontinuity Designs, the following condition holds: Hypothesis 4.7 (Sharp RDD Design) There exists a running variable \\(Z_i\\) and a threshold \\(\\bar{z}\\) such that: \\[\\begin{align*} D_i=\\uns{Z_i\\leq\\bar{z}}. \\end{align*}\\] Example 4.13 Let us illustrate this assumption in our example (it is easy since our basic selection rule has a discontinuous feature). Let’s first choose parameter values and compute a function for the TT parameter: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) delta.y.tt &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;theta&quot;]*((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } Let us now simulate the data: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let us now illustrate the resulting dataset: par(mar=c(5,4,4,5)) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;blue&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) text(x=c(log(param[&quot;barY&quot;])),y=c(5),labels=c(expression(bar(&#39;y&#39;))),pos=c(2),col=c(&#39;red&#39;)) legend(5,10.5,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;D&#39;),pch=c(1,3,2),col=c(&#39;black&#39;,&#39;blue&#39;,&#39;red&#39;),ncol=1) par(new=TRUE) plot(yB,Ds,pch=2,col=&#39;red&#39;,xlim=c(5,11),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) axis(4) mtext(&quot;D&quot;,side=4,line=3) Figure 4.5: Sharp RDD Design Figure 4.5 shows that there is a sharp decrease in treatment intake when moving above \\(y_i^B=\\bar{y}\\). 4.2.1.1 Identification The main assumption we need on top of Assumption 4.7 is that outcomes are continuous around the threshold: Hypothesis 4.8 (Continuity of Expected Potential Outcomes) For \\(d\\in\\left\\{0,1\\right\\}\\), \\[\\begin{align*} \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i^d|Z_i=\\bar{z}-e} &amp; = \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i^d|Z_i=\\bar{z}+e}. \\end{align*}\\] Example 4.14 Let us see how this assumption works in our example. We are going to use a linear conditional expectation to link \\(y^d_i\\) and \\(y_i^B\\), which is consistent since they are jointly normally distributed in our example. We fit the linear conditional expectation using OLS. reg.ols.00 &lt;- lm(y0[Ds==0]~yB[Ds==0]) reg.ols.01 &lt;- lm(y0[Ds==1]~yB[Ds==1]) reg.ols.10 &lt;- lm(y1[Ds==0]~yB[Ds==0]) reg.ols.11 &lt;- lm(y1[Ds==1]~yB[Ds==1]) Let us now illustrate how these expectations look. # plot for y1 plot(yB[Ds==0],y1[Ds==0],pch=3,xlim=c(5,11),ylim=c(5,11),col=&#39;red&#39;,xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y1[Ds==1],pch=3) points(yB[Ds==0],reg.ols.10$fitted.values,col=&#39;blue&#39;,pch=3) points(yB[Ds==1],reg.ols.11$fitted.values,col=&#39;blue&#39;,pch=3) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) text(x=c(log(param[&quot;barY&quot;])),y=c(5),labels=c(expression(bar(&#39;y&#39;))),pos=c(2),col=c(&#39;red&#39;)) legend(5,11,c(&#39;y1|D=0&#39;,&#39;y1|D=1&#39;,&#39;E[y1|yB]&#39;),pch=c(3,3,3),col=c(&#39;red&#39;,&#39;black&#39;,&#39;blue&#39;),ncol=2) # plot for y0 plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),col=&#39;black&#39;,xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) points(yB[Ds==0],reg.ols.00$fitted.values,col=&#39;blue&#39;,pch=1) points(yB[Ds==1],reg.ols.01$fitted.values,col=&#39;blue&#39;,pch=1) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) text(x=c(log(param[&quot;barY&quot;])),y=c(5),labels=c(expression(bar(&#39;y&#39;))),pos=c(2),col=c(&#39;red&#39;)) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,&#39;E[y0|yB]&#39;),pch=c(1,1,1),col=c(&#39;black&#39;,&#39;red&#39;,&#39;blue&#39;),ncol=2) Figure 4.6: Continuity of potential outcomes As we can see on Figure 4.6, at \\(\\bar{y}\\), both \\(\\esp{y_i^1|y_i^B=y}\\) and \\(\\esp{y_i^0|y_i^B=y}\\) are continuous. Under Assumptions 4.7 and 4.8, we can prove identification of a local versino of the Treatment on the Treated parameter: Theorem 4.4 (Identification in a Sharp RDD Design) Under Assumptions 4.7 and 4.8, the Treatment Effect on the Treated is identified at \\(Z_i=\\bar{z}\\): \\[\\begin{align*} \\Delta^Y_{TT}(\\bar{z}) &amp; = \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}-e}-\\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}+e}, \\end{align*}\\] where \\(\\Delta^Y_{TT}(\\bar{z})=\\esp{\\Delta^Y_i|Z_i=\\bar{z}}\\). Proof. \\[\\begin{align*} \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}-e} -\\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}+e} &amp; = \\lim_{e\\rightarrow 0^{+}}\\esp{Y^1_i|Z_i=\\bar{z}-e} -\\lim_{e\\rightarrow 0^{+}}\\esp{Y^0_i|Z_i=\\bar{z}+e} \\\\ &amp; = \\esp{Y^1_i|Z_i=\\bar{z}} - \\esp{Y^0_i|Z_i=\\bar{z}} \\\\ &amp; = \\esp{Y^1_i-Y^0_i|Z_i=\\bar{z}} \\\\ &amp; = \\Delta^Y_{TT}(\\bar{z}), \\end{align*}\\] where the first equality uses Assumption 4.7 and the second equality uses Assumption 4.8. Example 4.15 Let us try to illustrate how identification works in our numerical example. plot(yB[Ds==0],y[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3) points(yB[Ds==0],reg.ols.00$fitted.values,col=&#39;blue&#39;,pch=1) points(yB[Ds==1],reg.ols.11$fitted.values,col=&#39;blue&#39;,pch=3) abline(v=log(param[&quot;barY&quot;]),col=&#39;black&#39;) text(x=c(log(param[&quot;barY&quot;])),y=c(5),labels=c(expression(bar(&#39;y&#39;))),pos=c(2),col=c(&#39;black&#39;)) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,expression(hat(&#39;y0&#39;)),expression(hat(&#39;y1&#39;))),pch=c(1,3,1,3),col=c(&#39;black&#39;,&#39;black&#39;,&#39;blue&#39;,&#39;blue&#39;),ncol=2) Figure 4.7: Identification in a sharp RDD design On Figure 4.7, we can see a small decrease in the fitted lines just when we cross \\(y_i=\\bar{y}\\). This decrease is due to the positive effect of the treatment, since moving from above to below \\(\\bar{y}\\) swtiches the treatment on. 4.2.1.2 Estimation in a Sharp RD Design For estimating the treatment effect in a Sharp RD Design, we can use OLS, if we are willing to assume that expected potential outcomes are a linear function of the running variable. This is obviously a huge assumption. In order to relax it, we can use non-parametric methods, and among them the ones that are unbiased when applied at a boundary of the parameter space. The best method in that case is the Local Linear Regression. 4.2.1.2.1 Estimation using OLS Using OLS to estimate the treatment effect in a sharp RD Design works as follows. We fit two linear models, one on the left and one on the right of the discontinuity: \\[\\begin{align*} \\esp{Y_i|D_i=1,Z_i=z} &amp; = \\alpha_1+\\beta_1z\\\\ \\esp{Y_i|D_i=0,Z_i=z} &amp; = \\alpha_0+\\beta_0z. \\end{align*}\\] We then estimate the treatment effect by taking the difference in predicted outcomes at \\(Z_i=z\\): \\[\\begin{align*} \\hat{\\Delta}^Y_{TT}(z) &amp; = \\hatesp{Y_i|D_i=1,Z_i=z}-\\hatesp{Y_i|D_i=0,Z_i=z}\\\\ &amp; = \\hat\\alpha_1+\\hat\\beta_1z-\\hat\\alpha_0-\\hat\\beta_0z. \\end{align*}\\] Example 4.16 Let’s see how this works in our example. First, we need to compute the predicted values and the value of our estimated parameter: # Predicted values y0.bary.pred &lt;- reg.ols.00$coef[[1]]+reg.ols.00$coef[[2]]*log(param[&#39;barY&#39;]) y1.bary.pred &lt;- reg.ols.11$coef[[1]]+reg.ols.11$coef[[2]]*log(param[&#39;barY&#39;]) # estimated treatment effect delta.y.rddols &lt;- y1.bary.pred-y0.bary.pred In order to be able to compare our estimate to the truth, let’s compute the true value of our target parameter: \\[\\begin{align*} \\Delta^y_{TT}(\\bar{z}) &amp; = \\bar{\\alpha} + \\theta\\bar{\\mu}+\\theta\\frac{\\sigma^2_{\\mu}}{\\sigma^2_{\\mu}+\\sigma^2_{U}}(\\bar{y}-\\bar{\\mu}). \\end{align*}\\] Let’s write a function to compute this formula: delta.y.tt.z &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]+param[&quot;theta&quot;]*(log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])*param[&quot;sigma2mu&quot;]/(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) } delta.y.tt.z.pop &lt;- delta.y.tt.z(param) Our estimate of the treatment effect using OLS is thus 0.18 while the true value of our target parameter is 0.18. 4.2.1.2.2 Bias of the OLS RDD estimator when conditional expectations are nonlinear The problem with the OLS approach to implement the RDD estimator is that it is highly dependent on the assumption that the conditional expectation functions \\(\\esp{Y_i|D_i=d,Z_i=z}\\) are linear. That might generate a strong functional form bias, as the following example shows. Example 4.17 Let’s simulate some data in order to visualize the issue with OLS when the conditional expectation functions are non linear. In order to do that, we need to add some non linearity in the way potential outcomes are generated. We choose to make the equation for \\(y_i^0\\) nonlinear in \\(y_i^B\\): \\[\\begin{align*} y_i^0 &amp; = \\mu_i+\\delta+U_i^0 +\\gamma*(y_i^B-\\bar{y_i^B})^2. \\end{align*}\\] Let’s choose some parameter values and simulate the data before seeing wht it looks like: # parameters param &lt;- c(param,0.1,7.98) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;gamma&quot;,&quot;baryB&quot;) # simulations set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) # linear regressions reg.ols.00 &lt;- lm(y0[Ds==0]~yB[Ds==0]) reg.ols.01 &lt;- lm(y0[Ds==1]~yB[Ds==1]) reg.ols.10 &lt;- lm(y1[Ds==0]~yB[Ds==0]) reg.ols.11 &lt;- lm(y1[Ds==1]~yB[Ds==1]) # predicted values and estimated treatment effect using lienar OLS y0.bary.pred &lt;- reg.ols.00$coef[[1]]+reg.ols.00$coef[[2]]*log(param[&#39;barY&#39;]) y1.bary.pred &lt;- reg.ols.11$coef[[1]]+reg.ols.11$coef[[2]]*log(param[&#39;barY&#39;]) delta.y.rddols &lt;- y1.bary.pred-y0.bary.pred Let’s take a look at the data now: plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y1[Ds==1],pch=3,col=&#39;black&#39;) points(yB[Ds==0],reg.ols.00$fitted.values,col=&#39;blue&#39;,pch=1) points(yB[Ds==1],reg.ols.11$fitted.values,col=&#39;blue&#39;,pch=3) abline(v=log(param[&quot;barY&quot;]),col=&#39;black&#39;) legend(5,11,c(&#39;y|D=0&#39;,&#39;y|D=1&#39;,expression(hat(&#39;y0&#39;)),expression(hat(&#39;y1&#39;))),pch=c(1,3,1,3),col=c(&#39;black&#39;,&#39;black&#39;,&#39;blue&#39;,&#39;blue&#39;),ncol=2) Figure 4.8: OLS estimates of sharp RDD with non linear conditional expectations Our estimate of the treatment effect using OLS is now 0.25 while the true value of our target parameter is still 0.18. The reason wy the estimate is too large with respect to the truth is because the linear estimate of the conditional expectation \\(\\hatesp{y_i^0|y_i^B=\\bar{y}}\\) is biased downwards: it should start curving upwards when approaching \\(\\bar{y}\\) but it does not, as we can see on Figure 4.8. 4.2.1.2.3 Estimation using Local Linear Regression The reason the OLS RDD estimator fails when conditional expectations are nonlinear (as in Figure 4.8) is because the OLS estimate of the conditional expectation function is mispecified. What we need to replace OLS is an approach that is going to be well-specified under the assumption of continuous conditional expectations. We also want an estimator that behaves well (for example, is not biased) when operating at a boundary: note that we try to predict the value of the two conditional expectation functions just at the point after which they stop being defined. This second requirement is actually pretty harsh. The most robust estimator that complies with these requirements is the Local Linear Regression estimator, or LLR. It is a basically just weighted OLS but only applied locally within a tiny window around the prediction point, with weights decreasing as they get further away from the prediction point. The weigths are generated by a kernel function. Which exact kernel function is used does not matter much in practice. What matters much more for LLR is the choice of the bandwidth, the width of the small window around the prediction point. Cross-validation (a form of leave-one-out assessment of goodness of fit) is generally used to choose the optimal bandwidth. In short, the LLR RDD estimator works as follows: Estimate \\(\\hatesp{Y^1_i|D_i=1,Z_i=\\bar{z}}\\) using LLR on the treated side of the threshold. Estimate \\(\\hatesp{Y_i^0|D_i=0,Z_i=\\bar{z}}\\) using LLR on the untreated side of the threshold. \\(\\hat\\Delta^{y}_{RDDLLR}=\\hatesp{Y^1_i|D_i=1,Z_i=\\bar{z}}-\\hatesp{Y^0_i|D_i=0,Z_i=\\bar{z}}\\). Bandwidth choice: use cross-validation on each side. Example 4.18 Let’s see how all of this works in our example. First, let us code the LLR function and the cross validation function. llr &lt;- function(y,x,gridx,bw,kernel){ if (kernel==&#39;uniform&#39;){ K &lt;- function(u){ K.u &lt;- 0 if (abs(u)&lt;=.5){K.u &lt;- 1} return(K.u) } } if (kernel==&#39;triangular&#39;){ K &lt;- function(u){ K.u &lt;- 0 if (abs(u)&lt;=.5){K.u &lt;- 2*(1-2*abs(u))} return(K.u) } } if (kernel==&#39;epanechnikov&#39;){ K &lt;- function(u){ K.u &lt;- 0 if (abs(u)&lt;=.5){K.u &lt;- (3/2)*(1-4*u^2)} return(K.u) } } if (kernel==&#39;quartic&#39;){ K &lt;- function(u){ K.u &lt;- 0 if (abs(u)&lt;=.5){K.u &lt;- (15/8)*(1-4*u^2)^2} return(K.u) } } if (kernel==&#39;gaussian&#39;){ K &lt;- function(u){ return(exp(-0.5*u^2)/(sqrt(2*pi))) } } K.vec &lt;- Vectorize(K) y0.hat &lt;- rep(0,length(gridx)) for (i in (1:length(gridx))){ x.i &lt;- gridx[i]-x weights.i &lt;- K.vec((x.i)/bw) ols.i &lt;- lm(y~x.i,weights=weights.i) y0.hat[i] &lt;- ols.i$coefficients[1] } return(y0.hat) } MSE.llr &lt;- function(bw,y,D,x,kernel,d){ MSE &lt;- 0 for (i in (1:length(y[D==d]))){ MSE &lt;- MSE + (y[D==d][i]-llr(y[D==d][-i],x[D==d][-i],x[D==d][i],bw=bw,kernel=kernel))^2 } return(MSE) } We can now use these two functions to choose the optimal bandwidth on each side of the cut-off point: kernel &lt;- &#39;gaussian&#39; bw &lt;- 0.5 MSE.grid &lt;- seq(0.1,1,by=.1) MSE.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel=kernel,d=0) MSE.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel=kernel,d=1) bw0 &lt;- MSE.grid[MSE.llr.0==min(MSE.llr.0)] bw1 &lt;- MSE.grid[MSE.llr.1==min(MSE.llr.1)] Let us see what the results of this computation look like: par(mar=c(5,4,4,5)) plot(MSE.grid,MSE.llr.0,xlab=&#39;Bandwidth&#39;,ylab=&#39;MSE (y|D=0)&#39;) legend(0.8,50,c(&#39;y|D=0&#39;,&#39;y|D=1&#39;),pch=c(1,3),col=c(&#39;black&#39;,&#39;black&#39;),ncol=1) par(new=TRUE) plot(MSE.grid,MSE.llr.1,pch=3,xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) axis(4) mtext(&quot;MSE (y|D=1)&quot;,side=4,line=3) Figure 4.9: Cross Validation Results As Figure 4.9 shows, the optimal bandwidth is equal to 0.3 on the right of the threshold and to 0.2 on the left. We can now proceed with the estimation of the whole conditional expectations (in order to visualize them) and the estimated treatment effect using these optimal bandwidth levels: # whole conditional expectations at each sample point y0.llr &lt;- llr(y[Ds==0],yB[Ds==0],yB[Ds==0],bw=bw0,kernel=kernel) y1.llr &lt;- llr(y[Ds==1],yB[Ds==1],yB[Ds==1],bw=bw1,kernel=kernel) # estimation of the treatment effect y0.bary.llr.pred &lt;- llr(y[Ds==0],yB[Ds==0],c(log(param[&#39;barY&#39;])),bw=bw0,kernel=kernel) y1.bary.llr.pred &lt;- llr(y[Ds==1],yB[Ds==1],c(log(param[&#39;barY&#39;])),bw=bw1,kernel=kernel) delta.y.rdd.llr &lt;- y1.bary.llr.pred-y0.bary.llr.pred Let us plot the resulting estimates: plot(yB[Ds==0],y[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3) points(yB[Ds==0],y0.llr,col=&#39;blue&#39;,pch=1) points(yB[Ds==1],y1.llr,col=&#39;blue&#39;,pch=3) abline(v=log(param[&quot;barY&quot;]),col=&#39;black&#39;) text(x=c(log(param[&quot;barY&quot;])),y=c(5),labels=c(expression(bar(&#39;y&#39;))),pos=c(2),col=c(&#39;black&#39;)) legend(5,11,c(&#39;y|D=0&#39;,&#39;y|D=1&#39;,expression(hat(&#39;y0&#39;)),expression(hat(&#39;y1&#39;))),pch=c(1,3,1,3),col=c(&#39;black&#39;,&#39;black&#39;,&#39;blue&#39;,&#39;blue&#39;),ncol=2) Figure 4.10: LLR estimates of sharp RDD with non linear conditional expectations Our estimate of the treatment effect using LLR is 0.19 while the true value of our target parameter is still 0.18. The reason why the LLR estimate is an improvement over the OLS estimate is because the LLR estimate of the conditional expectation \\(\\hatesp{y_i^0|y_i^B=\\bar{y}}\\) curves upwards when approaching \\(\\bar{y}\\) as it should (as Figure 4.10 shows) while the linear prediction using OLS does not (see Figure 4.8). Let us finally see how sampling noise moves that estimator around as sample size increases. I am first going to ignore the noise stemming from estimating the optimal bandwidth, because it increases computation time exponentially. I am going to stick with the bandwidths optimal for the test sample (\\(N=1000\\)). They are going to be too large for the large samples, and as a consequence, they are going to generate a biased estimator there. Let’s see how severe that is: monte.carlo.rdd.llr.bw &lt;- function(s,N,param,bw1,bw0,kernel){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) y0.bary.llr &lt;- llr(y[Ds==0],yB[Ds==0],c(log(param[&#39;barY&#39;])),bw=bw0,kernel=kernel) y1.bary.llr &lt;- llr(y[Ds==1],yB[Ds==1],c(log(param[&#39;barY&#39;])),bw=bw1,kernel=kernel) delta.y.rdd.llr &lt;- y1.bary.llr-y0.bary.llr return(delta.y.rdd.llr) } simuls.rdd.llr.bw.N &lt;- function(N,Nsim,param,bw0,bw1,kernel){ simuls.rdd.llr.bw &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.rdd.llr.bw,N=N,param=param,bw1=bw1,bw0=bw0,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.rdd.llr.bw) &lt;- c(&#39;RDD LLR&#39;) return(simuls.rdd.llr.bw) } sf.simuls.rdd.llr.bw.N &lt;- function(N,Nsim,param,bw0,bw1,kernel){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr&#39;,&#39;MSE.llr&#39;,&#39;param&#39;) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.rdd.llr.bw,N=N,param=param,bw1=bw1,bw0=bw0,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;RDD LLR&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(1000) simuls.rdd.llr.bw &lt;- lapply(N.sample,sf.simuls.rdd.llr.bw.N,Nsim=Nsim,param=param,bw1=bw1,bw0=bw0,kernel=kernel) names(simuls.rdd.llr.bw) &lt;- N.sample Let us now plot the results: par(mfrow=c(2,2)) for (i in 1:length(simuls.rdd.llr.bw)){ hist(simuls.rdd.llr.bw[[i]][,&#39;RDD LLR&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yRDDLLR)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.z(param),col=&quot;red&quot;) } Figure 4.11: Distribution of the RDD LLR estimator over replications of samples of different sizes As expected, there is a small downward bias for the sample sizes. In order to see how much sampling noise estimates are affected by the computation of the optimal bandwidth, let’s run simulations including optimal bandwidth choice. Because of computational costs, I only run them for the smallest sample size for now. monte.carlo.rdd.llr &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) MSE.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel=kernel,d=0) MSE.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel=kernel,d=1) y0.bary.llr &lt;- llr(y[Ds==0],yB[Ds==0],c(log(param[&#39;barY&#39;])),bw=MSE.grid[MSE.llr.0==min(MSE.llr.0)],kernel=kernel) y1.bary.llr &lt;- llr(y[Ds==1],yB[Ds==1],c(log(param[&#39;barY&#39;])),bw=MSE.grid[MSE.llr.1==min(MSE.llr.1)],kernel=kernel) delta.y.rdd.llr &lt;- y1.bary.llr-y0.bary.llr return(delta.y.rdd.llr) } simuls.rdd.llr.N &lt;- function(N,Nsim,param){ simuls.rdd.llr &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.rdd.llr,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.rdd.llr) &lt;- c(&#39;RDD LLR&#39;) return(simuls.rdd.llr) } sf.simuls.rdd.llr.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr&#39;,&#39;MSE.llr&#39;,&#39;param&#39;,&#39;MSE.grid&#39;,&#39;kernel&#39;,&#39;bw&#39;) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.rdd.llr,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;RDD LLR&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) N.sample &lt;- c(100) simuls.rdd.llr &lt;- lapply(N.sample,sf.simuls.rdd.llr.N,Nsim=Nsim,param=param) names(simuls.rdd.llr) &lt;- N.sample Let’s plot the resulting estimate: Figure 4.12: Distribution of the RDD LLR estimator over replications of samples of different sizes, with optimal bandwidth choice The results are broadly comparable. For \\(N=100\\), 99% sampling noise of LLR estimated by Monte Carlo simulations is 0.57 when keeping the bandwidth fixed while it is equal to 0.59 when the bandwidth is optimized at each run. 4.2.1.2.4 Simplified estimator of Lee and Lemieux Imbens and Lemieux (2008) propose a simplified version of the RDD LLR estimator. \\(\\hat{\\delta}\\) estimated by OLS on the sample of observations such as \\(\\bar{z}-h\\leq Z_i\\leq\\bar{z}+h\\) is an estimate of \\(TT(z)\\): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta (Z_i-\\bar{z})(1-D_i) + \\gamma(Z_i-\\bar{z})D_i + \\delta D_i + \\epsilon_i \\end{align*}\\] It is actually equal to the LLR estimate with uniform kernel and identical bandwidth on each side of the threshold. Example 4.19 Lets run the simplified LLR estimator in our example. bw &lt;- 0.25 y.h &lt;- y[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] Ds.h &lt;- Ds[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.l &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*Ds[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.r &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*(1-Ds[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]) reg.rdd.local.ols &lt;- lm(y.h ~ Ds.h + yB.l + yB.r) reg.rdd.local.ols$coef[2] The estimated value of TT(z) by simplified LLR is 0.11 while the true value of our target parameter is still 0.18. 4.2.1.3 Estimating sampling noise Several approaches are available to estimate sampling noise of the RDD LLR estimator in a sharp design: Hahn, Todd and van der Klaauw (2001) derive general CLT results Imbens and Lemieux (2008) simplify the CLT results and propose a plug-in estimator Imbens and Lemieux (2008) propose to use the robust variance OLS estimator We can always use the Bootstrap. It should be valid. Let us first look at some CLT results: Theorem 4.5 (Asymptotic Variance of the LLR Estimator in a Sharp RDD) Under standard assumptions, the variance of the simplified LLR Estimator in a Sharp Design can be approximated by: \\[\\begin{align*} \\var{\\hat{\\Delta}_{LLRRDD}} &amp; \\approx \\frac{1}{Nh}\\frac{4}{f_{Z}(\\bar{z})}\\left(\\lim_{e\\rightarrow 0^{\\text{+}}}\\var{Y_i|Z_i=\\bar{z}-e}+\\lim_{e\\rightarrow 0^{\\text{+}}}\\var{Y_i|Z_i=\\bar{z}+e}\\right), \\end{align*}\\] with \\(f_{Z}\\) the density of \\(Z_i\\). Proof. See Hahn, Todd and van der Klaauw (2001) and Imbens and Lemieux (2008). Example 4.20 Let’s see what happens when using the the robust variance estimator in the simplified LLR estimator proposed by Imbens and Lemieux (2008). The estimated 99% sampling noise using this approach is 0.44 while the true 99% sampling noise of LLR estimated by Monte Carlo simulations is equal to 0.57. 4.2.2 Fuzzy Regression Discontinuity Designs We say that a Regression Discontinuity Design is fuzzy when the probability of obtaining the treatment does not move from \\(0\\) to \\(1\\) when moving across the threshold of the running variable, but moves from some probability to a different one, when both are strictly positive and strictly smaller than one. This means that there is some event that discontinuously affects the enrollment of some people but not the enrollment of others. We thus are going to see compliers, always takers and never takers, as we did with Instrumental Variables. In this section, we are going to study the identification, estimation and estimation of sampling noise of treatment effects in the Fuzzy Regression Discontinuity Design. 4.2.2.1 Identification The first assumption characterizing the Fuzzy Regression Discontinuity Design is the asumption that the probability of receiving treatment is discontinuous: Hypothesis 4.9 (Fuzzy RDD Design) There exists a running variable \\(Z_i\\) and a threshold \\(\\bar{z}\\) such that: \\[\\begin{align*} \\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}-e) &amp; \\neq \\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}+e). \\end{align*}\\] Example 4.21 Let’s see how this plays in our example. Let’s first simulate some data: \\[\\begin{align*} y_i^1 &amp; = y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i \\\\ y_i^0 &amp; = \\mu_i+\\delta+U_i^0+\\gamma(y_i^B-\\bar{y})^2 \\\\ U_i^0 &amp; = \\rho U_i^B+\\epsilon_i \\\\ y_i^B &amp; =\\mu_i+U_i^B \\\\ U_i^B &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_i &amp; = \\uns{y_i^B\\leq\\bar{y} \\land V_i\\leq\\kappa \\lor y_i^B&gt;\\bar{y} \\land V_i&gt;\\kappa} \\\\ (\\eta_i,\\omega_i,V_i) &amp; \\sim\\mathcal{N}(0,0,0,\\sigma^2_{\\eta},\\sigma^2_{\\omega},\\sigma^2_{\\mu}+\\sigma^2_{U},0,0,0). \\end{align*}\\] param &lt;- c(param,1) names(param)[[length(param)]] &lt;- &quot;kappa&quot; N &lt;- 1000 set.seed(123) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[((yB&lt;=log(param[&quot;barY&quot;])) &amp; (V&lt;=param[&quot;kappa&quot;])) | ((yB&gt;log(param[&quot;barY&quot;])) &amp; (V&gt;param[&quot;kappa&quot;])) ] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let us now plot the corresponding data: par(mar=c(5,4,4,5)) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;black&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) legend(5,10.5,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;D&#39;),pch=c(1,3,2),col=c(&#39;black&#39;,&#39;black&#39;,&#39;red&#39;),ncol=1) par(new=TRUE) plot(yB,Ds,pch=2,col=&#39;red&#39;,xlim=c(5,11),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) axis(4) mtext(&quot;D&quot;,side=4,line=3) Figure 4.13: Fuzzy RDD As you can see on Figure 4.13, there are untreated individuals below \\(\\bar{y}\\) and treated individual above \\(\\bar{y}\\). This is why the design is not sharp. But Figure 4.13 fails to convey that the design still exhibits a discontinuity in the proportion of treated. In order to see it, we need to compute an estimate of the probability of being treated conditional on the running variable (\\(y_i^B\\)): \\(\\Pr(D_i=1|y_i^B=y)\\). It turns out that this quantity is simply the expected value of \\(D_i\\) conditional on \\(y_i^B\\). We’ve just learned a cool way to estimate a conditional expectation: Local Linear Regression. Let’s put it to work, using \\(D_i\\) as the outcome variable now: kernel &lt;- &#39;gaussian&#39; MSE.grid &lt;- seq(0.1,1,by=.1) # the instrument in our case is the position relative to the threshoold (or side, hence S) S &lt;- rep(0,length(yB)) S[yB&lt;=log(param[&#39;barY&#39;])] &lt;- 1 # computing optimal bandwidth using Cross Validation MSE.pr.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=Ds,D=S,x=yB,kernel=kernel,d=0) MSE.pr.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=Ds,D=S,x=yB,kernel=kernel,d=1) bwD0 &lt;- MSE.grid[MSE.pr.llr.0==min(MSE.pr.llr.0)] bwD1 &lt;- MSE.grid[MSE.pr.llr.1==min(MSE.pr.llr.1)] # LLR estoimate of conditional expectation of D on yB Pr.D0.llr &lt;- llr(Ds[S==0],yB[S==0],yB[S==0],bw=bwD0,kernel=kernel) Pr.D1.llr &lt;- llr(Ds[S==1],yB[S==1],yB[S==1],bw=bwD1,kernel=kernel) Let’s now plot the resulting estimate: par(mar=c(5,4,4,5)) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;black&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) legend(5,10.5,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;D&#39;,&#39;Pr(D=1|S=1,yB)&#39;,&#39;Pr(D=1|S=0,yB)&#39;),pch=c(1,3,2,3,1),col=c(&#39;black&#39;,&#39;black&#39;,&#39;red&#39;,&#39;red&#39;,&#39;red&#39;),ncol=1) par(new=TRUE) plot(yB,Ds,pch=2,col=&#39;red&#39;,xlim=c(5,11),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) points(yB[S==0],Pr.D0.llr,col=&#39;red&#39;) points(yB[S==1],Pr.D1.llr,col=&#39;red&#39;,pch=3) axis(4) mtext(&quot;D&quot;,side=4,line=3) Figure 4.14: Fuzzy RDD with probability of being treated as a function of the running variable Figure 4.13 now clearly shows that the probability of receiving the treatment decreases discontinuously when crossing the threshold \\(\\bar{y}\\). The decrease is not a move from \\(1\\) to \\(0\\) and hence is a clear case of a Fuzzy Regression Discontinuity Design. Identification in a Fuzzy Regression Discontinuity Design proceeds along the same lines as with Instrumental Variables: either we assume that treatment effects are somewhat independent from Types or we impose that there are no defiers (though some more options are feasible, as we saw in the section on Instrumental Variables). 4.2.2.1.1 Identification under Independence of treatment effects from Types Let us first define the types in a Fuzzy Regression Discontinuity Design. For that, we define \\(D_i(z)\\) as the potential outcome of individual \\(i\\) when \\(Z_i=z\\). We have (as seems natural now) four possible types of individuals depending on how they react when exogenously moved from one side of the threshold to the other: Always takers (\\(T^{\\bar{z}}_i=a\\)) are such that \\(\\lim_{z\\rightarrow \\bar{z}^+}D_i(z)=\\lim_{z\\rightarrow \\bar{z}^-}D_i(z)=1\\). Never takers (\\(T^{\\bar{z}}_i=n\\)) are such that \\(\\lim_{z\\rightarrow \\bar{z}^+}D_i(z)=\\lim_{z\\rightarrow \\bar{z}^-}D_i(z)=0\\). Compliers (\\(T^{\\bar{z}}_i=c\\)) are such that \\(\\lim_{z\\rightarrow \\bar{z}^+}D_i(z)-\\lim_{z\\rightarrow \\bar{z}^-}D_i(z)=1\\). Defiers (\\(T^{\\bar{z}}_i=d\\)) are such that \\(\\lim_{z\\rightarrow \\bar{z}^+}D_i(z)-\\lim_{z\\rightarrow \\bar{z}^-}D_i(z)=-1\\). We can now encode the assumption of independent treatment effects: Hypothesis 4.10 (Independence of Treatment Effects from Types) We assume that treatment effects are independent of Types at the discontinuity: \\[\\begin{align*} \\Delta^Y_i\\Ind T^{\\bar{z}}_i|Z_i=z. \\end{align*}\\] We are now equipped to prove identification in the Fuzzy Regression Discontinuity Design under Independence of Treatment Effects from Types: Theorem 4.6 (Identification of TT(z) in Fuzzy RDD under Independence) Under Assumptions 4.8 and 4.10, we have: \\[\\begin{align*} \\Delta^Y_{RDDWALD} &amp; = \\Delta^Y_{TT}(z), \\end{align*}\\] with \\[\\begin{align*} \\Delta^Y_{RDDWALD} &amp; = \\frac{\\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}-e} - \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}+e}} {\\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}-e) - \\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}+e)} \\end{align*}\\] Proof. Using the switching equation and Assumption 4.8, we can decompose the numerator of the Local Wald estimator as follows: \\[\\begin{align*} \\lim_{z\\rightarrow \\bar{z}^+}\\esp{Y_i|Z_i=z}&amp;=\\esp{Y_i^1|Z_i=\\bar{z},T^{\\bar{z}}_i=a}\\Pr(T_i=a|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^1|Z_i=\\bar{z},T^{\\bar{z}}_i=c}\\Pr(T_i=c|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=d}\\Pr(T_i=d|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=n}\\Pr(T_i=n|Z_i=\\bar{z})\\\\ \\lim_{z\\rightarrow \\bar{z}^-}\\esp{Y_i|Z_i=z}&amp;=\\esp{Y_i^1|Z_i=\\bar{z},T^{\\bar{z}}_i=a}\\Pr(T_i=a|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=c}\\Pr(T_i=c|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^1|Z_i=\\bar{z},T^{\\bar{z}}_i=d}\\Pr(T_i=d|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}+\\esp{Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=n}\\Pr(T_i=n|Z_i=\\bar{z})\\\\ N_{\\bar{z}}&amp;= \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}-e}- \\lim_{e\\rightarrow 0^{+}}\\esp{Y_i|Z_i=\\bar{z}+e}\\\\ &amp; = \\esp{Y_i^1-Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=c}\\Pr(T_i=c|Z_i=\\bar{z})\\\\ &amp; \\phantom{=}-\\esp{Y_i^1-Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=d}\\Pr(T_i=d|Z_i=\\bar{z}) \\end{align*}\\] We also have that the denominator of the Local Wald estimator is equal to: \\[\\begin{align*} D_{\\bar{z}}&amp; =\\lim_{z\\rightarrow \\bar{z}^+}\\Pr(D_i=1|Z_i=z)-\\lim_{z\\rightarrow \\bar{z}^-}\\Pr(D_i=1|Z_i=z)\\\\ &amp; = \\lim_{z\\rightarrow \\bar{z}^+}\\left(\\Pr(T_i^z=a|Z_i=z)+\\Pr(T_i^z=c|Z_i=z)\\right)\\\\ &amp; \\phantom{=}-\\lim_{z\\rightarrow \\bar{z}^-}\\left(\\Pr(T_i^z=a|Z_i=z)+\\Pr(T_i^z=d|Z_i=z)\\right)\\\\ &amp; = \\Pr(T_i^{\\bar{z}}=c|Z_i=\\bar{z})-\\Pr(T_i^{\\bar{z}}=d|Z_i=\\bar{z}) \\end{align*}\\] Under Assumption 4.10, we have that \\(\\esp{Y_i^1-Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=c}=\\esp{Y_i^1-Y_i^0|Z_i=\\bar{z},T^{\\bar{z}}_i=d}=\\esp{Y_i^1-Y_i^0|Z_i=\\bar{z}}\\). This proves the result. 4.2.2.1.2 Identification under Monotonicity We can weaken Assumption 4.10 and allow for treatment effects correlated with types (which seems highly likely) if we are willing to make stronger assumptions on the distribution of types. As we have seen before with Instrumental Variables, assuming away defiers enables the identification of a Local Average Treatment Effect. Let’s see how this works: Hypothesis 4.11 (Monotonicity in a Fuzzy Regression Discontinuity Design) \\(D_i(z)\\) is non-decreasing at \\(z=\\bar{z}\\) (or \\(\\Pr(T^{\\bar{z}}_i=d|Z_i=\\bar{z})=0\\)). We can now prove identification of the local average treatment effect: Theorem 4.7 (Identification of TT(z) in Fuzzy RDD under Monotonicity) Under Assumptions 4.8 and 4.11, we have: \\[\\begin{align*} \\Delta^Y_{RDDWALD} &amp; = \\Delta^Y_{LATE}(z), \\end{align*}\\] with \\[\\begin{align*} \\Delta^Y_{LATE}(z) &amp; = \\esp{y_i^1-Y_i^0|T_i^{\\bar{z}}=c,Z_i=\\bar{z}}. \\end{align*}\\] Proof. The proof essentially follows the proof of Theorem 4.6 up to its penultimate step. Under Assumption 4.11, we have that \\(\\Pr(T^{\\bar{z}}_i=d|Z_i=\\bar{z})=0\\). This proves the result. 4.2.2.2 Estimation For estimation, we can either use the Local Linear Regression Wald estimator or use a simplified version proposed by Imbens and Lemieux (2008). Let’s see how both of them work in practice. 4.2.2.2.1 Estimation using Local Linear Regression The Wald LLR estimator can be formed as follows, with \\(S_i=1\\) when \\(Z_i\\geq\\bar{z}\\) and \\(S_i=0\\) when \\(Z_i&lt;\\bar{z}\\) (in the case where \\(\\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}-e) &lt; \\lim_{e\\rightarrow 0^{+}}\\Pr(D_i=1|Z_i=\\bar{z}+e))\\) (simply revert the values of \\(S_i\\) if the converse is true)): Estimate \\(\\hatesp{Y^1_i|S_i=1,Z_i=\\bar{z}}\\) and \\(\\hatesp{D_i|S_i=1,Z_i=\\bar{z}}\\) using LLR on the right of \\(\\bar{z}\\). Estimate \\(\\hatesp{Y^0_i|S_i=0,Z_i=\\bar{z}}\\) and \\(\\hatesp{D_i|S_i=0,Z_i=\\bar{z}}\\) using LLR on the left of \\(\\bar{z}\\). \\(\\hat\\Delta^{Y}_{WaldRDDLLR}=\\frac{\\hatesp{Y^1_i|S_i=1,Z_i=\\bar{z}}-\\hatesp{Y^0_i|S_i=0,Z_i=\\bar{z}}}{\\hatesp{D_i|S_i=1,Z_i=\\bar{z}}-\\hatesp{D_i|S_i=0,Z_i=\\bar{z}}}\\). For bandwidth choice: use cross-validation for each estimation. Example 4.22 Let’s see how this works in our example. Note that we have to revert the definition of \\(S_i\\) since the highest treatment probability is below \\(\\bar{y}\\). # bandwidth choice MSE.llr.S0 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=S,x=yB,kernel=kernel,d=0) MSE.llr.S1 &lt;- sapply(MSE.grid,MSE.llr,y=y,D=S,x=yB,kernel=kernel,d=1) bwyS0 &lt;- MSE.grid[MSE.llr.S0==min(MSE.llr.S0)] bwyS1 &lt;- MSE.grid[MSE.llr.S1==min(MSE.llr.S1)] # LLR estimation y.S0.llr &lt;- llr(y[S==0],yB[S==0],yB[S==0],bw=bwyS0,kernel=kernel) y.S1.llr &lt;- llr(y[S==1],yB[S==1],yB[S==1],bw=bwyS1,kernel=kernel) # Wald estimator Pr.D0.llr.ybar &lt;- llr(Ds[S==0],yB[S==0],c(log(param[&#39;barY&#39;])),bw=bwD0,kernel=kernel) Pr.D1.llr.ybar &lt;- llr(Ds[S==1],yB[S==1],c(log(param[&#39;barY&#39;])),bw=bwD1,kernel=kernel) y.S0.llr.ybar &lt;- llr(y[S==0],yB[S==0],c(log(param[&#39;barY&#39;])),bw=bwyS0,kernel=kernel) y.S1.llr.ybar &lt;- llr(y[S==1],yB[S==1],c(log(param[&#39;barY&#39;])),bw=bwyS1,kernel=kernel) num.Wald.RDD.llr &lt;- y.S1.llr.ybar-y.S0.llr.ybar denom.Wald.RDD.llr &lt;- Pr.D1.llr.ybar-Pr.D0.llr.ybar wald.rdd.llr &lt;- (num.Wald.RDD.llr)/(denom.Wald.RDD.llr) Let us now plot the resulting estimate: Figure 4.15: Fuzzy RDD estimation with LLR It is difficult to see the reduced form estimate on Figure 4.15. The numerator of the Wald estimator is equal to 0.11. The Wald estimator of our local average treatment effect is equal to 0.13. The true value of our target parameter (the average treatment effect on the complier at \\(y_i^B=\\bar{y}\\)) is equal to 0.18, which is the same value as in our example with the Sharp RDD, since the added noise in the participation equation, \\(V_i\\), is independent from potential outcomes, and thus, Assumption 4.10 holds in our example. Remark. Making \\(V_i\\) correlated with \\(\\eta_i\\) or \\(\\mu_i\\) in our example would generate a model in which treatment effects are not independent from types (i.e. Assumption 4.10 would not hold). LATE would be different from the treatment on the treated parameter. The formula for the LATE would be: \\(\\Delta^Y_{LATE}(z)=\\esp{\\alpha_i|yi^B=\\bar{y},V_i=0}\\). The proof is left as an exercise. 4.2.2.2.2 Estimation using the simplified IV estimator of Imbens and Lemieux Imbens and Lemieux (2008) propose the following simplified version of the WALD LLR estimator: \\(\\hat{\\delta}\\) estimated by 2SLS using \\(\\uns{Z_i\\leq\\bar{z}}\\) as an instrument on the sample of observations such as \\(\\bar{z}-h\\leq Z_i\\leq\\bar{z}+h\\) is an estimate of \\(LATE(z)\\): \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta (Z_i-\\bar{z})\\uns{Z_i\\leq\\bar{z}} + \\gamma(Z_i-\\bar{z})\\uns{Z_i&gt;\\bar{z}} + \\delta D_i + \\epsilon_i \\end{align*}\\] It is actually equal to the Wald LLR estimate with uniform kernel and identical bandwidth on each side of the threshold. The bandwidth can be chosen as to be the minimum of the four LLR bandwidths. Example 4.23 Let’s see how this works in our example. bw &lt;- min(bwD0,bwD1,bwyS0,bwyS1) #bw &lt;- 0.4 y.h &lt;- y[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] Ds.h &lt;- Ds[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.l &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*S[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.r &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*(1-S[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]) S.h &lt;- S[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] reg.fuzzy.rdd.local.iv &lt;- ivreg(y.h ~ Ds.h + yB.l + yB.r | S.h + yB.l + yB.r) delta.rdd.fuzzy.il &lt;- reg.fuzzy.rdd.local.iv$coef[2] delta.y.tt.rdd.fuzzy &lt;- delta.y.tt.z(param) With this estimator and using the minimum of the four bandwidths, we estimate the effect of the treatment to be equal to 0.15, while the true effect in the population is equal to 0.18. Let’s see how this estimator behaves around sampling replications: monte.carlo.fuzzy.rdd.llr.bw &lt;- function(s,N,param,bw){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[((yB&lt;=log(param[&quot;barY&quot;])) &amp; (V&lt;=param[&quot;kappa&quot;])) | ((yB&gt;log(param[&quot;barY&quot;])) &amp; (V&gt;param[&quot;kappa&quot;])) ] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Z &lt;- ifelse(yB&lt;=log(param[&#39;barY&#39;]),1,0) y.h &lt;- y[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] Ds.h &lt;- Ds[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.l &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*Z[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] yB.r &lt;- (yB[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]-log(param[&#39;barY&#39;]))*(1-Z[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw]) Z.h &lt;- Z[log(param[&#39;barY&#39;])-bw&lt;yB &amp; yB&lt;log(param[&#39;barY&#39;])+bw] reg.fuzzy.rdd.local.iv &lt;- ivreg(y.h ~ Ds.h + yB.l + yB.r | Z.h + yB.l + yB.r) delta.rdd.fuzzy.il &lt;- reg.fuzzy.rdd.local.iv$coef[2] return(delta.rdd.fuzzy.il) } simuls.fuzzy.rdd.llr.bw.N &lt;- function(N,Nsim,param,bw){ simuls.fuzzy.rdd.llr.bw &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.fuzzy.rdd.llr.bw,N=N,param=param,bw=bw)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.fuzzy.rdd.llr.bw) &lt;- c(&#39;RDD LLR&#39;) return(simuls.fuzzy.rdd.llr.bw) } sf.simuls.fuzzy.rdd.llr.bw.N &lt;- function(N,Nsim,param,bw){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr&#39;,&#39;MSE.llr&#39;,&#39;param&#39;) sfLibrary(AER) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.fuzzy.rdd.llr.bw,N=N,param=param,bw=bw)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;RDD LLR&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.fuzzy.rdd.llr.bw &lt;- lapply(N.sample,sf.simuls.fuzzy.rdd.llr.bw.N,Nsim=Nsim,param=param,bw=bw) names(simuls.fuzzy.rdd.llr.bw) &lt;- N.sample Let’s plot the resulting estimates: par(mfrow=c(2,2)) for (i in 1:length(simuls.fuzzy.rdd.llr.bw)){ hist(simuls.fuzzy.rdd.llr.bw[[i]][,&#39;RDD LLR&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yIVRDDLLR)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.z(param),col=&quot;red&quot;) } Figure 4.16: Distribution of the \\(IV RDD LLR\\) estimator over replications of samples of different sizes 4.2.2.3 Estimation of sampling noise We can use several approaches to estimate the sampling noise of the Wald RDDLLR eestimator: Hahn, Todd and van der Klaauw (2001) derive general CLT results Imbens and Lemieux (2008) simplify the CLT results and propose a plug-in estimator Imbens and Lemieux (2008) propose to use the robust variance of the 2SLS estimator Bootstrap should be valid. The following theorem derives the CLT-based variance of the simplified Wald RDDLLR estimator: Theorem 4.8 (Asymptotic Variance of the LLR-IV Estimator) The variance of the simplified LLR-IV Estimator in a Fuzzy Design can be approximated by: \\[\\begin{align*} \\var{\\hat{\\Delta}_{LLRRDDIV}} &amp; \\approx \\frac{1}{Nh}\\left(\\frac{1}{\\tau^2_{D}}V_{\\tau_Y}+\\frac{\\tau^2_{Y}}{\\tau^4_{D}}V_{\\tau_D}-2\\frac{\\tau_{Y}}{\\tau^3_{D}}C_{\\tau_Y,\\tau_D}\\right), \\end{align*}\\] with \\[\\begin{align*} \\tau_{D} &amp; = \\lim_{e\\rightarrow 0^{+}}\\esp{D_i|Z_i=\\bar{z}+e}-\\lim_{e\\rightarrow 0^{+}}\\esp{D_i|Z_i=\\bar{z}-e}\\\\ V_{\\tau_Y} &amp; = \\frac{4}{f_Z(\\bar{z})}\\left(\\sigma^2_{Y^r}+\\sigma^2_{Y^l}\\right) \\qquad V_{\\tau_D} = \\frac{4}{f_Z(\\bar{z})}\\left(\\sigma^2_{D^r}+\\sigma^2_{D^l}\\right)\\\\ C_{\\tau_Y,\\tau_D}&amp; = \\frac{4}{f_Z(\\bar{z})}\\left(C_{YD^r}+C_{YD^l}\\right) \\qquad \\sigma^2_{Y^r} = \\lim_{e\\rightarrow 0^{+}}\\var{Y_i|Z_i=\\bar{z}+e} \\\\ C_{YD^r} &amp; = \\lim_{e\\rightarrow 0^{+}}\\cov{Y_i,D_i|Z_i=\\bar{z}+e} \\end{align*}\\] Proof. Hahn, Todd and van der Klaauw (2001) and Imbens and Lemieux (2008). Another way is tu simply use the robust standard errors from the 2SLS estimator. Example 4.24 Let’s see what happens with this estimator of sampling noise in our example. The estimated 99% sampling noise the robust standard errors from the 2SLS estimator is 0.37. The true 99% sampling noise of Wald RDDLLR estimated by Monte Carlo simulations is 0.39. 4.3 Difference In Differences In Difference In Differences (a.k.a. DID), the difference between treated and untreated before the treatment is used to approximate selection bias. As a consequence, DID works by correcting the With/Without comparison after treatment by the With/Without comparison before treatment and hopes that it is enough to recover the TT. Hence the name Difference in Differences (DID), since the estimator, in its simplest form, is a difference between two differences. In this section, we are going to look at identification using DID, estimation and estimation of sampling noise. At first, we are going to assume that we have only access to two time periods. In that case, estimation and inference are pretty straightforward. We will then examine the case of several time periods, but we will first allow for only one treatment date. In that case, we will introduce the standard tools used by applied researchers to analyze these types of designs: the event study graph and the Two-Way Fixed Effects estimator (a.k.a. TWFE). We will determine which effect is estimated by the TWFE estimator and what are the goals of the event study graph. We will then look at the most complex case: the staggered design, where we have several time periods (strictly more than two) and the date of treatment differs across units. In the staggered design, troubles start appearing for the TWFE estimator. We will survey these problems and the proposed solutions to address them. Finally, we will look at the combination of DID with instrumental variables (the DID-IV estimator) and see which specific types of problems happen there as well. Let’s get to it. 4.3.1 Difference In Differences with two time periods Before getting into the rigorous derivations, let’s start with a very simple illustration using our workhorse example. Example 4.25 How does DID perform and what does it look like in our example model? Let’s first generate a dataset with selection bias. \\[\\begin{align*} y_i^1 &amp; = y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i \\\\ y_i^0 &amp; = \\mu_i+\\delta+U_i^0 \\\\ U_i^0 &amp; = \\rho U_i^B+\\epsilon_i \\\\ y_i^B &amp; =\\mu_i+U_i^B \\\\ U_i^B &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_i &amp; = \\uns{y_i^B+ V_i\\leq\\bar{y}} \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_i \\\\ (\\eta_i,\\omega_i) &amp; \\sim\\mathcal{N}(0,0,\\sigma^2_{\\eta},\\sigma^2_{\\omega},\\rho_{\\eta,\\omega}) \\end{align*}\\] param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1,0.1,7.98,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;gamma&quot;,&quot;baryB&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) Let’s see how DID works on this data. Figure 4.17: Evolution of average outcomes in the treated and control group Figure 4.17 shows the evolution of the mean log-outcomes for the treated and untreated groups over time in our simulated dataset. We can see that in the Before period, outcomes (\\(y_i^B\\) in that case) are much higher for the non participants than for the participants, in agreement with the selection rule that makes participation into the program more likely for individuals with lower pre-treatment outcomes. The With/Without difference in outcomes before the program takes place is \\(\\hat{\\Delta}^{y^B}_{WW}=\\) -1.361. Second, we see that the difference between participants and non-participants decreases after receiving the treatment. This is because the outcomes of the participants increase faster than the outcomes of the non participants. As a consequence, the With/Without difference in outcomes after the program takes place is \\(\\hat{\\Delta}^{y}_{WW}=\\) -1.154. The DID estimator is built by comparing these two differences. In our example, \\(\\hat{\\Delta}^{y}_{DID}=\\) 0.206. It is not too far from the true treatment effect of \\(\\hat{\\Delta}^{y}_{TT}=\\) 0.165. Figure 4.17 also demonstrates that the DID estimator can also be seen as the difference between the Before/After differences in outcomes of the treated and the untreated. The Before/After difference in outcomes for the non participants is \\(\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.046 while the Before/After difference for the participants is \\(\\hat{\\Delta}^{y}_{BA|D=1}=\\) 0.252, leading to the same DID estimand. One way to understand the DID estimator is to see it as recreating the counterfactual trajectory of the participants (show as a discontinuous line on Figure 4.17) by using the trajectory of the non participants and making it start at the pre-treatment level of the participants. This estimated counterfactual trajectory is shown as the purple continuous line at the bottom of Figure 4.17. In our example, the true counterfactual trajectory (the discontinuous line) and the estimated counterfactual trajectory almost coincide, making the estimated counterfactual outcome of the participants very close to their true counterfactual outcome (7.046 vs 7.087). The difference between these two quantities measures the bias of the DID estimator, and we can see that it is very low in our example. The fact that the Before/After difference in outcomes for the non participants approximates well the counterfactual Before/After difference in outcomes for the participants is THE crucial assumption of the DID estimator. It is called the parallel trends assumption. 4.3.1.1 Identification The formal setting for introducing the DID estimator is to start with two time periods, Before and After (\\(t=B\\) and \\(t=A\\) respectively). Outcomes with and without the treatment in both periods are denoted \\(Y^d_{i,t}\\), for \\(d\\in\\left\\{0,1\\right\\}\\) and \\(t\\in\\left\\{B,A\\right\\}\\). Treatment participation in both periods is denoted \\(D_{i,t}\\) for \\(t\\in\\left\\{B,A\\right\\}\\). In the Before period, the treatment is unavailable, so that we get to observe the potential outcomes of the agents in the absence of the treatment. These two very specific requirements of DID are encoded in the following way: Hypothesis 4.12 (No Treatment in the Before Period) We assume that no unit in the population receives the treatment in the Before period: \\(D_{i,B}=0\\), \\(\\forall i\\) and not all units receive the program in the After period, but some units receive it: \\(0&lt;\\Pr(D_{i,A}=1)&lt;1\\). Under Assumption 4.12, and without loss of generality, we are going to write \\(D_i=D_{i,A}\\). Hypothesis 4.13 (No Anticipation Effects) We assume that, in the Before period, agents cannot anticipate that the program will happen in the After period, or that they do not change their behavior as a consequence: \\(Y_{i,B}=Y^0_{i,B}\\), \\(\\forall i\\). A consequence of Assumptions 4.12 and 4.13 is that we can write observed outcomes as a function of treatment and potential outcomes using the usual switching equation: \\[\\begin{align}\\label{eqn:switchDID} Y_{i,t} &amp; = Y^1_{i,t}D_{i,t} + Y^0_{i,t}(1-D_{i,t}). \\end{align}\\] The final very important assumption that we can make is to assume that the trends in the potential outcomes in the absence the treatment are the same for the treated and the untreated units: Hypothesis 4.14 (Parallel Trends) We assume that the trends in the potential outcomes in the absence the treatment are the same for the treated and the untreated units: \\[\\begin{align*} \\esp{Y^0_{i,A}|D_i=1} - \\esp{Y^0_{i,B}|D_i=1} &amp; = \\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}. \\end{align*}\\] Assumption 4.14 is actually equivalent to assuming that selection bias is constant over time. This is what this very simple lemma shows: Lemma 4.3 (Parallel Trends is Constant Selection Bias) Assumption 4.14 is equivalent to assuming that selection bias is constant over time: \\[\\begin{align*} \\esp{Y^0_{i,A}|D_i=1} - \\esp{Y^0_{i,A}|D_i=0} &amp; = \\esp{Y^0_{i,B}|D_i=1} - \\esp{Y^0_{i,B}|D_i=0} . \\end{align*}\\] Proof. The proof follows immediately by adding \\(\\esp{Y^0_{i,B}|D_i=1}-\\esp{Y^0_{i,A}|D_i=0}\\) to both sides of the equation in Assumption 4.14. Under these assumptions, we are ready to state the main identification result of this section: Theorem 4.9 (DID identifies TT) Under Assumptions 4.12, 4.13 and 4.14, the DID estimator identifies the average effect of the Treatment on the Treated after the treatment: \\[\\begin{align*} \\Delta_{DID}^{Y} &amp; = \\Delta^{Y_A}_{TT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}|D_i=1} - \\esp{Y_{i,B}|D_i=1} - (\\esp{Y_{i,A}|D_i=0} - \\esp{Y_{i,B}|D_i=0}),\\\\ \\Delta^{Y_A}_{TT} &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_{i}=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}|D_i=1}-\\esp{Y_{i,B}|D_i=1}-(\\esp{Y_{i,A}|D_i=0}-\\esp{Y_{i,B}|D_i=0}) \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^0_{i,B}|D_i=1}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^0_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,A}|D_i=1}-\\left(\\esp{Y^0_{i,A}|D_i=0}+(\\esp{Y^0_{i,B}|D_i=1}-\\esp{Y^0_{i,B}|D_i=0})\\right) \\end{align*}\\] where the second equality follows from Assumptions 4.12 and 4.13 and the switching equation, and the third equality follows from Lemma 4.3. Under Assumption 4.14, we have: \\[\\begin{align*} \\esp{Y^0_{i,A}|D_i=1} &amp; = \\esp{Y^0_{i,A}|D_i=0} + (\\esp{Y^0_{i,B}|D_i=1}-\\esp{Y^0_{i,B}|D_i=0}) \\end{align*}\\] As a consequence, we have: \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^0_{i,A}|D_i=1}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=1}\\\\ &amp; = \\Delta^{Y_A}_{TT}. \\end{align*}\\] Example 4.26 How does the DID estimator behave in our example? The Before/After comparison among the participants is equal to \\(\\hat{\\Delta}^{y}_{BA|D=1}=\\) 0.252. The Before/After comparison among the non-participants is equal to \\(\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.046. The DID estimator is thus equal to \\(\\hat{\\Delta}^{y}_{DID}=\\hat{\\Delta}^{y}_{BA|D=1}-\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.252 \\(-\\) 0.046 \\(=\\) 0.206. It is also equal to the difference between the before and after With/Without estimators. The Before With/Without estimator is equal to \\(\\hat{\\Delta}^{y^B}_{WW}=\\) -1.361. The After With/Without estimator is equal to \\(\\hat{\\Delta}^{y}_{WW}=\\) -1.154. The DID estimator is thus equal to \\(\\hat{\\Delta}^{y}_{DID}=\\hat{\\Delta}^{y}_{WW}-\\hat{\\Delta}^{y^B}_{WW}=\\) -1.154 \\(-(\\) -1.361 \\()=\\) 0.206. This is not too far from the true effect of the treatment in the sample which is equal to \\(\\hat{\\Delta}^{y}_{TT}=\\) 0.165. Now, another very important question is whether the DID estimator is consistent, that is whether it is equal to \\(\\Delta^{y}_{TT}\\) in our model. A necessary and sufficient condition for that is for the Parallel Trends Assumption 4.14 to hold. Indeed, it can be shown that the bias of the DID estimator is \\(\\Delta^{y}_{B(DID)}=\\Delta^{y}_{DID}-\\Delta^{y}_{TT}=\\) \\(\\esp{y^0_{i}|D_i=1} - \\esp{y^B_{i}|D_i=1}-(\\esp{y^0_{i}|D_i=0} - \\esp{y^B_{i}|D_i=0})\\). Let us derive \\(\\Delta^{y}_{B(DID)}\\) in our example. Let us compute the trend in potential outcomes among the treated: \\[\\begin{align*} \\esp{y^0_{i,A}|D_i=1} &amp; - \\esp{y^0_{i,B}|D_i=1} \\\\ &amp; = \\esp{y^0_{i}|D_i=1} - \\esp{y^B_{i}|D_i=1} \\\\ &amp; = \\esp{\\mu_i+\\delta+U_i^0|D_i=1}-\\esp{\\mu_i+U_i^B|D_i=1} \\\\ &amp; = \\esp{\\mu_i|D_i=1}+\\delta+\\esp{U_i^0|D_i=1}\\\\ &amp; \\phantom{=}-\\esp{\\mu_i|D_i=1}-\\esp{U_i^B|D_i=1} \\\\ &amp; = \\delta + \\esp{\\rho U_i^B+\\epsilon_i|D_i=1}-\\esp{U_i^B|D_i=1}\\\\ &amp; = \\delta -(1-\\rho)\\esp{U_i^B|D_i=1}. \\end{align*}\\] Following the same line of reasoning, the trend in potential outcomes among the untreated is: \\[\\begin{align*} \\esp{y^0_{i}|D_i=0} - \\esp{y^B_{i}|D_i=0} &amp; = \\delta -(1-\\rho)\\esp{U_i^B|D_i=0}. \\end{align*}\\] As a consequence, the bias of the DID estimator in our model is: \\[\\begin{align*} \\Delta^{y}_{B(DID)} &amp; = -(1-\\rho)(\\esp{U_i^B|D_i=1}-\\esp{U_i^B|D_i=0}) \\\\ &amp; = -(1-\\rho)(\\esp{U_i^B|\\mu_i+U_i^B+V_i\\leq\\bar{y}}-\\esp{U_i^B|\\mu_i+U_i^B+V_i&gt;\\bar{y}}) \\end{align*}\\] Is this zero? The answer actually is that it is not. In order to see why, notice intuitively that the conditional expectation of \\(U_i^B\\) is taken conditional on something correlated with \\(U_i^B\\) being above or below some threshold. As a consequence, the two values whose difference is taken in the parenthesis cannot be equal. More formally, let us derive the formula for the bias of the DID estimator in our model, using the formula for the expectation of a truncated bivariate normal distribution: \\[\\begin{align*} \\Delta^{y}_{B(DID)} &amp; = -(1-\\rho)(\\esp{U_i^B|\\mu_i+U_i^B+V_i\\leq\\bar{y}}-\\esp{U_i^B|\\mu_i+U_i^B+V_i&gt;\\bar{y}}) \\\\ &amp; = (1-\\rho)\\left(\\frac{\\sigma^2_U}{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}\\right) \\left(\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}\\right)} {\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}\\right)} +\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}\\right)} {1-\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{(1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega}}\\right)} \\right) \\end{align*}\\] In order to compute the value of this parameter, and of the average treatment effect, we are going to use the package tmtvnorm which provides the moments from a truncated multivariate normal variable. Here, we use the distribution of \\((\\alpha_i,U_i^B,\\mu_i+U_i^B+V_i)\\) which is normal with mean \\((\\bar{\\alpha}+\\theta\\bar{\\mu},0,\\bar{\\mu})\\) and covariance matrix \\(\\mathbf{D}\\) with: \\[\\begin{align*} \\mathbf{D} &amp;= \\left(\\begin{array}{ccc} \\theta^2\\sigma^2_{\\mu}+ \\sigma^2_{\\eta} &amp; 0 &amp; (\\theta+\\gamma\\theta)\\sigma^2_{\\mu}+\\rho_{\\eta,\\omega}\\sigma_{\\eta}\\sigma_{\\omega}\\\\ 0 &amp; \\sigma^2_U &amp; \\sigma^2_U \\\\ (\\theta+\\gamma\\theta)\\sigma^2_{\\mu}+\\rho_{\\eta,\\omega}\\sigma_{\\eta}\\sigma_{\\omega}&amp; \\sigma^2_U &amp; (1+\\gamma^2)\\sigma^2_{\\mu}+\\sigma^2_U+\\sigma^2_{\\omega} \\end{array}\\right) \\end{align*}\\] mean.alpha.UB.yBV &lt;- c(param[&#39;baralpha&#39;]+param[&#39;barmu&#39;]*param[&#39;theta&#39;],0,param[&#39;barmu&#39;]) cov.alpha.UB.yBV &lt;- matrix(c(param[&#39;theta&#39;]^2*param[&#39;sigma2mu&#39;]+param[&#39;sigma2eta&#39;], 0, (param[&#39;theta&#39;]+param[&#39;gamma&#39;]*param[&#39;theta&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], 0, param[&#39;sigma2U&#39;], param[&#39;sigma2U&#39;], (param[&#39;theta&#39;]+param[&#39;gamma&#39;]*param[&#39;theta&#39;])*param[&#39;sigma2mu&#39;]+param[&#39;rhoetaomega&#39;]*param[&#39;sigma2eta&#39;]*param[&#39;sigma2omega&#39;], param[&#39;sigma2U&#39;], (1+param[&#39;gamma&#39;]^2)*param[&#39;sigma2mu&#39;]+param[&#39;sigma2U&#39;]+param[&#39;sigma2omega&#39;]),3,3,byrow=TRUE) # cuts #non participants lower.cut.D0 &lt;- c(-Inf,-Inf,log(param[&#39;barY&#39;])) upper.cut.D0 &lt;- c(Inf,Inf,Inf) # participants lower.cut.D1 &lt;- c(-Inf,-Inf,-Inf) upper.cut.D1 &lt;- c(Inf,Inf,log(param[&#39;barY&#39;])) # means TT.pop &lt;- mtmvnorm(mean=mean.alpha.UB.yBV,sigma=cov.alpha.UB.yBV,lower=lower.cut.D1,upper=upper.cut.D1,doComputeVariance=FALSE)[[1]][[1]] mean.UB.D0 &lt;- mtmvnorm(mean=mean.alpha.UB.yBV,sigma=cov.alpha.UB.yBV,lower=lower.cut.D0,upper=upper.cut.D0,doComputeVariance=FALSE)[[1]][[2]] mean.UB.D1 &lt;- mtmvnorm(mean=mean.alpha.UB.yBV,sigma=cov.alpha.UB.yBV,lower=lower.cut.D1,upper=upper.cut.D1,doComputeVariance=FALSE)[[1]][[2]] B.DID &lt;- -(1-param[&#39;rho&#39;])*(mean.UB.D1-mean.UB.D0) In our example, the population \\(TT\\) is equal to \\(\\Delta^y_{TT}=\\) 0.173. The DID estimator is equal to \\(\\Delta^y_{DID}=\\) 0.211. As a consequence, the bias of the DID estimator is equal to \\(\\Delta^y_{B(DID)}=\\) 0.046. In order to make the DID estimator consistent for the \\(TT\\) parameter, we need to impose that \\(\\rho=1\\). When shocks are permanent, their bias remains constant over time and thus DID can estimate it without error. Let us generate new data that are compatible with that assumption. set.seed(1234) N &lt;-1000 param[&quot;rho&quot;] &lt;- 1 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta.omega$eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let’s see how DID works on this data. Figure 4.18: Evolution of average outcomes in the treated and control group when the Parallel Trends Assumption holds Now, the counterfactual change in outcome for the treated and its approximation using the trend experienced by the untreated are extremely close, as the curves Treated counterfactual and Treated DID show on Figure 4.18. 4.3.1.2 Estimation Estimation of \\(TT\\) under the \\(DID\\) assumptions can be performed in a variety of ways: using directly the DID formula, using OLS with group fixed effects, using OLS with individual and time dummy variables, using first differences and using the within transformation (also known as the Two-Way Fixed Effects or TWFE estimator). With only two periods of data and a fully balanced panel, all of these estimators are actually numerically equivalent. Let’s examine them in turn. 4.3.1.2.1 Using the DID formula One could go directly and use the DID formula of Theorem 4.9. The sample DID estimator is thus equal to: \\[\\begin{align*} \\hat{\\Delta}^Y_{DID} &amp; = \\frac{\\sum_{i=1}^NY_{i,A}D_i}{\\sum_{i=1}^ND_i} -\\frac{\\sum_{i=1}^NY_{i,B}D_i}{\\sum_{i=1}^ND_i} - \\left(\\frac{\\sum_{i=1}^NY_{i,A}(1-D_i)}{\\sum_{i=1}^N(1-D_i)} -\\frac{\\sum_{i=1}^NY_{i,B}(1-D_i)}{\\sum_{i=1}^N(1-D_i)}\\right). \\end{align*}\\] Example 4.27 In our example, let’s see how this estimator works. The Before/After comparison among the participants is equal to \\(\\hat{\\Delta}^{y}_{BA|D=1}=\\) 0.218. The Before/After comparison among the non-participants is equal to \\(\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.057. The DID estimator is thus equal to \\(\\hat{\\Delta}^{y}_{DID}=\\hat{\\Delta}^{y}_{BA|D=1}-\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.218 \\(-\\) 0.057 \\(=\\) 0.161. It is also equal to the difference between the before and after With/Without estimators. The Before With/Without estimator is equal to \\(\\hat{\\Delta}^{y^B}_{WW}=\\) -1.361. The After With/Without estimator is equal to \\(\\hat{\\Delta}^{y}_{WW}=\\) -1.2. The DID estimator is thus equal to \\(\\hat{\\Delta}^{y}_{DID}=\\hat{\\Delta}^{y}_{WW}-\\hat{\\Delta}^{y^B}_{WW}=\\) -1.2 \\(-(\\) -1.361 \\()=\\) 0.161. This is not too far from the true effect of the treatment in the sample which is equal to \\(\\hat{\\Delta}^{y}_{TT}=\\) 0.165. In the population, the \\(TT\\) parameter has not changed, since its computation does not involve \\(\\rho\\). We still have \\(\\Delta^y_{TT}=\\) 0.173. 4.3.1.2.2 Using the Least Squares pooling DID estimator The most basic regression-based way to implement DID is to run a linear regression of outcomes on a treatment group dummy, a time dummy and their interaction. The interaction captures the effect of the treatment estimated using DID. The way it works is as follows: estimate the following equation using OLS and use \\(\\hat{\\beta}_{OLS}\\) as your DID estimate: \\(\\hat{\\beta}_{OLS}=\\hat{\\Delta}^{Y}_{DID}\\). \\[\\begin{align*} Y_i &amp; = \\alpha + \\mu D_i + \\delta T_i + \\beta D_iT_i + \\epsilon_i. \\end{align*}\\] \\(D_i\\) is our usual treatment indicator while \\(T_i\\) takes value one when observation \\(i\\) is observed in the After and zero otherwise. Example 4.28 Let’s see how this works in our example. Before estimating the model, we need to build a data frame with all the necessary variables. # building a data frame data.DID &lt;- as.data.frame(cbind(c(y,yB),c(Ds,Ds),c(rep(1,N),rep(0,N)))) colnames(data.DID) &lt;- c(&#39;y&#39;,&#39;D&#39;,&#39;T&#39;) # running the OLS regression reg.DID &lt;- lm(y ~ D + T + D*T,data = data.DID) # coefficients yB.D0.reg &lt;- coef(reg.DID)[[1]] WW.before.reg &lt;- coef(reg.DID)[[2]] BA.untreated.reg &lt;- coef(reg.DID)[[3]] DID.est.reg &lt;- coef(reg.DID)[[4]] # comparisons yB.D0.sample &lt;- mean(yB[Ds==0]) The estimate of \\(\\hat{\\beta}_{OLS}\\) in our sample is equal to 0.161. It is exactly equal to \\(\\hat{\\Delta}^{y}_{DID}\\) as estimated just above. What is interesting with the regression-based DID approach is that the other coefficients in the regression have a direct interpretation. For example, the constant \\(\\alpha\\) estimates the mean outcome in the untreated group before the treatment. In our case, we have \\(\\hat{\\alpha}_OLS=\\) 8.36. Remember that in our sample, the average outcomes of the untreated before the treatment is equal to \\(\\hatesp{y_i^B|D_i=0}=\\) 8.36. \\(\\mu\\), the coefficient in front of the \\(D_i\\) dummy, estimates the With/Without estimator before the treatment. In our case, we have \\(\\hat{\\mu}_{OLS}=\\) -1.361. Remember that in our sample, the With/Without estimator before the treatment is equal to \\(\\hat{\\Delta}^{y^B}_{WW}=\\) -1.361. \\(\\delta\\), the coefficient in front of the \\(T_i\\) dummy, estimates the Before/After change in outcomes among the untreated. In our case, we have \\(\\hat{\\delta}_{OLS}=\\) 0.057. Remember that in our sample, the Before/After estimator among the untreated is equal to \\(\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.057. Remark. A pretty cool property of the regression-based DID estimator is that is does not require panel data. It works even with repeated cross sections, i.e. when observations are drawn from the same population in both periods but are not the same. 4.3.1.2.3 Using First Differences In the presence of panel data, an alternative to the regression-based DID estimator is the first-difference estimator. It simply regresses the change over time in outcomes on the treatment dummy: \\[\\begin{align*} Y_{i,A}-Y_{i,B} &amp; = \\alpha^{FD} + \\beta^{FD} D_i + \\epsilon^{FD}_i. \\end{align*}\\] The coefficient \\(\\beta^{FD}\\) estimated by OLS is an estimate of the DID parameter. Example 4.29 Let’s see how this works in our example. Before running the model, we need to generate first the differenced estimates. One very simple way to do that is simply to take the difference between the before and the after outcome vectors. # building a data frame data.FD &lt;- as.data.frame(cbind(y-yB,Ds)) colnames(data.FD) &lt;- c(&#39;BAy&#39;,&#39;D&#39;) # running the OLS regression reg.FD &lt;- lm(BAy ~ D,data = data.FD) # coefficients BA.untreated.FD &lt;- coef(reg.FD)[[1]] DID.est.FD &lt;- coef(reg.FD)[[2]] The estimate of \\(\\hat{\\beta}^{FD}_{OLS}\\) in our sample is equal to 0.161. It is exactly equal to \\(\\hat{\\Delta}^{y}_{DID}\\) as estimated just above. Note also that \\(\\alpha^{FD}\\) estimates the Before/After change in outcomes among the untreated. In our case, we have \\(\\hat{\\alpha}^{FD}_{OLS}=\\) 0.057. Remember that in our sample, the Before/After estimator among the untreated is equal to \\(\\hat{\\Delta}^{y}_{BA|D=0}=\\) 0.057. 4.3.1.2.4 Using the Least Squares Dummy Variables estimator One very computer-intensive way to estimate \\(TT\\) in a DID setting is to use the OLS estimator supplemented with dummies for each observation and for each time period, also called the Least-Squares Dummy Variables estimator. In practice, the estimator is based on the following regression: \\[\\begin{align*} Y_{i,t} &amp; = \\sum_{j=1}^N\\mu_j\\uns{j=i} + \\sum_{l=0}^1\\delta_l\\uns{l=t} + \\beta^{LSDV} D_{i,t} + \\epsilon^{LSDV}_{i,t}. \\end{align*}\\] The notation is generally simplified as follows: \\[\\begin{align*} Y_{i,t} &amp; = \\mu_i + \\delta_t + \\beta^{TWFE} D_{i,t} + \\epsilon^{TWFE}_{i,t}, \\end{align*}\\] This last estimator is generally called the Two-Way Fixed Effects estimator, since it has two-sets of so-called fixed effects (individual fixed effects, \\(\\mu_i\\), and time fixed effects \\(\\delta_t\\)). I will write it using this second, more compact, formulation, but I think the first formulation encapsulates better how the Least-Squares Dummy Variables estimator works. In what follows, we will see other ways of estimating the Two-Way Fixed Effects model, but for now, let us focus on the Least-Squares Dummy Variables estimator. The way it works is simply by throwing a bunch of dummy variables in the regression. Example 4.30 Let’s see how the Least Squares Dummy Variable works in our example. For that, we need to generate one dummy variable for each individual \\(i\\) in our sample. This is made simple by the factor function in R. We are also going to run the model without a constant, so that all the fixed effects are identified. # adding one column to the DID data frame with the individual index for each observation of the same $i$ data.DID$indiv &lt;- as.factor(c(1:N,1:N)) # generating Dit (time varying) data.DID$Dit &lt;- data.DID$D*data.DID$T # running the LSDV estimator reg.LSDV &lt;- lm(y~-1 + Dit + as.factor(T) + indiv,data=data.DID) # result DID.est.LSDV &lt;- coef(reg.LSDV)[[1]] The Least-Squares Dummy Variables estimate of \\(TT\\) is equal to: \\(\\hat{\\beta}^{LSDV}=\\) 0.161. Remark. The term fixed effect is specific to the panel data literature in econometrics. It refers to the fact that both \\(\\mu_i\\) and \\(\\delta_t\\) are allowed to be correlated with \\(D_{i,t}\\) in this model. This is in contrast to the random effects model where \\(\\mu_i\\) and \\(\\delta_t\\) are assumed to be independent of the regressors of interest. 4.3.1.2.5 Using the Within estimator You might have noticed that the Least-Squares Dummy Variables estimator took some time to compute on your computer. This is because it requires the inversion of a very large matrix, as large as the number of fixed effects plus one. The size of this computation increases as the number of observation and time periods increases, meaning that this computation might become practically unfeasible in very large datasets. Several tricks have been developed to decrease the computational burden of the estimation of the Two-Way Fixed Effects model. One approach is to use the First Difference estimator. Another approach is the Within estimator. The way the Within estimator works is by taking the difference between each observation and its mean over time or over individuals. More precisely, the Within estimator estimates the following model by OLS: \\[\\begin{align*} Y_{i,t}-\\frac{1}{2}\\sum_{t=0}^1Y_{i,t} &amp; = \\delta^{W}_t + \\beta^{W}(D_{i,t}-\\frac{1}{2}\\sum_{t=0}^1D_{i,t}) + \\epsilon^{W}_{i,t}. \\end{align*}\\] The reason why this trick works is because of the shape of the Two-Way Fixed Effects model. Indeed, taking the average of the Two-Way Fixed Effects model over time gives: \\[\\begin{align*} \\frac{1}{2}\\sum_{t=0}^1Y_{i,t} &amp; = \\mu_i + \\frac{1}{2}\\sum_{t=0}^1\\delta_t + \\beta^{TWFE}\\frac{1}{2}\\sum_{t=0}^1D_{i,t} + \\frac{1}{2}\\sum_{t=0}^1\\epsilon^{TWFE}_{i,t}. \\end{align*}\\] Taking the difference between the Two-Way Fixed Effects model and its time-averaged version gives the Within estimator. The key is that the differencing gets rid of the individual fixed effects parameter \\(\\mu_i\\) and thus makes it unnecessary to estimate it. The set of parameters to estimate is thus much smaller than in the Least-Squares Dummy Variables estimator. Example 4.31 Let’s see how the Within estimator works in our example. For that, we need to compute the average over time of the outcome and of the treatment for each observation in our dataset. This is made simple by the summarize function of the dplyr package. # generating the time means of Y and Dit TimeMeansYDit &lt;- data.DID %&gt;% group_by(indiv) %&gt;% summarize( TimeMeanY = mean(y), TimeMeanDit = mean(Dit) ) # doubling the observations to be able to take the difference in both periods TimeMeansYDit &lt;- rbind(TimeMeansYDit,TimeMeansYDit) # taking the difference in both periods data.DID$W.y &lt;- data.DID$y-TimeMeansYDit$TimeMeanY data.DID$W.Dit &lt;- data.DID$Dit-TimeMeansYDit$TimeMeanDit # running the within estimator reg.W &lt;- lm(W.y~-1 + W.Dit + as.factor(T),data=data.DID) # result DID.est.W &lt;- coef(reg.W)[[1]] The Within estimate of \\(TT\\) is equal to: \\(\\hat{\\beta}^{W}=\\) 0.161. The plm package directly implements the Within transformation. The same package also estimates the First Difference model and the Least Squares pooling DID estimator. Let’s see how this works. # running the within estimator reg.W.plm &lt;- plm(y ~ Dit + as.factor(T) , data = data.DID, index= c(&quot;indiv&quot;, &quot;T&quot;), model = &quot;within&quot;) # result DID.est.W.plm &lt;- coef(reg.W.plm)[[1]] # running the first difference estimator reg.FD.plm &lt;- plm(y ~ Dit + as.factor(T) , data = data.DID, index= c(&quot;indiv&quot;, &quot;T&quot;), model = &quot;fd&quot;) # result DID.est.FD.plm &lt;- coef(reg.FD.plm)[[2]] # running the OLS pooling DID estimator reg.OLS.plm &lt;- plm(y ~ as.factor(T) + D + Dit , data = data.DID, index= c(&quot;indiv&quot;, &quot;T&quot;), model = &quot;pooling&quot;) # result DID.est.OLS.plm &lt;- coef(reg.OLS.plm)[[4]] As expected, plm gives the following estimates for \\(TT\\): \\(\\hat{\\beta}^{W}=\\) 0.161, \\(\\hat{\\beta}^{FD}=\\) 0.161 and \\(\\hat{\\beta}^{OLS}=\\) 0.161. 4.3.1.2.6 Using fast estimators of the Two-Way Fixed Effects model All the estimators of the TWFE model that we have seen so far have issues. The OLS pooling DID estimator does not account for the panel structure of the data when it exists. It does not alter the precision of the estimator but it makes it mode difficult to account for more dimensions of fixed effects than two. The First Difference estimator, similarly, cannot easily account for more than two sets of fixed effects. The Least Squares Dummy variable is slow because of the very large matrix inversion problem. Therefore, applied econometricians tend to prefer using the Within estimator in practice. The Within estimtor of the Two-Way Fixed Effects model is not without problems as well. As the sample size grows large, or the number of fixed effects increases, it becomes more and more difficult to compute the within transformation. As a consequence, recent packages have proposed to optimize the computation of the TWFE model using various computational tricks. Let’s examine two in turn. 4.3.1.2.6.1 The Alternating Projections method The lfe package in R implements an alternating projections method to estimate the \\(N\\)-Way Fixed effects model. It is based on an algorithm proposed by Gaure (2013). The basic idea of Gaure (2013) is to repeat centering on the means of the fixed effects (the within operation) in an alternating manner between the various fixed effects dimensions until convergence. Example 4.32 Let’s see how the lfe estimator works in our example. # running the within estimator reg.W.lfe &lt;- felm(y ~ Dit + as.factor(T) | indiv , data = data.DID) # result DID.est.W.lfe &lt;- coef(reg.W.lfe)[[1]] As expected, lfe gives the following estimate for \\(TT\\): \\(\\hat{\\beta}^{AP}=\\) 0.161. 4.3.1.2.6.2 The Likelihood Concentration method One problem with the lfe package is that it works only for linear models. The fixest package in R proposes a solution for estimating fixed effects models in non-linear cases as well. The solution is based on the concentrated likelihood as explained in Berge (2018). The intuition is as follows. We first postulate a value for the treatment effect and the coefficient on the time dummies and we estimate each of the individual fixed effects using maximum likelihood. We then use maximum likelihood to find the treatment effect using the values of the fixed effects estimated in the previous step. This seems complicated but the key idea is to separate the estimation of the fixed effects from the estimation of the parameters of interest. Example 4.33 Let’s see how the fixest estimator works in our example. # running the within estimator reg.W.fixest &lt;- feols(y ~ Dit + as.factor(T) | indiv , data = data.DID) # result DID.est.W.fixest &lt;- coef(reg.W.fixest)[[1]] As expected, fixest gives the following estimate for \\(TT\\): \\(\\hat{\\beta}^{LC}=\\) 0.161. 4.3.1.2.7 Equivalence between the various DID methods with two time periods The above results suggest that all DID estimators are equivalent when working with two time periods. The following theorem actually states this result rigorously: Theorem 4.10 (All DID estimators are numerically equivalent with two time periods) Under Assumptions 4.12, 4.13 and 4.14, in a panel with only two periods of data, all the DID estimators are numerically equivalent: \\(\\hat{\\beta}^{OLS}=\\hat{\\beta}^{FD}=\\hat{\\beta}^{W}=\\hat{\\beta}^{LSDV}=\\hat{\\beta}^{AP}=\\hat{\\beta}^{LC}=\\hat{\\Delta}^Y_{DID}\\). Proof. See Section A.3.1. A corollary to Theorem 4.10 shows that the coefficients in the Least Squares Pooling DID estimator all estimate some relevant parameters that help make sense of the DID estimator: Corollary 4.2 (Coefficients in the OLS DID model) Under Assumptions 4.12, 4.13 and 4.14, in a panel with only two periods of data, the coefficients of the Least Squares pooling DID estimator are: \\[\\begin{align*} \\hat{\\alpha}^{OLS} &amp; = \\bar{Y}^0_B \\\\ \\hat{\\mu}^{OLS} &amp; = \\bar{Y}^1_B-\\bar{Y}^0_B\\\\ \\hat{\\delta}^{OLS} &amp; = \\bar{Y}^0_A-\\bar{Y}^0_B \\\\ \\hat{\\beta}^{OLS} &amp; = \\bar{Y}^1_A-\\bar{Y}^1_B-(\\bar{Y}^0_A-\\bar{Y}^0_B), \\end{align*}\\] with \\(\\bar{Y}^d_t=\\frac{\\sum_{i=1}^NY_{i,t}\\uns{D_i=d}}{\\sum_{i=1}^N\\uns{D_i=d}}\\). Proof. See Section A.3.1, the proof for the OLS DID estimator. Corollary 4.2 shows that the constant in the OLS DID model \\(\\hat{\\alpha}^{OLS}\\) estimates the average outcome for the untreated group in the period before the treatment date; the coefficient on the group dummy \\(D_i\\) \\(\\hat{\\mu}^{OLS}\\) estimates the difference between the average outcome for the treated group and the average outcome in the untreated group in the period before the treatment takes place; the coefficient on the time dummy \\(T_i\\) \\(\\hat{\\delta}^{OLS}\\) estimates the difference in average outcomes in the untreated group before and after the treatment takes place. These coefficients are useful to udenrstand how the DID estimator is formed. They can also be used to plot the trajectory of the mean outcomes in each group over time to make a visual impression of how DID works. Finally, let’s see how our estimator varies across sampling replications. A key difference is whether we have access to panel data or not. Indeed, estimates from a repeated cross section are going to be more noisy since they are going to sample different people in different periods and thus are going to be affected by sampling noise stemming from the fixed effects. This is not going to be the case with panel data, since all the estimators based on the TWFE estimator differentiate out the individual fixed effects. Example 4.34 Let’s first start with the case of panel data: # let us write a function that generates a DID estimate out of each sample of a given size monte.carlo.did.panel &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) delta.y.did &lt;- mean(y[Ds==1])-mean(y[Ds==0])-(mean(yB[Ds==1])-mean(yB[Ds==0])) return(delta.y.did) } simuls.did.panel.N &lt;- function(N,Nsim,param){ simuls.did.panel &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.did.panel,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.did.panel) &lt;- c(&#39;DID&#39;) return(simuls.did.panel) } sf.simuls.did.panel.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.did.panel,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;DID&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.did.panel &lt;- lapply(N.sample,sf.simuls.did.panel.N,Nsim=Nsim,param=param) names(simuls.did.panel) &lt;- N.sample Let us now plot the results of the simulations: par(mfrow=c(2,2)) for (i in 1:length(simuls.did.panel)){ hist(simuls.did.panel[[i]][,&#39;DID&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yDID)),xlim=c(-0.15,0.55)) abline(v=TT.pop,col=&quot;red&quot;) } Figure 4.19: Distribution of the DID estimator over replications of panels of different sizes Figure 4.19 shows that the DID estimator converges pretty fast to the true treatment effect as sample size grows large. Let us now wee what happens with a repeated cross section: monte.carlo.did.cross &lt;- function(s,N,param){ N.tot &lt;- 2*N set.seed(s) mu &lt;- rnorm(N.tot,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N.tot) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) # first cross section: 1-N first &lt;- seq(1,N) # second cross section: 1001-2000 second &lt;- seq(N+1,N.tot) # repeated cross section DID delta.y.did.cross &lt;- mean(y[second][Ds[second]==1])-mean(y[second][Ds[second]==0])-(mean(yB[first][Ds[first]==1])-mean(yB[first][Ds[first]==0])) return(delta.y.did.cross) } simuls.did.cross.N &lt;- function(N,Nsim,param){ simuls.did.cross &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.did.cross,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.did.cross) &lt;- c(&#39;DID&#39;) return(simuls.did.cross) } sf.simuls.did.cross.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.did.cross,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;DID&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.did.cross &lt;- lapply(N.sample,sf.simuls.did.cross.N,Nsim=Nsim,param=param) names(simuls.did.cross) &lt;- N.sample Let us now plot the results: par(mfrow=c(2,2)) for (i in 1:length(simuls.did.cross)){ hist(simuls.did.cross[[i]][,&#39;DID&#39;],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yDID)),xlim=c(-0.15,0.55)) abline(v=TT.pop,col=&quot;red&quot;) } Figure 4.20: Distribution of the DID estimator over replications of repeated cross sections of different sizes Relative to Figure 4.19, Figure 4.20 shows that sampling noise is larger at each sample size with a repeated cross section estimator. Let’s see how we can estimate these below using the Central Limit Theorem. 4.3.1.3 Estimation of sampling noise It is especially important to understand the properties of sampling noise for treatment effect estimators in DID designs because it can serve as a basis for power analysis, but also to understand the sources of improvements or loss of precision when moving from the simple with/without comparison to the DID estimator. Let us first look at the sampling noise of the simpler \\(2\\times 2\\) DID estimator in a panel data with only two time periods. We will then move to the sampling noise of the simpler \\(2\\times 2\\) DID estimator in a repeated cross section. 4.3.1.3.1 Estimating sampling noise in panel settings When we estimate DID in a panel of two time periods, Theorem 4.10 shows that all possible DID estimators are equivalent. We can thus use the most convenient one in order to derive the Central Limit Theorem-based approximation to its distribution, and use it to estimate sampling noise. The most convenient estimator, to me, is the First Difference estimator. We indeed know that it is formulated as an OLS estimator, regressing the change in outcomes over time to the treatment dummy. The First Difference estimator is thus simply a With/Without estimator where the outcomes are replaced by the changes in outcomes over time. And we already know how to derive an Central Limit Theorem-based estimate of the sampling noise of the With/Without estimator. In order to use these results, we need some assumptions: Hypothesis 4.15 (i.i.d. sampling in First Difference) We assume that the observations in the sample are identically and independently distributed in First Differences: \\[\\begin{align*} \\forall i,j\\leq N\\text{, }i\\neq j\\text{, } &amp; (Y_{i,A}-Y_{i,B},D_i)\\Ind(Y_{j,A}-Y_{j,B},D_j),\\\\ &amp; (Y_{i,A}-Y_{i,B},D_i)\\&amp;(Y_{j,A}-Y_{j,B},D_j)\\sim F_{Y_A-Y_B,D}. \\end{align*}\\] Assumption 4.15 imposes that the changes in outcome over time are not correlated across units. This is not a strong assumption. It is actually much weaker than imposing that the levels of outcomes are distributed i.i.d. in the sample. That would require that the outcomes of the same unit are not correlated over time, which is wrong if there are unit fixed effects \\(\\mu_i\\) or if the error terms are correlated across time (which is possible if shocks are persistent). Assumption 4.15 rules out spatial correlation between units, be it in the changes in outcomes or in receiving the treatment. This is very restrictive. We also need to assume that the changes in outcomes in both groups have finite variances: Hypothesis 4.16 (Finite variance of $\\hat{\\Delta^Y_{WW}}$) We assume that \\(\\var{Y^1_A-Y^0_B|D_i=1}\\) and \\(\\var{Y^0_A-Y^0_B|D_i=0}\\) are finite. We now can state the following theorem: Theorem 4.11 (Asymptotic Distribution of the DID Estimator in Panel Data) Under Assumptions 4.12, 4.13, 4.14, 4.15 and 4.16, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{DID}-\\Delta^Y_{DID}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y_{i,A}^1-Y_{i,B}^0|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_{i,A}^0-Y_{i,B}^0|D_i=0}}{1-\\Pr(D_i=1)}\\right). \\end{align*}\\] Proof. Under Assumptions 4.12, 4.13, 4.14, Theorem 4.10 proves that \\(\\hat{\\Delta}^Y_{DID}=\\hat{\\beta}^{FD}\\). \\(\\hat{\\beta}^{FD}\\) is obtained as the OLS estimator of the coefficient in front of \\(D_i\\) in a regression of \\(Y_{i,A}-Y_{i,B}\\) on \\(D_i\\) and a constant. Lemma A.3 shows that, in such a regression, this coefficient is also a WW estimator, so that \\(\\hat{\\beta}^{FD}=\\hat{\\Delta}^{Y_{A}-Y_{B}}_{WW}\\). Using Theorem 2.5 proves the result. Theorem 4.11 shows that the precision of the DID estimator in panel settings depends on the variance of the changes in outcomes over time in the treated and control group. Since outcomes for a given individual are generally correlated over time, the variance of the DID estimator will in general be lower than the variance of the WW estimator. A case in point is when there are individual fixed effects in the equation generating outcomes: in that case, differencing outcomes over time gets rid of the individual fixed effects and thus the variance of the differences out outcomes is lower than the variance of outcomes in levels, since it misses the part due to the individual fixed effects. So, in most cases (but not all of them), we can expect an increase in precision when moving from WW to DID. Example 4.35 Let’s see how our estimator of sampling noise performs in the data. The true level of 99% sampling noise in the \\(N=\\) 1000 sample is estimated from the simulations to be equal to 0.12, while the estimated level of 99% sampling noise using the formula from Theorem 4.11 is equal to 0.1. The estimated level of 99% sampling noise obtained using the heteroskedasticity robust standard errors from the First Difference regression using OLS is equal to 0.11. The estimated level of 99% sampling noise obtained using the heteroskedasticity robust standard errors from the DID regression using OLS is equal to 0.34. It is much larger, because it assumes that we only have access to a repeated cross section, and thus it does not take into account the fact that we have more precision thanks to the panel data. The estimated level of 99% sampling noise obtained using the heteroskedasticity robust standard errors from the Within regression using OLS is equal to 0.08. The plm package corrects all standard errors for the panel nature of the data (irrespective of the type of estimator), and thus returns an estimate of 99% sampling noise equal to 0.11 for the Within estimator, 0.11 for the First Difference estimator and 0.11 for the pooled DID estimator. Neither lfe nor fixest seem compatible with vcovHC, which enables the estimation of heteroskedasticity-robust standard errors. The lfe package seems not to take into account heteroskedasticity by default: its estimate of 99% sampling noise is equal to 0.1. The fixest package seems to take into account heteroskedasticity by default: its estimate of 99% sampling noise is equal to 0.11. 4.3.1.3.2 Estimating sampling noise in repeated cross sections When we do not have access to panel data, a lot of the estimators we have studied here are infeasible. This is the case of the First Difference estimator (we cannot build the difference in out comes over time for the same unit since we observe each unit only once). The Within estimator is also compromised (we cannot build the average outcome over time for each observation, since, again, we only observe each observation only once). The Least Squares Dummy Variables estimator is also infeasible, for the same reason: we need to observe each observation at least twice in order for the treatment dummy to not be collinear with the unit and time fixed effects. But, both the basic DID formula and the Least Squares pooling estimator can still be computed with repeated cross sections. As Figure 4.20 has shown, the DID estimator is much more variable in repeated cross section: the level of 99% sampling noise in the \\(N=\\) 1000 sample is estimated from the simulations to be equal to 0.28, while it is of 0.12 with panel data of the same size. Let’s see how the Central-Limit Theorem can help us estimate this variance and shed some light on why we lose so much precision when moving from panel to cross section estimators. It is unfortunately much more work to derive the CLT-based estimate of sampling noise with repeated cross-sections than with panel data. We first need to respecify an i.i.d. assumption adapted to repeated cross sections: Hypothesis 4.17 (i.i.d. sampling in Repeated Cross Sections) We assume that the observations in the sample are identically and independently distributed: \\[\\begin{align*} \\forall i,j\\leq N_t\\text{, }i\\neq j\\text{, }, \\forall t,t&#39;\\in\\{A,B\\}\\text{, }t\\neq t&#39;\\text{, } &amp; (Y_{i,t},D_i)\\Ind(Y_{j,t&#39;},D_j),\\\\ &amp; (Y_{i,t},D_i)\\&amp;(Y_{j,t&#39;},D_j)\\sim F_{Y,D}. \\end{align*}\\] Assumption 4.17 imposes that outcomes are not correlated across units nor across time. This is not a strong assumption in a repeated cross section, as long as the same units are not observed at both periods. We now can state the following theorem: Theorem 4.12 (Asymptotic Distribution of the DID Estimator in Repeated Cross Sections) Under Assumptions 4.12, 4.13, 4.14, 4.17 and 2.3, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{DID}-\\Delta^Y_{DID}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y^0_{i,B}|D_i=0}}{(1-p)(1-p_A)} +\\frac{\\var{Y^0_{i,B}|D_i=1}}{p(1-p_A)}\\right.\\\\ &amp; \\phantom{\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(0,\\right.} \\left. +\\frac{\\var{Y^0_{i,A}|D_i=0}}{(1-p)p_A} +\\frac{\\var{Y^1_{i,A}|D_i=1}}{pp_A}\\right). \\end{align*}\\] where \\(p=\\Pr(D_i=1)\\) and \\(p_A\\) is the proportion of observations belonging to the After period. Proof. See Section A.3.2. Remark. Note that the difference between the amount of sampling noise of the DID estimator in panel data in repeated cross sections is present whatever the estimator (in panel data, all the estimators are equivalent). It is not differencing or taking the within transformation that gets rid of sampling noise, it is collecting data on the same observations twice. Differencing only helps the OLS estimator of the standard errors to understand that we have panel data and to reflect it in its estimate of precision. The DID estimator is always more precise in panel data (in our example). The CLT-based estimator of precision does not always reflect that fact, because we have not correctly specified it. Example 4.36 Let’s see how our estimator of sampling noise performs in the data. The true level of 99% sampling noise in the \\(N=\\) 1000 sample is estimated from the simulations to be equal to 0.28, while the estimated level of 99% sampling noise using the formula from Theorem 4.12 is equal to 0.34. The estimated level of 99% sampling noise obtained using the heteroskedasticity robust standard errors from the DID regression using OLS is equal to 0.34. 4.3.2 Reverse Difference In Differences designs with two time periods Before getting into the general case of DID with several time periods and several treatment dates, it is useful to quickly look at identification in the case of reverse DID designs. We are going to look at two such designs. In the first type, some units are exposed to the treatment in the first period and the rest of the units enter the treatment in the second period. In the second type of reverse DID design, all units receive the treatment in the first period and some units exit the treatment in the second period. 4.3.2.1 Reverse DID designs where everyone enters the treatment at the second period Compared to the setting in the previous section, the main change is to Assumption 4.12: Hypothesis 4.18 (Everyone Receives Treatment in the Second Period) We assume that every unit in the population receives the treatment in the second period: \\(D_{i,A}=1\\), \\(\\forall i\\). Under Assumption 4.18, and without loss of generality, we can write \\(D_i=D_{i,B}\\), \\(\\forall i\\). We are going to call the units which stay in the treatment during the two periods always takers and the units who enter the treatment in the second period switchers. Always takers are defined by \\(D_i=1\\) while switchers are defined by \\(D_i=0\\). In this new setting, we have to redefine the DID estimator. We are going to choose an estimator that compares the change in outcomes among individuals who have changed treatment status (switchers) to the change in outcome among individuals who have not changed treatment status (always takers): \\[\\begin{align*} \\Delta^Y_{DID^r} &amp; = \\esp{Y_{i,A}|D_i=0} - \\esp{Y_{i,B}|D_i=0} - (\\esp{Y_{i,A}|D_i=1} - \\esp{Y_{i,B}|D_i=1}).\\\\ \\end{align*}\\] Note that \\(\\Delta^Y_{DID^r}\\) is the opposite of the more usual DID estimator \\(\\Delta^Y_{DID}\\), hence the name of reverse DID. Example 4.37 Let us generate data in our example model that complies with Assumption 4.18. \\[\\begin{align*} y^1_{i,A} &amp; = y_{i,A}^0+\\bar{\\alpha}_A+\\bar{\\alpha}_{AT}D_{i,B}+\\theta_A\\mu_i+\\eta_{i,A} \\\\ y^0_{i,A} &amp; = \\mu_i+\\delta+U^0_{i,A} \\\\ U^0_{i,A} &amp; = \\rho U_{i,B}+\\epsilon_{i,A} \\\\ y^1_{i,B} &amp; =y^0_{i,B} + \\bar{\\alpha}_B+\\theta_B\\mu_i+\\eta_{i,B} \\\\ y^0_{i,B} &amp; =\\mu_i+U_{i,B} \\\\ U_{i,B} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_{i,B} &amp; = \\uns{y^0_{i,B}+ V_i\\leq\\bar{y}} \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_i \\\\ (\\eta_{i,A},\\eta_{i,B},\\omega_i) &amp; \\sim\\mathcal{N}(0,0,0,\\sigma^2_{\\eta},\\sigma^2_{\\eta},\\sigma^2_{\\omega},0,\\rho_{\\eta,\\omega}) \\end{align*}\\] Note that in this model we first have imposed that some people enter the treatment in the first period (period \\(B\\)). We also have added other important features, such as the fact that the effect of the treatment varies over time. The most important component of this variation is the constant parameter \\(\\bar{\\alpha}\\) which now differs from period to period (\\(\\bar{\\alpha}_A\\neq\\bar{\\alpha}_B\\)). The treatment effect also varies over group and over time, with the always treated group (characterized by \\(D_{i,B}=1\\)) having an additional increase in treatment effects of \\(\\bar{\\alpha}_{AT}\\) in period \\(A\\). Let’s encode new parameter values. param &lt;- c(8,.5,.28,1500,0.9,0.01,0.01,0.05,0.05,0.05,0.2,0.1,0.3,0.1,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;thetaA&quot;,&quot;thetaB&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralphaA&quot;,&quot;baralphaB&quot;,&quot;baralphaAT&quot;,&quot;gamma&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) Let’s now simulate a dataset according to these new equations. set.seed(1234) N &lt;- 1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],0,param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), 0,param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=3,nrow=3,byrow=T) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;etaA&#39;,&#39;etaB&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) y0B &lt;- mu + UB Y0B &lt;- exp(y0B) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[y0B+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 alphaB &lt;- param[&quot;baralphaB&quot;]+ param[&quot;thetaB&quot;]*mu + eta.omega$etaB y1B &lt;- y0B+alphaB Y1B &lt;- exp(y1B) epsilonA &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0A &lt;- param[&quot;rho&quot;]*UB + epsilonA y0A &lt;- mu + U0A + param[&quot;delta&quot;] alphaA &lt;- param[&quot;baralphaA&quot;]+ param[&quot;baralphaAT&quot;]*Ds+ param[&quot;thetaA&quot;]*mu + eta.omega$etaA y1A &lt;- y0A+alphaA Y0A &lt;- exp(y0A) Y1A &lt;- exp(y1A) yB &lt;- y1B*Ds+y0B*(1-Ds) YB &lt;- Y1B*Ds+Y0B*(1-Ds) yA &lt;- y1A YA &lt;- Y1A Let’s see how DID works on this data. x &lt;- c(&quot;Before&quot;,&quot;After&quot;) y.AT &lt;- c(mean(yB[Ds==1]),mean(yA[Ds==1])) y.AT.counterfactual &lt;- c(mean(y0B[Ds==1]),mean(y0A[Ds==1])) y.Switchers &lt;- c(mean(yB[Ds==0]),mean(yA[Ds==0])) y.Switchers.counterfactual &lt;- c(mean(y0B[Ds==0]),mean(y0A[Ds==0])) y.Switchers.counterfactual.1 &lt;- c(mean(y1B[Ds==0]),mean(y1A[Ds==0])) y.Switchers.DID &lt;- c(mean(yB[Ds==0]),mean(yB[Ds==0])+mean(yA[Ds==1])-mean(yB[Ds==1])) y.Switchers.DID.1 &lt;- c(mean(yA[Ds==0])-(mean(yA[Ds==1])-mean(yB[Ds==1])),mean(yA[Ds==0])) data.DID.plot &lt;- as.data.frame(c(y.AT,y.AT.counterfactual,y.Switchers,y.Switchers.counterfactual,y.Switchers.counterfactual.1,y.Switchers.DID,y.Switchers.DID.1)) colnames(data.DID.plot) &lt;- c(&quot;Outcome&quot;) data.DID.plot$Period &lt;- factor(rep(x,7),levels=c(&quot;Before&quot;,&quot;After&quot;)) data.DID.plot$Group &lt;- factor(c(&quot;Always Treated&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Switchers&quot;,&quot;Switchers&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Switchers DIDr1&quot;),levels=c(&quot;Switchers&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;)) data.DID.plot$Observed &lt;- factor(c(&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;),levels=c(&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;)) WW.before &lt;- (mean(yB[Ds==0])-mean(yB[Ds==1])) WW.after &lt;- (mean(yA[Ds==0])-mean(yA[Ds==1])) BA.AT &lt;- mean(yA[Ds==1])-mean(yB[Ds==1]) BA.Switchers &lt;- mean(yA[Ds==0])-mean(yB[Ds==0]) Counterfactual.after &lt;- mean(yB[Ds==0])+BA.AT DIDr &lt;- BA.Switchers - BA.AT TTASwitchers &lt;- mean(alphaA[Ds==0]) TTBSwitchers &lt;- mean(alphaB[Ds==0]) TTAAT &lt;- mean(alphaA[Ds==1]) TTBAT &lt;- mean(alphaB[Ds==1]) ggplot(data.DID.plot,aes(x=Period,y=Outcome,group=Group,color=Group,shape=Group,linetype=Observed))+ geom_line() + geom_point()+ scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.21: Evolution of average outcomes in the always treated and switchers group in the reverse DID design where everyone is treated in the second period Figure 4.21 shows that DID does not work well in this example. Indeed, the true treatment effect among switchers after the treatment is equal to 0.3 in the sample, while the DID estimator is equal to -0.11. The \\(DID^r\\) estimator is of the wrong sign. Why is that? Note that the \\(DID^r\\) estimator uses the change in outcomes among the always treated to approximate the change in outcome that would have occurred for the switchers if they have stayed outside of the treatment. The problem is that this approximation does not work at all: the increases in outcome for the always treated is much steeper than the increase in outcomes that would have happened to the switchers had they stayed outside of the treatment (0.44 \\(&gt;\\) 0.33). As a consequence, the \\(DID^r\\) estimator overestimates the counterfactual level that would have been reached by the switchers in the second period in the absence of the treatment. Ultimately, the \\(DID^r\\) estimator underestimates severely the effect of the treatment. Note that the usual assumption of parallel trends does hold in this example. The problem comes form somewhere else. One way to understand the problems with the \\(DID^r\\) estimator is to see that the change in treatment effects over time and between groups over time confounds the effect of the treatment. The only way to make the \\(DID^r\\) estimator work is to assume these confounders away. In order to clarify the conditions under which the \\(DID^r\\) estimator is valid, let us state the following assumption: Hypothesis 4.19 (Parallel Trends in the presence of the treatment) We assume that the trends in the potential outcomes in the presence the treatment are the same for the treated and the untreated units: \\[\\begin{align*} \\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1} &amp; = \\esp{Y^1_{i,A}|D_i=0} - \\esp{Y^1_{i,B}|D_i=0}. \\end{align*}\\] Under Assumption 4.19, we can show that the \\(DID^r\\) estimator identifies the effect of the treatment on the switchers in the first period: Theorem 4.13 (DIDr identifies TUT in the first period) Under Assumptions 4.12, 4.13 and 4.19, the \\(DID^r\\) estimator identifies the average effect of the Treatment on the switchers before the treatment: \\[\\begin{align*} \\Delta_{DID^r}^{Y} &amp; = \\Delta^{Y_B}_{TUT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^{Y_B}_{TUT} &amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_{i}=0}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID^r} &amp; = \\esp{Y_{i,A}|D_i=0}-\\esp{Y_{i,B}|D_i=0}-(\\esp{Y_{i,A}|D_i=1}-\\esp{Y_{i,B}|D_i=1}) \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=0}-\\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^1_{i,B}|D_i=1})\\\\ &amp; = \\esp{Y^1_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^1_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0} \\end{align*}\\] where the second equality follows from Assumptions 4.12 and 4.13 and the switching equation, and the third equality follows from Assumption 4.19. Theorem 4.13 shows that under an alternative assumption of parallel trends (that they hold for potential outcomes when units are in the treatment), the \\(DID^r\\) estimator identifies the causal effect of the treatment on the switchers before the treatment takes place. Remark. Note that it makes intuitive sense: the only true change is that of the switchers entering the treatment. Using the always takers, we can only learn about the changes in potential outcomes when in the treatment. Under Assumption 4.19, the switchers would have experimented the same change in outcomes than the always takers if they have been constantly treated. As a consequence, we can use the change in outcomes among the always takers to project back what would have been the outcomes of the switchers in the first period had they been exposed to the treatment. Remark. Note as well that Assumption 4.19, when paired with Assumption 4.14, is actually restrictive in terms of how the treatment effects might change over time and between groups, as the following lemma shows: Lemma 4.4 (Parallel Trends Restricts the Way Treatment Effects Change Over Time) Assumptions 4.14 and 4.19 imply that always takers and switchers experience the same changes in treatment effects over time: \\[\\begin{align*} \\Delta^{Y_A}_{TUT}- \\Delta^{Y_B}_{TUT} &amp; = \\Delta^{Y_A}_{TT}- \\Delta^{Y_B}_{TT}. \\end{align*}\\] Proof. Substracting the parallel trends condition in Assumption 4.14 from the parallel trends condition in Assumption 4.19, we have: \\[\\begin{align*} \\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1}-(\\esp{Y^0_{i,A}|D_i=1} - \\esp{Y^0_{i,B}|D_i=1}) &amp; = \\esp{Y^1_{i,A}|D_i=0} - \\esp{Y^1_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}). \\end{align*}\\] After some manipulation, we get: \\[\\begin{align*} \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=1} - \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=1}&amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0} - \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0},. \\end{align*}\\] which proves the result. Remark. There remains a final question: are there any conditions under which we could use the \\(DID^r\\) estimator to identify the effect of the treatment on the switchers after the treatment takes place? In practice, that means that we need to recover the trends the switchers would have experienced had they not entered the treatment. This puts a stark requirement on the available data because we have no information on what outcomes in the absence of the treatment would be in the second period. One natural but also super strong assumption is to assume that the change in outcomes among the always takers in the presence of the treatment is the same as the one that the switchers would have experienced in the absence of the treatment: Hypothesis 4.20 (Parallel Trends for Always Takers in the Presence of the Treatment and Switchers in the Absence of the Treatment) We assume that the trends in the potential outcomes in the presence the treatment for the always takers are the same as the trends in potential outcomes in the absence of the treatment for the switchers : \\[\\begin{align*} \\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1} &amp; = \\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}. \\end{align*}\\] Under Assumption 4.20, we can recover the treatment effect on teh switchers in the second period: Theorem 4.14 (DIDr identifies TUT in the second period) Under Assumptions 4.12, 4.13 and 4.20, the \\(DID^r\\) estimator identifies the average effect of the Treatment on the switchers after the treatment: \\[\\begin{align*} \\Delta_{DID^r}^{Y} &amp; = \\Delta^{Y_A}_{TUT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^{Y_A}_{TUT} &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_{i}=0}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID^r} &amp; = \\esp{Y_{i,A}|D_i=0}-\\esp{Y_{i,B}|D_i=0}-(\\esp{Y_{i,A}|D_i=1}-\\esp{Y_{i,B}|D_i=1}) \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=0}-\\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^1_{i,B}|D_i=1})\\\\ &amp; = \\esp{Y^1_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^0_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0} \\end{align*}\\] where the second equality follows from Assumptions 4.12 and 4.13 and the switching equation, and the third equality follows from Assumption 4.20. Remark. What does Assumption 4.20 really mean? It is unusual, but is it highly restrictive? The following lemma helps to make sense of it: Lemma 4.5 (Parallel Trends and Treatment Effects) The parallel trends assumptions restrict the way treatment effects might change over time: (i) Assumptions 4.14 and 4.20 together imply the effect of the treatment is constant over time among always takers: \\(\\Delta^{Y_A}_{TT} = \\Delta^{Y_B}_{TT}\\); (ii) Assumptions 4.19 and 4.20 together imply the effect of the treatment is constant over time among switchers: \\(\\Delta^{Y_A}_{TUT} = \\Delta^{Y_B}_{TUT}\\); (iii) Assumptions 4.14, 4.19 and 4.20 together imply the effect of the treatment is constant over time among switchers and always takers: \\(\\Delta^{Y_A}_{TUT} = \\Delta^{Y_B}_{TUT}\\) and \\(\\Delta^{Y_A}_{TT} = \\Delta^{Y_B}_{TT}\\). Proof. Substracting the parallel trends condition in Assumption 4.14 from the parallel trends condition in Assumption 4.20, we have: \\[\\begin{align*} \\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1}-(\\esp{Y^0_{i,A}|D_i=1} - \\esp{Y^0_{i,B}|D_i=1}) &amp; = \\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}). \\end{align*}\\] After some manipulation, we get: \\[\\begin{align*} \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=1}&amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=1}. \\end{align*}\\] which proves the first result. Substracting the parallel trends condition in Assumption 4.19 from the parallel trends condition in Assumption 4.20, we have: \\[\\begin{align*} \\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1}-(\\esp{Y^1_{i,A}|D_i=1} - \\esp{Y^1_{i,B}|D_i=1}) &amp; = \\esp{Y^1_{i,A}|D_i=0} - \\esp{Y^1_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0} - \\esp{Y^0_{i,B}|D_i=0}). \\end{align*}\\] After some manipulation, we get: \\[\\begin{align*} \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0}&amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0}. \\end{align*}\\] which proves the second result. The first two results imply the last one. Remark. It is noteworthy that combining the three assumptions together does not imply anything more than when combining them separately. The key is that Assumptions 4.14 and 4.19 together already imply that treatment effects change in the same way over time in both groups. Assumption 4.20 together with Assumptions 4.14 and 4.19 implies also that all potential outcomes have to change in the same way over time in both groups. The only way for these two properties to be true at the same time is for treatment effects in noth groups to be constant over time. Remark. Note that Lemma 4.5 does not imply that treatment effects are the same in both groups. They do not have to be. Assumptions 4.14, 4.19 and 4.20 allow for the treatment effects among switchers and always takers to be different. Remark. A useful result is also to express the bias of the \\(DID^r\\) estimator when only Assumption 4.14 holds. The following lemma does the job: Theorem 4.15 (Bias of the DIDr estimator) Under Assumptions 4.12, 4.13 and 4.14, the \\(DID^r\\) estimator is biased for the average effect of the Treatment on the switchers before and after the treatment: \\[\\begin{align*} \\Delta_{DID^r}^{Y} &amp; = \\Delta^{Y_B}_{TUT}+B^{Y_B}_{DID^r} \\\\ \\Delta_{DID^r}^{Y} &amp; = \\Delta^{Y_A}_{TUT}+B^{Y_A}_{DID^r} \\end{align*}\\] with: \\[\\begin{align*} B^{Y_B}_{DID^r} &amp; = \\Delta^{Y_A}_{TUT}-\\Delta^{Y_B}_{TUT}-(\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT})\\\\ B^{Y_A}_{DID^r} &amp; = -(\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}). \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID^r} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_i=0}-\\esp{Y_{i,A}-Y_{i,B}|D_i=1} \\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1} \\\\ &amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1} \\\\ &amp; = \\Delta^{Y_B}_{TUT}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}\\\\ &amp; \\phantom{=}-(\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1})\\\\ &amp; = \\Delta^{Y_B}_{TUT}+\\Delta^{Y_A}_{TUT}-\\Delta^{Y_B}_{TUT}-(\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}) \\end{align*}\\] where the second equality follows from Assumptions 4.12 and 4.13 and the switching equation, and the fifth equality follows from Assumption 4.14. \\[\\begin{align*} \\Delta^Y_{DID^r} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_i=0}-\\esp{Y_{i,A}-Y_{i,B}|D_i=1} \\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0}+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0}\\\\ &amp; \\phantom{=}-\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1}+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1} \\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0}+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1} \\\\ &amp; = \\Delta^{Y_A}_{TUT}-(\\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=1}-\\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=1}) \\\\ &amp; = \\Delta^{Y_A}_{TUT}-(\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}) \\end{align*}\\] where the second equality follows from Assumptions 4.12 and 4.13 and the switching equation, and the fourth equality follows from Assumption 4.14. Theorem 4.15 helps to make sense of Figure 4.21. The bias of the \\(DID^r\\) estimator for the average effect of the treatment on the switchers in the second period is equal to the opposite of the change in treatment effects for the always treated between the first and the second period. This means that if the effect of the treatment increases over time for the always takers, the \\(DID^r\\) estimator will be biased negatively. If this negative bias is sufficiently large, it can make an altogether positive treatment effect (both on switchers and always takers at every period) look negative. This is a very serious problem and the main reason why you want to be very careful when using the \\(DID^r\\) estimator. This is actually what happens in Figure 4.21: the change in treatment effect over time among the always treated is very large (it is equal to 0.37) while the treatment effect is only equal to 0.3. As a consequence, the \\(DID^r\\) estimator is equal to -0.11 whereas every average treatment effect is positive: \\(\\hat{\\Delta}^{y_A}_{TT}=\\) 0.54 \\(\\hat{\\Delta}^{y_B}_{TT}=\\) 0.17, \\(\\hat{\\Delta}^{y_A}_{TUT}=\\) 0.3 and \\(\\hat{\\Delta}^{y_B}_{TUT}=\\) 0.17. Theorem 4.15 also explains why the \\(DID^r\\) estimator is biased for the effect of the treatment in the first period. This is because the effect of the treatment changes differently over time among switchers and among always takers. On Figure 4.21, the average treatment effect on switchers increases by 0.12, and it is not approximated well by the change in treatment effect among the always takers (0.37). As a consequence, the \\(DID^r\\) estimator is equal to -0.11 while the average effect of the treatment on the switchers in the first period is equal to: \\(\\hat{\\Delta}^{y_B}_{TUT}=\\) 0.17. Example 4.38 Let us now explore how the way Theorem 4.15 plays out in our data. For that, we are going to first switch off the change in treatment effects that is specific to the always takers in the second period. As a case in point, we are going to set \\(\\bar{\\alpha}_{AT}=0\\). param[&quot;baralphaAT&quot;] &lt;- 0 Let’s now simulate a dataset according to these new equations. set.seed(1234) N &lt;- 1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],0,param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), 0,param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=3,nrow=3,byrow=T) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;etaA&#39;,&#39;etaB&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) y0B &lt;- mu + UB Y0B &lt;- exp(y0B) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[y0B+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 alphaB &lt;- param[&quot;baralphaB&quot;]+ param[&quot;thetaB&quot;]*mu + eta.omega$etaB y1B &lt;- y0B+alphaB Y1B &lt;- exp(y1B) epsilonA &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0A &lt;- param[&quot;rho&quot;]*UB + epsilonA y0A &lt;- mu + U0A + param[&quot;delta&quot;] alphaA &lt;- param[&quot;baralphaA&quot;]+ param[&quot;baralphaAT&quot;]*Ds+ param[&quot;thetaA&quot;]*mu + eta.omega$etaA y1A &lt;- y0A+alphaA Y0A &lt;- exp(y0A) Y1A &lt;- exp(y1A) yB &lt;- y1B*Ds+y0B*(1-Ds) YB &lt;- Y1B*Ds+Y0B*(1-Ds) yA &lt;- y1A YA &lt;- Y1A Let’s see how DID works on this data. x &lt;- c(&quot;Before&quot;,&quot;After&quot;) y.AT &lt;- c(mean(yB[Ds==1]),mean(yA[Ds==1])) y.AT.counterfactual &lt;- c(mean(y0B[Ds==1]),mean(y0A[Ds==1])) y.Switchers &lt;- c(mean(yB[Ds==0]),mean(yA[Ds==0])) y.Switchers.counterfactual &lt;- c(mean(y0B[Ds==0]),mean(y0A[Ds==0])) y.Switchers.counterfactual.1 &lt;- c(mean(y1B[Ds==0]),mean(y1A[Ds==0])) y.Switchers.DID &lt;- c(mean(yB[Ds==0]),mean(yB[Ds==0])+mean(yA[Ds==1])-mean(yB[Ds==1])) y.Switchers.DID.1 &lt;- c(mean(yA[Ds==0])-(mean(yA[Ds==1])-mean(yB[Ds==1])),mean(yA[Ds==0])) data.DID.plot &lt;- as.data.frame(c(y.AT,y.AT.counterfactual,y.Switchers,y.Switchers.counterfactual,y.Switchers.counterfactual.1,y.Switchers.DID,y.Switchers.DID.1)) colnames(data.DID.plot) &lt;- c(&quot;Outcome&quot;) data.DID.plot$Period &lt;- factor(rep(x,7),levels=c(&quot;Before&quot;,&quot;After&quot;)) data.DID.plot$Group &lt;- factor(c(&quot;Always Treated&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Switchers&quot;,&quot;Switchers&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Switchers DIDr1&quot;),levels=c(&quot;Switchers&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;)) data.DID.plot$Observed &lt;- factor(c(&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;),levels=c(&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;)) WW.before &lt;- (mean(yB[Ds==0])-mean(yB[Ds==1])) WW.after &lt;- (mean(yA[Ds==0])-mean(yA[Ds==1])) BA.AT &lt;- mean(yA[Ds==1])-mean(yB[Ds==1]) BA.Switchers &lt;- mean(yA[Ds==0])-mean(yB[Ds==0]) Counterfactual.after &lt;- mean(yB[Ds==0])+BA.AT DIDr &lt;- BA.Switchers - BA.AT TTASwitchers &lt;- mean(alphaA[Ds==0]) TTBSwitchers &lt;- mean(alphaB[Ds==0]) TTAAT &lt;- mean(alphaA[Ds==1]) TTBAT &lt;- mean(alphaB[Ds==1]) ggplot(data.DID.plot,aes(x=Period,y=Outcome,group=Group,color=Group,shape=Group,linetype=Observed))+ geom_line() + geom_point()+ scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.22: Evolution of average outcomes in the always treated and switchers group in the reverse DID design where everyone is treated in the second period and \\(\\bar{\\alpha}_{AT}=0\\) What is happening on Figure 4.22? First, the \\(DID^r\\) estimator is equal to 0.19, while the effect of the treatment on switchers is equal to 0.3 in the second period and to 0.17 in the first period. So now, the bias of the \\(DID^r\\) is not so large as to make it reverse signs with respect to the true effect of the treatment. It is actually almost zero for the effect on the switchers in the first period (\\(\\hat{B}^{Y_B}_{DID^r}=\\) 0.01). This is because the condition for \\(DID^r\\) to capture the effect of the treatment on switchers in the first period is almost fulfilled in the data. Theorem 4.15 shows that this bias is equal to the difference in the change in teatment effect over time between the switchers and the always takers. The change in treatment effect for the switchers is equal to \\(\\hat{\\Delta}^{Y_A}_{TUT}-\\hat\\Delta^{Y_B}_{TUT}=\\) 0.12 and the change in treatment effect for the always takers is equal to \\(\\hat{\\Delta}^{Y_A}_{TT}-\\hat\\Delta^{Y_B}_{TT}=\\) 0.07. They are almost equal which makes \\(DID^r\\) almost unbiased for the effect of the treatment on switchers in the first period. On the contrary, the condition for \\(DID^r\\) to capture the effect of the treatment on the switchers in the second period is not fulfilled in the data, not even almost. Theorem 4.15 shows that the condition for \\(DID^r\\) to capture the effect of the treatment on the switchers in the second period is that the treatment effect on always takers be constant over time. This is unfortunately not the case in this data, since \\(\\hat{\\Delta}^{Y_A}_{TT}-\\hat\\Delta^{Y_B}_{TT}=\\) 0.07. The bias of the \\(DID^r\\) estimator is thus large (and negative) for \\(\\hat{\\Delta}^{Y_A}_{TUT}\\): \\(\\hat{B}^{Y_A}_{DID^r}=\\) -0.11. Remark. Note that in this model, the \\(DID^r\\) estimator is still biased for \\(\\Delta^{Y_B}_{TUT}\\). The reasons why are left as an exercise. Example 4.39 Let us finally explore the last condition in Theorem 4.15 that makes \\(DID^r\\) unbiased for \\(\\Delta^{Y_A}_{TUT}\\), the effect of the treatment on switchers in the second period. We are going to switch off the change in treatment effects that occurs over time in both groups: we are going to set \\(\\bar{\\alpha}_{A}=\\bar{\\alpha}_{B}=0.1\\). param[&quot;baralphaA&quot;] &lt;- 0.1 param[&quot;baralphaB&quot;] &lt;- 0.1 Let’s now simulate a dataset according to these new equations. set.seed(1234) N &lt;- 1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],0,param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), 0,param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=3,nrow=3,byrow=T) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;etaA&#39;,&#39;etaB&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) y0B &lt;- mu + UB Y0B &lt;- exp(y0B) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[y0B+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 alphaB &lt;- param[&quot;baralphaB&quot;]+ param[&quot;thetaB&quot;]*mu + eta.omega$etaB y1B &lt;- y0B+alphaB Y1B &lt;- exp(y1B) epsilonA &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0A &lt;- param[&quot;rho&quot;]*UB + epsilonA y0A &lt;- mu + U0A + param[&quot;delta&quot;] alphaA &lt;- param[&quot;baralphaA&quot;]+ param[&quot;baralphaAT&quot;]*Ds+ param[&quot;thetaA&quot;]*mu + eta.omega$etaA y1A &lt;- y0A+alphaA Y0A &lt;- exp(y0A) Y1A &lt;- exp(y1A) yB &lt;- y1B*Ds+y0B*(1-Ds) YB &lt;- Y1B*Ds+Y0B*(1-Ds) yA &lt;- y1A YA &lt;- Y1A Let’s see how DID works on this data. x &lt;- c(&quot;Before&quot;,&quot;After&quot;) y.AT &lt;- c(mean(yB[Ds==1]),mean(yA[Ds==1])) y.AT.counterfactual &lt;- c(mean(y0B[Ds==1]),mean(y0A[Ds==1])) y.Switchers &lt;- c(mean(yB[Ds==0]),mean(yA[Ds==0])) y.Switchers.counterfactual &lt;- c(mean(y0B[Ds==0]),mean(y0A[Ds==0])) y.Switchers.counterfactual.1 &lt;- c(mean(y1B[Ds==0]),mean(y1A[Ds==0])) y.Switchers.DID &lt;- c(mean(yB[Ds==0]),mean(yB[Ds==0])+mean(yA[Ds==1])-mean(yB[Ds==1])) y.Switchers.DID.1 &lt;- c(mean(yA[Ds==0])-(mean(yA[Ds==1])-mean(yB[Ds==1])),mean(yA[Ds==0])) data.DID.plot &lt;- as.data.frame(c(y.AT,y.AT.counterfactual,y.Switchers,y.Switchers.counterfactual,y.Switchers.counterfactual.1,y.Switchers.DID,y.Switchers.DID.1)) colnames(data.DID.plot) &lt;- c(&quot;Outcome&quot;) data.DID.plot$Period &lt;- factor(rep(x,7),levels=c(&quot;Before&quot;,&quot;After&quot;)) data.DID.plot$Group &lt;- factor(c(&quot;Always Treated&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Switchers&quot;,&quot;Switchers&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Switchers DIDr1&quot;),levels=c(&quot;Switchers&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;)) data.DID.plot$Observed &lt;- factor(c(&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;),levels=c(&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;)) WW.before &lt;- (mean(yB[Ds==0])-mean(yB[Ds==1])) WW.after &lt;- (mean(yA[Ds==0])-mean(yA[Ds==1])) BA.AT &lt;- mean(yA[Ds==1])-mean(yB[Ds==1]) BA.Switchers &lt;- mean(yA[Ds==0])-mean(yB[Ds==0]) Counterfactual.after &lt;- mean(yB[Ds==0])+BA.AT DIDr &lt;- BA.Switchers - BA.AT TTASwitchers &lt;- mean(alphaA[Ds==0]) TTBSwitchers &lt;- mean(alphaB[Ds==0]) TTAAT &lt;- mean(alphaA[Ds==1]) TTBAT &lt;- mean(alphaB[Ds==1]) ggplot(data.DID.plot,aes(x=Period,y=Outcome,group=Group,color=Group,shape=Group,linetype=Observed))+ geom_line() + geom_point()+ scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.23: Evolution of average outcomes in the always treated and switchers group in the reverse DID design where everyone is treated in the second period and \\(\\bar{\\alpha}_{A}=\\bar{\\alpha}_{B}=0\\) Figure 4.23 shows that the \\(DID^r\\) estimator is almost OK in our setting. The \\(DID^r\\) estimator is equal to 0.19 while the treatment effect on the switchers is equal to \\(\\hat\\Delta^{Y_A}_{TUT}=\\) 0.2 in the second period and \\(\\hat\\Delta^{Y_B}_{TUT}=\\) 0.17 in the first period. There still is a difference between the estimator and the treatment effect of interest, but the difference is small enough that it might be attributed to sampling noise. Remember that the condition for \\(DID^r\\) to identify \\(\\Delta^{Y_A}_{TUT}\\) is Assumption 4.20 that the trends in potential outcomes in the absence of the treatment among switchers is the same as the trend in potential outcomes in the presence of the treatment among always takers. This is almost what we see, since the change in potential outcomes absent the treatment among switchers is equal to 0.03 while the change in potential outcomes under the treatment regime among always takers is equal to 0.04. The fact that these two quantities differ slightly is what biases the \\(DID^r\\) estimator in the sample that we have generated. Note finally that Assumption 4.20 together with Assumption 4.14 implies that the effect of the treatment is constant over time among always takers, as Lemma 4.5 shows. This is also the condition for the \\(DID^r\\) estimator to identify \\(\\Delta^{Y_A}_{TUT}\\) under Assumption 4.14, as Lemma 4.5 shows. Here, the effect of the treatment among always takers is equal to 0.17 in the first period and to 0.14 in the second period. Remark. Actually, the conditions for \\(DID^r\\) to indentify any treatment effect are not fulfilled in our model. That reasons why are left as an exercise. 4.3.2.2 DID designs where everyone is in the treatment at the first period Compared to the setting in the previous section, the main change is to Assumption 4.12: Hypothesis 4.21 (Everyone Receives Treatment in the First Period) We assume that every unit in the population receives the treatment in the first period: \\(D_{i,B}=1\\), \\(\\forall i\\). Under Assumption 4.21, and without loss of generality, we can still write \\(D_i=D_{i,A}\\). In order for the \\(DID\\) estimator to identify a fully-fledged treatment effect, we are going to need a pretty stark assumption: Hypothesis 4.22 (No Effect After Exiting the Treatment) We assume that, after exiting the treatment, agents experience the same outcomes as if they had never entered the treatment: \\(Y_{i,A}=Y^0_{i,A}\\), \\(\\forall i\\) such that \\(D_{i,A}=0\\). A consequence of Assumptions 4.21 and 4.22 is that we can write observed outcomes as a function of treatment and potential outcomes using the usual switching equation. Remark. Note that Assumption 4.22 is extremely restrictive: units return immediately to their outcomes in the absence of the treatment right after exiting the treatment state. We are going to relax that assumption later. The following theorem shows that \\(DID\\) identifies a fully-fledged treatment effect under (arguably strong) assumptions: Theorem 4.16 (DID identifies TUT in the second period) Under Assumptions 4.21, 4.22 and 4.19, the \\(DID\\) estimator identifies the effect of the treatment on the switchers in the second period: \\[\\begin{align*} \\Delta_{DID}^{Y} &amp; = \\Delta^{Y_A}_{TUT}, \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}|D_i=1}-\\esp{Y_{i,B}|D_i=1}-(\\esp{Y_{i,A}|D_i=0}-\\esp{Y_{i,B}|D_i=0}) \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^1_{i,B}|D_i=1}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0} \\end{align*}\\] where the second equality follows from Assumptions 4.21 and 4.22 and the switching equation, and the third equality follows from Assumption 4.19. Invoking another (even stronger) assumption, DID identifies the effect of the treatment on switchers in the first period: Theorem 4.17 (DID identifies TUT in the first period) Under Assumptions 4.21, 4.22 and 4.20, the \\(DID\\) estimator identifies the effect of the treatment on the switchers in the first period: \\[\\begin{align*} \\Delta_{DID}^{Y} &amp; = \\Delta^{Y_B}_{TUT}, \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}|D_i=1}-\\esp{Y_{i,B}|D_i=1}-(\\esp{Y_{i,A}|D_i=0}-\\esp{Y_{i,B}|D_i=0}) \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=1}-\\esp{Y^1_{i,B}|D_i=1}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^0_{i,B}|D_i=0}-(\\esp{Y^0_{i,A}|D_i=0}-\\esp{Y^1_{i,B}|D_i=0})\\\\ &amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0} \\end{align*}\\] where the second equality follows from Assumptions 4.21 and 4.22 and the switching equation, and the third equality follows from Assumption 4.20. We can also study the bias of the DID estimator under the classical parallel trends assumption (Assumption 4.14): Lemma 4.6 (Bias of the DID estimator) Under Assumptions 4.21, 4.22 and 4.14, the \\(DID\\) estimator is biased for the average effect of the Treatment on the switchers before and after the treatment: \\[\\begin{align*} \\Delta_{DID}^{Y} &amp; = \\Delta^{Y_B}_{TUT}+B^{Y_B}_{DID} \\\\ \\Delta_{DID}^{Y} &amp; = \\Delta^{Y_A}_{TUT}+B^{Y_A}_{DID} \\end{align*}\\] with: \\[\\begin{align*} B^{Y_B}_{DID} &amp; = \\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}\\\\ B^{Y_A}_{DID} &amp; = \\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}-(\\Delta^{Y_A}_{TUT}-\\Delta^{Y_B}_{TUT}). \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_i=1}-\\esp{Y_{i,A}-Y_{i,B}|D_i=0} \\\\ &amp; = \\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^0_{i,A}-Y^1_{i,B}|D_i=0}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1}+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0}-\\esp{Y^0_{i,A}-Y^1_{i,B}|D_i=0} \\\\ &amp; = \\esp{Y^1_{i,B}-Y^0_{i,B}|D_i=0}+ \\esp{Y^1_{i,A}-Y^1_{i,B}-(Y^0_{i,A}-Y^0_{i,B})|D_i=1} &amp; = \\Delta^{Y_B}_{TUT}+\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}, \\end{align*}\\] where the second equality follows from Assumptions 4.21, 4.22 and the switching equation, and the third equality follows from Assumption 4.14. \\[\\begin{align*} \\Delta^Y_{DID} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_i=1}-\\esp{Y_{i,A}-Y_{i,B}|D_i=0} \\\\ &amp; = \\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^0_{i,A}-Y^1_{i,B}|D_i=0}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}-\\esp{Y^0_{i,A}-Y^1_{i,B}|D_i=0}\\\\ &amp; = \\esp{Y^1_{i,A}-Y^0_{i,A}|D_i=0}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0} \\\\ &amp; = \\Delta^{Y_A}_{TUT}+\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=1}-\\esp{Y^1_{i,A}-Y^1_{i,B}|D_i=0}\\\\ &amp; \\phantom{=} -\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=1}+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0} \\\\ &amp; = \\Delta^{Y_A}_{TUT}+\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}-(\\Delta^{Y_A}_{TUT}-\\Delta^{Y_B}_{TUT}), \\end{align*}\\] where the second equality follows from Assumptions 4.21, 4.22 and the switching equation, and the fifth equality follows from Assumption 4.14. Example 4.40 Let us generate data in our example model that complies with Assumptions 4.21 and 4.22. \\[\\begin{align*} y_{i,A}^1 &amp; = y_{i,A}^0+\\bar{\\alpha}_A+\\bar{\\alpha}_{AT}D_{i,A}+\\theta_A\\mu_i+\\eta_{i,A} \\\\ y_{i,A}^0 &amp; = \\mu_i+\\delta+U_{i,A}^0 \\\\ U_{i,A}^0 &amp; = \\rho U_{i,B}+\\epsilon_{i,A} \\\\ y^1_{i,B} &amp; =y^0_{i,B} + \\bar{\\alpha}_B+\\theta_B\\mu_i+\\eta_{i,B} \\\\ y^0_{i,B} &amp; =\\mu_i+U_{i,B} \\\\ U_{i,B} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_{i,A} &amp; = \\uns{y^0_{i,B}+ V_i\\leq\\bar{y}} \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_i \\\\ (\\eta_{i,A},\\eta_{i,B},\\omega_i) &amp; \\sim\\mathcal{N}(0,0,0,\\sigma^2_{\\eta},\\sigma^2_{\\eta},\\sigma^2_{\\omega},0,\\rho_{\\eta,\\omega}) \\end{align*}\\] param &lt;- c(8,.5,.28,1500,0.9,0.01,0.01,0.05,0.05,0.05,0.2,0.1,0.3,0.1,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;thetaA&quot;,&quot;thetaB&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralphaA&quot;,&quot;baralphaB&quot;,&quot;baralphaAT&quot;,&quot;gamma&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) set.seed(1234) N &lt;- 1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],0,param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), 0,param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=3,nrow=3,byrow=T) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;etaA&#39;,&#39;etaB&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) y0B &lt;- mu + UB Y0B &lt;- exp(y0B) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[y0B+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 alphaB &lt;- param[&quot;baralphaB&quot;]+ param[&quot;thetaB&quot;]*mu + eta.omega$etaB y1B &lt;- y0B+alphaB Y1B &lt;- exp(y1B) epsilonA &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0A &lt;- param[&quot;rho&quot;]*UB + epsilonA y0A &lt;- mu + U0A + param[&quot;delta&quot;] alphaA &lt;- param[&quot;baralphaA&quot;]+ param[&quot;baralphaAT&quot;]*Ds+ param[&quot;thetaA&quot;]*mu + eta.omega$etaA y1A &lt;- y0A+alphaA Y0A &lt;- exp(y0A) Y1A &lt;- exp(y1A) yA &lt;- y1A*Ds+y0A*(1-Ds) YA &lt;- Y1A*Ds+Y0A*(1-Ds) yB &lt;- y1B YB &lt;- Y1B Let’s see how DID works on this data. x &lt;- c(&quot;Before&quot;,&quot;After&quot;) y.AT &lt;- c(mean(yB[Ds==1]),mean(yA[Ds==1])) y.AT.counterfactual &lt;- c(mean(y0B[Ds==1]),mean(y0A[Ds==1])) y.Switchers &lt;- c(mean(yB[Ds==0]),mean(yA[Ds==0])) y.Switchers.counterfactual &lt;- c(mean(y0B[Ds==0]),mean(y0A[Ds==0])) y.Switchers.counterfactual.1 &lt;- c(mean(y1B[Ds==0]),mean(y1A[Ds==0])) y.Switchers.DID &lt;- c(mean(yB[Ds==0]),mean(yB[Ds==0])+mean(yA[Ds==1])-mean(yB[Ds==1])) y.Switchers.DID.1 &lt;- c(mean(yA[Ds==0])-(mean(yA[Ds==1])-mean(yB[Ds==1])),mean(yA[Ds==0])) data.DID.plot &lt;- as.data.frame(c(y.AT,y.AT.counterfactual,y.Switchers,y.Switchers.counterfactual,y.Switchers.counterfactual.1,y.Switchers.DID,y.Switchers.DID.1)) colnames(data.DID.plot) &lt;- c(&quot;Outcome&quot;) data.DID.plot$Period &lt;- factor(rep(x,7),levels=c(&quot;Before&quot;,&quot;After&quot;)) data.DID.plot$Group &lt;- factor(c(&quot;Always Treated&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Switchers&quot;,&quot;Switchers&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Switchers DIDr1&quot;),levels=c(&quot;Switchers&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;)) data.DID.plot$Observed &lt;- factor(c(&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;),levels=c(&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;)) WW.before &lt;- (mean(yB[Ds==1])-mean(yB[Ds==0])) WW.after &lt;- (mean(yA[Ds==1])-mean(yA[Ds==0])) BA.AT &lt;- mean(yA[Ds==1])-mean(yB[Ds==1]) BA.Switchers &lt;- mean(yA[Ds==0])-mean(yB[Ds==0]) Counterfactual.after &lt;- mean(yB[Ds==0])+BA.AT DID &lt;- BA.AT - BA.Switchers TTASwitchers &lt;- mean(alphaA[Ds==0]) TTBSwitchers &lt;- mean(alphaB[Ds==0]) TTAAT &lt;- mean(alphaA[Ds==1]) TTBAT &lt;- mean(alphaB[Ds==1]) ggplot(data.DID.plot,aes(x=Period,y=Outcome,group=Group,color=Group,shape=Group,linetype=Observed))+ geom_line() + geom_point()+ scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.24: Evolution of average outcomes in the always treated and switchers group in the reverse DID design where everyone is treated in the first period In Figure 4.24, the effect of the treatment on the switchers is equal to \\(\\hat\\Delta^{y_A}_{TUT}=\\) 0.3 in the second period and to \\(\\hat\\Delta^{y_B}_{TUT}=\\) 0.17 in the first period. The \\(DID\\) estimator is equal to \\(\\hat\\Delta^{y}_{DID}=\\) 0.58 which is of the correct sign but much too big for both treatment effects. The problem is that the change in the outcomes of the always treated (0.44) overestimates the change in outcomes the switchers would have experienced had they stayed in the treatment (0.16). As a consequence, Assumption 4.19 is not valid and the DID estimator is biased. Following Lemma 4.6, the bias of the DID estimator for the effect on the switchers in the second period is equal to the difference in the change of treatment effect over time between always treated (\\(\\hat\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}=\\) 0.54 \\(-\\) 0.17 \\(=\\) 0.37) and switchers (\\(\\hat\\Delta^{Y_A}_{TUT}-\\hat\\Delta^{Y_B}_{TUT}=\\) 0.3 \\(-\\) 0.17 \\(=\\) 0.12). The bias of the DID estimator for the effect of the treatment on the switchers in the first period is even larger (\\(\\hat B^{y_B}_{DID}=\\) 0.41). Following Lemma 4.6, it is close to the change in treatment effect over time among the switchers (\\(\\hat\\Delta^{Y_A}_{TT}-\\hat\\Delta^{Y_B}_{TT}=\\) 0.54 \\(-\\) 0.17 \\(=\\) 0.37). Example 4.41 What happens if we enforce the fact that treatment effects vary in the same way among always takers and switchers. Let’s find out. param[&quot;baralphaAT&quot;] &lt;- 0 Let’s simulate the new data: set.seed(1234) N &lt;- 1000 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],0,param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), 0,param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=3,nrow=3,byrow=T) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega)) colnames(eta.omega) &lt;- c(&#39;etaA&#39;,&#39;etaB&#39;,&#39;omega&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) y0B &lt;- mu + UB Y0B &lt;- exp(y0B) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[y0B+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 alphaB &lt;- param[&quot;baralphaB&quot;]+ param[&quot;thetaB&quot;]*mu + eta.omega$etaB y1B &lt;- y0B+alphaB Y1B &lt;- exp(y1B) epsilonA &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0A &lt;- param[&quot;rho&quot;]*UB + epsilonA y0A &lt;- mu + U0A + param[&quot;delta&quot;] alphaA &lt;- param[&quot;baralphaA&quot;]+ param[&quot;baralphaAT&quot;]*Ds+ param[&quot;thetaA&quot;]*mu + eta.omega$etaA y1A &lt;- y0A+alphaA Y0A &lt;- exp(y0A) Y1A &lt;- exp(y1A) yA &lt;- y1A*Ds+y0A*(1-Ds) YA &lt;- Y1A*Ds+Y0A*(1-Ds) yB &lt;- y1B YB &lt;- Y1B Let’s see how DID works on this data. x &lt;- c(&quot;Before&quot;,&quot;After&quot;) y.AT &lt;- c(mean(yB[Ds==1]),mean(yA[Ds==1])) y.AT.counterfactual &lt;- c(mean(y0B[Ds==1]),mean(y0A[Ds==1])) y.Switchers &lt;- c(mean(yB[Ds==0]),mean(yA[Ds==0])) y.Switchers.counterfactual &lt;- c(mean(y0B[Ds==0]),mean(y0A[Ds==0])) y.Switchers.counterfactual.1 &lt;- c(mean(y1B[Ds==0]),mean(y1A[Ds==0])) y.Switchers.DID &lt;- c(mean(yB[Ds==0]),mean(yB[Ds==0])+mean(yA[Ds==1])-mean(yB[Ds==1])) y.Switchers.DID.1 &lt;- c(mean(yA[Ds==0])-(mean(yA[Ds==1])-mean(yB[Ds==1])),mean(yA[Ds==0])) data.DID.plot &lt;- as.data.frame(c(y.AT,y.AT.counterfactual,y.Switchers,y.Switchers.counterfactual,y.Switchers.counterfactual.1,y.Switchers.DID,y.Switchers.DID.1)) colnames(data.DID.plot) &lt;- c(&quot;Outcome&quot;) data.DID.plot$Period &lt;- factor(rep(x,7),levels=c(&quot;Before&quot;,&quot;After&quot;)) data.DID.plot$Group &lt;- factor(c(&quot;Always Treated&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Always Treated counterfactual y0&quot;,&quot;Switchers&quot;,&quot;Switchers&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Switchers DIDr1&quot;),levels=c(&quot;Switchers&quot;,&quot;Switchers counterfactual y1&quot;,&quot;Switchers counterfactual y0&quot;,&quot;Switchers DIDr&quot;,&quot;Switchers DIDr1&quot;,&quot;Always Treated&quot;,&quot;Always Treated counterfactual y0&quot;)) data.DID.plot$Observed &lt;- factor(c(&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Observed&quot;,&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;,&quot;Generated&quot;),levels=c(&quot;Observed&quot;,&quot;Unobserved&quot;,&quot;Generated&quot;)) WW.before &lt;- (mean(yB[Ds==1])-mean(yB[Ds==0])) WW.after &lt;- (mean(yA[Ds==1])-mean(yA[Ds==0])) BA.AT &lt;- mean(yA[Ds==1])-mean(yB[Ds==1]) BA.Switchers &lt;- mean(yA[Ds==0])-mean(yB[Ds==0]) Counterfactual.after &lt;- mean(yB[Ds==0])+BA.AT DID &lt;- BA.AT - BA.Switchers TTASwitchers &lt;- mean(alphaA[Ds==0]) TTBSwitchers &lt;- mean(alphaB[Ds==0]) TTAAT &lt;- mean(alphaA[Ds==1]) TTBAT &lt;- mean(alphaB[Ds==1]) ggplot(data.DID.plot,aes(x=Period,y=Outcome,group=Group,color=Group,shape=Group,linetype=Observed))+ geom_line() + geom_point()+ scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.25: Evolution of average outcomes in the always treated and switchers group in the reverse DID design where everyone is treated in the first period and treatment effects that vary in the same way among switchers and always takers As expected from Theorem 4.16, Figure 4.25 shows that DID almost estimates the effect of the treatment on the switchers in the second period. This makes sense, since the change in outcomes for the switchers in the presence of the treatment (0.16) is well approximated by the observed change in outcomes for the always treated (0.14). According to Lemma 4.6, this is because the change in treatment effect over time for the always treated (\\(\\hat\\Delta^{Y_A}_{TT}-\\Delta^{Y_B}_{TT}=\\) 0.24 \\(-\\) 0.17 \\(=\\) 0.07) is close to the change in treatment effect over time for the switchers (\\(\\hat\\Delta^{Y_A}_{TUT}-\\hat\\Delta^{Y_B}_{TUT}=\\) 0.3 \\(-\\) 0.17 \\(=\\) 0.12). Note that the DID estimator is still biased for the effect of the treatment on the switchers in the first period, because the treatment effect on the always takers changes over time (Lemma 4.6). Remark. Note that in this model, DID does not identify \\(\\Delta^{Y_A}_{TUT}\\). The reasons why are left as an exercise. Remark. We can relax Assumption 4.22 by redefining the potential outcomes observed after the switchers exit from the treatment as the potential outcomes observed when the treatment stops after having been experienced. One way to parameterize this potential outcome is to make it a function of the time elapsed since exiting the treatment: \\(Y^0_{i,t}(\\tau)\\), where \\(\\tau\\) denotes the number of periods after exiting the treatment. For the switchers, in period \\(A\\), \\(\\tau=1\\), for example. One can then show that the DID estimator identifies the effect of the treatment relative to exiting the treatment: \\(\\Delta^Y_{DID}=\\esp{Y^1_{i,A}-Y^0_{i,A}(1)|D_i=0}\\) under Assumptions 4.21 and 4.19. The proof is left as an exercise. 4.3.3 Difference In Differences with multiple time periods In real life, we generally have access to several time periods before and after the treatment date. What happens to DID in that case? Well, several things actually happen: We now have several pre-treatment observations for each unit. Which one should we choose to form our DID estimator? If we use all of them, should we combine them? If yes, how? We also have several post-treatment observations. Which one should we choose to form our DID estimator? If we use all of them, should we combine them? If yes, how? We also have some units that will be treated for several periods in a row. Should we use them to form a \\(DID^r\\) estimator? If yes, should we combine them with the DID estimates? If yes, how? We also might have some units that exit the treatment after some time. Should we use them to form a DID estimator? Should we combine this estimate with the others? If yes, how? There is a lot of questions. In order to be able to answer them, I am for the moment going to abstract from the last one. I am going to assume that once a unit has entered the treatment, it cannot exit it. DID designs such as these are called staggered designs. This is obviously a very strong assumption, but we will relax it at some point. Let’s go now. 4.3.3.1 Identification In this section, we are going to define rigorously the setting that we have in front of us and the several treatment effects that we might want to estimate. This will be the most important part of the identification exercise. Once the definitions are in place, identification will be mostly straightforward. In a DID design with multiple time periods, time flows from \\(t=1\\) to \\(t=T\\). \\(D_{i,t}\\) takes value one when unit \\(i\\) is treated at period \\(t\\) and zero otherwise. In a staggered design, once treated, a unit is treated forever (the treatment is said to be an absorbing state). As a consequence, we can characterize units by the date at which they start to be treated. We are going to call this variable \\(D_{i}\\) and it takes values in the set \\(\\left\\{1,2,\\dots,T,\\infty\\right\\}\\). Units treated at period \\(1\\) (or even before, we cannot say for sure) are always treated in a staggered design. Then, units enter at successive periods until the last one. Finally, some units may never receive the treatment (never takers). By convention, we denote them with \\(D_{i}=\\infty\\). We can define a separate treatment effect for each of the treatment groups and for each time period: \\(\\Delta^{Y_{\\tau}}_{TT_d}=\\esp{Y^1_{i,d+\\tau}-Y^0_{i,d+\\tau}|D_i=d}\\), for \\(\\tau,d\\in\\left\\{1,2,\\dots,T\\right\\}\\). We can also form a very large bunch of DID estimators: \\[\\begin{align*} \\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;) &amp; = \\esp{Y_{i,d+\\tau}|D_i=d}-\\esp{Y_{i,d-\\tau&#39;}|D_i=d}-(\\esp{Y_{i,d+\\tau}|D_i=d&#39;}-\\esp{Y_{i,d-\\tau&#39;}|D_i=d&#39;}), \\end{align*}\\] where \\(\\tau,\\tau&#39;&gt;0\\) and \\(d&#39;&gt;d+\\tau\\). \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) tries to estimate the effect of the treatment on units that first entered the treatment at period \\(t=d\\) (the treated group here) using the units that received the treatment at period \\(d&#39;&gt;d\\) as a benchmark. \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) compares how outcomes have changed between \\(\\tau\\) periods after the treatment and \\(\\tau&#39;\\) periods before the treatment. Imposing \\(d&#39;&gt;d+\\tau\\) ensures that \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) is a proper DID estimator. If \\(d-\\tau&#39;&lt;d&#39;&lt;d+\\tau\\), \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) is not a proper DID estimator since units in group \\(d&#39;\\) also receive the treatment between the two dates at which outcomes are measured. When \\(d&#39;&lt;d-\\tau&#39;\\), \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) compares the change in outcomes in the group entering the treatment at date \\(d\\) with the changes in outcomes occurring in a group that has already entered the treatment at a date \\(d&#39;\\) that is prior the starting date of the DID. Since this estimator is a \\(DID^r\\) estimator, I am going to denote it as such in the future. \\(\\Delta^{Y}_{DID^r}(d,d&#39;,\\tau,\\tau&#39;)\\) is well-defined only when \\(d&#39;&lt;d-\\tau&#39;\\). Before stating our first identification result, let us make some assumptions that will mirror the simpler ones we made in the previous section. First, we are going to assume that at least some units are untreated at some period: Hypothesis 4.23 (Some Units are Not Treated) We assume that not all units in the population are treated in the first period: \\(\\Pr(D_i=1)&lt;1\\). Next, we assume that agents cannot anticipate the treatment: Hypothesis 4.24 (No Anticipation Effects over Time) We assume that agents cannot anticipate that the program will happen and that they do not change their behavior as a consequence: \\(Y_{i,t}=Y^0_{i,t}\\), \\(\\forall i\\in \\left\\{i:D_i=d\\right\\}\\), \\(\\forall t&lt;d\\). As a consequence of Assumptions 4.23 and 4.24, we can write observed outcomes as a function of treatment and potential outcomes using the usual switching equation. The final very important assumption that we can make is to assume that the trends in the potential outcomes in the absence the treatment are the same for the treated and the untreated units: Hypothesis 4.25 (Parallel Trends for All Groups) We assume that the trends in the potential outcomes in the absence the treatment are the same for all the treatment groups: \\[\\begin{align*} \\forall d,t,t&#39;\\in\\left\\{1,2,\\dots,T\\right\\} &amp; = \\esp{Y^0_{i,t}|D_i=d} - \\esp{Y^0_{i,t&#39;}|D_i=d} = \\esp{Y^0_{i,t}|D_i=\\infty} - \\esp{Y^0_{i,t&#39;}|D_i=\\infty}. \\end{align*}\\] We are now ready to state our main identification result: Theorem 4.18 (DID identifies TT at Each Point in Time) Under Assumptions 4.23, 4.24 and 4.25, the DID estimator identifies the average effect of the Treatment on the Treated in each time period: \\[\\begin{align*} \\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;) &amp; = \\Delta^{Y_{\\tau}}_{TT_d}, \\end{align*}\\] where \\(\\tau,\\tau&#39;&gt;0\\) and \\(d&#39;&gt;d+\\tau\\). Proof. \\[\\begin{align*} \\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;) &amp; = \\esp{Y_{i,d+\\tau}-Y_{i,d-\\tau&#39;}|D_i=d}-\\esp{Y_{i,d+\\tau}-Y_{i,d-\\tau&#39;}|D_i=d&#39;}\\\\ &amp; = \\esp{Y^1_{i,d+\\tau}-Y^0_{i,d-\\tau&#39;}|D_i=d}-\\esp{Y^0_{i,d+\\tau}-Y^0_{i,d-\\tau&#39;}|D_i=d&#39;}\\\\ &amp; = \\esp{Y^1_{i,d+\\tau}-Y^0_{i,d-\\tau&#39;}|D_i=d}-\\esp{Y^0_{i,d+\\tau}-Y^0_{i,d-\\tau&#39;}|D_i=d}\\\\ &amp; = \\esp{Y^1_{i,d+\\tau}-Y^0_{i,d+\\tau}|D_i=d} \\end{align*}\\] where the second equality follows from Assumptions 4.23 and 4.24 and the fact that \\(d&#39;&gt;d+\\tau\\). The third equality follows from Assumption 4.25. This proves the result. Theorem 4.18 shows that the basic mechanics of the DID estimator extends to multiple periods. The problem with Theorem 4.18 is that we now have multiple ATT estimates for various groups and time periods, using various time periods and groups as reference. How do we reconcile all of these estimates in a unique parameter, or at least a vector of parameters that makes some sense? Let’s define sets of positive weights \\(w^k(d,d&#39;,\\tau,\\tau&#39;)\\) that sum to one. We can then define a set of DID estimators: \\[\\begin{align*} \\Delta^{Y}_{DID}(k)=\\sum w^k(d,d&#39;,\\tau,\\tau&#39;)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;), \\end{align*}\\] where the sum is taken in coherence with the weights. These DID estimators are going to identify various features of the effects of the treatment, using various types of reference groups and time periods. Let us be more precise: A first set of weights combines the various estimates of the same treatment effect on the outcomes of group \\(d\\) observed at period \\(d=\\tau\\). These weights, which we denote \\(w^s_{d,\\tau}(d&#39;,\\tau&#39;)\\), are such that they take value zero for estimates \\(\\Delta^{Y}_{DID}(d&#39;&#39;,d&#39;,\\tau&#39;&#39;,\\tau&#39;)\\) that are such \\(d&#39;&#39;\\neq d\\) and \\(\\tau&#39;&#39;\\neq\\tau\\) and they have: \\(\\sum_{\\tau&#39;,d&#39;&gt;d+\\tau}w^s_{d,\\tau}(d&#39;,\\tau&#39;)=1\\). One way to define these weights is to make them proportional to the proportion of \\((d&#39;,\\tau&#39;)\\) groups of observations in the population. A second set of weights is going to combine the treatment effects themselves. For example, one might want to measure the average effect of the treatment \\(\\tau\\) periods after entering it. This type of dynamic treatment effect is useful to measure how the effect of the treatment varies over time. There are two versions of this set of weights: one unconditional and one conditional on at least reaching a certain number of periods in the treatment (let’s say \\(\\tau&#39;&#39;&gt;\\tau\\) periods after the treatment). With the second version, all the estimates of the dynamic effects of the treatment are going to be taken over the same set of groups. With the first version, changes in treatment effects over time might be confounded by changes in group composition. Let’s denote the first type of weights \\(w^u_{\\tau}(d,d&#39;,\\tau&#39;)\\) and the second \\(w^c_{\\tau,\\tau&#39;&#39;}(d,d&#39;,\\tau&#39;)\\) , with \\(\\tau&#39;&#39;&gt;\\tau\\). We then have \\(\\Delta^{Y_u}_{DID}(\\tau)=\\sum_{d,d&#39;&gt;d+\\tau,\\tau&#39;} w^u_{\\tau}(d,d&#39;,\\tau&#39;)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) and \\(\\Delta^{Y_c}_{DID}(\\tau,\\tau&#39;&#39;)=\\sum_{d,d&#39;&gt;d+\\tau,\\tau&#39;} w^c_{\\tau,\\tau&#39;&#39;}(d,d&#39;,\\tau&#39;)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). These effects can also be restricted to versions using a single reference period \\(\\tau&#39;\\) to build the DID estimator: \\(\\Delta^{Y_u}_{DID}(\\tau,\\tau&#39;)\\) and \\(\\Delta^{Y_c}_{DID}(\\tau,\\tau&#39;,\\tau&#39;&#39;)\\). A third set of effects is simply taking the average of all the treatment effects at a given time period. Let’s denote these set of weights \\(w^t(d,d&#39;,\\tau,\\tau&#39;)\\) for the effect observed at period \\(t\\). Then, we have \\(\\Delta^{Y_t}_{DID}=\\sum_{\\tau+d=t,d&#39;&gt;d+\\tau,\\tau&#39;} w^t(d,d&#39;,\\tau,\\tau&#39;)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). Another version again uses only estimates taken with period \\(d-\\tau&#39;\\) as a reference: \\(\\Delta^{Y_t}_{DID}(\\tau&#39;)=\\sum_{\\tau+d=t,d&#39;&gt;d+\\tau} w^t_{\\tau&#39;}(d,d&#39;,\\tau)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). Finally, one can simply define the overall effect of the treatment on the treated as the sum of all relevant treatment effects estimated in the sample. Let’s define the set of weights \\(w^a(d,d&#39;,\\tau,\\tau&#39;)\\) and the estimate of the average treatment effect on the treated as \\(\\Delta^{Y}_{DID}=\\sum_{\\tau,d,d&#39;&gt;d+\\tau,\\tau&#39;} w^a(d,d&#39;,\\tau,\\tau&#39;)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). Again, some authors restrict this estimate to be specific to a given reference period: \\(\\Delta^{Y}_{DID}(\\tau&#39;)=\\sum_{\\tau,d,d&#39;&gt;d+\\tau} w^a_{\\tau&#39;}(d,d&#39;,\\tau)\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). As a consequence of Theorem 4.18, all the aggregate treatment effects are identified, as long as each of their separate components are identified. The following corollary makes that clear: Corollary 4.3 (DID identifies Weighted TT) Under Assumptions 4.23, 4.24 and 4.25, assuming that \\(\\Pr(D_i=d)&gt;0\\) and \\(\\Pr(D_i=d&#39;)&gt;0\\), \\(\\forall (d,d&#39;)\\in \\left\\{1,2,\\dots,T,\\infty\\right\\}\\) such that \\(w^k(d,d&#39;,\\tau,\\tau&#39;)&gt;0\\) and assuming that \\(\\forall d,d&#39;,\\tau,\\tau&#39;\\) such that \\(w^k(d,d&#39;,\\tau,\\tau&#39;)&gt;0\\), \\((d+\\tau,d&#39;-\\tau&#39;)\\in\\left\\{1,2,\\dots,T,\\infty\\right\\}^2\\), the weighted DID estimator identifies the corresponding weigthed average of Treatment on the Treated: \\[\\begin{align*} \\Delta^{Y}_{DID}(k) &amp; = \\Delta^{Y}_{TT}(k), \\end{align*}\\] with \\[\\begin{align*} \\Delta^{Y}_{TT}(k) &amp; = \\sum w^k(d,d&#39;,\\tau,\\tau&#39;)\\Delta^{Y_{\\tau}}_{TT_d} \\end{align*}\\] Proof. The proof follows from Theorem 4.18: as long as the groups for which the weights are non null exist, and the time periods for which the weights are non null also exist in the data, Theorem 4.18 ensures that each of the components of the weighted average is identifed and thus the weighted average is identified as well. Before going through an example to illustrate all of these notions, let me introduce one estimator. 4.3.3.2 Estimation Estimation of the various DID estimators that we have defined in the previous section can take several forms. The simplest form estimates the separate individual DID components using the methods seen in Section 4.3.1, and then manually computes their weighted averages. I will detail this approach first. A very similar approach uses the estimates obtained with one reference period (in general \\(\\tau&#39;=1\\)) and combines them to obtain one treatment effect or a series of treatment effects around the treatment date. This approach has been proposed by Sun and Abraham (2021) and by Callaway and Sant’Anna (2021). A more intricate approach uses an imputation model to derive the predicted counterfactual values for all treated observations and then averages them. This approach has been proposed by Borusyak, Jaravel and Speiss (2021), Liu, Wang and Xu (2021) and Gardner (2021). de Chaisemartin and d’Haultfoeuille (2020) propose to only use changes that occur around the treatment date. Finally, one could use the Two Way Fixed Effects model presented in Section 4.3.1, combining all the time periods in a single estimator. Recent work by Goodman-Bacon (2021) has shown that this approach is only valid under much more restrictive assumptions than the ones stated in Corollary 4.3. The main reason for why it is so is that the Two Way Fixed Effects estimator combines individual DID and \\(DID^r\\) estimates, thereby generating strong biases if the assumptions that ensure the validity of \\(DID^r\\) are not valid. An extension to the Two Way Fixed Effects estimator, the stacked DID estimator, restores its good properties. It has been proposed by Cengiz, Dube, Lindner and Zipperer (2019) and extended by Gardner (2021). The R packages required to implement all of these estimators are listed on Asjad Naqvi’s DID webpage. We are going to see how they perform on our data. 4.3.3.2.1 Using weighted averages of individual DID estimators This estimator is pretty simple to define. Simply take all the possible \\(2\\times2\\) possible DID estimators \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\), with \\(\\tau,\\tau&#39;&gt;0\\) and \\(d&#39;&gt;d+\\tau\\), and then average them using the pre-defined weights \\(w^k(d,d&#39;,\\tau,\\tau&#39;)\\) of your choice. The key to this section is to illustrate how to operationalize this approach in practice with an example. Let’s go. Example 4.42 The key here is first to generate some data. We are going to have four successive time periods, \\(1\\), \\(2\\), \\(3\\), and \\(4\\). At each of these time periods, some units start receiving the treatment, generating four treatment groups: \\(D_i\\in\\{1,2,3,4\\}\\). Let us write a model compatible with this setting, choose a parameterization and generate the data. \\[\\begin{align*} y^1_{i,t} &amp; = y_{i,t}^0+\\bar{\\alpha}_t+\\sum_{d}(\\bar{\\alpha}_{t,d}+\\theta_d\\mu_i)\\uns{D_{i,d}=1}+\\eta_{i,t} \\\\ y^0_{i,t} &amp; = \\mu_i+\\delta_t+U^0_{i,t} \\\\ U^0_{i,t} &amp; = \\rho U^0_{i,t-1}+\\epsilon_{i,t} \\\\ D_{i,t} &amp; = \\uns{y^0_{i,1} + \\xi_t+ V_i\\leq\\bar{y}} \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_{i,1} \\\\ U^0_{i,1} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ (\\eta_{i,t},\\omega_{i,t}) &amp; \\sim\\mathcal{N}(0,0,\\sigma^2_{\\eta},\\sigma^2_{\\omega},\\rho_{\\eta,\\omega})\\\\ \\epsilon_{i,t} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{\\epsilon}). \\end{align*}\\] I am going to parameterize the \\(\\bar{\\alpha}_{t,d}\\) process in order to avoid having to specify the 14 parameters that it otherwise would require. The parameterization I am choosing is \\(\\bar{\\alpha}_{t,d}=\\bar\\chi_d+\\kappa_d(t-d)\\uns{t\\geq d}\\), so that treatment effects increase linearly as time into the treatment increases. Let us now choose some parameter values: param &lt;- c(8,.5,.28,1500,0.9, 0.01,0.01,0.01,0.01, 0.05,0.05, 0,0.1,0.2,0.3, 0.05,0.1,0.15,0.2, 0.25,0.1,0.05,0, 1.5,1.25,1,0.75, 0.5,0,-0.5,-1, 0.1,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;, &quot;theta1&quot;,&quot;theta2&quot;,&quot;theta3&quot;,&quot;theta4&quot;, &quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;, &quot;delta1&quot;,&quot;delta2&quot;,&quot;delta3&quot;,&quot;delta4&quot;, &quot;baralpha1&quot;,&quot;baralpha2&quot;,&quot;baralpha3&quot;,&quot;baralpha4&quot;, &quot;barchi1&quot;,&quot;barchi2&quot;,&quot;barchi3&quot;,&quot;barchi4&quot;, &quot;kappa1&quot;,&quot;kappa2&quot;,&quot;kappa3&quot;,&quot;kappa4&quot;, &quot;xi1&quot;,&quot;xi2&quot;,&quot;xi3&quot;,&quot;xi4&quot;, &quot;gamma&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) Let us now generate the corresponding data (in long format): set.seed(1234) N &lt;- 1000 T &lt;- 4 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) data &lt;- as.data.frame(mvrnorm(N*T,c(0,0),cov.eta.omega)) colnames(data) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) # time and individual identifiers data$time &lt;- c(rep(1,N),rep(2,N),rep(3,N),rep(4,N)) data$id &lt;- rep((1:N),T) # unit fixed effects data$mu &lt;- rep(rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])),T) # time fixed effects data$delta &lt;- c(rep(param[&quot;delta1&quot;],N),rep(param[&quot;delta2&quot;],N),rep(param[&quot;delta3&quot;],N),rep(param[&quot;delta4&quot;],N)) data$baralphat &lt;- c(rep(param[&quot;baralpha1&quot;],N),rep(param[&quot;baralpha2&quot;],N),rep(param[&quot;baralpha3&quot;],N),rep(param[&quot;baralpha4&quot;],N)) # building autocorrelated error terms data$epsilon &lt;- rnorm(N*T,0,sqrt(param[&quot;sigma2epsilon&quot;])) data$U[1:N] &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) data$U[(N+1):(2*N)] &lt;- param[&quot;rho&quot;]*data$U[1:N] + data$epsilon[(N+1):(2*N)] data$U[(2*N+1):(3*N)] &lt;- param[&quot;rho&quot;]*data$U[(N+1):(2*N)] + data$epsilon[(2*N+1):(3*N)] data$U[(3*N+1):(T*N)] &lt;- param[&quot;rho&quot;]*data$U[(2*N+1):(3*N)] + data$epsilon[(3*N+1):(T*N)] # potential outcomes in the absence of the treatment data$y0 &lt;- data$mu + data$delta + data$U data$Y0 &lt;- exp(data$y0) # treatment timing # error term data$V &lt;- param[&quot;gamma&quot;]*(data$mu-param[&quot;barmu&quot;])+data$omega # treatment group, with 99 for the never treated instead of infinity Ds &lt;- if_else(data$y0[1:N]+param[&quot;xi1&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),1, if_else(data$y0[1:N]+param[&quot;xi2&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),2, if_else(data$y0[1:N]+param[&quot;xi3&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),3, if_else(data$y0[1:N]+param[&quot;xi4&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),4,99)))) data$Ds &lt;- rep(Ds,T) # Treatment status data$D &lt;- if_else(data$Ds&gt;data$time,0,1) # potential outcomes with the treatment # effect of the treatment by group data$baralphatd &lt;- if_else(data$Ds==1,param[&quot;barchi1&quot;], if_else(data$Ds==2,param[&quot;barchi2&quot;], if_else(data$Ds==3,param[&quot;barchi3&quot;], if_else(data$Ds==4,param[&quot;barchi4&quot;],0))))+ if_else(data$Ds==1,param[&quot;kappa1&quot;], if_else(data$Ds==2,param[&quot;kappa2&quot;], if_else(data$Ds==3,param[&quot;kappa3&quot;], if_else(data$Ds==4,param[&quot;kappa4&quot;],0))))*(data$t-data$Ds)*if_else(data$time&gt;=data$Ds,1,0) data$y1 &lt;- data$y0 + data$baralphat + data$baralphatd + if_else(data$Ds==1,param[&quot;theta1&quot;],if_else(data$Ds==2,param[&quot;theta2&quot;],if_else(data$Ds==3,param[&quot;theta3&quot;],param[&quot;theta4&quot;])))*data$mu + data$eta data$Y1 &lt;- exp(data$y1) data$y &lt;- data$y1*data$D+data$y0*(1-data$D) data$Y &lt;- data$Y1*data$D+data$Y0*(1-data$D) Let us now plot the data, especially the potential outcomes for each group. dataplotDIDStaggered &lt;- data %&gt;% group_by(Ds,time) %&gt;% summarize( y1=mean(y1), y0=mean(y0) ) %&gt;% pivot_longer(cols=c(&quot;y1&quot;,&quot;y0&quot;),values_to=&quot;Outcome&quot;,names_to=&quot;PotentialOutcome&quot;) %&gt;% mutate( TreatmentDate = factor(Ds,levels=c(&quot;99&quot;,&quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;1&quot;)) ) ggplot(dataplotDIDStaggered,aes(x=time,y=Outcome,color=TreatmentDate,shape=TreatmentDate,linetype=PotentialOutcome))+ geom_line() + geom_point()+ # scale_linetype_discrete(guide=&#39;none&#39;) + theme_bw() Figure 4.26: Evolution of average outcomes in the various treatment groups defined by their date of entry into the treatment Figure 4.26 shows that the first units to be treated have the lowest potential outcomes in the absence of the treatment (\\(y^0\\), in full line), and that each successive cohort entering the treatment over time has increasingly large potential outcomes. Assumption 4.25 seems to hold in this dataset, at least visually: the trends in potential outcomes in the absence of the treatment seem to be rather parallel to each other in each group. Once a group of unit has entered the treatment, it experiences an increase in outcomes that grows over time. Finally, note that we will be unable to estimate the impact on the group with \\(D_i=1\\) since they enter the treatment at the first period. Let us now compute each possible DID estimator on this dataset. In order to save some space and time, we will start by focusing on group 2. Group 2 starts treatment at period 2, and thus only period 1 can be used for building a DID estimator. But several comparison groups exist: the never treated (note that we have used \\(D_i=99\\) instead of \\(D_i=\\infty\\) to characterize this group, in order to make it simpler to manipulate it in R) but also group 3, that can serve as an untreated benchmark between periods 1 and 2, and group 4, which can be used as an untreated benchmark in periods 1, 2 and 3. Let’s compute all these effects. In order to make our lives simpler, we are going to generate a function to generate \\(\\hat\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\). # StaggeredDID22 is a function that takes as inputs: # y: name of outcome variable (character) # D: name of treatment group variable (character) # d: treatment group defined by date of entry into the treatment # dprime: comparison group # tau: number of periods after treatment date at which we estimate the effect of the treatment # tauprime: number of periods before the treatment date that we use a baseline period (defaults to one) # t: time indicator (character) # i: individual unit indicator (character) # data: dataset containing the outcomes and treatments and time and unit indicators StaggeredDID22 &lt;- function(tau,y,D,d,dprime,tauprime=1,t,i,data){ # taking out the irrelevant groups and time periods and generating a useful treatment variable data.DID &lt;- data %&gt;% filter(!!sym(D)==d | !!sym(D)==dprime) %&gt;% filter(time==d+tau | time==d-tauprime) %&gt;% mutate( Dit = if_else(!!sym(D)==d &amp; time==d+tau,1,0) ) # running the within estimator (fixest) # regression formula DID.form &lt;- as.formula(paste(paste(y,paste(&quot;Dit&quot;,t,sep=&quot;+&quot;),sep=&quot;~&quot;),i,sep=&quot;|&quot;)) reg.W.fixest &lt;- feols(DID.form, data = data.DID) # result vector DID.est.W.fixest &lt;- c(d,dprime,tau,tauprime,coef(reg.W.fixest)[[1]],sqrt(vcov(reg.W.fixest)[[1,1]])) names(DID.est.W.fixest) &lt;- c(&quot;d&quot;,&quot;dprime&quot;,&quot;tau&quot;,&quot;tauprime&quot;,&quot;DIDest&quot;,&quot;DIDse&quot;) return(DID.est.W.fixest) } # Run the regression and keep results # D=99 as benchmark # list of tau for d=2 and dprime=99 and tauprime=1 tau.2.99 &lt;- c(0,1,2) DID.2.99.1 &lt;- map_dfr(tau.2.99,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=2,dprime=99,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # D=3 # list of tau for d=2 and dprime=3 and tauprime=1 tau.2.3 &lt;- c(0) DID.2.3.1 &lt;- map_dfr(tau.2.3,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=2,dprime=3,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # D=4 # list of tau for d=2 and dprime=4 and tauprime=1 tau.2.4 &lt;- c(0,1) DID.2.4.1 &lt;- map_dfr(tau.2.4,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=2,dprime=4,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # regroup results DID.2.1 &lt;- rbind(DID.2.99.1,DID.2.3.1,DID.2.4.1) # true effects (in the sample) ATT.2.0 &lt;- mean(data$y1[data$Ds==2 &amp; data$time==2])-mean(data$y0[data$Ds==2 &amp; data$time==2]) ATT.2.1 &lt;- mean(data$y1[data$Ds==2 &amp; data$time==3])-mean(data$y0[data$Ds==2 &amp; data$time==3]) ATT.2.2 &lt;- mean(data$y1[data$Ds==2 &amp; data$time==4])-mean(data$y0[data$Ds==2 &amp; data$time==4]) Let us now plot the results for the DID estimates on group \\(2\\) using \\(\\tau&#39;=1\\) as a benchmark pre-treatment period. # preparing data DID.2.1 &lt;- DID.2.1 %&gt;% mutate( dprime=factor(dprime,levels=c(&quot;99&quot;,&quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;1&quot;)) ) # plot ggplot(DID.2.1,aes(x=tau,y=DIDest,colour=dprime,linetype=dprime))+ geom_line() + geom_pointrange(aes(ymin=DIDest-1.96*DIDse,ymax=DIDest+1.96*DIDse))+ ylab(&quot;DID estimate&quot;) + xlab(&quot;Time after treatment (tau)&quot;) + scale_x_continuous(breaks=c(0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Comparison\\ngroup&quot;)+ scale_linetype_discrete(name=&quot;Comparison\\ngroup&quot;)+ theme_bw() Figure 4.27: DID estimates for Group 2 at various time periods after the treament and with various comparison groups and with the reference period \\(\\tau&#39;=1\\) Figure 4.27 shows the \\(\\hat\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\) estimates for \\(d=2\\) and \\(\\tau&#39;=1\\), varying both \\(\\tau\\) and \\(d&#39;\\). The treatment effects estimated using different reference groups are similar to each other when we can compare them. Moreover, the treatment effect grows with time, as expected from Figure 4.26. The true effects of the treatment on group 2 are, in our sample: \\(\\hat\\Delta^{Y_{0}}_{TT_2}=\\) 0.31, \\(\\hat\\Delta^{Y_{1}}_{TT_2}=\\) 1.56 and \\(\\hat\\Delta^{Y_{2}}_{TT_2}=\\) 2.86. These are very close to our DID estimates. For example, \\(\\hat\\Delta^{Y}_{DID}(2,99,0,1)=\\) 0.37, while \\(\\hat\\Delta^{Y}_{DID}(2,4,0,1)=\\) 0.31 and \\(\\hat\\Delta^{Y}_{DID}(2,3,0,1)=\\) 0.3, which are all pretty close to \\(\\hat\\Delta^{Y_{0}}_{TT_2}=\\) 0.31. \\(\\hat\\Delta^{Y}_{DID}(2,99,1,1)=\\) 1.65, while \\(\\hat\\Delta^{Y}_{DID}(2,4,1,1)=\\) 1.57, which are also all pretty close to \\(\\hat\\Delta^{Y_{1}}_{TT_2}=\\) 1.56. Finally, \\(\\hat\\Delta^{Y}_{DID}(2,99,2,1)=\\) 2.99, while \\(\\hat\\Delta^{Y_{2}}_{TT_2}=\\) 2.86. In order to aggregate the estimates presented in Figure 4.27, we could for example use the proportion of each comparison group in the sample and average the treatment effects for each post treatment period \\(\\tau\\) with these weights. We can do the same thing with groups 3 and 4 and see what happens. Note that with these two groups, I can also estimate a placebo test: that is the effect of the treatment before the treatment takes place. Such event study estimates have become standard in the DID literature. I will expand on these tests in Section 8. For group 3, I can estimate the effect for \\(\\tau\\in\\{-2,0,1\\}\\) and for group 4, for \\(\\tau\\in\\{-3,-2,0\\}\\), when the benchmark group is the never treated group. # do the DID22 estimates for d=3 # Run the regression and keep results # D=99 as benchmark # list of tau for d=3 and dprime=99 and tauprime=1 tau.3.99 &lt;- c(-2,0,1) DID.3.99.1 &lt;- map_dfr(tau.3.99,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=3,dprime=99,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # D=4 as a benchmark # list of tau for d=3 and dprime=4 and tauprime=1 tau.3.4 &lt;- c(-2,0) DID.3.4.1 &lt;- map_dfr(tau.3.4,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=3,dprime=4,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # regroup results DID.3.1 &lt;- rbind(DID.3.99.1,DID.3.4.1) # true effects (in the sample) ATT.3.0 &lt;- mean(data$y1[data$Ds==3 &amp; data$time==3])-mean(data$y0[data$Ds==3 &amp; data$time==3]) ATT.3.1 &lt;- mean(data$y1[data$Ds==3 &amp; data$time==4])-mean(data$y0[data$Ds==3 &amp; data$time==4]) # do the DID22 estimates for d=4 # Run the regression and keep results # D=99 as benchmark # list of tau for d=4 and dprime=99 and tauprime=1 tau.4.99 &lt;- c(-3,-2,0) DID.4.99.1 &lt;- map_dfr(tau.4.99,StaggeredDID22,y=&#39;y&#39;,D=&#39;Ds&#39;,d=4,dprime=99,tauprime=1,t=&quot;time&quot;,i=&quot;id&quot;,data=data) # true effects (in the sample) ATT.4.0 &lt;- mean(data$y1[data$Ds==4 &amp; data$time==4])-mean(data$y0[data$Ds==4 &amp; data$time==4]) # regrouping all effects DID.1 &lt;- rbind(DID.2.1,DID.3.1,DID.4.99.1) # computing the weights prop.groups.DID &lt;- data %&gt;% filter(time==1) %&gt;% group_by(Ds) %&gt;% summarize( prop.group = n()/N ) %&gt;% rename( dprime=Ds )%&gt;% mutate( dprime=factor(dprime,levels=c(&quot;99&quot;,&quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;1&quot;)) ) # joining the weights to the results DID.1 &lt;- DID.1 %&gt;% left_join(prop.groups.DID,by=c(&quot;dprime&quot;)) # generating the weighted averages by tau DID.tau &lt;- DID.1 %&gt;% mutate( w.ATT = prop.group*DIDest ) %&gt;% group_by(tau,d) %&gt;% summarize( sum.w.ATT = sum(w.ATT), sum.w = sum(prop.group) ) %&gt;% mutate( ATT.tau = sum.w.ATT/sum.w ) %&gt;% select(d,tau,ATT.tau) %&gt;% mutate( d=factor(d,levels=c(&quot;2&quot;,&quot;3&quot;,&quot;4&quot;)) ) # adding the reference period DID.ref &lt;- as.data.frame(rbind(c(2,-1,0),c(3,-1,0),c(4,-1,0))) colnames(DID.ref) &lt;- colnames(DID.tau) DID.ref$d &lt;- factor(DID.ref$d,levels=c(&quot;2&quot;,&quot;3&quot;,&quot;4&quot;)) DID.tau &lt;- rbind(DID.tau,DID.ref) Let us now plot the results for the DID estimates in groups \\(2\\), \\(3\\) and \\(4\\) using \\(\\tau&#39;=1\\) as a benchmark pre-treatment period and aggregating the estimates using every possible valid control group: ggplot(DID.tau,aes(x=tau,y=ATT.tau,colour=d,linetype=d))+ geom_line() + geom_point() + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time after treatment (tau)&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Treatment\\ngroup&quot;)+ scale_linetype_discrete(name=&quot;Treatment\\ngroup&quot;)+ theme_bw() Figure 4.28: DID estimates for all groups at various time periods after the treament aggregated across all comparison groups and with the reference period \\(\\tau&#39;=1\\) On Figure 4.28, we can see that all the estimators are comparable for each other at each time period \\(\\tau\\), no matter the treatment group. We thus can aggregate the impacts at each period \\(\\tau\\) across all treatment groups. There are two ways to do that: one is to use all the groups for which we observe the effect of the treatment at period \\(\\tau\\). The drawback of this approach is that group composition changes with \\(\\tau\\). For example, on Figure 4.28, we can see that the treatment group treated in the last period (for which \\(D_i=4\\)) contributes only to the computation of the effect of the treatment at period \\(\\tau=0\\). This is because we cannot observe what happens to this group in later periods with our dataset. As a consequence, in period \\(\\tau=0\\), all three groups–\\(D_i=2\\), \\(D_i=3\\) and \\(D_i=4\\)–contribute to the estimation of the effect of the treatment, whereas only groups with \\(D_i=2\\) and \\(D_i=3\\) contribute to the estimation of the effect at \\(\\tau=1\\), and only \\(D_i=2\\) contributes to estimating the effect at \\(\\tau=2\\). If treatment effects were heterogeneous across treatment groups, this change in group composition would confound actual changes in the magnitude of treatment effects. Since the effect of the treatment is rather homogenous across groups, this group comopsition problem will not matter in our application. Nevertheless, we are still going to estimate the effect of the treatment at \\(\\tau=0\\) and \\(\\tau=1\\) maintaining group composition constant (\\(D_i=2\\) and \\(D_i=3\\)). In our application, both approaches will yield very similar results. The weights we are going to use for our aggregation are the proportions of units belonging to each group. # joining the weights to the results DID.tau &lt;- DID.tau %&gt;% left_join(prop.groups.DID,by=c(&quot;d&quot;=&quot;dprime&quot;)) # generating the weighted averages by tau (varying group composition) DID.tau.agg &lt;- DID.tau %&gt;% mutate( w.ATT = prop.group*ATT.tau ) %&gt;% group_by(tau) %&gt;% summarize( sum.w.ATT = sum(w.ATT), sum.w = sum(prop.group) ) %&gt;% mutate( ATT.tau.agg = sum.w.ATT/sum.w ) %&gt;% select(tau,ATT.tau.agg) %&gt;% mutate( Composition=&quot;Varying&quot; ) # generating the weighted averages by tau (constant group composition) DID.tau.agg.cst &lt;- DID.tau %&gt;% filter(d==2 | d==3) %&gt;% filter(tau==0 | tau==1) %&gt;% mutate( w.ATT = prop.group*ATT.tau ) %&gt;% group_by(tau) %&gt;% summarize( sum.w.ATT = sum(w.ATT), sum.w = sum(prop.group) ) %&gt;% mutate( ATT.tau.agg = sum.w.ATT/sum.w ) %&gt;% select(tau,ATT.tau.agg) %&gt;% mutate( Composition=&quot;Constant&quot; ) #regrouping estimates DID.tau.agg.tot &lt;- rbind(DID.tau.agg,DID.tau.agg.cst) %&gt;% mutate( Composition = factor(Composition,levels=c(&quot;Constant&quot;,&quot;Varying&quot;)) ) Let’s plot the resulting estimates. ggplot(DID.tau.agg.tot,aes(x=tau,y=ATT.tau.agg,colour=Composition,linetype=Composition))+ geom_line() + geom_point() + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time after treatment (tau)&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Group\\ncomposition&quot;)+ scale_linetype_discrete(name=&quot;Group\\ncomposition&quot;)+ theme_bw() Figure 4.29: DID estimates at various time periods after the treament aggregated across all treatment groups and maintaining treatment group composition constant (reference period \\(\\tau&#39;=1\\)) As expected, Figure 4.29 confirms that group composition does not play an important role in treatment effect heterogeneity: there actually is a true heterogeneity along the time dimension: the treatment effect seems to increase linearly over time (as we suspected it would, since we parameterized our model just like it). Another plot that might prove very helpful is the one combining the aggregated estimates obtained in Figure 4.29 with the estimates obtained on each subgroup. This plot helps understand the source of heterogeneity in the profile of the aggregated treatment effects by attributing it to true treatment effect heterogeneity or to changes in group composition. Let’s go: # building the dataset DID.tau.agg.tot.inter &lt;- DID.tau.agg.tot %&gt;% filter(Composition==&quot;Varying&quot;) %&gt;% select(tau,ATT.tau.agg) %&gt;% rename( ATT.tau=ATT.tau.agg ) %&gt;% mutate( d = &quot;Aggregate&quot;, prop.group=0 ) DID.tau &lt;- rbind(DID.tau,DID.tau.agg.tot.inter) %&gt;% mutate( d=factor(d,levels=c(&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;Aggregate&quot;)) ) # plotting the result ggplot(DID.tau,aes(x=tau,y=ATT.tau,colour=d,linetype=d))+ geom_line() + geom_point() + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time after treatment (tau)&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Group\\ncomposition&quot;)+ scale_linetype_discrete(name=&quot;Group\\ncomposition&quot;)+ theme_bw() Figure 4.30: DID estimates at various time periods after the treament aggregated across all treatment groups (reference period \\(\\tau&#39;=1\\)) Finally, let us aggregate all treatment effects from all periods into one unique estimate. It is not an easy feat, especially in our current example which exhibits lots of treatment effect heterogeneity over \\(\\tau\\). Should we simply aggregate all treatment effect estimates using equal weights for each period \\(\\tau\\) or, rather, should we try to reflect the actual composition of treated groups and time periods in the sample? The choice of the mode of aggregation might make a huge difference to the eventual result, since giving more weights to higher \\(\\tau\\) will result in a much higher overall treatment effect. Let’s see what happens with both approaches. # aggregating by weighing equally each time period tau ATT.equal &lt;- DID.tau.agg.tot %&gt;% filter(Composition==&quot;Varying&quot;,tau&gt;=0) %&gt;% summarize( ATT.equal = mean(ATT.tau.agg) ) %&gt;% pull(ATT.equal) # aggregating by weighing as a proportion of time spent by each group in the treatment state ATT.varying &lt;- DID.tau %&gt;% ungroup() %&gt;% filter(d!=&quot;Aggregate&quot;,tau&gt;=0) %&gt;% mutate( w.ATT = prop.group*ATT.tau ) %&gt;% summarize( sum.w.ATT = sum(w.ATT), sum.w = sum(prop.group) ) %&gt;% mutate( ATT.varying = sum.w.ATT/sum.w ) %&gt;% pull(ATT.varying) The average effect of the treatment, giving equal weight to each time period \\(\\tau\\in\\{0,1,2\\}\\), is equal to \\(\\hat\\Delta^{Y}_{TT}(e)=\\) 1.59, where \\(e\\) stands for “equal” weights. The average effect of the treatment, giving weights proportional to group composition and time spent in the treatment is equal to \\(\\hat\\Delta^{Y}_{TT}(v)=\\) 1.06, where \\(v\\) stands for “varying” weights. 4.3.3.2.2 Direct weighting using one reference period and one reference group (Sun and Abraham) OK, so now, we know how to compute the various DID estimators by hand and how to aggregate them. Is there a way to obtain directly an aggregated estimate with an R package? Yes, actually, plenty of such estimator exist. They are listed on Asjad Naqvi’s DID webpage. Let’s start with the ones implementing the Sun and Abraham (2021) estimator. Sun and Abraham (2021)’s estimator start with estimating a Two Way Fixed Effect model with a rich dynamic specification: \\[\\begin{align*} Y_{i,t} &amp; = \\mu_i + \\delta_t + \\sum_{d=2}^T\\sum_{\\tau\\neq-1}\\beta_{d,\\tau}^{SA}\\uns{D_{i}=d \\land t=d+\\tau} + \\epsilon^{SA}_{i,t}, \\end{align*}\\] on the sample excluding the always treated individuals (\\(D_i=1\\)). In order to be consistent with previous estimators, we are going to start using the fixest package to obtain our estimator. In order to be able to estimate Sun and Abraham (2021)’s estimator with fixest, we simply are going to add a sunab(d,t) term to the feols command, with the first term giving the treatment group and the second term the time fixed effect. We then can aggregate the estimated terms using regexp in order to detect the string patterns. Example 4.43 Let’s go: # regression reg.fixest.SA.Agg &lt;- feols(y ~ sunab(Ds,time)| id + time, data=filter(data,Ds&gt;1)) # aggregate estimate (this is a command specific to fixest that aggregates various coefficients where an i. specification was used) # The selection of coefficients to aggregate uses a string detection pattern language # varying composition aggregate.SA.varying &lt;- aggregate(reg.fixest.SA.Agg, c(&quot;tau&quot; = &quot;time::([[:digit:]]+)&quot;)) # another approach using the i function: not run, but works # creating a time to treatment variable: # data &lt;- data %&gt;% # mutate( # tau=time-Ds # ) %&gt;% # mutate( # tau = replace(tau,tau&lt;=-90,-99) # ) # regression # reg.fixest.SA.nonAgg &lt;- feols(y ~ i(tau,i.Ds,ref=c(-1,-99))| id + time, data=filter(data,Ds&gt;1)) # aggregate estimate (this is a command specific to fixest that aggregates various coefficients where an i. specification was used) # The selection of coefficients to aggregate uses a string detection pattern language # varying composition # aggregate.SA.nonAgg.varying &lt;- aggregate(reg.fixest.SA.nonAgg, c(&quot;tau&quot; = &quot;tau::([[:digit:]]+)&quot;)) Let’s plot the results: # preparation colnames(aggregate.SA.varying) &lt;- c(&quot;ATT&quot;,&quot;Se&quot;,&quot;t&quot;,&quot;pval&quot;) aggregate.SA.varying &lt;- aggregate.SA.varying %&gt;% as.data.frame(.) %&gt;% mutate(tau = 0:2) # plot ggplot(aggregate.SA.varying,aes(x=tau,y=ATT))+ geom_line() + geom_pointrange(aes(ymin=ATT-1.96*Se,ymax=ATT+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time after treatment (tau)&quot;) + scale_x_continuous(breaks=c(0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Group\\ncomposition&quot;)+ scale_linetype_discrete(name=&quot;Group\\ncomposition&quot;)+ theme_bw() Figure 4.31: DID estimates at various time periods after the treament using Sun and Abraham’s estimator implemented by fixest (reference period \\(\\tau&#39;=1\\)) Again, as we have seen before, the change in group composition makes it look like there is a trend break in the treatment effect. What we would need is to aggregate treatment effects with a constant group composition. One way to do that would be to use the full disaggregated results of the Sun and Abraham decomposition and to reaggregate them in another way. In order to access the disaggregated results of the Sun and Abraham regression, we need to use the option agg=FALSE in the coef and se commands. Let’s see how this works. # Disaggregate estimates disaggregate.SA &lt;- as.data.frame(cbind(coef(reg.fixest.SA.Agg,agg=FALSE),se(reg.fixest.SA.Agg,agg=FALSE))) colnames(disaggregate.SA) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding treatment groups and time to treatment disaggregate.SA &lt;- disaggregate.SA %&gt;% mutate(test = names(coef(reg.fixest.SA.Agg,agg=FALSE))) %&gt;% mutate( Group = factor(str_sub(test,-1),levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)), TimeToTreatment = factor(if_else(str_detect(test,&quot;\\\\-&quot;),str_extract(test,&quot;\\\\-[[:digit:]]&quot;),str_extract(test,&quot;[[:digit:]]&quot;)),levels=c(&#39;-3&#39;,&#39;-2&#39;,&#39;-1&#39;,&#39;0&#39;,&#39;1&#39;,&#39;2&#39;)) ) %&gt;% select(-test) # adding reference period Group &lt;- c(&#39;2&#39;,&#39;3&#39;,&#39;4&#39;) TimeToTreatment &lt;- rep(&#39;-1&#39;,3) ref.dis &lt;- as.data.frame(cbind(Group,TimeToTreatment)) %&gt;% mutate( Coef = 0, Se = 0, Group = factor(Group,levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)), TimeToTreatment = factor(TimeToTreatment,levels=c(&#39;-3&#39;,&#39;-2&#39;,&#39;-1&#39;,&#39;0&#39;,&#39;1&#39;,&#39;2&#39;)) ) disaggregate.SA &lt;- rbind(disaggregate.SA,ref.dis) # adding aggregate results # aggregate estimates aggregate.SA &lt;- as.data.frame(cbind(coef(reg.fixest.SA.Agg),se(reg.fixest.SA.Agg))) colnames(aggregate.SA) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding treatment groups and time to treatment aggregate.SA &lt;- aggregate.SA %&gt;% mutate(test = names(coef(reg.fixest.SA.Agg))) %&gt;% mutate( Group = factor(rep(&quot;Aggregate&quot;,5),levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)), TimeToTreatment = factor(if_else(str_detect(test,&quot;\\\\-&quot;),str_extract(test,&quot;\\\\-[[:digit:]]&quot;),str_extract(test,&quot;[[:digit:]]&quot;)),levels=c(&#39;-3&#39;,&#39;-2&#39;,&#39;-1&#39;,&#39;0&#39;,&#39;1&#39;,&#39;2&#39;)) ) %&gt;% select(-test) # adding reference period Group &lt;- c(&quot;Aggregate&quot;) TimeToTreatment &lt;- rep(&#39;-1&#39;,1) ref &lt;- as.data.frame(cbind(Group,TimeToTreatment)) %&gt;% mutate( Coef = 0, Se = 0, Group = factor(Group,levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)), TimeToTreatment = factor(TimeToTreatment,levels=c(&#39;-3&#39;,&#39;-2&#39;,&#39;-1&#39;,&#39;0&#39;,&#39;1&#39;,&#39;2&#39;)) ) disaggregate.SA &lt;- rbind(disaggregate.SA,aggregate.SA,ref) %&gt;% mutate(TimeToTreatment = as.numeric(as.character(TimeToTreatment))) Let’s plot the result: ggplot(disaggregate.SA,aes(x=TimeToTreatment,y=Coef,colour=Group,linetype=Group))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Treatment\\ngroup&quot;)+ scale_linetype_discrete(name=&quot;Treatment\\ngroup&quot;)+ theme_bw() Figure 4.32: Disaggregated DID estimates around the treatment date estimated using the Sun and Abraham procedure in fixest (reference period \\(\\tau&#39;=1\\)) Figure 4.32 shows very well how the Sun and Abraham estimator works: it aggregates each group specific treatment effect (relative to the reference period \\(\\tau&#39;=-1\\) and to the reference group (\\(D_i=\\infty\\))) with period-specific weights which depend on the proportion of each treated group among the treated at this period. As a result, some dynamic changes in treatment effects might be driven by changes in group composition and not by genuine changes in the effect of the treatment. This is the case in Figure 4.32 between periods 1 and 2 where the acceleration in the growth of the aggregated treatment effect is due to the disappearance of group 3, which has a lower speed of increase of its average treatment effect, at period 2. As it is always tricky to interpret the aggregated result, I suggest to always plot the disaggregated results on the same graph, as in Figure 4.32. Let us finally compute the aggregated effect: ATT.agg.SA &lt;- aggregate(reg.fixest.SA.Agg, c(&quot;ATT&quot; = &quot;time::[^-]&quot;)) The aggregated effect estimated using the Sun and Abraham approach as implemented in fixest is equal to 1.07 \\(\\pm\\) 0.04. Remark. Sun and Abraham’s estimator can also be formulated in repeated cross sections by estimating the following model by OLS: \\[\\begin{align*} Y_{i,t} &amp; = \\alpha + \\sum_{d=2}^T\\mu_d\\uns{D_{i}=d} + \\sum_{\\tau=2}^{T}\\delta_{\\tau}\\uns{t=\\tau} + \\sum_{d=2}^T\\sum_{\\tau\\neq-1}\\beta_{d,\\tau}^{SA}\\uns{D_{i}=d \\land t=d+\\tau} + \\epsilon^{SA}_{i,t}. \\end{align*}\\] Remark. We can also show that Sun and Abraham’s estimator is equal to our individual DID estimators in the population: Theorem 4.19 (Sun and Abraham estimator is equivalent to individual DID in the population) In the population, Sun and Abraham’s estimator (formulated in a panel and in a repeated cross section) is equal to the individual DID estimators using the never treated as the comparison group and the period just before receiving the treatment as the reference period: \\(\\forall d\\in\\left\\{2,\\dots,T\\right\\}\\), \\(\\forall\\tau\\in\\left\\{-(T-1),\\dots,T-2\\right\\}\\setminus\\left\\{-1\\right\\}\\), \\[\\begin{align*} \\beta_{d,\\tau}^{SA} &amp; = \\Delta^{Y}_{DID}(d,\\infty,\\tau,d-1). \\end{align*}\\] Proof. See Section A.3.3. Remark. We can also show that Sun and Abraham’s estimator is equal to our individual DID estimators in the sample: Theorem 4.20 (Sun and Abraham estimator is equivalent to individual DID in the sample) In the sample, Sun and Abraham’s estimator (estimated by OLS in repeated cross sections or in panel data or by OLS using the Least Squares Dummy Variables model, the Within transformation or the First Difference transformation relative to \\(d-1\\) in panel data) is equal to the individual DID estimators using the never treated as the comparison group and the period just before receiving the treatment as the reference period: \\(\\forall d\\in\\left\\{2,\\dots,T\\right\\}\\), \\(\\forall\\tau\\in\\left\\{-(T-1),\\dots,T-2\\right\\}\\setminus\\left\\{-1\\right\\}\\), \\[\\begin{align*} \\hat{\\beta}_{d,\\tau}^{SA} &amp; = \\frac{\\sum_{i=1}^{N_{d+\\tau}}Y_{i,d+\\tau}\\uns{D_i=d}}{\\sum_{i=1}^{N_{d+\\tau}}\\uns{D_i=d}} -\\frac{\\sum_{i=1}^{N_{d-1}}Y_{i,d-1}\\uns{D_i=d}}{\\sum_{i=1}^{N_{d-1}}\\uns{D_i=d}} \\\\ &amp; \\phantom{=} - \\left(\\frac{\\sum_{i=1}^{N_{d+\\tau}}Y_{i,d+\\tau}\\uns{D_i=\\infty}}{\\sum_{i=1}^{N_{d+\\tau}}\\uns{D_i=\\infty}} -\\frac{\\sum_{i=1}^{N_{d-1}}Y_{i,d-1}\\uns{D_i=\\infty}}{\\sum_{i=1}^{N_{d-1}}\\uns{D_i=\\infty}}\\right) \\end{align*}\\] Proof. See Section A.3.4. Remark. The First Difference transformation of the Sun and Abraham model that is equivalent to the individual DID estimator is not a standard first difference where observations observed at date \\(t-1\\) are subtracted from observations at \\(t\\). The correct First Difference transformation is relative to \\(d-1\\): the OLS regression is performed on the following model, restricted to the sample where \\(D_i=d\\) or \\(D_i=\\infty\\) and \\(T_i=t\\) or \\(T_i=d-1\\): \\[\\begin{align*} D_j^{d,\\tau}(Y_{j,d+\\tau} - Y_{j,d-1}) &amp; = \\alpha_{d,\\tau}^{FD}D_j^{d,\\tau} + \\beta_{d,\\tau}^{FD}\\uns{D_j=d}D_j^{d,\\tau} + \\epsilon^{FD}_{j,t}D_j^{d,\\tau}, \\end{align*}\\] where \\(D_j^{d,\\tau}\\) takes value one when observation \\(j\\) is used to estimate \\(\\hat\\beta^{SA}_{d,\\tau}\\). Example 4.44 In order to see how Theorem 4.20 works in practice, let us collect all the estimated effects obtained thanks to our separate individual DID estimators and compare them with the coefficients of Sun and Abraham’s model. We are going to compare the coefficients in the Sun and Abraham model to the DID estimates that compare each treated group to the never treated group, since the Sun and Abraham estimator do not use the observations belonging to groups that eventually get treated as controls when they are not yet treated. # reorganize the DID estimator DID.1.mod &lt;- DID.1 %&gt;% filter(dprime==&quot;99&quot;) %&gt;% # keep only never treated as counterfactuals rename( TimeToTreatment=tau, Group=d ) %&gt;% mutate( Group=factor(Group,levels=c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;Aggregate&quot;)), TimeToTreatment=as.numeric(TimeToTreatment) ) %&gt;% select(DIDest,DIDse,Group,TimeToTreatment) # add reference period to DID estimator DID.1.mod &lt;- rbind(DID.1.mod,ref.dis %&gt;% rename(DIDest=Coef,DIDse=Se)) %&gt;% mutate( TimeToTreatment=as.numeric(TimeToTreatment) ) # joining DID and SA estimates CompDIDSA &lt;- DID.1.mod %&gt;% left_join(disaggregate.SA,by=c(&#39;Group&#39;,&#39;TimeToTreatment&#39;)) %&gt;% mutate( TimeToTreatment = factor(TimeToTreatment,levels=c(&#39;-3&#39;,&#39;-2&#39;,&#39;-1&#39;,&#39;0&#39;,&#39;1&#39;,&#39;2&#39;)) ) Let’s now plot the results: ggplot(CompDIDSA,aes(x=DIDest,y=Coef,shape=Group,color=TimeToTreatment))+ geom_point() + geom_abline(slope=1,intercept=0,linetype=&quot;dotted&quot;,color=&quot;red&quot;)+ ylab(&quot;Sun and Abraham estimate&quot;) + xlab(&quot;DID estimate&quot;) + theme_bw() Figure 4.33: Comparison of treatment effects estimated using DID and Sun and Abraham estimator (reference period \\(\\tau&#39;=1\\)) As Figure 4.33 shows, the coefficients estimated through DID are identical to the coefficients estimated using Sun and Abraham approach (they all lone up on the 45 degree line). This is an illustration of the main result of Theorem 4.20. Note that the estimated aggregated effect using DID with weights proportional to group composition and time spent in the treatment is equal to \\(\\hat\\Delta^{Y}_{TT}(v)=\\) 1.06. The corresponding estimate using Sun and Abraham estimator is equal to 1.07 \\(\\pm\\) 0.04. The two estimator are slightly different. This is because Sun and Abraham aggregate effects estimated using exclusively the never treated group as the control group while the DID estimator aggregates the same and effects estimated using the other treated groups before they receive the treatment. It should be the case that if we aggregate the DID estimates using only the never treated as the control group, we should obtain the same result as with Sun and Abraham estimator. Let’s check. # joining the weights to the results DID.1.agg.SA &lt;- DID.1 %&gt;% filter(dprime==&quot;99&quot;,tau&gt;=0) %&gt;% select(-prop.group) %&gt;% mutate( d= factor(d,levels=c(&quot;99&quot;,&quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;1&quot;)) ) %&gt;% left_join(prop.groups.DID,by=c(&quot;d&quot;=&quot;dprime&quot;)) %&gt;% mutate( w.ATT = prop.group*DIDest ) %&gt;% summarize( sum.w.ATT = sum(w.ATT), sum.w = sum(prop.group) ) %&gt;% mutate( ATT.varying.DID = sum.w.ATT/sum.w ) %&gt;% pull(ATT.varying.DID) The estimated aggregated effect using DID with weights proportional to group composition and time spent in the treatment, restricting the estimates to the ones obtained using the never treated as the control group is equal to \\(\\hat\\Delta^{Y}_{TT}(v)=\\) 1.07, which is indeed equal to the aggregate estimate computed by the Sun and Abraham estimator in fixest. Remark. What to do in pratice? Use only the never treated as controls? It seems that using more groups as controls (if they are valid) should increase efficiency. 4.3.3.2.3 Direct weighting using one reference period and one reference group (Callaway and Sant’Anna) Callaway and Sant’Anna (2021) propose an alternative estimator to the one proposed by Sun and Abraham. They suggest using a doubly robust matching estimator to condition on observed covariates. We are only going to encouter these estimators in Section ??. In the absence of covariates, Callaway and Sant’Anna’s estimator is equivalent to the Sun and Abraham estimator. Callaway and Sant’Anna have proposed the did package to implement their estimator. The main command is att_gt, which computes all the estimates for each treatment group \\(D_i=g\\) and each time period \\(t\\). Example 4.45 Let’s see if we can make it work. # preparing the data # The Group variable has to take value 0 for the never treated (instead of infty or 99) data &lt;- data %&gt;% mutate( Group = if_else(Ds&lt;99,Ds,0) ) # regression reg.CSA &lt;- att_gt(yname=&quot;y&quot;,tname=&quot;time&quot;,idname=&quot;id&quot;,gname=&quot;Group&quot;,data=filter(data,Ds!=1),base_period=&quot;universal&quot;) # dynamic treatment effects (event-study graph) reg.CSA.Agg &lt;- aggte(reg.CSA,type=&quot;dynamic&quot;) Let’s plot the result: # preparing the results for the plot DID.CSA &lt;- as.data.frame(reg.CSA$group) colnames(DID.CSA) &lt;- c(&quot;Group&quot;) DID.CSA &lt;- DID.CSA %&gt;% mutate( time = reg.CSA$t, Coef = reg.CSA$att, Se = reg.CSA$se ) %&gt;% mutate( TimeToTreatment = time-Group, Group = factor(Group,levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)), ) # add aggregate effect DID.CSA.Agg &lt;- as.data.frame(cbind(reg.CSA.Agg$egt,reg.CSA.Agg$att.egt,reg.CSA.Agg$se.egt)) colnames(DID.CSA.Agg) &lt;- c(&#39;TimeToTreatment&#39;,&#39;Coef&#39;,&#39;Se&#39;) DID.CSA.Agg &lt;- DID.CSA.Agg %&gt;% mutate( Group = factor(rep(&quot;Aggregate&quot;,nrow(DID.CSA.Agg)),levels=c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;Aggregate&#39;)) ) # merge all results DID.CSA &lt;- rbind(select(DID.CSA,-time),DID.CSA.Agg) ggplot(DID.CSA,aes(x=TimeToTreatment,y=Coef,colour=Group,linetype=Group))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Treatment\\ngroup&quot;)+ scale_linetype_discrete(name=&quot;Treatment\\ngroup&quot;)+ theme_bw() Figure 4.34: Disaggregated DID estimates around the treatment date estimated using the Callaway and Sant’Anna procedure in did (reference period \\(\\tau&#39;=1\\)) Figure 4.34 shows a result that is very similar to the one obtained in Figure 4.32 using Sun and Abraham’s approch as implemented in fixest. The two approaches are indeed equivalent with the options that we have chosen. Let us finally compute the aggregated treatment effect: ATT.agg.CSA &lt;- aggte(reg.CSA,type=&quot;simple&quot;) The aggregated effect estimated using the Callaway and Sant’Anna approach as implemented in did is equal to 1.07 \\(\\pm\\) 0.06. 4.3.3.2.4 De Chaisemartin and d’Haultfoeuille de Chaisemartin et d’Haultfoeuille propose two ways to deal with DID with differences in treatment timing. In de Chaisemartin and d’Haultfoeuille (2020), they propose to estimate the effect of the treatment using only the periods where a change in treatment status occurs, by comparing the treated to the not yet treated at the same time periods. In de Chaisemartin et d’Haultfoeuille (2021), they propose to estimate the dynamic effect of the treatment using a discounted sum of treatment effects over time. In its simplest form, with staggered designs, a discrete treatment and no covariates, de Chaisemartin et d’Haultfoeuille (2021)’s estimator is equivalent to that of Sun and Abraham or Callaway and Sant’Anna. Both estimators have been implemented in the DIDmutiplegt package with the did_multiplegt function. Example 4.46 Let’s see how it works. # regression reg.dCdH &lt;- did_multiplegt(Y=&quot;y&quot;,T=&quot;time&quot;,G=&quot;id&quot;,D=&quot;D&quot;,df=filter(data,Ds!=1),placebo=3,dynamic=3,average_effect=&quot;prop_number_switchers&quot;) Let us now pot the results: # preparing the results for the plot DID.dCdH &lt;- as.data.frame(c(reg.dCdH$placebo_2,reg.dCdH$placebo_1,0,reg.dCdH$effect,reg.dCdH$dynamic_1,reg.dCdH$dynamic_2)) colnames(DID.dCdH) &lt;- c(&quot;Coef&quot;) DID.dCdH &lt;- DID.dCdH %&gt;% mutate( TimeToTreatment = c(-3,-2,-1,0,1,2), Se = c(reg.dCdH$se_placebo_2,reg.dCdH$se_placebo_1,0,reg.dCdH$se_effect,reg.dCdH$se_dynamic_1,reg.dCdH$se_dynamic_2) ) ggplot(DID.dCdH,aes(x=TimeToTreatment,y=Coef))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.35: DID estimates around the treatment date estimated using the de Chaisemartin and d’Haultfoeuille procedure (reference period \\(\\tau&#39;=1\\)) Figure 4.35 shows that the profile estimated using de Chaisemartin and d’Haultfoeuille’s aprproach is similar but distinct from the one estimated by the other authors. Why is still to be determined. Finally, the aggregate efect of the treatment as estimated by the de Chaisemartin and d’Haultfoeuille (2020) approach is equal to 0.3. I have been unable to obtain standard errors for this estimator for now. 4.3.3.2.5 Imputation methods: Borusyak, Jaravel and Speiss Borusyak, Jaravel and Speiss (2021) adopt a very different framework from the previous ones. They do not build from the individual DID estimators \\(\\Delta^{Y}_{DID}(d,d&#39;,\\tau,\\tau&#39;)\\), but instead propose to estimate the individual level treatment effects \\(\\hat\\Delta^Y_{i,t}\\) and then to aggregate them as one wishes to. In order to build an estimate of the individual level treatment effects \\(\\hat\\Delta^Y_{i,t}\\), Borusyak, Jaravel and Speiss (2021) propose to use an imputation estimator, \\(\\hat Y^0_{i,t}\\), which predicts the value of \\(Y^0_{i,t}\\) for each treated unit. Borusyak, Jaravel and Speiss (2021)’s imputation estimator works as follows: Within the never treated and not-yet-treated observations only, estimate \\(\\hat\\mu_i^{OLS}\\) and \\(\\hat\\delta_t^{OLS}\\) using the following OLS regression: \\[\\begin{align*} Y^0_{i,t} &amp; = \\mu_i + \\delta_t + U^0_{i,t} \\end{align*}\\] For each treated observation, set \\(\\hat Y^0_{i,t} = \\hat\\mu_i^{OLS}+\\hat\\delta_t^{OLS}\\) and \\(\\hat\\Delta^Y_{i,t}=Y^1_{i,t}-\\hat Y^0_{i,t}\\). Finally, Borusyak, Jaravel and Speiss (2021) propose to aggregate the estimates for each treatment effect using weights \\(w^{BJS_k}_{i,t}\\) in order to form \\(\\hat\\Delta^{Y}_{TT}(BJS_k)=\\sum w^{BJS_k}_{i,t}\\hat\\Delta^Y_{i,t}\\). In the absence of covariates, or group-specific time trends, the main assumption of Borusyak, Jaravel and Speiss (2021)’s framework is that the potential outcomes in the absence of the treatment can be decomposed in two separate influences: Hypothesis 4.26 (Additive Separability of Potential Outcomes in the Absence of the Treatment) We assume that the potential outcomes in the absence of the treatment are additively separable between time and individual fixed effects: \\[\\begin{align*} Y^0_{i,t} &amp; = \\mu_i + \\delta_t + U^0_{i,t}, \\end{align*}\\] with \\(\\esp{U^0_{i,t}|D_i}=0\\), \\(\\forall t\\in\\{1,\\dots,T\\}\\). Assumption 4.26 assumes that all the time and individual-level influences on potential outcomes that are potentially correlated with treatment intake are additively separable. Remark. Borusyak, Jaravel and Speiss (2021) claim that Assumption 4.26 is equivalent to Assumption 4.25 of parallel trends. I think we still need a formal proof of that claim. Borusyak, Jaravel and Speiss (2021) add another assumption, namely that error terms are homoskedastic: Hypothesis 4.27 (Homoskedasticity) We assume that the error terms are homoskedastic and mutually uncorrelated: \\[\\begin{align*} \\esp{U_0U_0&#39;} &amp; = \\sigma^2\\mathbf{I}, \\end{align*}\\] with \\(U_0\\) the vector of error terms and \\(\\mathbf{I}\\) the identity matrix of the coresponding dimension. Under these assumptions, and the no-anticipation condition, Borusyak, Jaravel and Speiss (2021) prove a very powerful result: Theorem 4.21 (Imputation identifies Weighted TT) Under Assumptions 4.23, 4.24 and 4.26, the imputation estimator is the unique efficient linear unbiased estimator of the corresponding weighted average of Treatment on the Treated: \\[\\begin{align*} \\sum w^{BJS_k}_{i,t}\\hat\\Delta^Y_{i,t} &amp; = \\Delta^{Y}_{TT}(BJS_k). \\end{align*}\\] with \\[\\begin{align*} \\Delta^{Y}_{TT}(BJS_k) &amp; = \\sum w^k_{i,t}\\Delta^Y_{i,t} \\end{align*}\\] Proof. See Borusyak, Jaravel and Speiss (2021) Theorems 1 and 2. Theorem 4.21 is a pretty cool result. It shows that, under the assumptions made so far, the imputation estimator is the most efficient way to combine observations in order to obtain DID estimates of the effect of the treatment. Remark. The “trick” that makes the Borusyak, Jaravel and Speiss (2021)’s imputation estimator more efficient than Sun and Abraham or Callaway and Sant’Anna’s estimators is that it combines all pre-treatment observations when generating the treatment effect estimate. An open question is whether a weigthed average of the individual DID estimates, including all the ones formed using all pre-treatment observations as reference periods, is as efficient as Borusyak, Jaravel and Speiss (2021)’s imputation estimator. Remark. Borusyak, Jaravel and Speiss (2021) claim that Assumption 4.27 can be relaxed to any known form of heteroskedasticity or autocorrelation and that Theorem 4.21 would still hold. How does Borusyak, Jaravel and Speiss (2021)’s imputation estimator work in practice? Thanks to the amazing Kyle Butts, we have a package that computes Borusyak, Jaravel and Speiss (2021)’s imputation estimator, didimputation. The command is did_imputation. Example 4.47 Let’s see how it works. # regression reg.BJS &lt;- did_imputation(yname=&quot;y&quot;,tname=&quot;time&quot;,idname=&quot;id&quot;,gname=&quot;Group&quot;,data=filter(data,Ds!=1),horizon=TRUE,pretrends=TRUE) Let us now plot the results: # preparing the results for the plot DID.BJS &lt;- reg.BJS %&gt;% rename( TimeToTreatment=term, Coef=estimate, Se=std.error ) %&gt;% mutate( TimeToTreatment=as.numeric(TimeToTreatment) ) # adding reference period DID.BJS[nrow(DID.BJS)+1,] &lt;- list(-1,0,0,0,0) #plot ggplot(DID.BJS,aes(x=TimeToTreatment,y=Coef))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.36: DID estimates around the treatment date estimated using Borusyak, Jaravel and Speiss’s procedure (reference period \\(\\tau&#39;=1\\)) As Figure 4.36 shows, the dynamic profile of the treatment effect estimated using Borusyak, Jaravel and Speiss’s procedure is very similar to the one obtained using Sun and Abraham and Callaway and Sant’Anna. Let us finally estimate the average treatment effect on the treated using Borusyak, Jaravel and Speiss’s procedure: # regression reg.BJS.Agg &lt;- did_imputation(yname=&quot;y&quot;,tname=&quot;time&quot;,idname=&quot;id&quot;,gname=&quot;Group&quot;,data=filter(data,Ds!=1)) The treatment effect estimated using Borusyak, Jaravel and Speiss’s estimator is equal to 1.08 \\(\\pm\\) 0.04. 4.3.3.2.6 Imputation methods: Gardner Gardner (2021) proposes a two stage estimator very similar to the one by Borusyak, Jaravel and Speiss (2021). Gardner writes outcomes for individual \\(i\\) at time \\(t\\) as follows, with group and time fixed effects: \\[\\begin{align*} Y_{i,t} &amp; = \\sum_{d=1}^{\\infty}\\lambda_d\\uns{D_i=d} + \\sum_{l=1}^T\\delta_l\\uns{l=t} + \\sum_{d=1}^{\\infty}\\sum_{l=1}^T\\beta^G_{d,l}\\uns{D_i=d}\\uns{l=t} + \\epsilon^{G}_{i,t}, \\end{align*}\\] where the groups are defined by the date at which they start receiving the treatment. In practice, Gardner’s estimator works as follows: Estimate the following model using OLS on the sample of observations for which \\(D_{i,t}=0\\) (which excludes all the currently treated): \\[\\begin{align*} Y_{i,t} &amp; = \\sum_{d=2}^{\\infty}\\lambda_d\\uns{D_i=d} + \\sum_{l=1}^T\\delta_l\\uns{l=t} + \\epsilon^{G}_{i,t} \\end{align*}\\] Regress the adjusted outcomes \\(Y_{i,t}-\\sum_{d=2}^{\\infty}\\hat\\lambda_d\\uns{D_i=d}-\\sum_{l=1}^T\\hat\\delta_l\\uns{l=t}\\) on \\(D_{i,t}\\) and retain the coefficient \\(\\hat\\beta^G\\). Note as well that one can also estimate the average effect of the treatment around each treatment date by regressing the adjusted outcomes on a set of dummies taking value one when observation \\(i\\) at period \\(t\\) is \\(\\tau\\) periods from the treatment (here, we omit the dummy for the never treated group and for one reference period, in general \\(\\tau=-1\\)). Gardner shows that the coefficient on \\(D_{i,t}\\) in the second stage of this procedure (\\(\\hat\\beta^G\\)) identifies the average effect of the treatment on the treated under the usual parallel trends assumptions: \\(\\beta^G=\\esp{\\Delta^Y_{i,t}|D_{i,t}=1}\\), where \\(\\Delta^Y_{i,t}=Y^1_{i,t}-Y^0_{i,t}\\). What is pretty great is that Gardner, together with Kyle Butts, have provided an R package in order to perform the estimation: did2s. Example 4.48 Let’s see how it works in our example. # regression reg.Gardner &lt;- did2s(data=filter(data,Ds!=1),yname = &quot;y&quot;, first_stage = ~ 0 | id + time,second_stage = ~i(D, ref=FALSE), treatment = &quot;D&quot;,cluster_var = &quot;id&quot;) The overall estimated treatment effect is 1.08 \\(\\pm\\) 0.06. This seems valid enough. Now, did2s also provides a way to estimate the effect at each time period relative the treatment date (a.k.a. the event study estimates). # generating a TimeToTreatment variable data &lt;- data %&gt;% mutate( TimeToTreatment = if_else(abs(time-Ds)&lt;90,time-Ds,-99) ) # regression reg.Gardner.event.study &lt;- did2s(data=filter(data,Ds!=1),yname = &quot;y&quot;, first_stage = ~ 0 | id + time,second_stage = ~i(TimeToTreatment, ref=c(-1, -99)), treatment = &quot;D&quot;,cluster_var = &quot;id&quot;) Let us now plot the results: # putting results into a dataframe resultsGardnerEventStudy &lt;- as.data.frame(cbind(coef(reg.Gardner.event.study),se(reg.Gardner.event.study))) colnames(resultsGardnerEventStudy) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding the time to treatment variable resultsGardnerEventStudy &lt;- resultsGardnerEventStudy %&gt;% mutate( TimeToTreatment = c(-3,-2,0,1,2) ) # adding the reference period resultsGardnerEventStudy &lt;- rbind(resultsGardnerEventStudy,c(0,0,-1)) #plot ggplot(resultsGardnerEventStudy,aes(x=TimeToTreatment,y=Coef))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.37: DID estimates around the treatment date estimated using Gardner’s procedure (reference period \\(\\tau&#39;=1\\)) 4.3.3.2.7 Imputation methods: Liu, Wang and Xu Liu, Wang and Xu (2021) also propose a series of imputation estimators, with some very similar to the ones proposed by Borusyak, Jaravel and Speiss and by Gardner. Their Proposition 1 is very close to Theorem 4.21, albeit they do not prove that their estimator is the most efficient among linear estimators. They also propose an R package to estimate their estimators, fect. I will come back to this package later, in Section ??, since most of the estimators they propose try to relax the parallel trends assumption. 4.3.3.2.8 Stacked DID The stacked DID approach has been proposed by Cengiz, Dube, Lindner and Zipperer (2019) and extended by Gardner (2021). For stacked DID, one creates a dataset for each group defined by its date of treatment, with all observations treated at that date and the ones that are not yet treated, one then stacks all these datasets together, and estimates a two-way fixed effects model with time \\(\\times\\) dataset specific fixed effects and individual fixed effects. Gardner’s Appendix A show that this procedure yields a weighted average of group and time specific treatment effects, with weights that do not generally correspond to the ones of the ATT estimate, but that are positive and sum to one. One issue I have with this approach is that it focuses only on cases where there are no never treated observations. If we keep never treated observations in the stacked DID approach, they are going to be used multiple times and one certainly needs to account for that when estimating precision. The way I’m choosing to implement this approach is by adding specific group \\(\\times\\) time dummies for all the members of a given group defined by its date of first treatment and all the not-yet-treated observations at that same date. We are going to run a two-way fixed effects model on these fixed effects and on individual fixed effects as well as on treatment dummies. Example 4.49 Let’s see how it goes. # generating the groups x time dummies data &lt;- data %&gt;% mutate( FE.1.1 = if_else(time ==1 &amp; (Ds==1 | D==0),1,0), FE.1.2 = if_else(time ==2 &amp; (Ds==1 | D==0),1,0), FE.1.3 = if_else(time ==3 &amp; (Ds==1 | D==0),1,0), FE.1.4 = if_else(time ==4 &amp; (Ds==1 | D==0),1,0), FE.2.1 = if_else(time ==1 &amp; (Ds==2 | D==0),1,0), FE.2.2 = if_else(time ==2 &amp; (Ds==2 | D==0),1,0), FE.2.3 = if_else(time ==3 &amp; (Ds==2 | D==0),1,0), FE.2.4 = if_else(time ==4 &amp; (Ds==2 | D==0),1,0), FE.3.1 = if_else(time ==1 &amp; (Ds==3 | D==0),1,0), FE.3.2 = if_else(time ==2 &amp; (Ds==3 | D==0),1,0), FE.3.3 = if_else(time ==3 &amp; (Ds==3 | D==0),1,0), FE.3.4 = if_else(time ==4 &amp; (Ds==3 | D==0),1,0), FE.4.1 = if_else(time ==1 &amp; (Ds==4 | D==0),1,0), FE.4.2 = if_else(time ==2 &amp; (Ds==4 | D==0),1,0), FE.4.3 = if_else(time ==3 &amp; (Ds==4 | D==0),1,0), FE.4.4 = if_else(time ==4 &amp; (Ds==4 | D==0),1,0) ) # regression for individual parameter reg.stacked.aggregate &lt;- feols(y ~ D + FE.1.1 + FE.1.2 + FE.1.3 + FE.1.4 + FE.2.1 + FE.2.2 + FE.2.3 + FE.2.4 + FE.3.1 + FE.3.2 + FE.4.3 + FE.4.4 | id + time, data=filter(data,Ds!=1)) # event study regression reg.stacked.event.study &lt;- feols(y ~ i(TimeToTreatment,ref=c(-99,-1)) + FE.1.1 + FE.1.2 + FE.1.3 + FE.1.4 + FE.2.1 + FE.2.2 + FE.2.3 + FE.2.4 + FE.3.1 + FE.3.2 + FE.4.3 + FE.4.4 | id + time, data=filter(data,Ds!=1)) The total estimate given by the stacked regression is of 1.86, which seems pretty large compared to the other estimators. Remember that the average effect of the treatment, giving equal weight to each time period \\(\\tau\\in\\{0,1,2\\}\\), is equal to \\(\\hat\\Delta^{Y}_{TT}(e)=\\) 1.59 while the average effect of the treatment, giving weights proportional to group composition and time spent in the treatment is equal to \\(\\hat\\Delta^{Y}_{TT}(v)=\\) 1.06. Let us plot the corresponding results of the event study regression. # putting results into a dataframe resultsStackedDIDEventStudy &lt;- as.data.frame(cbind(reg.stacked.event.study$coefficients[1:5],reg.stacked.event.study$se[1:5])) colnames(resultsStackedDIDEventStudy) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding the time to treatment variable resultsStackedDIDEventStudy &lt;- resultsStackedDIDEventStudy %&gt;% mutate( TimeToTreatment = c(-3,-2,0,1,2) ) # adding the reference period resultsStackedDIDEventStudy &lt;- rbind(resultsStackedDIDEventStudy,c(0,0,-1)) #plot ggplot(resultsStackedDIDEventStudy,aes(x=TimeToTreatment,y=Coef))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.38: DID estimates around the treatment date estimated using Stacked DID (reference period \\(\\tau&#39;=1\\)) The results seem pretty nice and close to what we have obtained so far with the other methods we have used. 4.3.3.2.9 Two-Way Fixed Effects Before we conclude, there is one last set of methods that we might have wanted to use: the methods based on the standard Two Way Fixed Effects model with time and unit-specific fixed effects that we have introduced in Sections 4.3.1.2.4, 4.3.1.2.5 and 4.3.1.2.6, and which can be estimated using various types of methods (Least Squares Dummy Variables, Within regression or other fast methods). Methods based on the Two Way Fixed Effects model were actually the most used ones to estimate treatment effects and event study regressions in staggered designs before a string of results showed that they had severe issues. In this section, we will cover the basic issues that methods based on the Two Way Fixed Effects model face in a staggered design and we will state conditions under which they can be correct. Example 4.50 Before that, let us simply look at how the Two Way Fixed Effects model performs in our example. # regression for individual parameter reg.TWFE.aggregate &lt;- feols(y ~ D | id + time, data=data) # event study regression reg.TWFE.event.study &lt;- feols(y ~ i(TimeToTreatment,ref=c(-99,-1)) | id + time, data=data) The Two Way Fixed Effects-based estimate of the aggregate treatment effect on the treated is equal to -0.08 \\(\\pm\\) 0.1, while the effect estimated the correct weighting of basic DID estimators giving weights proportional to group composition and time spent in the treatment is equal to \\(\\hat\\Delta^{Y}_{TT}(v)=\\) 1.06. Let us now plot the event study estimates obtained using Two Way Fixed Effects-based methods: # putting results into a dataframe resultsTWFEEventStudy &lt;- as.data.frame(cbind(reg.TWFE.event.study$coefficients[1:5],reg.TWFE.event.study$se[1:5])) colnames(resultsTWFEEventStudy) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding the time to treatment variable resultsTWFEEventStudy &lt;- resultsTWFEEventStudy %&gt;% mutate( TimeToTreatment = c(-3,-2,0,1,2) ) # adding the reference period resultsTWFEEventStudy &lt;- rbind(resultsTWFEEventStudy,c(0,0,-1)) #plot ggplot(resultsTWFEEventStudy,aes(x=TimeToTreatment,y=Coef))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.39: DID estimates around the treatment date estimated using TWFE (reference period \\(\\tau&#39;=1\\)) Surprisingly, the profile of the event-study estimates does not seem to be too different from the ones we have estimated before. What has happened? Why would the aggregate estimate be so wrong and the event-study estimate correct? Let us dig into the technical properties of the Two Way Fixed Effects-based estimators in order to understand why. We are first going to look at the properties of the Two Way Fixed Effects-based estimators for the average effect of the treatment on the treated and then we will look at the properties of the event study estimates. 4.3.3.2.9.1 Bias of the Two Way Fixed Effects-based estimators for the Average Treatment Effect on the Treated The properties of the Two Way Fixed Effects-based estimators have been studied in detail by Goodman-Bacon (2021). In order to state Goodman-Bacon’s main result, we are going to consider that there are only three time periods in the data: a \\(t=pre\\) time period, where no one is treated, a \\(t=mid\\) time period, where only early adopters are treated (those with \\(D_i=mid\\)) and finally a \\(t=last\\) time period, where a second group receives the treatment. We also allow for some units to be never treated, and we denote them with \\(D_i=u\\). We denote \\(n_d=\\frac{\\sum_i\\uns{D_i=d}}{N}\\), with \\(d\\in\\{u,mid,last\\}\\) the share of each treatment group in the sample and \\(\\bar{D}_d\\) the share of time each group spends in the treament state. In this setting, Goodman-Bacon (2021) proves the following theorem: Theorem 4.22 (Goodman-Bacon Decomposition of Two Way Fixed Effects-based estimators) The parameter \\(\\hat\\beta^{TWFE}\\) estimated by Two Way Fixed Effects-based estimators can be written as follows: \\[\\begin{align*} \\hat\\beta^{TWFE} &amp; = w^{TWFE}_u(mid)\\Delta^Y_{DID}(mid,u,mid,pre) \\\\ &amp; \\phantom{=} + w^{TWFE}_u(mid)\\Delta^Y_{DID}(mid,u,last,pre) \\\\ &amp; \\phantom{=} + w^{TWFE}_u(last)\\Delta^Y_{DID}(last,u,last,pre) \\\\ &amp; \\phantom{=} + w^{TWFE}_u(last)\\Delta^Y_{DID}(last,u,last,mid) \\\\ &amp; \\phantom{=} + w^{TWFE}_{last}(mid)\\Delta^Y_{DID}(mid,last,mid,pre)\\\\ &amp; \\phantom{=} + w^{TWFE}_r(last,mid)\\Delta^Y_{DID^r}(last,mid,last,mid) \\end{align*}\\] with \\[\\begin{align*} \\Delta^Y_{DID}(d,d&#39;,\\tau,\\tau&#39;) &amp; = \\esp{Y_{i,\\tau}-Y_{i,\\tau&#39;}|D_i=d}-\\esp{Y_{i,\\tau}-Y_{i,\\tau&#39;}|D_i=d&#39;}\\\\ w^{TWFE}_u(d) &amp; = (n_{d}+n_{u})^2\\frac{\\hat V^{D}_{d,u}}{\\hat V^{D}}\\text{, }d\\in\\{mid,last\\}\\\\ w^{TWFE}_{last}(mid) &amp; = ((n_{last}+n_{mid})(1-\\bar{D}_{last}))^2\\frac{\\hat V^{D}_{mid,last}}{\\hat V^{D}}\\\\ w^{TWFE}_{r}(last,mid) &amp; = ((n_{last}+n_{mid})\\bar{D}_{mid}^2\\frac{\\hat V^{D}_{last,mid}}{\\hat V^{D}}\\\\ \\hat V^{D}_{d,u} &amp; = n_{d,u}(1-n_{d,u})\\bar{D}_{d}(1-\\bar{D}_{d})\\text{, }d\\in\\{mid,last\\} \\\\ \\hat V^{D}_{mid,last} &amp; = n_{mid,last}(1-n_{mid,last})\\frac{\\bar{D}_{mid}-\\bar{D}_{last}}{1-\\bar{D}_{last}}\\frac{1-\\bar{D}_{mid}}{1-\\bar{D}_{last}}\\\\ \\hat V^{D}_{last,mid} &amp; = n_{mid,last}(1-n_{mid,last})\\frac{\\bar{D}_{last}}{\\bar{D}_{mid}}\\frac{\\bar{D}_{mid}-\\bar{D}_{last}}{\\bar{D}_{mid}}\\\\ n_{d,d&#39;} &amp; = \\frac{n_d}{n_d+n_d&#39;} \\end{align*}\\] and \\(\\sum_{d,d&#39;}w^{TWFE}(d,d&#39;)=1\\). Proof. See Goodman-Bacon (2021) Theorem 1. The beauty of Goodman-Bacon’s theorem is that it relates directly the Two Way Fixed Effects-based estimators to the individual two-period DID estimators we have studied in Section 4.3.1. The key to understand the bias of the Two Way Fixed Effects-based estimators is that the \\(DID^r\\) estimator we studied in Section 4.3.2 appears in Goodman-Bacon’s decomposition. This is because units with \\(D_i=mid\\) become always treated observations for the last two periods. They are used as counterfactuals by the Two Way Fixed Effects-based estimators for the observations that enter in the last period. We have shown with Theorem 4.15 that, under the classical parallel trends assumption, the \\(DID^r\\) estimator is biased for the treatment effect on the treated after the treatment takes place. The bias is equal to minus the change over time in treatment effect on the treated. It means that if treatment effects increase over time, the \\(DID^r\\) estimator will introduce a negative bias in the Two Way Fixed Effects-based estimators. In our example, this bias is made even more severe by the fact that we have an always treated group, which is used at every period as a counterfactual. Since the effect for the always treated group increases very fast over time, the bias of the \\(DID^r\\) estimator becomes large and negative. Remark. If the treatment effects are constant over time (but possibly heterogeneous across groups), then the bias due to the \\(DID^r\\) disappears, as Lemma 4.5 shows, and the Two Way Fixed Effects-based estimators recover a weighted average of treatment effects, with positive weights summing to one. The problem with the Two Way Fixed Effects-based estimators is still that the weights used to combine the various treatment effects are not easy to interpret. One probably prefers using tailor-made weights as in the estimators we have studied previously. Add corollary showing that TWFE is consistent under constant treatment effects over time 4.3.3.2.9.2 Bias of the Two Way Fixed Effects-based estimators for the event study estimates The properties of the Two Way Fixed Effects-based estimators for event study parameters have been studied in detail by Sun and Abraham (2021). They focus on the following Two Way Fixed Effects model of an event-study analysis: \\[\\begin{align*} Y_{i,t} &amp; = \\mu_i + \\delta_t + \\sum_{g\\in\\mathcal{G}}\\beta_{\\mathcal{g}}^{TWFE}\\uns{t-D_{i}\\in g} + \\epsilon^{TWFE}_{i,t}, \\end{align*}\\] where the set \\(\\mathcal{G}\\) collects disjoint sets \\(g\\) of relative time periods \\(\\tau\\in\\{-T,\\dots,T\\}\\), and excludes some of them. The excluded sets of time periods are collected in a set \\(g_{excl}\\). The most classical specification corresponding to the general case above uses as sets \\(g\\): Observations that are such that \\(-K\\leq t-D_i \\leq-2\\), with one specific indicator for each of the individual relative time periods \\(\\tau=t-D_i\\), Observations that are such that \\(0\\leq t-D_i \\leq L\\), with one specific indicator for each of the individual relative time periods, All the observations that will be treated more than \\(K\\) periods in the future (\\(t-D_{i}&lt;-K\\)), All the observations that are such that \\(t-D_i&gt;L\\). In general, \\(g_{excl}=\\{-1,-\\infty\\}\\), so that the reference period with respect to which all treatment effects are estimated is the period just before the treatment. By convention, \\(\\uns{t-D_{i}=-\\infty}=0\\). Note that this is the specification we have adopted in most of our numerical examples so far, without using the strategy of binning together far away observations on both sides of the treatment date. In this setting, Sun and Abraham prove the following result: Theorem 4.23 (Sun and Abraham Decomposition of Two Way Fixed Effects-based event-study estimators) The parameter \\(\\beta_{g}^{TWFE}\\) estimated by Two Way Fixed Effects-based event-study estimators can be written as follows: \\[\\begin{align*} \\beta_{g}^{TWFE} &amp; = \\sum_{\\tau\\in g}\\sum_dw^{g}_{d,\\tau}\\Delta^Y_{DID}(d,\\infty,\\tau,-d+1) \\\\ &amp; \\phantom{=} + \\sum_{g&#39;\\neq g,g&#39;\\in g}\\sum_{\\tau\\in g&#39;}\\sum_d w^{g}_{d,\\tau}\\Delta^Y_{DID}(d,\\infty,\\tau,-d+1) \\\\ &amp; \\phantom{=} + \\sum_{\\tau\\in g_{excl}}\\sum_d w^{g}_{d,\\tau}\\Delta^Y_{DID}(d,\\infty,\\tau,-d+1), \\end{align*}\\] where the weights \\(w^{g}_{d,\\tau}\\) are equal to the population regression coefficients on \\(\\uns{t-D_{i}\\in g}\\) from regressing \\(\\uns{t-D_{i}=\\tau}\\uns{D_{i}=d}\\) on time and individual fixed effects and all bin indicators \\(\\{\\uns{t-D_{i}\\in g}\\}_{g\\in g}\\) Proof. See Sun and Abraham (2021) Proposition 1. Theorem 4.23 shows that the coefficient \\(\\beta_{g}^{TWFE}\\) in the TWFE event-study regression does not only capture the DID estimate at that period, but also the DID estimates at other periods \\(g&#39;\\) and at the reference periods \\(g_{excl}\\). This is potentially a severe problem. For example, estimates of the effect pre-treatment can appear large and positive whereas the effect at these dates is actually zero. Example 4.51 In our numerical example, we have already seen that the TWFE event-study estimator is not severely biased for the event study coefficients. We are going to use an example from Andrew Baker in order to illustrate the bias of the TWFE event-study estimator and try to understand its sources. The data-generating process is: \\[\\begin{align*} y_{i,t} &amp; = \\mu_i + \\delta_t + \\tau_{i,t} + \\epsilon_{i,t}, \\end{align*}\\] where \\(\\mu_i\\sim\\mathcal{N}(0,1)\\), \\(\\delta_t\\sim\\mathcal{N}(0,1)\\) and \\(\\epsilon_{i,t}\\sim\\mathcal{N}(0,0.25)\\). The \\(N=1000\\) inits (firms) are randomly allocated to 40 states \\(g\\), and each state is randommly allocated to one of four treatment groups depending on the year in which it is treated (\\(\\tau_g\\in\\{1986,1992,1998,2004\\}\\)). For every unit incorporated in a treated state, we draw a unit specific treatment effect \\(\\tau_i\\sim\\mathcal{N}(0.3,(1/5)^2)\\), and the cumulated treatment effect for unit \\(i\\) is \\(\\tau_{i,t}=\\tau_i(t-\\tau_g+1)\\). # set seed set.seed(20200403) # Fixed Effects ------------------------------------------------ # unit fixed effects unit &lt;- tibble( unit = 1:1000, unit_fe = rnorm(1000, 0, 1), # generate state state = sample(1:40, 1000, replace = TRUE), # generate treatment effect mu = rnorm(1000, 0.3, 0.2)) # year fixed effects year &lt;- tibble( year = 1980:2010, year_fe = rnorm(31, 0, 1)) # Trend Break ------------------------------------------------------------- # Put the states into treatment groups treat_taus &lt;- tibble( # sample the states randomly state = sample(1:40, 40, replace = FALSE), # place the randomly sampled states into five treatment groups G_g cohort_year = sort(rep(c(1986, 1992, 1998, 2004), 10))) # make main dataset # full interaction of unit X year data.baker &lt;- expand_grid(unit = 1:1000, year = 1980:2010) %&gt;% left_join(., unit) %&gt;% left_join(., year) %&gt;% left_join(., treat_taus) %&gt;% # make error term and get treatment indicators and treatment effects mutate(error = rnorm(31000, 0, 0.5), treat = ifelse(year &gt;= cohort_year, 1, 0), tau = ifelse(treat == 1, mu, 0)) %&gt;% # calculate cumulative treatment effects group_by(unit) %&gt;% mutate(tau_cum = cumsum(tau)) %&gt;% ungroup() %&gt;% # calculate the dep variable mutate(dep_var = unit_fe + year_fe + tau_cum + error) Let’s plot the data now: # plot plot &lt;- data.baker %&gt;% ggplot(aes(x = year, y = dep_var, group = unit)) + geom_line(alpha = 1/8, color = &quot;grey&quot;) + geom_line(data = data.baker %&gt;% group_by(cohort_year, year) %&gt;% summarize(dep_var = mean(dep_var)), aes(x = year, y = dep_var, group = factor(cohort_year), color = factor(cohort_year)), size = 2) + labs(x = &quot;&quot;, y = &quot;Value&quot;) + geom_vline(xintercept = 1986, color = &#39;#E41A1C&#39;, size = 2) + geom_vline(xintercept = 1992, color = &#39;#377EB8&#39;, size = 2) + geom_vline(xintercept = 1998, color = &#39;#4DAF4A&#39;, size = 2) + geom_vline(xintercept = 2004, color = &#39;#984EA3&#39;, size = 2) + scale_color_brewer(palette = &#39;Set1&#39;) + theme(legend.position = &#39;bottom&#39;, legend.title = element_blank(), axis.title = element_text(size = 14), axis.text = element_text(size = 12)) plot Figure 4.40: Average outcomes in Baker’s dataset Let’s estimate an event-study regression on this data: \\[\\begin{align*} y_{i,t} &amp; = \\mu_i + \\delta_t + \\sum_{k\\neq -1}\\beta_k1\\{D^k_{i,t}=k\\} + \\epsilon_{i,t}, \\end{align*}\\] where \\(D^k_{i,t}\\) measures the time to treatment. In practice, we bin together all the treated observations that are treated more than 5 time periods ahead and, in a separate dummy, all the observations that have been treated more than 5 time periods before. Let’s run the regression (note that Andrew Baker uses the felm function of the lfe package instead of the feols function of the fixest package that we have prefentially used): # variables we will use keepvars &lt;- c(&quot;`rel_year_-5`&quot;, &quot;`rel_year_-4`&quot;, &quot;`rel_year_-3`&quot;, &quot;`rel_year_-2`&quot;, &quot;rel_year_0&quot;, &quot;rel_year_1&quot;, &quot;rel_year_2&quot;, &quot;rel_year_3&quot;, &quot;rel_year_4&quot;, &quot;rel_year_5&quot;) # make dummy columns data.baker &lt;- data.baker %&gt;% # make dummies mutate(rel_year = year - cohort_year) %&gt;% dummy_cols(select_columns = &quot;rel_year&quot;) %&gt;% # generate pre and post dummies mutate(Pre = ifelse(rel_year &lt; -5, 1, 0), Post = ifelse(rel_year &gt; 5, 1, 0)) # estimate the model mod &lt;- felm(dep_var ~ Pre + `rel_year_-5` + `rel_year_-4` + `rel_year_-3` + `rel_year_-2` + `rel_year_0` + `rel_year_1` + `rel_year_2` + `rel_year_3` + `rel_year_4` + `rel_year_5` + Post | unit + year | 0 | state, data = data.baker, exactDOF = TRUE) # grab the obs we need DIDBakerEstimTWFEBinned &lt;- broom::tidy(mod) %&gt;% filter(term %in% keepvars) %&gt;% mutate(t = c(-5:-2, 0:5)) %&gt;% select(t, estimate,std.error) %&gt;% bind_rows(tibble(t = -1, estimate = 0, std.error = 0)) %&gt;% mutate(true_tau = ifelse(t &gt;= 0, (t + 1)*.3, 0)) Let us now plot the results estimates: ggplot(aes(x = t, y = estimate),data=DIDBakerEstimTWFEBinned) + geom_linerange(aes(ymin = estimate-1.96*std.error, ymax = estimate+1.96*std.error), color = &#39;darkgrey&#39;, size = 2) + geom_point(color = &#39;blue&#39;, size = 4) + geom_line(aes(x = t, y = true_tau), color = &#39;red&#39;, linetype = &quot;dashed&quot;, size = 2) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_x_continuous(breaks = -5:5) + labs(x = &quot;Relative Time&quot;, y = &quot;Estimate&quot;) + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12)) Figure 4.41: Binned Two Way Fixed Effects estimator in Baker’s dataset The true estimates (in red) appear to have been severely misestimated by the TWFE binned estimator. The pre-trends, which are parallel in the generated data, appear to be affected by a downward slope with the Two Way Fixed Effects estimator. The treatment effects do not increase continuously over time, as they should, and they are most of the time biased downwards. There are two main problems with the event-study model estimated with the TWFE estimator on the data plotted in Figure 4.40: The binned treatment groups, especially the post treatment group, that regroups all observations that have been in the treatment for more than 5 years, does not move after once has entered it. It thus serves as a control group for the more recently treated, which generates a reverse DID estimator, which is biased when treatment effects grow over time. Post 2003, all groups are treated and there thus are no untreated observations to serve as a control group, except for the post treatment binned group. This exacerbates the first problem. The cures for this issues seem to: Never bin observations post-treatment, so that they are never used in a reverse DID design. Never include time periods without any control group in the data. Let’s see what happens when we stop binning our post-treatment observations, we drop all treatment years for which there are no controls and we replace the time-to-treatment indicator by a constant for the never treated group (so that it is not used to build the time to treatment indicators, but only as a control group, to estimate the time fixed effects). data.baker &lt;- data.baker %&gt;% filter(year &lt;= 2003) %&gt;% mutate(cohort_year = ifelse(cohort_year == 2004, 0, cohort_year)) %&gt;% # make relative year indicator mutate(rel_year = year - cohort_year) # get the minimum relative year - we need this to reindex min_year &lt;- min(data.baker %&gt;% filter(cohort_year != 0) %&gt;% pull(rel_year)) # reindex the relative years data.baker &lt;- data.baker %&gt;% mutate(rel_year = rel_year - min_year) %&gt;% dummy_cols(select_columns = &quot;rel_year&quot;) # make regression formula indics &lt;- paste(&quot;rel_year&quot;, (1:max(data.baker %&gt;% filter(cohort_year != 0) %&gt;% pull(rel_year)))[-(-1 - min_year)], sep = &quot;_&quot;, collapse = &quot; + &quot;) keepvars &lt;- paste(&quot;rel_year&quot;, c(-5:-2, 0:5) - min_year, sep = &quot;_&quot;) formula &lt;- as.formula(paste(&quot;dep_var ~&quot;, indics, &quot;| unit + year | 0 | state&quot;)) # run mod mod &lt;- felm(formula, data = data.baker, exactDOF = TRUE) # grab the obs we need DIDBakerEstimTWFECorrect &lt;- broom::tidy(mod) %&gt;% filter(term %in% keepvars) %&gt;% mutate(t = c(-5:-2, 0:5)) %&gt;% select(t, estimate, std.error) %&gt;% bind_rows(tibble(t = -1, estimate = 0, std.error=0)) %&gt;% mutate(true_tau = ifelse(t &gt;= 0, (t + 1)*.3, 0)) Let us now plot the data: ggplot(aes(x = t, y = estimate),data=DIDBakerEstimTWFECorrect) + geom_linerange(aes(ymin = estimate-1.96*std.error, ymax = estimate+1.96*std.error), color = &#39;darkgrey&#39;, size = 2) + geom_point(color = &#39;blue&#39;, size = 4) + geom_line(aes(x = t, y = true_tau), color = &#39;red&#39;, linetype = &quot;dashed&quot;, size = 2) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_x_continuous(breaks = -5:5) + labs(x = &quot;Relative Time&quot;, y = &quot;Estimate&quot;) + theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12)) Figure 4.42: Corrected Two Way Fixed Effects estimator in Baker’s dataset So, in general, Sun and Abraham bias seems to come from a misleading binning of treated observations post treatment and the absence of a never treated group. Let us check whether this would generate weird results for the Two-Way Fixed Effects estimator in our dataset as well. Example 4.52 Let us check whether binning the post-treatment observations together (let’s say the last two) generates bias for the event study estimator in our original dataset. We distinguish between an estimator using the data from the always takers and an estimator not using these observations. # generating the binned indicator data &lt;- data %&gt;% mutate( TimeToTreatmentBinned = if_else(TimeToTreatment&lt;=0,TimeToTreatment,1) ) # event study regression # without the always treated reg.TWFE.event.study.binned.No1 &lt;- feols(y ~ i(TimeToTreatmentBinned,ref=c(-99,-1)) | id + time, data=filter(data,Ds&gt;1)) # with the always treated reg.TWFE.event.study.binned.1 &lt;- feols(y ~ i(TimeToTreatmentBinned,ref=c(-99,-1)) | id + time, data=data) Let us now plot the event study estimates obtained using Two Way Fixed Effects-based methods with binned data: # putting results into a dataframe resultsTWFEEventStudyBinned &lt;- as.data.frame(rbind(cbind(reg.TWFE.event.study.binned.No1$coefficients[1:4],reg.TWFE.event.study.binned.No1$se[1:4]), cbind(reg.TWFE.event.study.binned.1$coefficients[1:4],reg.TWFE.event.study.binned.1$se[1:4]))) colnames(resultsTWFEEventStudyBinned) &lt;- c(&#39;Coef&#39;,&#39;Se&#39;) # adding the time to treatment variable resultsTWFEEventStudyBinned &lt;- resultsTWFEEventStudyBinned %&gt;% mutate( TimeToTreatment = rep(c(-3,-2,0,1),2) ) # adding the reference periods resultsTWFEEventStudyBinned &lt;- rbind(resultsTWFEEventStudyBinned,c(0,0,-1)) resultsTWFEEventStudyBinned &lt;- rbind(resultsTWFEEventStudyBinned,c(0,0,-1)) # adding the method dummy resultsTWFEEventStudyBinned &lt;- resultsTWFEEventStudyBinned %&gt;% mutate( Method = c(rep(&quot;Without Always Treated&quot;,4),rep(&quot;With Always Treated&quot;,4),c(&quot;Without Always Treated&quot;,&quot;With Always Treated&quot;)) ) #plot ggplot(resultsTWFEEventStudyBinned,aes(x=TimeToTreatment,y=Coef,color=Method,linetype=Method))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.43: DID estimates around the treatment date estimated using the Binned TWFE estimator (reference period \\(\\tau&#39;=1\\)) Figure 4.43 confirms the analysis based on Andrew Baker’s data presented in Figure 4.41. Binning the data post-treatment severely biases the event study graph estimated using a Two-Way Fixed Effects estimator, especially if one keeps the always treated observations in the dataset. 4.3.3.2.10 Summary Let us regroup all the event study estimates and all the aggregated estimates of the TT together in order to compare them with the true estimator. Let us start with the event study estimates first. 4.3.3.2.10.1 Event study estimates # let us first combine all the estimators together DID.event.study.all &lt;- rbind( DID.tau %&gt;% filter(d==&quot;Aggregate&quot;) %&gt;% select(tau,ATT.tau) %&gt;% mutate(Method=&quot;Weighted DID&quot;,Se=0) %&gt;% rename(TimeToTreatment=tau,Coef=ATT.tau), disaggregate.SA %&gt;% filter(Group==&quot;Aggregate&quot;) %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;Sun &amp; Abraham&quot;), DID.CSA %&gt;% filter(Group==&quot;Aggregate&quot;) %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;Callaway &amp; SantAnna&quot;), DID.dCdH %&gt;% mutate(Method=&quot;de Chaisemartin &amp; d&#39;Haultfoeuille&quot;), DID.BJS %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;Borusyak, Jaravel &amp; Speiss&quot;), resultsGardnerEventStudy %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;Gardner&quot;), resultsStackedDIDEventStudy %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;Stacked DID&quot;), resultsTWFEEventStudy %&gt;% select(TimeToTreatment,Coef,Se) %&gt;% mutate(Method=&quot;TWFE&quot;) ) # Let us now add the true value of the treatment effect in the sample. # it is not easy to estimate # we are going to use variable weights and the meriod -1 as reference (taking its treatment effect our of all treatment effect estimates) DID.truth &lt;- data %&gt;% mutate( alpha = if_else(D==1,y1-y0,0) ) %&gt;% filter(Group&gt;1) %&gt;% group_by(TimeToTreatment) %&gt;% summarize( Coef=if_else(TimeToTreatment&gt;=0,mean(alpha),0) ) %&gt;% mutate( Method=&quot;Truth&quot;, Se=0 ) %&gt;% filter(TimeToTreatment&lt;3) # regrouping DID.event.study.all &lt;- rbind(DID.event.study.all,DID.truth) %&gt;% mutate( Method=factor(Method,levels=c(&quot;Truth&quot;,&quot;Weighted DID&quot;,&quot;Sun &amp; Abraham&quot;,&quot;Callaway &amp; SantAnna&quot;,&quot;de Chaisemartin &amp; d&#39;Haultfoeuille&quot;,&quot;Borusyak, Jaravel &amp; Speiss&quot;,&quot;Gardner&quot;,&quot;Stacked DID&quot;,&quot;TWFE&quot;)) ) Let us now plot the data: # plot ggplot(DID.event.study.all,aes(x=TimeToTreatment,y=Coef,colour=Method,linetype=Method,shape=Method))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + scale_colour_discrete(name=&quot;Treatment\\ngroup&quot;)+ scale_linetype_discrete(name=&quot;Treatment\\ngroup&quot;)+ scale_shape_discrete(name=&quot;Treatment\\ngroup&quot;)+ theme_bw() Figure 4.44: Event study estimates around the treatment date with various methods (reference period \\(\\tau&#39;=1\\)) Note that all estimators are pretty similar. There is a dip 3 periods before treatment for some estimators. It is actually a true dip due to time varying selection bias at the first period which is embedded in the model. Remark. Another approach to compare all estimators would be to use directly the did2s package. The command event_study uses almost all the commands already presented and integrates them into one unique analysis. Let’s see how this works. # modifying the name of the control group variable to 0 data &lt;- data %&gt;% mutate( Ds=if_else(Ds==99,0,Ds) ) # regression reg.event.study.all &lt;- event_study(data=filter(data,Ds!=1),yname = &quot;y&quot;, idname=&quot;id&quot;, tname = &quot;time&quot;,gname=&quot;Ds&quot;) # modifying the name of the control group variable back to 99 data &lt;- data %&gt;% mutate( Ds=if_else(Ds==0,99,Ds) ) Let’s now plot the results. It is made super easy by the command plot_event_study but we could also use the same ggplot command that we have used so far. # using the plot_event_study command (not super nice, so not shown) # plot_event_study(reg.event.study.all,seperate = F) # preparing data reg.event.study.all &lt;- reg.event.study.all %&gt;% mutate( estimator=factor(estimator,levels=c(&quot;Sun and Abraham (2020)&quot;,&quot;Callaway and Sant&#39;Anna (2020)&quot;,&quot;Borusyak, Jaravel, Spiess (2021)&quot;,&quot;Gardner (2021)&quot;,&quot;TWFE&quot;,&quot;Roth and Sant&#39;Anna (2021)&quot;)) ) %&gt;% rename( Method=estimator, Coef=estimate, Se=std.error, TimeToTreatment=term ) # using classical ggplot ggplot(reg.event.study.all,aes(x=TimeToTreatment,y=Coef,group=Method,color=Method))+ geom_line() + geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Time relative to treatment&quot;) + scale_x_continuous(breaks=c(-3,-2,-1,0,1,2)) + expand_limits(y=0) + theme_bw() Figure 4.45: DID estimates around the treatment date estimated using various procedures (reference period \\(\\tau&#39;=1\\)) There is a problem here, let’s hope we can find a way to solve it. 4.3.3.2.10.2 Aggregate Treatment on the Treated Estimates Let us now see what happens to the average effect of the treatment on the treated. # let us first combine all the estimators together DID.TT.all &lt;- DID.event.study.all &lt;- rbind( data.frame(Coef=c(ATT.equal),Se=c(0)) %&gt;% mutate(Method=&quot;Weighted DID Equal&quot;,Se=0), data.frame(Coef=c(ATT.varying),Se=c(0)) %&gt;% mutate(Method=&quot;Weighted DID Varying&quot;,Se=0), as.data.frame(ATT.agg.SA) %&gt;% rename(Coef=Estimate,Se=colnames(ATT.agg.SA)[[2]]) %&gt;% select(Coef,Se) %&gt;% mutate(Method=&quot;Sun &amp; Abraham&quot;), as.data.frame(ATT.agg.CSA[1:2]) %&gt;% rename(Coef=overall.att,Se=overall.se) %&gt;% mutate(Method=&quot;Callaway &amp; SantAnna&quot;), data.frame(Coef=c(reg.dCdH$effect),Se=c(0)) %&gt;% mutate(Method=&quot;de Chaisemartin &amp; d&#39;Haultfoeuille&quot;), reg.BJS.Agg[2:3] %&gt;% rename(Coef=estimate,Se=std.error) %&gt;% mutate(Method=&quot;Borusyak, Jaravel &amp; Speiss&quot;), data.frame(Coef=coef(reg.Gardner)[[1]],Se=se(reg.Gardner)[[1]]) %&gt;% mutate(Method=&quot;Gardner&quot;), data.frame(Coef=coef(reg.stacked.aggregate)[[1]],Se=se(reg.stacked.aggregate)[[1]]) %&gt;% mutate(Method=&quot;Stacked DID&quot;), data.frame(Coef=reg.TWFE.aggregate$coefficients[[1]],Se=reg.TWFE.aggregate$se[[1]]) %&gt;% mutate(Method=&quot;TWFE&quot;) ) # Let us now add the true value of the treatment effect in the sample. ATT.truth &lt;- data %&gt;% filter(Group&gt;1,D==1) %&gt;% mutate( alpha = y1-y0 ) %&gt;% summarize( Coef=mean(alpha) ) %&gt;% mutate( Method=&quot;Truth&quot;, Se=0 ) # regrouping DID.TT.all &lt;- rbind(DID.TT.all,ATT.truth) %&gt;% mutate( Method=factor(Method,levels=c(&quot;Truth&quot;,&quot;Weighted DID Equal&quot;,&quot;Weighted DID Varying&quot;,&quot;Sun &amp; Abraham&quot;,&quot;Callaway &amp; SantAnna&quot;,&quot;de Chaisemartin &amp; d&#39;Haultfoeuille&quot;,&quot;Borusyak, Jaravel &amp; Speiss&quot;,&quot;Gardner&quot;,&quot;Stacked DID&quot;,&quot;TWFE&quot;)) ) Let us now plot the results: # plot ggplot(DID.TT.all,aes(x=Method,y=Coef))+ geom_pointrange(aes(ymin=Coef-1.96*Se,ymax=Coef+1.96*Se)) + ylab(&quot;DID estimate&quot;) + xlab(&quot;Method&quot;) + expand_limits(y=0) + coord_flip() + theme_bw() Figure 4.46: Average treatment effect on the treated estimates with various methods (reference period \\(\\tau&#39;=1\\)) Figure 4.46 shows that the true effect of the treatment in the sample (with weights proportional to actual exposure to the treatment) is correctly estimated by the Weighted DID estimator using weights varying with exposure, but also by the correct estimators of Sun and Abraham, Callaway and Sant’Anna, Borusyak, Jaravel and Speiss and Gardner. The Two-Way fixed Effect estimator finds a negative treatment effect whereas all treatment effects are positive. The Stacked DID estimator finds too large a treatment effect, probably because it gives too much weight to later treatment periods. The de Chaisemartin and d’Haultfoeuille estimator used here only aims at estimating the effect of the treatment in the first time period, for which it is consistent. Remark. Several open questions remain after this section. They are mostly cosmetic since thay are questions about properties of the Two-Way Fixed Effects estimator, and thus do not affect the properties of the correct estimators that we have studied: Does the Two Way Fixed Effect estimator recover a correct treatment effect (that is only with positive weights) when the equivalent to Assumption 4.19 holds? Does the event-study Two Way Fixed Effect estimator recover the correct dynamics of treatment effects when there is no binning of the treated observations past some date, and there is a never treated group that is used to estimate the time fixed effects? Our example in Section 4.3.3.2.9.2 seems to suggest that it is so, while the slightly different results of that estimator with respect to the correct ones in the summary of results above seems to suggest otherwise. An example where the event-study Two Way Fixed Effect estimator fails but these conditions hold would be very useful to understand the scope of Theorem 4.23 better. Does the gain in efficiency obtained by the imputation estimator is still present when combining all the DID estimates from all the possible comparison groups, as in the weigthed DID estimator we have proposed? 4.3.3.3 Estimation of sampling noise We now need to derive the asymptotic distribution of our estimators in a staggered DID design. We are going to do that for the Sun and Abraham estimator, which is the simplest estimator that is estimated by OLS, Within, LSDV, First Difference or faster TWFE estimators and extends the simple DID estimators to staggered designs. There are two sets of parameters for which we might want to know their distribution: the parameter specific to each treated group and relative time to treatment \\(\\hat\\beta^{SA}_{d,\\tau}\\) and the aggregated treatment effect \\(\\hat\\Delta^{Y}_{TT}(k)\\) for some set of weights \\(w^k(d,d&#39;,\\tau,\\tau&#39;)\\). Let’s look at these parameters in turn. 4.3.3.3.1 Estimation of sampling noise for the effect of the treatment on each group and at each time period We can estimate the \\(\\hat\\beta^{SA}_{d,\\tau}\\) with either repeated cross section data or panel data. Let us start with studying what happens with repeated cross sections before moving to panel data. 4.3.3.3.1.1 Estimation of sampling noise for the effect of the treatment on each group and at each time period with repeated cross sections With repeated cross sections, we can only use the OLS DID estimator of the Sun and Abraham model. The following theorem derives its distribution: Theorem 4.24 (Asymptotic Distribution of Sun and Abraham Estimator in Repeated Cross Sections) Under Assumptions 4.12, 4.13, 4.14, 4.17 and 2.3, and with repeated cross sections of total size \\(N\\), we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\beta^{SA}_{d,\\tau}-\\beta^{SA}_{d,\\tau}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{1}{p^{d,\\tau}} \\left[\\frac{\\var{Y^0_{i,d-1}|D_i=\\infty}}{(1-p^{d,\\tau}_D)(1-p^{d,\\tau}_A)} +\\frac{\\var{Y^0_{i,d-1}|D_i=d}}{p^{d,\\tau}_D(1-p^{d,\\tau}_A)}\\right.\\right. \\\\ &amp; \\phantom{\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(0,\\frac{1}{p^{d,\\tau}}\\right.}\\left.\\left. +\\frac{\\var{Y^0_{i,d+\\tau}|D_i=\\infty}}{(1-p^{d,\\tau}_D)p^{d,\\tau}_A} +\\frac{\\var{Y^1_{i,d+\\tau}|D_i=\\infty}}{p^{d,\\tau}_Dp^{d,\\tau}_A} \\right]\\right) \\end{align*}\\] where \\(p^{d,\\tau}=\\Pr((D_i=d\\cup D_i=\\infty)\\cap(T_i=d-1\\cup T_i=d+\\tau))\\), \\(p^{d,\\tau}_D=\\Pr(D_i=d|(D_i=d\\cup D_i=\\infty)\\cap(T_i=d-1\\cup T_i=d+\\tau))\\) and \\(p^{d,\\tau}_A=\\Pr(T_i=d+\\tau|(D_i=d\\cup D_i=\\infty)\\cap(T_i=d-1\\cup T_i=d+\\tau))\\). Proof. See Section A.3.5. Remark. Note that Theorem 4.24 is very close to Theorem 4.12. The only difference is the additional \\(p^{d,\\tau}\\) term which adjusts the sample size by the actual number of observations used in the estimation of \\(\\hat\\beta^{SA}_{d,\\tau}\\). 4.3.3.3.1.2 Estimation of sampling noise for the effect of the treatment on each group and at each time period with panel data With panel data, we can estimate \\(\\hat\\beta^{SA}_{d,\\tau}\\) using various sets of estimators: the OLS DID model, the within transformation of the Sun and Abraham model with individual dummies, the Least Squares Dummy Variables model estimated by OLS, the First Difference model and the enhanced estimators (Alternating Projections and Likelihood Concentration). Theorem 4.20 implies that all these estiamtors are similar and identical to the individual DID estimators. We can thus use Theorem 4.11 in order to provide a CLT-based estimate the sampling noise of the Sun and Abraham estimator of the individual treatment effects in panel data. The following theorem derives its distribution: Theorem 4.25 (Asymptotic Distribution of Sun and Abraham Estimator in Panel Data) Under Assumptions 4.12, 4.13, 4.14, 4.15 and 4.16, and with panel data with \\(N\\) units observed over \\(T\\) periods, we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\beta^{SA}_{d,\\tau}-\\beta^{SA}_{d,\\tau}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{1}{p^{d,\\infty}}\\left(\\frac{\\var{Y_{i,d+\\tau}^1-Y_{i,d-1}^0|D_i=d}}{p^{d,\\tau}_D}+\\frac{\\var{Y_{i,d+\\tau}^0-Y_{i,d-1}^0|D_i=\\infty}}{1-p^{d,\\tau}_D}\\right)\\right), \\end{align*}\\] where \\(p^{d,\\infty}=\\Pr(D_i=d\\cup D_i=\\infty)\\). Proof. See Section A.3.7. 4.3.3.3.2 Estimation of sampling noise for aggregate treatment effects The key now is to derive the distribution of the event study parameters and of the average treatment effect on the treated. We are going to use the Delta Method in order to do so, but that requires determining the covariance matrix of the \\(\\hat\\beta_{d,\\tau}^{SA}\\) parameters. Under Assumption 4.15 for panel data or 4.17 in repeated cross sections, most of the \\(\\hat\\beta_{d,\\tau}^{SA}\\) parameters are independent from each other, except for the ones which make use of the same parts of the data. 4.3.3.3.2.1 Estimation of sampling noise for aggregate treatment effects with repeated cross sections The following theorem derives the asymptotic distribution of the aggregated treatment on the treated parameter based on the individual DID estimates stemming from Sun and Abraham’s estimator, in repeated cross sections. Theorem 4.26 (Asymptotic Distribution of Treatment of the Treated Estimated Using Sun and Abraham Estimator in Repeated Cross Sections) Under Assumptions 4.12, 4.13, 4.14, 4.17 and 2.3, and with repeated cross sections of total size \\(N\\), we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^{Y}_{TT_{SA}}(k)-\\Delta^{Y}_{TT_{SA}}(k)) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\sum_d\\sum_{\\tau}V(\\hat\\beta^{SA}_{d,\\tau})(w^k(d,d-1,\\tau,\\infty))^2 \\right.\\\\ &amp; \\phantom{\\stackrel{d}{\\rightarrow}}\\left.+\\sum_{d\\neq d&#39;}\\sum_{\\tau\\neq\\tau&#39;}\\text{Cov}(\\hat\\beta^{SA}_{d,\\tau},\\hat\\beta^{SA}_{d&#39;,\\tau&#39;})w^k(d,d-1,\\tau,\\infty)w^k(d&#39;,d&#39;-1,\\tau&#39;,\\infty)\\right), \\end{align*}\\] where: \\[\\begin{align*} V(\\hat\\beta^{SA}_{d,\\tau}) &amp; =\\frac{1}{p^{d,\\tau}}\\left[\\frac{\\var{Y^0_{i,d-1}|D_i=\\infty}}{(1-p^{d,\\tau}_D)(1-p^{d,\\tau}_A)} +\\frac{\\var{Y^0_{i,d-1}|D_i=d}}{p^{d,\\tau}_D(1-p^{d,\\tau}_A)}\\right. \\\\ &amp; \\phantom{=} \\left.+\\frac{\\var{Y^0_{i,d+\\tau}|D_i=\\infty}}{(1-p^{d,\\tau}_D)p^{d,\\tau}_A} +\\frac{\\var{Y^1_{i,d+\\tau}|D_i=\\infty}}{p^{d,\\tau}_Dp^{d,\\tau}_A}\\right]\\\\ \\text{Cov}(\\hat\\beta^{SA}_{d,\\tau},\\hat\\beta^{SA}_{d&#39;,\\tau&#39;}) &amp; = \\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}} \\left[\\frac{\\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{(1-p_A^{d,\\tau})(1-p_A^{d&#39;,\\tau&#39;})(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\right.\\\\ &amp; \\phantom{=\\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}}}\\left. +\\frac{\\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}}{(1-p_A^{d,\\tau})(1-p_A^{d&#39;,\\tau&#39;})p_D^{d,\\tau}p_D^{d&#39;,\\tau&#39;}}\\right] \\text{ when } d=d&#39;\\\\ &amp; = \\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}p_A^{d,\\tau}p_A^{d&#39;,\\tau&#39;}(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})}\\text{ when } d+\\tau=d&#39;+\\tau&#39; \\\\ &amp; = -\\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}(1-p_A^{d,\\tau})p_A^{d&#39;,\\tau&#39;}(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\text{ when } d-1=d&#39;+\\tau&#39;\\\\ &amp; = -\\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d&#39;-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}p_A^{d,\\tau}(1-p_A^{d&#39;,\\tau&#39;})(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\text{ when } d+\\tau=d&#39;-1\\\\ &amp; = 0 \\text{ otherwise}, \\end{align*}\\] with \\(p^{d,\\tau,d&#39;,\\tau&#39;}=\\Pr(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1)\\), \\(p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}=\\Pr(T_j=d+\\tau|D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1)\\) and \\(p_D^{d,\\tau,d&#39;,\\tau&#39;}=\\Pr(D_j^{d&#39;}=1\\cup D_j^{d}=1|D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1)\\). Proof. See Section A.3.6. Remark. Note that the covariance terms in Theorem 4.26 make a lot of sense. First, the proportions used to normalize the variance terms correspond exactly to the proportion of observations in the relevant groups. Second, the signs of the covariances are consistent with common sense. When \\(d=d&#39;\\), the individual components \\(\\hat\\beta^{SA}_{d,\\tau}\\) and \\(\\hat\\beta^{SA}_{d&#39;,\\tau&#39;}\\) estimate the impact for the same treatment group. They thus share their baseline means (both for the treated and control group observed at period \\(d-1\\)). As a consequence, they are positively correlated. When \\(d+\\tau=d&#39;+\\tau&#39;\\), both groups share the same post-treatment period, and thus use the same observations from the control group to build the After period, thereby generating a positive correlation again. When \\(d-1=d&#39;+\\tau&#39;\\) or \\(d&#39;-1=d+\\tau\\), both estimators share the same group of observations from the control group. One uses them as a reference period, while the other uses the same observations as the after treatment period. As a consequence, the estimators are negatively correlated in that case. 4.3.3.3.2.2 Estimation of sampling noise for aggregate treatment effects with panel data Finally, we need to determine the asymptotic distribution of the aggregate average treatment effect on the treated \\(\\Delta^Y_{TT}(k)\\). Theorem 4.27 (Asymptotic Distribution of Treatment of the Treated Estimated Using Sun and Abraham Estimator in Panel Data) Under Assumptions 4.12, 4.13, 4.14, 4.15 and 4.16, and with panel data containing a total of \\(N\\) units, we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^{Y}_{TT_{SA}}(k)-\\Delta^{Y}_{TT_{SA}}(k)) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\sum_d\\sum_{\\tau}V_P(\\hat\\beta^{SA}_{d,\\tau})(w^k(d,d-1,\\tau,\\infty))^2\\right), \\end{align*}\\] where: \\[\\begin{align*} V_P(\\hat\\beta^{SA}_{d,\\tau}) &amp; =\\frac{1}{p^{d,\\tau}}\\left(\\frac{\\var{Y_{i,d+\\tau}^1-Y_{i,d-1}^0|D_i=d}}{p^{d,\\tau}_D}+\\frac{\\var{Y_{i,d+\\tau}^0-Y_{i,d-1}^0|D_i=\\infty}}{1-p^{d,\\tau}_D}\\right). \\end{align*}\\] Proof. See Section A.3.8. 4.3.4 Difference In Differences with Instrumental Variables Sometimes, the Parallel Trends Assumption (Assumption 4.14 or Assumption 4.25 with staggered designs) does not hold. This might be because individuals select into the treatment based on unobservables correlated with the dynamics of outcomes in the absence of the treatment. One of the most famous cases in point is the dip in earnings that future participants experience before entering a Job Training Program. In that case, one might be able to reframe the Parallel Trends Assumption to hold not with respect to treatment participation, but with respect to an instrumental variable that affects participation in the treatment. In such a case, we say that we have a Difference In Differences design with Instrumental Variables or DID-IV for short. In this section, we are going to study how to identify treatment effects in this design and how to estimate them and their precision. In DID-IV designs, a key distinction is between a strong first stage and a weak first stage. In a strong first stage, observations with a low level of the instrumental variable do not access the program, while in a weak first stage, they can. In a world of heterogeneous treatment effects, this distinction turns out to be crucial. We will first delineate identification and estimation in the case of a strong first stage, and then move on to what happens in the more complex case of a weak first stage. 4.3.4.1 DID-IV with a strong first stage Let us first examine what is happening with DID-IV under a strong first stage. We are going to consider identification, estimation and estimation of sampling noise. 4.3.4.1.1 Identification under strong first stage DID-IV We need some assumptions first. We are going to go back to the case where there are only two time periods, one before (\\(t=B\\)) and one after (\\(t=A\\)). We are going to keep making Assumptions 4.12 and 4.13 of absence of treatment in period \\(t=B\\) and of absence of anticipation effects. On top of these assumptions, we are first going to assume that there is a random variable \\(Z_i\\) taking two values (\\(Z_i=1\\) and \\(Z_i=0\\)) such that the parallel trends assumption holds for this variable: Hypothesis 4.28 (Parallel Trends with Instrumental Variables) We assume that the trends in the potential outcomes in the absence the treatment are the same, independent of the value of the instrumental variable: \\[\\begin{align*} \\esp{Y^0_{i,A}|Z_i=1} - \\esp{Y^0_{i,B}|Z_i=1} &amp; = \\esp{Y^0_{i,A}|Z_i=0} - \\esp{Y^0_{i,B}|Z_i=0}. \\end{align*}\\] We also assume that the instrumental variables alters the probability that a unit receives the treatment: Hypothesis 4.29 (Strong First Stage) The probability of receiving the treatment is strictly positive when \\(Z_i=1\\) and is zero when \\(Z_i=0\\): \\[\\begin{align*} \\Pr(D_i=1|Z_i=1)&gt;\\Pr(D_i=1|Z_i=0)=0. \\end{align*}\\] Remark. Assumption 4.29 is really strong. Combined with Assumption 4.12, it implies that the only group which is able to receive the treament is the group with \\(Z_i=1\\) in the After period. Equipped with these assumptions, we can now prove the following theorem: Theorem 4.28 (Indentification of TT with DID-IV and a Strong First Stage) Under Assumptions 4.12, 4.13, 4.28 and 4.29, TT is identified by the Wald-DID estimator: \\[\\begin{align*} \\Delta^Y_{WaldDID} &amp; = \\Delta^{Y_A}_{TT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{WaldDID} &amp; = \\frac{\\esp{Y_{i,A}|Z_i=1}-\\esp{Y_{i,A}|Z_i=0}-(\\esp{Y_{i,B}|Z_i=1}-\\esp{Y_{i,B}|Z_i=0})}{\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,A}=1|Z_i=0)-(\\Pr(D_{i,B}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=0))}. \\end{align*}\\] Proof. Under Assumption 4.28, we have: \\[\\begin{align*} \\esp{Y^0_{i,A}|Z_i=1} &amp; = \\esp{Y^0_{i,A}|Z_i=0} + (\\esp{Y^0_{i,B}|Z_i=1}-\\esp{Y^0_{i,B}|Z_i=0}) \\end{align*}\\] As a consequence, the numerator of the Wald-DID estimator is: \\[\\begin{align*} \\esp{Y_{i,A}|Z_i=1} &amp; -\\esp{Y_{i,A}|Z_i=0}-(\\esp{Y_{i,B}|Z_i=1}-\\esp{Y_{i,B}|Z_i=0}) \\\\ &amp; = \\esp{Y_{i,A}|Z_i=1} - \\esp{Y^0_{i,A}|Z_i=1} \\\\ &amp; = \\esp{Y^1_{i,A}|D_i=1,Z_i=1}\\Pr(D_i=1|Z_i=1)+\\esp{Y^0_{i,A}|D_i=0,Z_i=1}\\Pr(D_i=0|Z_i=1)\\\\ &amp;\\phantom{=}-\\esp{Y^0_{i,A}|D_i=1,Z_i=1}\\Pr(D_i=1|Z_i=1)+\\esp{Y^0_{i,A}|D_i=0,Z_i=1}\\Pr(D_i=0|Z_i=1)\\\\ &amp; = \\left(\\esp{Y^1_{i,A}|D_i=1,Z_i=1}-\\esp{Y^0_{i,A}|D_i=1,Z_i=1}\\right)\\Pr(D_i=1|Z_i=1)\\\\ &amp; = \\Delta^{Y_A}_{TT}\\Pr(D_i=1|Z_i=1), \\end{align*}\\] where the last equality uses the fact that \\(D_i=1\\) is a subset of \\(Z_i=1\\). Using Assumption 4.29 proves that the denominator of the Wald-DID estimator is equal to \\(\\Pr(D_i=1|Z_i=1)\\), which proves the result. Example 4.53 Let’s see how this approach works in our example. We are going to assume that there are 50 states and that the treatment is only available in half of them. This state indicator is going to be our instrumental variable. In our model, states fixed effects are going to be correlated with treatment intake (and even with \\(Z_i\\)) but \\(Z_i\\) wil not be correlated with indiosyncratic shocks to outcomes that make people enter the treatment. \\[\\begin{align*} \\mu_i &amp; = \\mu^S_i + \\mu^U_i + \\bar{\\mu} \\\\ \\mu^S_i &amp; \\sim\\mathcal{N}(0,\\frac{1}{3}\\sigma_{\\mu}^2)\\\\ \\mu^U_i &amp; \\sim\\mathcal{N}(0,\\frac{2}{3}\\sigma_{\\mu}^2)\\\\ Z _i &amp; = \\begin{cases} 1 &amp; \\text{ if } \\mu^S_i\\leq 0 \\\\ 0 &amp; \\text{ if } \\mu^S_i&gt; 0 \\end{cases}\\\\ D_i &amp; = \\uns{y_i^B\\leq\\bar{y} \\land Z_i=1}. \\end{align*}\\] Let us first respecify the parameter vector: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1,0.1,7.98) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;gamma&quot;,&quot;baryB&quot;) Let’s simulate that dataset. set.seed(1234) N &lt;-1000 param[&quot;rho&quot;] &lt;- 0.9 # I am going to draw a state fixed effect for 50 states with variance 1/3 of the total variance of mu Nstates &lt;- 50 muS &lt;- rnorm(Nstates,0,sqrt(param[&quot;sigma2mu&quot;]/3)) muS &lt;- rep(muS,each=N/Nstates) # I draw an individual fixed effect with the remaining variance muU &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]*2/3)) mu &lt;- param[&quot;barmu&quot;] + muS + muU UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # Z=1 if states have lower muS than 0 Z &lt;- ifelse(muS&lt;=0,1,0) Ds &lt;- ifelse(YB&lt;=param[&quot;barY&quot;] &amp; Z==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let us know look at how Assumption 4.29 holds: # preparing the means of participants proportions means.did.iv &lt;- c(mean(Ds[Z==0]),mean(Ds[Z==1]),mean(y0[Z==0]),mean(y0[Z==1]),mean(y[Z==0]),mean(y[Z==1]),mean(yB[Z==0]),mean(yB[Z==1]),0,1) means.did.iv &lt;- matrix(means.did.iv,nrow=2,ncol=5,byrow=FALSE,dimnames=list(c(&#39;Z=0&#39;,&#39;Z=1&#39;),c(&#39;D&#39;,&#39;y0&#39;,&#39;y&#39;,&#39;yB&#39;,&#39;Z&#39;))) means.did.iv &lt;- as.data.frame(means.did.iv) # plotting the result ggplot(means.did.iv, aes(x=as.factor(Z), y=D)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;)+ xlab(&#39;Z&#39;)+ ylab(&#39;Pr(D=1|Z)&#39;)+ theme_bw() Figure 4.47: Illustration of the DID-IV assumptions: Strong First Stage Figure 4.47 shows that no unit with \\(Z_i=0\\) receives the treatment. We also have that \\(\\hat{\\Pr}(D_i=1|Z_i=1)=\\) 0.36. A key feature of the simulated dataset is that the parallel trends assumption does not hold for \\(D_i\\) but it does for \\(Z_i\\). Let’s check. We indeed have that \\(\\hatesp{y^0_{i}|D_i=1}-\\hatesp{y^B_{i}|D_i=1}=\\) 0.12 and \\(\\hatesp{y^0_{i}|D_i=0}-\\hatesp{y^B_{i}|D_i=0}=\\) 0.04. We also have \\(\\hatesp{y^0_{i}|Z_i=1}-\\hatesp{y^B_{i}|Z_i=1}=\\) 0.06 and \\(\\hatesp{y^0_{i}|Z_i=0}-\\hatesp{y^B_{i}|Z_i=0}=\\) 0.05. The true effect of the treatment in our model is: \\[\\begin{align*} \\Delta^y_{TT} &amp; = \\bar{\\alpha}+ \\theta\\esp{\\mu_i|\\mu_i+U_i^B\\leq\\bar{y} \\land \\mu_i^S\\leq0} \\end{align*}\\] To compute the expectation of a this censored normal, I use the package tmvtnorm: The value of \\(\\Delta^y_{TT}\\) in the population is thus 0.17 and in the sample 0.17. Simple DID would not be a correct estimate of \\(TT\\). Indeed, the value of the DID estimator in the sample is 0.24. The Wald DID estimator should be closer to the truth. In the sample, it is equal to 0.2. 4.3.4.1.2 Estimation Estimation of the DID-IV estimator can be conducted using several approaches. Let’s review them in turn. 4.3.4.1.2.1 Using the direct Wald estimator The most direct way to compute the DID-IV estimator in a sample is simply to compute its sample equivalent: \\[\\begin{gather*} \\hat{\\Delta}^Y_{WaldDID}= \\\\ \\frac{\\frac{1}{\\sum_{i=1}^{N}Z_i}\\sum_{i=1}^{N}Y_{i,A}Z_i - \\frac{1}{\\sum_{i=1}^{N}(1-Z_i)}\\sum_{i=1}^{N}Y_{i,A}(1-Z_i) -\\left(\\frac{1}{\\sum_{i=1}^{N}Z_i}\\sum_{i=1}^{N}Y_{i,B}Z_i - \\frac{1}{\\sum_{i=1}^{N}(1-Z_i)}\\sum_{i=1}^{N}Y_{i,B}(1-Z_i)\\right)} {\\frac{1}{\\sum_{i=1}^{N}Z_i}\\sum_{i=1}^{N}D_{i,A}Z_i - \\frac{1}{\\sum_{i=1}^{N}(1-Z_i)}\\sum_{i=1}^{N}D_{i,A}(1-Z_i) -\\left(\\frac{1}{\\sum_{i=1}^{N}Z_i}\\sum_{i=1}^{N}D_{i,B}Z_i - \\frac{1}{\\sum_{i=1}^{N}(1-Z_i)}\\sum_{i=1}^{N}D_{i,B}(1-Z_i)\\right)}. \\end{gather*}\\] Remark. Under Assumption 4.29, the denominator simplifies to \\(\\frac{1}{\\sum_{i=1}^{N}Z_i}\\sum_{i=1}^{N}D_{i}Z_i\\). Example 4.54 Let’s see how this estimator works in our example. As we have already seen, in our example, the Wald DID estimator is equal to 0.2. Remember that the value of \\(\\Delta^y_{TT}\\) in the population is 0.17 and in the sample 0.17. 4.3.4.1.2.2 Using the pooled 2SLS DID estimator In repeated cross-sections, one can estimate the Wald estimator estimating the following model with the 2SLS estimator: \\[\\begin{align*} Y_i &amp; = \\alpha + \\delta t_i + \\gamma D_i + \\beta t_iD_i + U_i, \\end{align*}\\] with \\(t_iZ_i\\) as an instrument for \\(t_iD_i\\) and \\(Z_i\\) as an instrument for \\(D_i\\). \\(\\hat{\\beta}_{2SLS}\\) in the previous regression is the Pooled 2SLS DID estimator. Example 4.55 Let’s estimate that model in our example. # regrouping data y.pool &lt;- c(y,yB) Ds.pool &lt;- c(Ds,Ds) Z.pool &lt;- c(Z,Z) t &lt;- c(rep(1,N),rep(0,N)) t.D &lt;- t*Ds.pool t.Z &lt;- t*Z.pool # IV regression reg.iv.did.pooled.2sls &lt;- ivreg(y.pool ~ t + Ds.pool + t.D | t + Z.pool + t.Z) In our example, \\(\\hat{\\beta}_{2SLS}=\\) 0.2. 4.3.4.1.2.3 Using the within 2SLS DID estimator Estimating the following equation with \\(t_iZ_i\\) as an instrument for \\(t_iD_i\\): \\[\\begin{align*} Y_{i,t} &amp; = \\mu_i + \\delta_t + \\beta t_iD_i + U_i \\end{align*}\\] \\(\\hat{\\beta}_{IVFE}\\) in the previous regression is the Fixed Effects DID-IV estimator. Example 4.56 Let’s estimate this model in our example. data.panel &lt;- cbind(c(seq(1,N),seq(1,N)),t,y.pool,Ds.pool,t.D,t.Z,Z.pool) colnames(data.panel) &lt;- c(&#39;Individual&#39;,&#39;time&#39;,&#39;y&#39;,&#39;Ds&#39;,&#39;t.D&#39;,&#39;t.Z&#39;,&#39;Z&#39;) data.panel &lt;- as.data.frame(data.panel) reg.iv.did.fe &lt;- plm(y ~ time + t.D | time + t.Z,data=data.panel,index=c(&#39;Individual&#39;,&#39;time&#39;),model=&#39;within&#39;) In our illustration, \\(\\hat{\\beta}_{IVFE}=\\) 0.2. 4.3.4.1.2.4 Using the first-differenced 2SLS DID estimator Estimate the following equation with \\(Z_i\\) as an instrument for \\(D_i\\): \\[\\begin{align*} Y_{i,A}-Y_{i,B} &amp; = \\delta + \\beta D_i + U_i \\end{align*}\\] \\(\\hat{\\beta}_{IVFD}\\) in the previous regression estimated by 2SLS is the First Difference DID estimator. Example 4.57 Let’s see how this works in our example. reg.iv.did.fd &lt;- plm(y ~ time + t.D | time + t.Z,data=data.panel,index=c(&#39;Individual&#39;,&#39;time&#39;),model=&#39;fd&#39;) In our illustration, \\(\\hat{\\beta}_{IVFD}=\\) 0.2. 4.3.4.1.2.5 Equivalence result Theorem 4.29 (Equivalence of DID-IV Estimators) With panel data and two periods of observation, we have: \\[\\begin{align*} \\hat{\\Delta}^{Y}_{WaldDID} &amp; = \\hat{\\beta}_{2SLS} = \\hat{\\beta}_{IVFE} = \\hat{\\beta}_{IVFD}. \\end{align*}\\] Proof. To do. Seems pretty straightforward for \\(IVFD\\). Example 4.58 Let’s finally see how our estimators perform over sampling repetitions. Let us study panel data first. monte.carlo.iv.did.panel &lt;- function(s,N,Nstates,param){ set.seed(s) muS &lt;- rnorm(Nstates,0,sqrt(param[&quot;sigma2mu&quot;]/3)) muS &lt;- rep(muS,each=N/Nstates) # I draw an individual fixed effect with the remaining variance muU &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]*2/3)) mu &lt;- param[&quot;barmu&quot;] + muS + muU UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # Z=1 if states have lower muS than 0 Z &lt;- ifelse(muS&lt;=0,1,0) Ds &lt;- ifelse(YB&lt;=param[&quot;barY&quot;] &amp; Z==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) delta.y.iv.did &lt;- (mean(y[Z==1])-mean(y[Z==0])-(mean(yB[Z==1])-mean(yB[Z==0])))/mean(Ds[Z==1]) return(delta.y.iv.did) } simuls.iv.did.panel.N &lt;- function(N,Nstates,Nsim,param){ simuls.iv.did.panel &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.iv.did.panel,N=N,Nstates=Nstates,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.iv.did.panel) &lt;- c(&#39;DID-IV&#39;) return(simuls.iv.did.panel) } sf.simuls.iv.did.panel.N &lt;- function(N,Nstates,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.iv.did.panel,N=N,Nstates=Nstates,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;DID-IV&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.iv.did.panel &lt;- lapply(N.sample,sf.simuls.iv.did.panel.N,Nstates=Nstates,Nsim=Nsim,param=param) names(simuls.iv.did.panel) &lt;- N.sample Let us now plot the resulting estimates: (#fig:monte.carlo.hist.iv.did.panel)Distribution of the DID-IV estimator over replications of panels of different sizes Let us now look at repeated cross sections data monte.carlo.iv.did.cross &lt;- function(s,N,Nstates,param){ set.seed(s) N.tot &lt;- 2*N muS &lt;- rnorm(Nstates,0,sqrt(param[&quot;sigma2mu&quot;]/3)) muS &lt;- rep(muS,each=N/Nstates) muS &lt;- c(muS,muS) # I draw an individual fixed effect with the remaining variance muU &lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2mu&quot;]*2/3)) mu &lt;- param[&quot;barmu&quot;] + muS + muU UB &lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) epsilon &lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N.tot,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # Z=1 if states have lower muS than 0 Z &lt;- ifelse(muS&lt;=0,1,0) Ds &lt;- ifelse(YB&lt;=param[&quot;barY&quot;] &amp; Z==1,1,0) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) # first cross section: 1-N first &lt;- seq(1,N) # second cross section: 1001-2000 second &lt;- seq(N+1,N.tot) # repeated cross section DID-IV delta.y.iv.did.cross &lt;- (mean(y[second][Z[second]==1])-mean(y[second][Z[second]==0])-(mean(yB[first][Z[first]==1])-mean(yB[first][Z[first]==0])))/mean(Ds[second][Z[second]==1]) return(delta.y.iv.did.cross) } simuls.iv.did.cross.N &lt;- function(N,Nstates,Nsim,param){ simuls.iv.did.cross &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.iv.did.cross,N=N,Nstates=Nstates,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.iv.did.cross) &lt;- c(&#39;DID-IV&#39;) return(simuls.iv.did.cross) } sf.simuls.iv.did.cross.N &lt;- function(N,Nstates,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.iv.did.cross,N=N,Nstates=Nstates,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim) &lt;- c(&#39;DID-IV&#39;) return(sim) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.iv.did.cross &lt;- lapply(N.sample,sf.simuls.iv.did.cross.N,Nstates=Nstates,Nsim=Nsim,param=param) names(simuls.iv.did.cross) &lt;- N.sample Let us now plot the result: (#fig:monte.carlo.hist.iv.did.cross.sections)Distribution of the DID-IV estimator over replications of repeated cross sections of different sizes 4.3.4.1.3 Estimation of sampling noise What we need is to derive an estimator for the asymptotic variance of the DID-IV estimator in repeated cross sections and in panel data. 4.3.4.1.3.1 Estimating sampling noise with DID-IV in repeated cross sections Theorem 4.30 (Asymptotic Distribution of DID-IV in Repeated Cross Sections) Under Assumptions 4.12, 4.13, 4.28, 4.17 and ??, we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^Y_{DIDIV}-\\Delta^Y_TT) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\right). \\end{align*}\\] Proof. To do. 4.3.4.1.3.2 Estimating sampling noise with DID-IV in panel data Theorem 4.31 (Asymptotic Distribution of DID-IV in Panel Data) Under Assumptions 4.12, 4.13, 4.28, 4.15 and 4.16, we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^Y_{DIDIV}-\\Delta^Y_TT) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\right). \\end{align*}\\] Proof. To do. Example 4.59 Let’s see how estimators of sampling noise perform in practice. In panel data, true 99% sampling noise (from the simulations) is 0.25. 99% sampling noise estimated using default FE standard errors is 0.22`. 99% sampling noise estimated using heteroskedasticity robust FE standard errors is 0.22. In repeated cross sections, true 99% sampling noise (from the simulations) is 1.16. 99% sampling noise estimated using default OLS standard errors is 0.24. 99% sampling noise estimated using heteroskedasticity robust OLS standard errors is 0.25. 4.3.4.2 DID-IV with a weak first stage With a weak first stage, DID-IV has positive probability of receiving the treatment in the Before period and in the group with \\(Z_i=0\\). The main requirement of the weak first stage DID-IV is that the probability of receiving the treatment increases more over time in the group with \\(Z_i=1\\) compared to what happens in the group with \\(Z_i=0\\). We are going to codify this assumption next and see which effects can be identified under which supplementary assumptions, then talk about estimation and estimation of sampling noise. 4.3.4.2.1 Identification We are going to examine several sets of assumptions under which we can try to recover some average treatment effect of the treatment in a DID-IV design with a weak first stage. As you’ll see, there is not much hope unfortunately. 4.3.4.2.1.1 Identification under weak first stage DID-IV The main assumption on a weak first stage DID-IV is as follows: Hypothesis 4.30 (Weak First Stage) The treatment is available in both periods \\(B\\) and \\(A\\), but its takeover increases disproportionately among those with \\(Z_i=1\\): \\[\\begin{align*} \\Pr(D_{i,A}=1|Z_i=1)&amp; -\\Pr(D_{i,B}=1|Z_i=1)\\\\ &amp; &gt;\\Pr(D_{i,A}=1|Z_i=0)-\\Pr(D_{i,B}=1|Z_i=0). \\end{align*}\\] Remark. A great example of Assumption 4.30 is Esther Duflo’s paper in education expansion in Indonesia. In this paper, the states that invest in education are the ones for which education levels were the lowest initially. And the states with lower investments in education (\\(Z_i=0\\)) nevertheless saw some progress in education levels over time. But, the states with higher investments (\\(Z_i=1\\)) saw stronger improvements and caught up. Also, all states had some education in the baseline period. This is characteristic of a weak first stage DID-IV design. Example 4.60 Let us now see how we can model this in our example. We are going to introduce an eligibility rule that changes over time as a function of state and district fixed effects: \\[\\begin{align*} \\mu_i &amp; = \\mu^S_i + \\mu^d_i + \\mu^U_i + \\bar{\\mu} \\\\ \\mu^S_i &amp; \\sim\\mathcal{N}(0,\\frac{1}{3}\\sigma_{\\mu}^2)\\\\ \\mu^d_i &amp; \\sim\\mathcal{N}(0,\\frac{1}{3}\\sigma_{\\mu}^2)\\\\ \\mu^U_i &amp; \\sim\\mathcal{N}(0,\\frac{1}{3}\\sigma_{\\mu}^2)\\\\ E_{i,B} &amp; = \\begin{cases} 1 &amp; \\text{ if } \\mu^d_i\\leq -0.5 \\land Z_i=1 \\\\ 1 &amp; \\text{ if } \\mu^d_i\\leq 0.25\\land Z_i=0 \\end{cases}\\\\ E_{i,A} &amp; = \\begin{cases} 1 &amp; \\text{ if } \\mu^d_i\\leq 0 \\land Z_i=1 \\\\ 1 &amp; \\text{ if } \\mu^d_i\\leq 0.85\\land Z_i=0 \\end{cases}\\\\ D_{i,t} &amp; = \\uns{y_{i,BB}\\leq\\bar{y} \\land E_{i,t}=1}. \\end{align*}\\] The rest of the model is as follows, with a third period \\(BB\\) that is Before Before: \\[\\begin{align*} y^0_{i,A} &amp; =\\mu_i+\\delta+U_{i,A}^0 \\\\ y_{i,A}^1 &amp; =\\mu_i(1+\\theta)+\\bar{\\alpha}+\\delta+U_{i,A}^0+\\eta_i \\\\ y_{i,BB} &amp; =\\mu_i+U_{i,BB} \\\\ U_{i,B}^0 &amp; =\\rho U_{i,BB}+\\epsilon_{i,B} \\\\ U_{i,A}^0 &amp; =\\rho U_{i,B}+\\epsilon_{i,A} \\\\ U_{i,BB} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U})\\\\ \\epsilon_{i,t} &amp; \\sim\\mathcal{N}(0,\\sigma^2_{\\epsilon})\\\\ \\eta_i &amp; \\sim\\mathcal{N}(0,\\sigma^2_{\\eta}) \\end{align*}\\] Here is the simulation: Let us now see how the model generates a time varying proportion of participants: Figure 4.48: Illustration of the DID-IV assumptions: Weak First Stage We thus see that the change over time in treatment uptake is equal to 0.16 when \\(Z_i=1\\) and to 0.02 when \\(Z_i=0\\). 4.3.4.2.1.2 Identification with independent treatment effects Under constant treatment effects, the classical Wald DID estimator still identifies the effect of the treatment on the treated: Hypothesis 4.31 (Independent Treatment Effects) The average effect of the treatment on the treated is independent of \\(Z_i\\): \\[\\begin{align*} \\esp{Y_{i,t}^1-Y_{i,t}^0|D_i=1,Z_i=1} &amp; = \\esp{Y_{i,t}^1-Y_{i,t}^0|D_i=1,Z_i=0}. \\end{align*}\\] Under Assumption 4.31, we can show that the Wald DID estimator recovers the average effect of the treatment on the treated: Theorem 4.32 (Indentification of TT with DID-IV, a Weak First Stage and Independent Treatment Effects) Under Assumptions 4.12, 4.13, 4.28, 4.30 and 4.31, TT is identified by the Wald-DID estimator: \\[\\begin{align*} \\Delta^Y_{WaldDID} &amp; = \\Delta^{Y_A}_{TT}. \\end{align*}\\] Proof. We have, for \\(t\\in\\left\\{ A,B \\right\\}\\) and \\(d\\in\\left\\{ 0,1 \\right\\}\\): \\[\\begin{align*} \\esp{Y_{i,t}|Z_i=d} &amp; = \\esp{Y^0_{i,t}|Z_i=d} + \\esp{Y^1_{i,t}-Y^0_{i,t}|D_{i,t}=1,Z_i=d}\\Pr(D_{i,t}=1|Z_i=d) \\end{align*}\\] Under Assumption 4.31, \\(\\esp{Y^1_{i,t}-Y^0_{i,t}|D_{i,t}=1,Z_i=d}=\\Delta^Y_{TT}\\). As a consequence, the numerator of the Wald-DID estimator writes as follows: \\[\\begin{align*} \\esp{Y_{i,A}|Z_i=1} &amp; -\\esp{Y_{i,A}|Z_i=0}-(\\esp{Y_{i,B}|Z_i=1}-\\esp{Y_{i,B}|Z_i=0}) \\\\ &amp; = \\esp{Y^0_{i,A}-Y^0_{i,B}|Z_i=1}+ \\Delta^Y_{TT}\\left(\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)\\right)\\\\ &amp; \\phantom{=} -\\esp{Y^0_{i,A}-Y^0_{i,B}|Z_i=0}-\\Delta^Y_{TT}\\left(\\Pr(D_{i,A}=1|Z_i=0)-\\Pr(D_{i,B}=1|Z_i=0)\\right). \\end{align*}\\] Using the Assumption 4.28 and dividing by the denominator of the Wald-DID estimator (which is non null under Assumption 4.30) yields the result. 4.3.4.2.1.3 Identification under constant treatment effects over time The problem with DID-IV stems when treatment effects are not independent from \\(Z_i\\) conditional on \\(D_i=1\\). We can get an inkling of the problem at hand by deriving the Wald estimator without Assumption 4.31, but under Assumptions 4.12, 4.13, 4.28 and 4.30. Let’s get some notation first. We denote \\(\\Delta^D_{DID}=\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)-(\\Pr(D_{i,A}=1|Z_i=0)-\\Pr(D_{i,B}=1|Z_i=0))\\), the denominator of the Wald estimator. We also denote \\(p^{AB}_{11}=\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)\\) and \\(p^{AB}_{10}=\\Pr(D_{i,A}=1|Z_i=0)-\\Pr(D_{i,B}=1|Z_i=0)\\). We finally denote \\(\\Delta^{Y_A}_{TT_1}=\\esp{Y_{i,t}^1-Y_{i,t}^0|D_i=1,Z_i=1}\\) and \\(\\Delta^{Y_A}_{TT_0}=\\esp{Y_{i,t}^1-Y_{i,t}^0|D_i=1,Z_i=0}\\). We can now prove the following corollary to Theorem 4.32: Corollary 4.4 (DID-Wald Estimator Without Independent Treatment Effects) Under Assumptions 4.12, 4.13, 4.28 and 4.30, the DID-Wald estimator is a weighted average of treatment effects with possibly negative weights: \\[\\begin{align*} \\Delta^Y_{WaldDID} &amp; = \\Delta^{Y_A}_{TT_1}\\frac{p^{AB}_{11}}{\\Delta^D_{DID}}-\\Delta^{Y_A}_{TT_0}\\frac{p^{AB}_{10}}{\\Delta^D_{DID}}. \\end{align*}\\] Proof. Using the proof of Theorem 4.32 proves the result. Corollary 4.4 shows that, when the proportion of treated in the group with \\(Z_i=0\\) increases over time, the impact of the treatment on those with \\(Z_i=0\\) enters negatively in the Wald-DID estimator. It is thus possible that positive treatment effects for every unit in the population generates a negative Wald-DID estimator. We can even get a deeper understanding of what’s going on with the DID-IV estimator if we follow the classic treatment of this issue by de Chaisemartin and d’Haultfoeuille (2015). Let us first define four types of individuals: always takers: the individuals which have \\(D_{i,A}=D_{i,B}=1\\), which we denote \\(T_i=at\\), never takers: the individuals which have \\(D_{i,A}=D_{i,B}=0\\), which we denote \\(T_i=nt\\), switchers: the individuals which have \\(D_{i,A}=1\\) and \\(D_{i,B}=0\\), which we denote \\(T_i=s\\), anti-switchers: the individuals which have \\(D_{i,A}=0\\) and \\(D_{i,B}=1\\), which we denote \\(T_i=as\\). For now, we are going to assume away anti-switchers for simplicity. Assumption 4.30 amounts to assuming that \\(\\Pr(T_i=s|Z_i=1) &gt; \\Pr(T_i=s|Z_i=0)\\). We can now prove the following theorem: Theorem 4.33 (Numerator of the DID-Wald Estimator Without Independent Treatment Effects and Without Anti-Switchers) Under Assumptions 4.12, 4.13, 4.28 and 4.30, and in the absence of anti-switchers (\\(\\Pr(T_i=as)=0\\)), the numerator of the DID-Wald estimator can be written as follows: \\[\\begin{align*} \\Delta^Y_{WaldDID}\\Delta^D_{DID} &amp; = \\esp{Y^1_{i,A}-Y^1_{i,B}|T_i=at,Z_i=1}\\Pr(T_i=at|Z_i=1)\\\\ &amp; \\phantom{=} +\\esp{Y^0_{i,A}-Y^0_{i,B}|T_i=nt,Z_i=1}\\Pr(T_i=nt|Z_i=1)\\\\ &amp; \\phantom{=} +\\esp{Y^1_{i,A}-Y^0_{i,B}|T_i=s,Z_i=1}\\Pr(T_i=s|Z_i=1)\\\\ &amp; \\phantom{=} -(\\esp{Y^1_{i,A}-Y^1_{i,B}|T_i=at,Z_i=0}\\Pr(T_i=at|Z_i=0))\\\\ &amp; \\phantom{=} -(\\esp{Y^0_{i,A}-Y^0_{i,B}|T_i=nt,Z_i=0}\\Pr(T_i=nt|Z_i=0))\\\\ &amp; \\phantom{=} -(\\esp{Y^1_{i,A}-Y^0_{i,B}|T_i=s,Z_i=0}\\Pr(T_i=s|Z_i=0)). \\end{align*}\\] Proof. The result follows from the formula for the DID-Wald estimator and the fact that \\(T_i\\) is a partition of the population. So, the numerator of the Wald-DID estimator is a combination of the changes in outcomes over time of each type in the group with \\(Z_i=1\\) minus the changes the outcomes of each type in the group with \\(Z_i=0\\). The units with the same type are not the same in each group defined by \\(Z_i\\) so that their proportions differ and their changes in outcome differ as well. One useful simplification can still happen using Assumption 4.28. Let \\(\\Delta^{Y_A}_{\\text{type},z}=\\esp{Y_{i,t}^1-Y_{i,t}^0|T_i=\\text{type},Z_i=z}\\), for \\(\\text{type}\\in\\left\\{at,nt,s\\right\\}\\) and \\(z\\in\\left\\{0,1\\right\\}\\). Let also \\(p_{\\text{type},z}=\\Pr(T_i=\\text{type}|Z_i=z)\\). The following corollary proves that: Corollary 4.5 (DID-Wald Estimator Without Independent Treatment Effects) Under Assumptions 4.12, 4.13, 4.28 and 4.30, the DID-Wald estimator can be decomposed as follows: \\[\\begin{align*} \\Delta^Y_{WaldDID}\\Delta^D_{DID} &amp; = \\Delta^{Y_A}_{s,1}p_{s,1}-\\Delta^{Y_A}_{s,0}p_{s,0}+(\\Delta^{Y_A}_{at,1}-\\Delta^{Y_B}_{at,1})p_{at,1}-(\\Delta^{Y_A}_{at,0}-\\Delta^{Y_B}_{at,0})p_{at,0}. \\end{align*}\\] Proof. Using Theorem 4.33, we can now add and subtract \\(\\esp{Y^0_{i,A}-Y^0_{i,B}|T_i=at,Z_i=1}\\Pr(T_i=at|Z_i=1)\\), \\(\\esp{Y^0_{i,A}-Y^0_{i,B}|T_i=at,Z_i=0}\\Pr(T_i=at|Z_i=0)\\), \\(\\esp{Y^0_{i,A}|T_i=s,Z_i=1}\\Pr(T_i=s|Z_i=1)\\) and \\(\\esp{Y^0_{i,A}|T_i=s,Z_i=0}\\Pr(T_i=s|Z_i=0)\\) to the right hand side of the expression, and use the fact that \\(T_i\\) is a partition and then invoke Assumption 4.28 to obtain the result. Corollary 4.5 shows that the Wald-DID estimator is a weighted average of the effect of the treatment on the switchers in the group with \\(Z_i=1\\), minus the effect of the treatment on the switchers in the group with \\(Z_i=0\\), and the change in the treatment effect over time among always takers in the group with \\(Z_i=1\\) minus the change in treatment effect over time among always takers in the group with \\(Z_i=0\\). So, one way to get rid of the issue is to assume constant treatment effects over time for both groups of always takers. Let’s make this assumption and see where it takes us: Hypothesis 4.32 (Constant Treatment Effects Over Time) We assume that average effect of the treatment on the always takers is independent of time, conditional on \\(Z_i\\): \\(\\forall z \\in \\left\\{0,1\\right\\}\\): \\[\\begin{align*} \\Delta^{Y_A}_{at,z}&amp; = \\Delta^{Y_B}_{at,z} \\end{align*}\\] We can now prove the following Theorem: Theorem 4.34 (DID-Wald Estimator With Constant Treatment Effects Over Time) Under Assumptions 4.12, 4.13, 4.28, 4.30 and 4.32, the DID-Wald estimator can be decomposed as follows: \\[\\begin{align*} \\Delta^Y_{WaldDID} &amp; = \\begin{cases} \\Delta^{Y_A}_{s,1} \\text{ if }p_{s,0}=0\\\\ \\alpha\\Delta^{Y_A}_{s,1}-(1-\\alpha)\\Delta^{Y_A}_{s,0}\\text{, }0&lt;\\alpha&lt;1 \\text{ if } p_{s,0}&lt;0\\\\ \\alpha\\Delta^{Y_A}_{s,1}-(1-\\alpha)\\Delta^{Y_A}_{s,0}\\text{, }\\alpha&gt;1 \\text{ if } p_{s,0}&gt;0. \\end{cases} \\end{align*}\\] Proof. Using Corollary 4.5 and the fact that \\(\\Delta^D_{DID}=p_{s,1}-p_{s,0}\\) proves the result. Note that Theorem 4.34 still does not get rid of the issue of negative weights in the case when the proportion of treated units increases in the control group. 4.3.4.2.1.4 Identification under parallel trends by type de Chaisemartin and d’Haultfoeuille (2015) propose an alternative to Assumption 4.32. This approach requires that there are no shifters in the group with \\(Z_i=0\\), and thus that the proportion of treated units does not change over time in this group. This is thus very close to a DID-IV design with Strong First Stage. Finally, their approach requires an alternative parallel trends assumption over groups. Let is state all of these assumptions: Hypothesis 4.33 (Strong Weak First Stage) We assume that the proportion of treated stays constant in the group with \\(Z_i=0\\): \\(p_{s,0}=0\\). Hypothesis 4.34 (Conditional Parallel Trends) We assume that the trends in potential outcomes among groups defined by \\(D_{i,B}\\) does not depend on \\(Z_i\\): \\[\\begin{align*} \\esp{Y^d_{i,A}-Y^d_{i,B}|D_{i,B}=d,Z_i=1} &amp; = \\esp{Y^d_{i,A}-Y^d_{i,B}|D_{i,B}=d,Z_i=0}. \\end{align*}\\] Remark. Assumption 4.34 is very strong. It assumes away part of the time-varying selection bias that the instrumental variable procedure is trying to undo. de Chaisemartin and d’Haultfoeuille (2015) prove that a \\(Wald_{TC}\\), a time-corrected Wald estimator, is able to recover the average effect of the treatment on the shifters under these assumptions: Theorem 4.35 (Time-corrected Wald Estimator With Conditional Parallel Trends) Under Assumptions 4.12, 4.13, 4.33 and 4.34, the time-corrected Wald estimator identifies the average effect of the treatment on the shifters: \\[\\begin{align*} \\Delta^Y_{Wald_{TC}} &amp; = \\Delta^{Y_A}_{s,1}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{Wald_{TC}} &amp; = \\frac{\\esp{Y_{i,A}|Z_i=1}-\\esp{Y_{i,B}+D_{i,B}\\delta_1+(1-D_{i,B})\\delta_0|Z_i=1}}{\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)}\\\\ \\delta_1 &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=1,Z_i=0}\\\\ \\delta_0 &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=0,Z_i=0}. \\end{align*}\\] Proof. Note that: \\[\\begin{align*} \\esp{Y_{i,A}|Z_i=1} &amp; = \\esp{Y_{i,A}|D_{i,B}=1,Z_i=1}\\Pr(D_{i,B}=1|Z_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_{i,A}|D_{i,B}=0,Z_i=1}\\Pr(D_{i,B}=0|Z_i=1)\\\\ \\esp{Y_{i,B}|Z_i=1} &amp; = \\esp{Y_{i,B}|D_{i,B}=1,Z_i=1}\\Pr(D_{i,B}=1|Z_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_{i,B}|D_{i,B}=0,Z_i=1}\\Pr(D_{i,B}=0|Z_i=1)\\\\ \\esp{D_{i,B}\\delta_1|Z_i=1} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=1,Z_i=0}\\Pr(D_{i,B}=1|Z_i=1)\\\\ \\esp{(1-D_{i,B})\\delta_0|Z_i=1} &amp; = \\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=0,Z_i=0}\\Pr(D_{i,B}=0|Z_i=1). \\end{align*}\\] With \\(D_{i,B}=1\\), we know that \\(Y_{i,A}=Y^1_{i,A}\\) and \\(Y_{i,B}=Y^1_{i,B}\\). As a consequence, using Assumption 4.34, we have: \\[\\begin{align*} \\Delta^Y_{Wald_{TC}} &amp; = \\frac{(\\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=0,Z_i=1}-\\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=0,Z_i=0})\\Pr(D_{i,B}=0|Z_i=1)}{\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)}. \\end{align*}\\] Using the fact that, conditional on \\(Z_i=1\\), the population with \\(D_{i,B}=0\\) can be split totally into \\(T_i=s\\) and \\(T_i=nt\\), we can write the following equality (after adding and subtracting \\(\\esp{Y^0_{i,A}|T_i=s,Z_i=1}\\)): \\[\\begin{align*} \\esp{Y_{i,A}-Y_{i,B}|D_{i,B}=0,Z_i=1} &amp; = \\Delta^{Y_A}_{s,1}\\Pr(T_i=s|D_{i,B}=0,Z_i=1)+\\esp{Y^0_{i,A}-Y^0_{i,B}|D_{i,B}=0,Z_i=1}. \\end{align*}\\] Using Assumption 4.33, with \\(D_{i,B}=0\\) and \\(Z_i=0\\), we know that \\(Y_{i,A}=Y^0_{i,A}\\) and \\(Y_{i,B}=Y^0_{i,B}\\). Using Assumption 4.34 again, we have: \\[\\begin{align*} \\Delta^Y_{Wald_{TC}} &amp; = \\frac{\\Delta^{Y_A}_{s,1}\\Pr(T_i=s|D_{i,B}=0,Z_i=1)\\Pr(D_{i,B}=0|Z_i=1)}{\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)}. \\end{align*}\\] Note that \\(T_i=s\\Rightarrow D_{i,B}=0|Z_i=1\\), so that \\(\\Pr(T_i=s|D_{i,B}=0,Z_i=1)\\Pr(D_{i,B}=0|Z_i=1)=\\Pr(T_i=s|Z_i=1)\\). Under Assumption 4.33, \\(\\Pr(T_i=s|Z_i=1)=\\Pr(D_{i,A}=1|Z_i=1)-\\Pr(D_{i,B}=1|Z_i=1)\\), which proves the result. Remark. The problem with Theorem 4.34 is that it relies on Assumption 4.33: there are no changes in the proportion of units receiving the treatment in the group with \\(Z_i=0\\). This assumption might very often be untrue. Fortunately, de Chaisemartin and d’Haultfoeuille (2015) show that you can relax that assumption and still bound the treatment effect if your outcome is bounded. We will present this estimator in Section ??. 4.3.4.2.2 Estimation We are going to look at how to estimate the Time-Corrected Wald estimator of de Chaisemartin and d’Haultfoeuille (2015). The formula for the estimator is pretty straightforward: \\[\\begin{align*} \\hat\\Delta^Y_{Wald_{TC}} &amp; = \\frac{\\frac{\\sum_{i=1}^NY_{i,A}Z_i}{\\sum_{i=1}^NZ_i}-\\frac{\\sum_{i=1}^NY_{i,B}Z_i}{\\sum_{i=1}^NZ_i}-\\hat\\delta_1\\frac{\\sum_{i=1}^ND_{i,B}(1-Z_i)}{\\sum_{i=1}^N(1-Z_i)}-\\hat\\delta_0\\frac{\\sum_{i=1}^N(1-D_{i,B})(1-Z_i)}{\\sum_{i=1}^N(1-Z_i)}}{\\frac{\\sum_{i=1}^ND_{i,A}Z_i}{\\sum_{i=1}^NZ_i}-\\frac{\\sum_{i=1}^ND_{i,B}Z_i}{\\sum_{i=1}^NZ_i}}\\\\ \\hat\\delta_1 &amp; = \\frac{\\sum_{i=1}^NY_{i,A}D_{i,B}(1-Z_i)}{\\sum_{i=1}^ND_{i,B}(1-Z_i)}-\\frac{\\sum_{i=1}^NY_{i,B}D_{i,B}(1-Z_i)}{\\sum_{i=1}^ND_{i,B}(1-Z_i)}\\\\ \\hat\\delta_0 &amp; = \\frac{\\sum_{i=1}^NY_{i,A}(1-D_{i,B})(1-Z_i)}{\\sum_{i=1}^N(1-D_{i,B})(1-Z_i)}-\\frac{\\sum_{i=1}^NY_{i,B}(1-D_{i,B})(1-Z_i)}{\\sum_{i=1}^N(1-D_{i,B})(1-Z_i)}. \\end{align*}\\] Example 4.61 Let us now look at how the Wald-TC estimator and the more traditional Wald-DID estimator work in our example. Let’s compute them both: # Wald DID estimator # changes in mean outcomes over time DeltaYZ1 &lt;- mean(y[Z==1])-mean(yB[Z==1]) DeltaYZ0 &lt;- mean(y[Z==0])-mean(yB[Z==0]) DeltaDZ1 &lt;- mean(DsA[Z==1])-mean(DsB[Z==1]) DeltaDZ0 &lt;- mean(DsA[Z==0])-mean(DsB[Z==0]) WaldDID &lt;- (DeltaYZ1-DeltaYZ0)/(DeltaDZ1-DeltaDZ0) # Wald TC estimator DeltaYDZ10 &lt;- mean(y[DsB==1&amp;Z==0])-mean(yB[DsB==1&amp;Z==0]) DeltaYDZ00 &lt;- mean(y[DsB==0&amp;Z==0])-mean(yB[DsB==0&amp;Z==0]) MeanDBZ0 &lt;- mean(DsB[Z==0]) WaldTC &lt;- (DeltaYZ1-MeanDBZ0*DeltaYDZ10-(1-MeanDBZ0)*DeltaYDZ00)/(DeltaDZ1) # true effect on switchers in the sample DeltaYAs1Sample &lt;- mean(y1A[DsB==0&amp;DsA==1&amp;Z==1])-mean(y0A[DsB==0&amp;DsA==1&amp;Z==1]) DeltaYAs0Sample &lt;- mean(y1A[DsB==0&amp;DsA==1&amp;Z==0])-mean(y0A[DsB==0&amp;DsA==1&amp;Z==0]) DeltaYBs1Sample &lt;- mean(y1B[DsB==0&amp;DsA==1&amp;Z==1])-mean(y0B[DsB==0&amp;DsA==1&amp;Z==1]) DeltaYBs0Sample &lt;- mean(y1B[DsB==0&amp;DsA==1&amp;Z==0])-mean(y0B[DsB==0&amp;DsA==1&amp;Z==0]) DeltaYAat1Sample &lt;- mean(y1A[DsB==1&amp;DsA==1&amp;Z==1])-mean(y0A[DsB==1&amp;DsA==1&amp;Z==1]) DeltaYAat0Sample &lt;- mean(y1A[DsB==1&amp;DsA==1&amp;Z==0])-mean(y0A[DsB==1&amp;DsA==1&amp;Z==0]) DeltaYBat1Sample &lt;- mean(y1B[DsB==1&amp;DsA==1&amp;Z==1])-mean(y0B[DsB==1&amp;DsA==1&amp;Z==1]) DeltaYBat0Sample &lt;- mean(y1B[DsB==1&amp;DsA==1&amp;Z==0])-mean(y0B[DsB==1&amp;DsA==1&amp;Z==0]) # checking PTA DeltaY0BAZ1 &lt;- mean(y0A[Z==1])-mean(y0B[Z==1]) DeltaY0BAZ0 &lt;- mean(y0A[Z==0])-mean(y0B[Z==0]) DeltaY1atBAZ1 &lt;- mean(y1A[DsB==1&amp;DsA==1&amp;Z==1])-mean(y1B[DsB==1&amp;DsA==1&amp;Z==1]) DeltaY1atBAZ0 &lt;- mean(y1A[DsB==1&amp;DsA==1&amp;Z==0])-mean(y1B[DsB==1&amp;DsA==1&amp;Z==0]) # alpha alpha.shifters &lt;- DeltaDZ1/(DeltaDZ1-DeltaDZ0) # weighted average of shifters impacts DeltaYAsSample &lt;- DeltaYAs1Sample*alpha.shifters+(1-alpha.shifters)*DeltaYAs0Sample The Wald-DID estimator in our example is equal to 0.47 while the true average effect of the treatment on the shifters in the group with \\(Z_i=1\\) is equal to 0.2 in the sample. The Time-corrected Wald estimator is equal to 0.4. It is hard to say why these estimators are too big in our example. The Wald-DID estimator should not be too biased since Assumption 4.32 holds in our dataset, and the bias stemming from the failure of Assumption 4.33 is not too severe. Indeed, using Theorem 4.34, we know that Wald-DID estimator should converge to the weighted average of the effect on shifters, which is equal to 0.22 in the sample. As always with Wald estimators, I suspect that the denominator is slightly too small, and that the proportion of switchers is underestimated. "],["OM.html", "Chapter 5 Observational Methods 5.1 Parametric methods 5.2 Nonparametric methods 5.3 Imputation methods", " Chapter 5 Observational Methods In this lecture, we are going to study how to estimate the effect of an intervention on an outcome using observational methods, that is methods which try to correct for selection bias by accounting for as many observed confounders as possible. The key assumption that we are going to make is that of conditional independence: Hypothesis 5.1 (Conditional Independence (in Expectation)) We assume that there exists a known set of observable covariates \\(X_i\\) such that: \\[\\begin{align*} \\esp{Y_i^0|X_i,D_i=1} &amp; = \\esp{Y_i^0|X_i,D_i=0}. \\end{align*}\\] Under Assumption 5.1, the expected potential outcomes of the treated in the absence of the treatment are independent of the treatment conditional on a set of observed covariates \\(X_i\\). As a consequence, selection bias is zero after conditioning on \\(X_i\\), and we can recover the treatment on the treated parameter by using the With/Without comparison conditional on \\(X_i\\): \\[\\begin{align*} \\Delta^Y_{WW}(X_i) &amp; = \\esp{Y_i|X_i,D_i=1} - \\esp{Y_i|X_i,D_i=0} \\\\ &amp; = \\esp{Y^1_i|X_i,D_i=1} - \\esp{Y^0_i|X_i,D_i=0} \\\\ &amp; = \\esp{Y^1_i|X_i,D_i=1} - \\esp{Y^0_i|X_i,D_i=1} \\\\ &amp; = \\esp{Y^1_i-Y_i^0|X_i,D_i=1}\\\\ &amp; = \\Delta^Y_{TT}(X_i), \\end{align*}\\] where the third equality uses Assumption 5.1. There are several ways to use Assumption 5.1 (and thus Assumption 5.2) to build estimators of the treatment effect. Let’s start with the parametric approaches and then we’ll study the non-parametric approaches. Remark. Assumption 5.1 is the minimal assumption needed to indentify the average effect of the treatment on the treated. Researchers often use a stronger version of that assumption: Hypothesis 5.2 (Conditional Independence) We assume that there exists a known set of observable covariates \\(X_i\\) such that: \\[\\begin{align*} (Y_i^1,Y_i^0)\\Ind D_i|X_i. \\end{align*}\\] Assumption 5.2 is stronger than Assumption 5.1 because it imposes conditional independence of all the distribution of \\(Y_i^0\\), not only of its mean, and also because it imposes conditional independence of \\(Y_i^1\\) and moreover that this independence is jointly holding for \\((Y_i^1,Y_i^0)\\). Remark. Assumptions 5.1 and 5.2 are sometimes called Ignorability, Unconfoundedness or Selection on Observables. 5.1 Parametric methods We are going to study two approaches uses increasingly strong parametric assumptions. The first assumes the functional form of \\(\\esp{Y_i^0|X_i}\\) is known. The second assumes furthermore that the functional form of \\(\\esp{Y_i^1|X_i}\\) is known. We finaly are going to discuss the conditions under which a simple OLS regressions identifies the treatment effect on the treated. 5.1.1 Assuming \\(\\esp{Y_i^0|X_i}\\) is known Let’s study identification, estimation and inference when \\(\\esp{Y_i^0|X_i}\\) is known 5.1.1.1 Identification The most simple assumption that we can make in order to identify the treatment on the treated parameter under Conditional Indepedence is that the functional form of \\(\\esp{Y_i^0|X_i}\\) is known (and for example is linear): Hypothesis 5.3 We assume that there exists a known set of observable covariates \\(X_i\\) such that: \\[\\begin{align*} \\esp{Y_i^0|X_i} &amp; = \\alpha_0+\\beta_0&#39;X_i. \\end{align*}\\] One way to use this assumption to identify the effect of the treatment on the treated is to follow the following steps: Estimate \\(\\alpha_0\\) and \\(\\beta_0\\) on the population of untreated individuals. Use these estimates to predict potential outcomes for the treated. Compute the difference between the observed potential outcomes and the simulated ones for the treated observations. In practice, this estimator, which I call \\(\\Delta^Y_{WWOLS(X)}\\), is equal to: \\[\\begin{align*} \\Delta^Y_{WWOLS(X)} &amp; = \\esp{Y_i-\\alpha_0-\\beta_0&#39;X_i|D_i=1}. \\end{align*}\\] Under the assumptions we’ve made so far, \\(\\Delta^Y_{WWOLS(X)}\\) identifies \\(TT\\): Theorem 5.1 (Identification of TT using OLS) Under Assumptions 5.1 and (hyp:paramff0), TT is identified using the WW comparison adjusted by the OLS projection. \\[\\begin{align*} \\Delta^Y_{WWOLS(X)} &amp; = \\Delta^Y_{TT}. \\end{align*}\\] Proof. Under Assumptions 5.1 and (hyp:paramff0), we have: \\[\\begin{align*} \\esp{Y_i^0|D_i=0,X_i} &amp; = \\esp{Y_i^0|X_i} = \\alpha_0+\\beta_0&#39;X_i. \\end{align*}\\] As a consequence, \\(\\alpha_0\\) and \\(\\beta_0\\) are identified by using the untreated population, as long as the components of \\(X\\) are not colinear. Then, we have: \\[\\begin{align*} \\Delta^Y_{WWOLS(X)} &amp; = \\esp{Y_i-\\alpha_0-\\beta_0&#39;X_i|D_i=1}\\\\ &amp; = \\esp{Y_i-\\esp{Y_i^0|D_i=1,X_i}|D_i=1}\\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{\\esp{Y_i^0|D_i=1,X_i}|D_i=1}\\\\ &amp; = \\esp{Y^1_i|D_i=1}-\\esp{Y^0_i|D_i=1}\\\\ &amp; = \\Delta^Y_{TT}, \\end{align*}\\] where the first equality is the definition of the second step of the OLS projection procedure, the second equality is a consequence of Assumptions 5.1 and (hyp:paramff0), the third and fifth equalities use the linearity of conditional expectations and the fourth equality uses the Law of Iterated Expectations. 5.1.1.2 Estimation Estimation can follow in the sample steps similar to the ones taken in the population: Estimate \\(\\hat{\\alpha_0}\\) and \\(\\hat{\\beta_0}\\) using an OLS regression of \\(Y_i\\) on \\(X_i\\) on the sample of untreated individuals. Predict the counterfactual values for each treated using \\(\\hat{Y_i^0}=\\hat{\\alpha_0}+\\hat{\\beta_0}&#39;X_i\\). Compute \\(\\hat{\\Delta}^Y_{WWOLS(X)}=\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_i(Y_i^1-\\hat{Y_i^0})\\). Example 5.1 Let’s see how this works in our example. Let’s first choose some parameter values: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) Let us now simulate the data: \\[\\begin{align*} y_i^1 &amp; = y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i \\\\ y_i^0 &amp; = \\mu_i+\\delta+U_i^0 \\\\ U_i^0 &amp; = \\rho U_i^B+\\epsilon_i \\\\ y_i^B &amp; =\\mu_i+U_i^B \\\\ U_i^B &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ D_i &amp; = \\uns{y_i^B\\leq\\bar{y}} \\\\ (\\eta_i,\\mu_i,\\epsilon_i) &amp; \\sim\\mathcal{N}(0,0,0,\\sigma^2_{\\eta},\\sigma^2_{\\mu},\\sigma^2_{\\epsilon},0,0,0). \\end{align*}\\] set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let us now plot the sample and the procedure to estimate \\(\\hat{\\Delta}^Y_{WWOLS(X)}\\): col.obs &lt;- &#39;black&#39; col.unobs &lt;- &#39;red&#39; lty.obs &lt;- 1 lty.unobs &lt;- 2 xlim.big &lt;- c(-1.5,0.5) xlim.small &lt;- c(-0.15,0.55) adj &lt;- 0 # Sample plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs) abline(v=log(param[&quot;barY&quot;]),col=col.unobs) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;),pch=c(1,1),col=c(col.obs,col.unobs),ncol=1) # Step 1 ols.reg.0 &lt;- lm(y[Ds==0]~yB[Ds==0]) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs) points(yB[Ds==0],ols.reg.0$fitted.values,col=&#39;blue&#39;) abline(v=log(param[&quot;barY&quot;]),col=col.unobs) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,expression(hat(&#39;y0|D=0&#39;))),pch=c(1,1,1),col=c(col.obs,col.unobs,&#39;blue&#39;),ncol=2) # step 2 y.pred &lt;- ols.reg.0$coef[[1]]+ols.reg.0$coef[[2]]*yB[Ds==1] plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs) points(yB[Ds==0],ols.reg.0$fitted.values,col=&#39;blue&#39;) points(yB[Ds==1],y.pred,pch=3,col=&#39;blue&#39;) abline(v=log(param[&quot;barY&quot;]),col=col.unobs) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,expression(hat(&#39;y0|D=0&#39;)),expression(hat(&#39;y0|D=1&#39;))),pch=c(1,1,1,3),col=c(col.obs,col.unobs,&#39;blue&#39;,&#39;blue&#39;),ncol=2) # step 3 ww.ols &lt;- mean(y[Ds==1]-y.pred) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs) points(yB[Ds==0],ols.reg.0$fitted.values,col=&#39;blue&#39;) points(yB[Ds==1],y.pred,col=&#39;blue&#39;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;black&#39;) abline(v=log(param[&quot;barY&quot;]),col=col.unobs) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,&#39;y1|D=1&#39;,expression(hat(&#39;y0|D=0&#39;)),expression(hat(&#39;y0|D=1&#39;))),pch=c(1,1,3,1,3),col=c(col.obs,col.unobs,col.obs,&#39;blue&#39;,&#39;blue&#39;),ncol=2) Figure 5.1: Estimating treatment effects using WWOLS(X) Let’s also compute the true values of the treatment effects in the population: delta.y.tt &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;theta&quot;]*((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))) } delta.y.ate &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]) } The true effect of the treatment on the treated in the population is equal to 0.17 and our estimator, \\(\\hat{\\Delta}^Y_{WWOLS(X)}\\), is equal to 0.18. 5.1.1.3 Estimating precision Estimating the precision of this estimator can be done using the bootstrap. Or we could derive its distribution using the CLT. TO DO 5.1.2 Assuming \\(\\esp{Y_i^1|X_i}\\) is known One way to make our estimation procedure even simpler than using the \\(WWOLS(X)\\) estimator is to assume that \\(\\esp{Y_i^1|X_i}\\) is also linear. In that case, we are going to be able to use the OLS estimator conditioning on \\(X_i\\) to estimate the average treatment effect on the treated. We are going to see that this estimator will have a peculiar shape. We’ll understand better why in Section 5.1.3. Let’s start with how to use OLS under linearity of conditional expectations. 5.1.2.1 Identification Let’s assume that we also know the functional form of \\(\\esp{Y_i^1|X_i}\\): Hypothesis 5.4 We assume that there exists a known set of observable covariates \\(X_i\\) such that: \\[\\begin{align*} \\esp{Y_i^1|X_i} &amp; = \\alpha_1+\\beta_1&#39;X_i. \\end{align*}\\] The first thing we can show is that we now have a parametric formula for our target parameter \\(TT\\) (using the slighlty stronger version of the Conditional Indepedence Assumption): Theorem 5.2 (TT under Linearity of Conditional Expectations) Under Assumptions 5.2, 5.3 and 5.4, the Treatment on the Treated parameter simplifies to: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\alpha_1-\\alpha_0+(\\beta_1-\\beta_0)&#39;\\esp{X_i|D_i=1}. \\end{align*}\\] Proof. \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i^1-Y_i^0|D_i=1} \\\\ &amp; = \\esp{\\esp{Y_i^1-Y_i^0|X_i,D_i=1}|D_i=1} \\\\ &amp; = \\esp{\\esp{Y_i^1|X_i,D_i=1}-\\esp{Y_i^0|X_i,D_i=1}|D_i=1} \\\\ &amp; = \\esp{\\esp{Y_i^1|X_i}-\\esp{Y_i^0|X_i}|D_i=1} \\\\ &amp; = \\esp{\\alpha_1+\\beta_1&#39;X_i-(\\alpha_0+\\beta_0&#39;X_i)|D_i=1} \\\\ &amp; = \\alpha_1-\\alpha_0+(\\beta_1-\\beta_0)&#39;\\esp{X_i|D_i=1}, \\end{align*}\\] where the second equality follows from the Law of Iterated Exppectations, the third equality from Assumption 5.2 and the fourth equality from Assumptions 5.3 and 5.4. Remark. Theorem 5.2 shows that under our assumptions, treatment effects are heterogenous in a way that is correlated with the treatment only because of differences in \\(X_i\\). Equipped with this result, we can now state the identification result of this section: Theorem 5.3 (OLS Identifies TT under Linearity and Conditional Independence) Under Assumptions 5.2, 5.3 and 5.4, the OLS coefficient \\(\\delta\\) in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha_0 + \\beta_0&#39;X_i + (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i + \\delta D_i + U_i \\end{align*}\\] identifies the effect of the treatment on the treated. We denote: \\(\\delta=\\Delta^Y_{OLS(X)}\\). Proof. Under Assumptions 5.3 and 5.4, we have \\(Y_i^d=\\alpha_d + \\beta_d&#39;X_i +Y_i^d-\\esp{Y_i^d|X_i}\\), for \\(d\\in\\left\\{0,1\\right\\}\\). As a consequence, we have: \\[\\begin{align*} Y_i &amp; = Y_i^0+D_i(Y_i^1-Y_i^0) \\\\ &amp; = \\alpha_0 + \\beta_0&#39;X_i +D_i(\\alpha_1-\\alpha_0 + (\\beta_1-\\beta_0)&#39;X_i)\\\\ &amp; \\phantom{=}+Y_i^0-\\esp{Y_i^0|X_i}+D_i(Y_i^1-Y_i^0-(\\esp{Y_i^1|X_i}-\\esp{Y_i^0|X_i}))\\\\ &amp; = \\alpha_0 + \\beta_0&#39;X_i + (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i + (\\alpha_1-\\alpha_0 + (\\beta_1-\\beta_0)&#39;\\esp{X_i|D_i=1})D_i\\\\ &amp; \\phantom{=}+\\underbrace{Y_i^0-\\esp{Y_i^0|X_i}+D(Y_i^1-Y_i^0-\\esp{Y_i^1-Y_i^0|X_i})}_{U_i}\\\\ &amp; = \\alpha_0 + \\beta_0&#39;X_i + (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i + \\Delta^Y_{TT}D_i +U_i, \\end{align*}\\] where the first equation uses the Switching Equation, the second equation uses Assumptions 5.3 and 5.4 and the last equation uses Theorem 5.2. We are now going to show that \\(\\esp{U_i|X_i,D_i}=0\\). \\[\\begin{align*} \\esp{U_i|X_i,D_i=0} &amp; = \\esp{Y_i^0-\\esp{Y_i^0|X_i}|X_i,D_i=0}\\\\ &amp; =\\esp{Y_i^0|X_i,D_i=0}-\\esp{\\esp{Y_i^0|X_i}|X_i,D_i=0}\\\\ &amp; =\\esp{Y_i^0|X_i,D_i=0}-\\esp{\\esp{Y_i^0|X_i,D_i=0}|X_i,D_i=0}\\\\ &amp; =\\esp{Y_i^0|X_i,D_i=0}-\\esp{Y_i^0|X_i,D_i=0}\\\\ &amp; = 0\\\\ \\esp{U_i|X_i,D_i=1} &amp; = \\esp{Y_i^0-\\esp{Y_i^0|X_i}|X_i,D_i=1}+\\esp{Y_i^1-Y_i^0-\\esp{Y_i^1-Y_i^0|X_i}|X_i,D_i=1}\\\\ &amp; =\\esp{Y_i^1-Y_i^0|X_i,D_i=1}-\\esp{\\esp{Y_i^1-Y_i^0|X_i}|X_i,D_i=1} \\\\ &amp; =\\esp{Y_i^1-Y_i^0|X_i,D_i=1}-\\esp{\\esp{Y_i^1-Y_i^0|X_i,D_i=1}|X_i,D_i=1} \\\\ &amp; = 0, \\end{align*}\\] where the third and eighth equalities follow from Assumption 5.2. We thus have \\(\\esp{Y_i|X_i,D_i}=\\alpha_0 + \\beta_0&#39;X_i + (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i + \\Delta^Y_{TT}D_i\\). Theorem A.2 ensures that the OLS estimator identifies the parameters of this model. As a consequence, \\(\\Delta^Y_{TT}\\) is identified by the OLS estimator of \\(\\delta\\) in the model. This completes the proof. 5.1.2.2 Estimation What is pretty nice with Theorem 5.3 is that it suggests directly an estimation strategy. Let’s estimate \\(\\hat\\delta^{OLS}\\) in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha_0 + \\beta_0&#39;X_i + (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i + \\delta D_i + U_i. \\end{align*}\\] Example 5.2 Let’s see what happens in our example when doing that. # deameaning the control variable yB.Ds &lt;-(yB-mean(yB[Ds==1]))*Ds # running the OLS estimator with interactions between treatment and demeaned covariate ols.direct &lt;- lm(y~yB+Ds+yB.Ds) # estimate of TT ww.ols.direct &lt;- ols.direct$coef[[3]] Our estimator is equal to 0.18, while the true effect of the treatment on the treated in the population is equal to 0.17. Monte Carlo simulations 5.1.2.3 Estimating precision Estimating precision is pretty straightforward in our case. What is going to happen with respect to a simple WW estimator that does not condition on covariates is that the asymptotic variance of the estimated treatment effect is going to depend on the variance of outcomes conditional on observed covariates \\(X_i\\). As a consequence, and as we have already seen in Chapter 3, precision will increase as long as the covariates we control for explain part of the variance of the outcome. The main issue that we have to deal with is that of heteroskedasticity: \\(U_i\\) is correlated with both \\(X_i\\) and \\(D_i\\). So we need to use a heteroskedasticity-robust estimator for the variance of the treatment effect. Let us first state the main result. For that, we need to reformulate the classical assumptions so that they cover the case with covariates: Hypothesis 5.5 (i.i.d. sampling with covariates) We assume that the observations in the sample are identically and independently distributed: \\[\\begin{align*} \\forall i,j\\leq N\\text{, }i\\neq j\\text{, } &amp; (Y_i,D_i,X_i)\\Ind(Y_j,D_j,X_j),\\\\ &amp; (Y_i,D_i,X_i)\\&amp;(Y_j,D_j,X_j)\\sim F_{Y,D,X}. \\end{align*}\\] Hypothesis 5.6 (Finite variances of potential outcomes conditional on covariates) We assume that \\(\\var{Y_i^1|X_i,D_i=1}\\) and \\(\\var{Y_i^0|X_i,D_i=0}\\) are finite. We can now state our main result: Theorem 5.4 (Distribution of the OLS Estimator of TT under Conditional Independence) Under Assumptions 5.2, 5.3, 5.4, 2.1, 5.5 and 5.6, we have: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^Y_{OLS(X)}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y^0_i|X_i,D_i=0}}{1-p}+\\frac{\\var{Y^1_i|X_i,D_i=1}}{p}\\right), \\end{align*}\\] with \\(p=\\Pr(D_i=1)\\). Proof. See Section A.4.1 in the Appendix. Remark. Theorem 5.4 is super powerful: it tells us that conditioning on observed covariates yields an improvement in precision equivalent to the part of the variance of \\(Y_i\\) explained by the observed covariates. What is nice as well is that the distribution of the OLS estimator with controls has the same flavor as the distribution of the silpler With/Without estimator derived in Theorem 2.5 (and in Lemma A.5). Remark. In order to operationalize Theorem 5.4, one can either use the formula or simply use the heteroskedasticity-robust variance-covariance matrix proposed for the OLS estimator. Both estimators should be similar. Let \\(\\Theta=(\\alpha_0,\\beta_0,\\beta_1,\\delta)\\) and \\(X\\) be the matrix of all regressors, with a first column of ones and the last column of \\(D_i\\). Most available heteroskedasticity robust estimators based on the CLT can be written in the following way: \\[\\begin{align*} \\var{\\hat{\\Theta}_{OLS}} &amp; \\approx (X&#39;X)^{-1}X&#39;\\hat{\\Omega}X(X&#39;X)^{-1}, \\end{align*}\\] where \\(\\hat{\\Omega}=\\diag(\\hat{\\sigma}^2_{U_1},\\dots,\\hat{\\sigma}^2_{U_N})\\) is an estimate the covariance matrix of the residuals \\(U_i\\). Here are various classical estimators for \\(\\hat{\\Omega}\\): \\[\\begin{align*} \\text{HC0:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\hat{U_i}^2 \\\\ \\text{HC1:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{N}{N-K}\\hat{U_i}^2 \\\\ \\text{HC2:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{\\hat{U_i}^2}{1-h_i} \\\\ \\text{HC3:} &amp; &amp; \\hat{\\sigma_{U_i}}^2 &amp; = \\frac{\\hat{U_i}^2}{(1-h_i)^2}, \\end{align*}\\] where \\(\\hat{U}_i\\) is the residual from the OLS regression, \\(K\\) is the number of regressors, \\(h_i\\) is the leverage of observation \\(i\\), and is the \\(i^{\\text{th}}\\) diagonal element of \\(H=X(X&#39;X)^{-1}X&#39;\\). HC1 is the one reported by Stata when using the ‘robust’ option. All of these estimators are programmed in the sandwich package. Example 5.3 Let’s see how our estimator works to estimate precision. We can first try to implement the formula. # regs on X in both smaples ols.reg.0 &lt;- lm(y[Ds==0]~yB[Ds==0]) ols.reg.1 &lt;- lm(y[Ds==1]~yB[Ds==1]) # variance var.delta.ols &lt;- 1/N*(var(ols.reg.0$residuals)/(1-mean(Ds))+var(ols.reg.1$residuals)/(mean(Ds))) We can now try to see what the heteroskedasticity-robust variance estimator gives. ols.direct.HC1 &lt;- vcovHC(ols.direct,type=&#39;HC1&#39;) The robust standard error using HC1 is thus 0.03, while the default standard error assuming homoskedasticity is 0.03. The estimate obtained using Theorem 5.4 directly is equal to 0.02. 5.1.3 Properties of the OLS estimator under Conditional Independence As we have seen in Chapter 3, we could also have estimated \\(TT\\) using a regression omitting the interaction between the treatment indicator and control variables. With RCTs, this did not matter for the final result. With Observational Methods, this might make a huge difference. The reason is that the distribution of the observed covariates in the treatment and control group are the same in expectation in an RCT, while they are by essence different under Conditional Independence. As a consequence, when we estimate a model by OLS which does not insert interactions of the covariates, we might end up with a different parameter than the one we are after. Sloczynski (2020) studies this issue in great detail (Goldsmith-Pinkham, Hull and Kolesar (2022) make also progress on this front, but in a more general way.) In order to derive his result, Sloczynski (2020) slightly strengthens the assumptions we have made so far, especially by making potential outcomes dependent on \\(X_i\\) only through the propensity score: \\(p(X_i)=\\Pr(D_i=1|X_i)\\). Sloczynski (2020)’s main result concerns \\(\\delta\\) estimated by OLS in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta&#39; X_i + \\delta D_i + U_i. \\end{align*}\\] Theorem 5.5 (Weighted Average Interpretation of OLS) Under Assumptions 5.1, 5.3, 5.4, 5.6 (modified to hold with \\(p(X_i)\\) replacing \\(X_i\\)) and assuming that \\(\\esp{Y_i^2}\\) and \\(\\esp{\\lVert X_i^2 \\rVert}\\) are finite and that the covariance matrix of \\((D_i,X_i)\\) is non singular, we have \\(\\delta\\) in the previous equation when estimated by OLS equal to: \\[\\begin{align*} \\delta^{OLS} &amp; = w_1\\Delta^Y_{TT}+w_0\\Delta^Y_{TUT}, \\end{align*}\\] with: \\[\\begin{align*} w_1 &amp; = \\frac{(1-p)\\var{p(X_i)|D_i=0}}{p\\var{p(X_i)|D_i=1}+(1-p)\\var{p(X_i)|D_i=0}}\\\\ w_0 &amp; = \\frac{p\\var{p(X_i)|D_i=1}}{p\\var{p(X_i)|D_i=1}+(1-p)\\var{p(X_i)|D_i=0}} = 1-w_1. \\end{align*}\\] and \\(p=\\Pr(D_i=1)\\). Proof. See Sloczynski (2020). Remark. Theorem 5.5 shows that OLS without interactions between the treatment and the covariates is a weighted average of the effect of the treatment on the treated (\\(TT\\)) and of the effect of the treatment on the untreated (\\(TUT\\)). This is thus not the parameter we are after. Fortunately, the weights are positive and sum to one, so that we still find a weighted average of treatment effects with positive weights Unfortunately, the weigths do not behave as we would like. For example, \\(w_1\\), the weight on \\(TT\\), becomes larger as the proportion of the UNtreated increases. This is inconvenient for estimating the \\(ATE\\). It is also inco,venient for estimating \\(TT\\), since how close \\(\\delta^{OLS}\\) is to \\(TT\\) depends on whether there are a lot of treated units in the population (in which case \\(\\delta^{OLS}\\) will be closer to \\(TUT\\)) or not (in which case, \\(\\delta^{OLS}\\) will be closer to \\(TT\\)). Example 5.4 Let’s see how this result plays out in our example. Note however than treatment effect heterogeneity might not be enough to alter our estimates strongly. Let’s estimate a model without interactions: # running the OLS estimator without interactions ols.simp &lt;- lm(y~yB+Ds) # estimate of TT ww.ols.simp &lt;- ols.simp$coef[[3]] The estimate of \\(TT\\) using the OLS regression without interactions is equal to 0.182, while our estimate obtained with the added interaction term is equal to 0.184. 5.1.4 Problems with parametric methods When the conditional expectation of outcomes given the covariates is not linear, parametric methods which make this assumption will be erroneous. We will talk of specification bias. Example 5.5 Let’s see why in our example: We write outcomes as a non linear function of the pre-treatment covariate \\(y_i^B\\): \\[\\begin{align*} y^0_i &amp; =\\mu_i+\\delta+\\gamma (y_i^B - \\bar{y^B})^2 + U_i^0. \\end{align*}\\] Let’s choose some parameters: param &lt;- c(param,0.1,7.98) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;gamma&quot;,&quot;baryB&quot;) and then simulate a dataset: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) If we estimate the conditional expectation on the untreated population using a linear model, we are going to have biased predictions of the truth. Let’s first estimate the regression function: ols.reg.0 &lt;- lm(y[Ds==0]~yB[Ds==0]) # predicted values for the treated y.pred &lt;- ols.reg.0$coef[[1]]+ols.reg.0$coef[[2]]*yB[Ds==1] # estimated treatment effect by WWOLSX ww.ols &lt;- mean(y[Ds==1]-y.pred) # true value of TT in the sample tt.sample &lt;- mean(alpha[Ds==1]) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) points(yB[Ds==0],ols.reg.0$fitted.values,col=&#39;blue&#39;) points(yB[Ds==1],y.pred,pch=3,col=&#39;blue&#39;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;black&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,&#39;y1|D=1&#39;,expression(hat(&#39;y0|D=0&#39;)),expression(hat(&#39;y0|D=1&#39;))),pch=c(1,1,3,1,3),col=c(&#39;black&#39;,&#39;red&#39;,&#39;black&#39;,&#39;blue&#39;,&#39;blue&#39;),ncol=2) Figure 5.2: Biased parametric estimator We can see on Figure 5.2 that the predicted values for the potential outcomes of the treated in the absence of the treatment (\\(\\hatesp{y_i^0|D_i=1,y_i^B}\\)) based on the regression estimated on the untreated observations (in blue) are too low compared with the true values (in red). As a consequence, the OLS estimator is going to over estimate the true effect of the treatment. Indeed, the OLS estimate of the effect of the treatment is equal to 0.45 while the true value of the treatment effect in the sample is equal to 0.16. 5.2 Nonparametric methods Nonparametric observational methods enable to avoid (or at least mitigate) the issue of specification bias. In exchange, they have stronger requirements than parametric methods in terms of comparability between treated and control observations. The idea is that nonparametric methods rely on local comparisons to avoid specification bias. For that, we need that treated and untreated observations overlap. We call this assumption the Common Support Assumption, and it is required for nonparametric methods to solve the issue of specification bias. Hypothesis 5.7 (Common Support) We assume that, for the known set of observable covariates \\(X_i\\) for which the Selection on Observables Assumption holds, we have: \\[\\begin{align*} 0&lt;\\Pr(D_i=1|X_i)&lt;1. \\end{align*}\\] Example 5.6 Assumption 5.7 does not hold on Figure 5.2. The probability of receiving treatment jumps discontinuously at \\(y_i^B=\\bar{y}\\) from \\(1\\) to \\(0\\). Let’s generate some data with common support. For that, we are going to modify the selection equation to add some noise so that units with similar \\(y_i^B\\) might end up treated or untreated: \\[\\begin{align*} D_i &amp; = \\uns{y_i^B+V_i\\leq\\bar{y}} \\\\ V_i &amp; \\Ind Y_i^0 \\\\ V_i &amp; \\sim\\mathcal{N}(0,\\sigma^2_{\\mu}+\\sigma^2_{U}) \\end{align*}\\] Let’s now generate some data following this new selection equation: set.seed(1234) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) Let’s plot this new dataset and examine it for common support: par(mar=c(5,4,4,5)) plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y[Ds==1],pch=3,col=&#39;blue&#39;) abline(v=log(param[&quot;barY&quot;]),col=&#39;red&#39;) legend(5,10.5,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;D&#39;),pch=c(1,3,2),col=c(col.obs,&#39;blue&#39;,col.unobs),ncol=1) par(new=TRUE) plot(yB,Ds,pch=2,col=col.unobs,xlim=c(5,11),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) axis(4) mtext(&quot;D&quot;,side=4,line=3) Figure 5.3: Common Support Holds Figure 5.3 shows that we now have treated and untreated units on both sides of \\(y_i^B=\\bar{y}\\). Before we move to the identification of \\(TT\\) under Assumption 5.7, we need to compute the true value of the \\(TT\\) parameter in the population in our new example: Because we have changed the selection rule, the value of \\(TT\\) in the population has changed also: \\[\\begin{align*} \\Delta_{TT}^y &amp; =\\bar{\\alpha}+\\theta\\bar{\\mu} -\\theta\\frac{\\sigma^2_{\\mu}}{\\sqrt{2(\\sigma^2_{\\mu}+\\sigma^2_{U})}}\\frac{\\phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{2(\\sigma^2_{\\mu}+\\sigma^2_{U})}}\\right)}{\\Phi\\left(\\frac{\\bar{y}-\\bar{\\mu}}{\\sqrt{2(\\sigma^2_{\\mu}+\\sigma^2_{U})}}\\right)}. \\end{align*}\\] Let’s write a fiunction to compute this parameter: delta.y.tt.com.supp &lt;- function(param){ return(param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;theta&quot;]*((param[&quot;sigma2mu&quot;]*dnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(2*(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])))))/(sqrt(2*(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))*pnorm((log(param[&quot;barY&quot;])-param[&quot;barmu&quot;])/(sqrt(2*(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;]))))))) } delta.y.tt.CS.pop &lt;- delta.y.tt.com.supp(param) The value of \\(TT\\) in the population in our new example is 0.18. 5.2.1 Identification Let’s now derive identification of \\(TT\\): Theorem 5.6 (Identification of TT Under Conditional Independence and Common Support) Under Assumptions 5.1 (or the stronger 5.2) and 5.7, \\(TT\\) is identified using either a nonparametric regression approach or a reweighting approach: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\Delta^Y_{NPR(X)} = \\Delta^Y_{RW(X)}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^Y_{NPR(X)} &amp; = \\esp{Y_i-\\esp{Y_i|X_i,D_i=0}|D_i=1} \\\\ \\Delta^Y_{RW(X)} &amp; = \\esp{Y_i|D_i=1} \\\\ &amp; \\phantom{=} -\\esp{Y_i\\frac{\\Pr(D_i=1|X_i)}{1-\\Pr(D_i=1|X_i)}\\frac{1-\\Pr(D_i=1)}{\\Pr(D_i=1)}|D_i=0}. \\end{align*}\\] Proof. Let us start with the first equality: \\[\\begin{align*} \\Delta^Y_{NPR(X)} &amp; = \\esp{Y_i-\\esp{Y_i|X_i,D_i=0}|D_i=1} \\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{\\esp{Y_i|X_i,D_i=0}|D_i=1}\\\\ &amp; = \\esp{Y^1_i|D_i=1}- \\esp{\\esp{Y^0_i|X_i,D_i=0}|D_i=1} \\\\ &amp; = \\esp{Y^1_i|D_i=1}- \\esp{\\esp{Y^0_i|X_i,D_i=1}|D_i=1} \\\\ &amp; = \\esp{Y^1_i|D_i=1}- \\esp{Y^0_i|D_i=1} \\\\ &amp; = \\Delta^Y_{TT}, \\end{align*}\\] where the second equality follows from the linearity of linear expectations, the fourth equality follows from Assumptions 5.1 and 5.7 and the fifth equality follows from the Law of Iterated Expectations. Let us now examine the second equality: \\[\\begin{align*} \\Delta^Y_{RW(X)}-\\esp{Y_i|D_i=1} &amp; = \\esp{Y_i\\frac{\\Pr(D_i=1|X_i)}{1-\\Pr(D_i=1|X_i)}\\frac{1-\\Pr(D_i=1)}{\\Pr(D_i=1)}|D_i=0} \\\\ &amp; = \\frac{1}{\\Pr(D_i=1)}\\esp{Y^0_i(1-D_i)\\frac{\\Pr(D_i=1|X_i)}{1-\\Pr(D_i=1|X_i)}} \\\\ &amp; = \\frac{1}{\\Pr(D_i=1)}\\esp{\\esp{Y^0_i(1-D_i)\\frac{\\Pr(D_i=1|X_i)}{1-\\Pr(D_i=1|X_i)}|X_i}}\\\\ &amp; = \\frac{1}{\\Pr(D_i=1)}\\esp{\\esp{Y_i^0|X_i}(1-\\Pr(D_i=1|X_i))\\frac{\\Pr(D_i=1|X_i)}{1-\\Pr(D_i=1|X_i)}} \\\\ &amp; = \\frac{1}{\\Pr(D_i=1)}\\esp{\\esp{Y_i^0|X_i}\\Pr(D_i=1|X_i)}\\\\ &amp; = \\frac{1}{\\Pr(D_i=1)}\\esp{\\esp{Y_i^0D_i|X_i}}\\\\ &amp; =\\frac{1}{\\Pr(D_i=1)}\\esp{Y_i^0D_i} \\\\ &amp; =\\frac{1}{\\Pr(D_i=1)}\\esp{Y_i^0|D_i=1}\\Pr(D_i=1)\\\\ &amp; = \\esp{Y_i^0|D_i=1}, \\end{align*}\\] where Assumption 5.7 ensures that \\(\\Delta^Y_{RW(X)}\\) is well-defined, the third and seven equalities follow from the Law of Iterated Expectations, and the fourth and sixth equalities use Assumption 5.1. Theorem 5.6 shows that we can identify the effect of the treatment on the treated in the population under Conditional Independence (and Common Support) by adopting one of two approaches. With the regression-based approach, untreated observations help us estimate the predicted value of the treated with the same values of the observed covariates \\(X_i\\). This is very similar to what we did with the \\(OLS(X)\\) estimator above. The only exception is that we do not use a parametric model to predict the counterfactual value of the outcome of the untreated. With the reweighting approach, we use the propensity score \\(\\Pr(D_i=1|X_i)\\) to reweight all untreated observations so that the weighted expectation is equal to those that the treated would have had absent the treatment. Reweighting puts more weight on the untreated observations that have a large probability of being treated: they resemble the treated a lot in terms of their observed covariates and thus inform us on what would have happened to the treated in the absence of the treatment. 5.2.2 Estimation How do we implement matching estimators in practice? There are almost zillions of way to implement them. What’s nice is that mosst (all?) of them can be written as a reweighting estimator: \\[\\begin{align*} \\hat{\\Delta}^Y_{M} &amp; = \\frac{1}{N_1^S}\\sum_{i\\in\\mathcal{I}^1\\cap S}\\left(Y_i-\\sum_{j\\in\\mathcal{I}^0}w_{i,j}Y_j\\right) \\end{align*}\\] with \\(\\mathcal{I}^1\\) is the set of treated individuals, \\(\\mathcal{I}^0\\) the set of untreated individuals, \\(S\\) the set of individuals lying on the common support and \\(N_1^S\\) the number of treated on the common support. Each specific estimator differs on how it computes the weights \\(w_{i,j}\\) and how it chooses the set of observations in the common support \\(S\\). Here are the methods we are going to detail in this section: Local Regression Matching (on the propensity score) Local Averaging Matching Nearest Neighbor Matching Reweighting Matching Doubly Robust Matching 5.2.2.1 Local Regression Matching (on the Propensity Score) The idea of Local Regression Matching is very simple: run a separate regression for each treated observation using only untreated observations that are close enough to it. Closeness is defined by a bandwidth, or a window around the treated observation of interest. In order to be more efficient, more weight is given to untreated observations that lie closer to the treated observation. Weights are given using a kernel function. The key difficulty is what to do when the number of covariates is more than one (as it will very likely happen). How do you define close observations then? There are several possible approaches to that issue. One is to use multivariate kernel functions (generally after standardizing covariates so that bandwidth choice is similar for all covariates). Another approach more heavily used in practice is to summarize the influence of observed covariates on selection by using the propensity score. A very nice result shows that conditioning on the propensity score is similar for estimating the \\(TT\\) as conditioning on all the covariates. The propensity score is also very useful to build the set of observations that lie on the common support. Let’s first study the Local Regression Matching and then add the propensity score to the mix. 5.2.2.1.1 Local Regression Matching In practice, with LLR, \\(\\sum_{j\\in\\mathcal{I}^0}w_{i,j}Y_j=\\hatesp{Y_i|X_i,D_i=0}\\) is equal to \\(\\hat{\\theta_0}\\) estimated by weighted OLS in the following regression on the sample of untreated individuals \\[\\begin{align*} Y_j = \\theta_0 + (X_i-X_j)\\theta_1 + \\epsilon_j, \\end{align*}\\] with weights \\(K\\left(\\frac{X_i-X_j}{h}\\right)\\), where \\(h\\) is the bandwidth and \\(K\\) is a kernel function. Using some algebra, on can show, in the case of one-dimensional covariate \\(X_i\\), that the weights of LLR are as follows (Fan (1992) and Smith and Todd (2005)): \\[\\begin{align*} w_{i,j} &amp; =\\frac{K_{i,j}\\sum^{}_{k\\in \\mathcal{I}_0}K_{i,k}(X_k-X_i)^2-[K_{i,j}(X_j-X_i)][\\sum_{k\\in \\mathcal{I}_0}^{}K_{i,k}(X_k-X_i)]}{\\sum_{j\\in \\mathcal{I}_0}^{}K_{i,j}\\sum_{k\\in \\mathcal{I}_0}^{}K_{i,k}(X_k-X_i)^2-[\\sum_{k\\in \\mathcal{I}_0}^{}K_{i,k}(X_k-X_i)]^2} \\end{align*}\\] with \\(K_{i,j}=K\\left(\\frac{X_i-X_j}{h}\\right)\\). Example 5.7 Let us see how this works in our example. Let us now run the LLR regression on the untreated sample, using as grid points all the observations in the treated sample, and let us then compute the estimated \\(TT\\), with two candidates for the bandwidth: kernel &lt;- &#39;gaussian&#39; bw &lt;- 1 # run LLR on the untreated sample using treated points as grid points y0.llr.1 &lt;- llr(y[Ds==0],yB[Ds==0],yB[Ds==1],bw=bw,kernel=kernel) # compute TT ww.llr.1 &lt;- mean(y[Ds==1]-y0.llr.1) bw &lt;- 0.5 # run LLR on the untreated sample using treated points as grid points y0.llr.0.5 &lt;- llr(y[Ds==0],yB[Ds==0],yB[Ds==1],bw=bw,kernel=kernel) # compute TT ww.llr.0.5 &lt;- mean(y[Ds==1]-y0.llr.0.5) Let us now visualize how these estimates look like: plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab=&quot;yB&quot;,ylab=&quot;Outcomes&quot;) points(yB[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) points(yB[Ds==1],y0.llr.1,col=&#39;blue&#39;) points(yB[Ds==1],y0.llr.0.5,col=&#39;green&#39;) points(yB[Ds==1],y[Ds==1],pch=3) legend(5,11,c(&#39;y0|D=0&#39;,&#39;y0|D=1&#39;,expression(hat(y0.1)),expression(hat(y0.0.5)),&#39;y|D=1&#39;),pch=c(1,1,1,1,3),col=c(&#39;black&#39;,&#39;red&#39;,&#39;blue&#39;,&#39;green&#39;,&#39;black&#39;),ncol=2) Figure 5.4: LLR Matching estimates The LLR Matching estimate is equal to 0.192 with a bandwidth of \\(1\\) and to 0.164 with a bandwidth of \\(0.5\\), while the true value of the parameter in the population is equal to 0.175. Let us see how this estimator behaves over sample replications: # LLR matching fnciton llr.match &lt;- function(y,D,x,bw,kernel){ y0.llr &lt;- llr(y[D==0],x[D==0],x[D==1],bw=bw,kernel=kernel) return(mean(y[D==1]-y0.llr)) } # Monte Carlos monte.carlo.llr &lt;- function(s,N,param,bw,kernel){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) ww.llr &lt;- llr.match(y,Ds,yB,bw=bw,kernel=kernel) return(ww.llr) } simuls.llr.N &lt;- function(N,Nsim,param,bw,kernel){ simuls.llr &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.llr,N=N,param=param,bw=bw,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.llr) &lt;- c(&#39;LLR&#39;) return(simuls.llr) } sf.simuls.llr.N &lt;- function(N,Nsim,param,bw,kernel){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr.match&#39;,&#39;llr&#39;) sim.llr &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.llr,N=N,param=param,bw=bw,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.llr) &lt;- c(&#39;LLR&#39;) return(sim.llr) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) N.sample &lt;- c(100,1000) #simuls.llr &lt;- lapply(N.sample,simuls.llr.N,Nsim=Nsim,param=param,bw=bw,kernel=kernel) simuls.llr &lt;- lapply(N.sample,sf.simuls.llr.N,Nsim=Nsim,param=param,bw=bw,kernel=kernel) names(simuls.llr) &lt;- N.sample Let us now plot the resulting estimates: par(mfrow=c(2,2)) for (i in 1:length(simuls.llr)){ hist(simuls.llr[[i]][,&#39;LLR&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yLLR)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.com.supp(param),col=&quot;red&quot;) } Figure 5.5: Distribution of the \\(LLR\\) estimator over replications of samples of different sizes Remark. On key limitation of the LLR Matching estimator that we have studies so far is the fact that it requires the use on only one covariate. What to do when there is more than one covariate? There are basically two solutions. One is to use multidimensional kernels, which are simply products of unidimensionnal kernel functions. In order to make things simpler, we generally standardize variables so that their dimensions are similar. Another approach is to use the propensity score as a dimension reduction device. 5.2.2.1.2 Local Regression Matching on the Propensity Score The propensity score, which we denote \\(P(X_i)\\), is the probability that a unit is treated given its observed covariates: \\(P(X_i)=\\Pr(D_i=1|X_i)\\). The key results that enables us to use the propensity score as dimension reduction device has been introduced by Rosenbaum and Rubin (1983): Theorem 5.7 (Sufficiency of Propensity Score) \\((Y_i^1,Y_i^0)\\Ind D_i|X_i \\Rightarrow (Y_i^1,Y_i^0)\\Ind D_i|P(X_i)\\). Proof. \\[\\begin{align*} \\Pr(D_i=1|Y_i^1,Y_i^0,P(X_i)) &amp; = \\esp{\\Pr(D_i=1|Y_i^1,Y_i^0,X_i)|Y_i^1,Y_i^0,P(X_i)} \\\\ &amp; = \\esp{\\Pr(D_i=1|X_i)|Y_i^1,Y_i^0,P(X_i)} \\\\ &amp; = P(X_i) = \\Pr(D_i=1|X_i), \\end{align*}\\] where the first equality uses the Law of Iterated Expectations and the second one uses \\((Y_i^1,Y_i^0)\\Ind D_i|X_i\\). In practice, in order to estimate LLR Matching using the propensity score, you can follow the following steps: Estimate a logit or probit regression: \\(D_i = \\uns{\\gamma_0 + \\gamma_1&#39;X_i + \\zeta_i&gt;0}\\) (you might use series or splines to be more non-parametric here) Compute the predicted values (which are estimates of the propensity score): \\(\\hat{P}(X_i)\\) (you could also directly use multivariate non-parametric regression at this stage) Use \\(\\hat{P}(X_i)\\) as control variable in LLR Matching. Example 5.8 Let’s see how this works in our example. First, we need to estimate the propensity score. We are going to use a probit estimator, but things would be much similar with a logit. The most important assumption is the linearity of the link function. probit.Ds &lt;- glm(Ds~yB, family=binomial(link=&quot;probit&quot;)) pscore &lt;- predict(probit.Ds,type=&quot;response&quot;) Let us now see how the propensity score looks like as a function of \\(y_i^B\\): plot(yB,pscore, xlab=&quot;yB&quot;, ylab=&quot;Propensity score&quot;) Figure 5.6: Propensity score as a function of \\(y_i^B\\) Let us now compute the LLR Matching estimator using the propensity score. bw &lt;- 0.1 # run LLR on the untreated sample using treated points as grid points y0.llr.pscore.0.1 &lt;- llr(y[Ds==0],pscore[Ds==0],pscore[Ds==1],bw=bw,kernel=kernel) # compute TT ww.llr.pscore.0.1 &lt;- llr.match(y,Ds,pscore,bw=bw,kernel=kernel) Let’s see how the LLR estimator using the propensity score works: plot(pscore[Ds==0],y[Ds==0], ylab=&quot;Outcomes&quot;, xlab=&quot;Propensity score&quot;,xlim=c(0,1),ylim=c(5,12)) points(pscore[Ds==1],y[Ds==1],pch=3,col=&#39;blue&#39;) points(pscore[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) points(pscore[Ds==1],y0.llr.pscore.0.1,col=&#39;green&#39;) legend(0.7,11,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;y0|D=1&#39;,expression(hat(y0.0.1))),pch=c(1,3,1,1),col=c(&#39;black&#39;,&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;),ncol=1) Figure 5.7: Propensity score and potential outcomes The estimated value of the \\(TT\\) parameter using LLR Matching on the propensity score is equal to 0.139. Remember that the LLR Matching estimate using \\(y_i^B\\) directly is equal to 0.192 with a bandwidth of \\(1\\) and to 0.164 with a bandwidth of \\(0.5\\), while the true value of the parameter in the population is equal to 0.175. Remark. We have not seen how to choose the bandwidth optimally. A second thing we are missing is what to do when the density of the pscore is too low and the common support assumption almost does not hold. 5.2.2.1.3 Bandwidth choice Choosing a bandwidth can be done using one of two approaches. The smaller the bandwidth, the less biased the estimate is, but also the more noisy. With a larger bandwidth, bias increases, but noise decreases. This is the usual Bias/Variance trade-off in nonparametric estimation. Frolich (2005) derives formulae based on the asymptotic distribution of the LLR Matching estimator to help choose the optimal bandwidth. The problem is that these formulae are complex and they are not very precise (the criteria is flat in the bandwidth). In general, we thus prefer to use use Cross-Validation. Cross validation estimates the MSE using leave-one out estimation and searches for the bandwidth having the lower MSE. Galdo, Smith and Black (2008) suggest to weighted the MSE search by importance of the treated. Example 5.9 Let’s see how this works in our example. Let us first (re)define a function to compute the MSE and then compute is: Let us now plot the link between bandwidth and MSE and what the prediction looks like: plot(MSE.grid.pscore[1:10],MSE.pscore[1:10], xlab=&quot;Bandwidth&quot;, ylab=&quot;MSE&quot;) plot(pscore[Ds==0],y[Ds==0], ylab=&quot;Outcomes&quot;, xlab=&quot;Propensity score&quot;,xlim=c(0,1),ylim=c(5,12)) points(pscore[Ds==1],y[Ds==1],pch=3,col=&#39;blue&#39;) points(pscore[Ds==1],y0[Ds==1],pch=1,col=&#39;red&#39;) points(pscore[Ds==1],y0.llr.pscore.0.1,col=&#39;green&#39;) points(pscore[Ds==1],y0.llr.pscore.bw,col=&#39;blue&#39;) legend(0.7,11,c(&#39;y0|D=0&#39;,&#39;y1|D=1&#39;,&#39;y0|D=1&#39;,expression(hat(y0.0.1)),expression(hat(y0.bw))),pch=c(1,3,1,1,1),col=c(&#39;black&#39;,&#39;blue&#39;,&#39;red&#39;,&#39;green&#39;,&#39;blue&#39;),ncol=2) Figure 5.8: LLR Matching on the propensity score with an optimal bandwidth With the optimal bandwidth, the estimated value of the \\(TT\\) parameter using LLR Matching on the propensity score is equal to 0.17. Remember that the LLR Matching on the propensity score estimate using a bandwidth of \\(0.1\\) is equal to 0.139. Using LLR Matching on \\(y_i^B\\) directly, the estimated \\(TT\\) is equal to 0.192 with a bandwidth of \\(1\\) and to 0.164 with a bandwidth of \\(0.5\\), while the true value of the parameter in the population is equal to 0.175. 5.2.2.1.4 Trimming Trimming is done to prevent areas where the density of the propensity score is low (where there are very few untreated observations) to blow up our estimates. This is a way to enforce the common support assumption. Note that at the same time we are changing the parameter estimate from \\(TT\\) to \\(TT\\) on the trimmed common support. Trimming, as done for example by Smith and Todd (2005)), goes as follows: Estimate conditional density \\(\\hat{f}_{P(X)|D=0}\\), for \\(i\\in\\mathcal{I}_1\\) Get rid of observations with density lower than the \\(t^{\\text{th}}\\) percentile of \\(\\hat{f}_{P(X)|D=0}\\), where \\(t\\) is the trimming level (5% in general). In order to estimate the density of the propensity score, we use a kernel estimator: \\[\\begin{align*} \\hat{f}_{P(X)|D=d}(P(X_i)) &amp;= \\frac{1}{N_dh}\\sum^{N_d}_{j=1}K\\left(\\frac{P(X_i)-P(X_j)}{h}\\right) \\\\ \\hat{S} &amp; = \\begin{cases} 1 &amp; \\text{ if } \\hat{f}_{P(X)|D=0}(P(X_i))&gt;\\text{quantile}_{t}(\\hat{f}_{P(X)|D=1}(P(X_i))) \\\\ 0 &amp; \\text{ if } \\hat{f}_{P(X)|D=0}(P(X_i))\\leq\\text{quantile}_{t}(\\hat{f}_{P(X)|D=1}(P(X_i))), \\end{cases} \\end{align*}\\] where \\(h\\) is a different bandwidth that the one chosen for LLR. It can be choosen by using Silverman’s rule of thumb, for example. Example 5.10 Let us illustrate how this works in our numerical example. First, let’s define a function to estimate the density and then compute the common support. # density function estimated at one point dens.fun.point &lt;- function(n,x,gridx,bw,kernel){ return(density(x,n=1,from=gridx[n],to=gridx[n],bw=bw,kernel=kernel)[[2]]) } dens.fun &lt;- function(x,gridx,bw,kernel){ return(sapply(1:length(gridx), dens.fun.point, x=x, gridx=gridx, bw=bw, kernel=kernel)) } dens.pscore.D0 &lt;- dens.fun(pscore[Ds==0],pscore[Ds==1],bw=bw.nrd(pscore[Ds==0]),kernel=&#39;b&#39;) dens.pscore.D1 &lt;- dens.fun(pscore[Ds==1],pscore[Ds==1],bw=bw.nrd(pscore[Ds==1]),kernel=&#39;b&#39;) com.supp &lt;- function(x,gridx,t,bw,kernel){ dens.x &lt;- dens.fun(x=x,gridx=gridx,bw=bw,kernel=kernel) return(ifelse(dens.x&lt;=quantile(dens.x,t),0,1)) } t&lt;- 0.05 com.supp.pscore &lt;- com.supp(pscore[Ds==0],pscore[Ds==1],t=t,bw=bw.nrd(pscore[Ds==0]),kernel=&#39;b&#39;) # estimation using common support and trimming llr.match.trim &lt;- function(y,D,x,t,bw,kernel){ com.supp.x &lt;- com.supp(x[D==0],x[D==1],t=t,bw=bw.nrd(x[D==0]),kernel=&#39;b&#39;) y0.llr &lt;- llr(y[D==0],x[D==0],x[D==1][com.supp.x==1],bw=bw,kernel=kernel) return(mean(y[D==1][com.supp.x==1]-y0.llr)) } ww.llr.pscore.trim &lt;- llr.match.trim(y,Ds,pscore,t=t,bw=bw,kernel=kernel) Let us now plot what the common support looks like: par(mar=c(5,4,4,5)) plot(pscore[Ds==1],dens.pscore.D0,pch=1,xlim=c(0,1),xlab=&quot;Propensity score&quot;,ylab=&quot;density&quot;) points(pscore[Ds==1],dens.pscore.D1,pch=3) legend(0.65,2.5,c(&#39;fP(yB)|D=0&#39;,&#39;fP(yB)|D=1&#39;,&#39;Common Support&#39;),pch=c(1,3,2),col=c(&#39;black&#39;,&#39;black&#39;,&#39;red&#39;),ncol=1) par(new=TRUE) plot(pscore[Ds==1],com.supp.pscore,pch=2,col=&#39;red&#39;,xlim=c(0,1),ylim=c(0,1),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) axis(4) mtext(&quot;Common Support&quot;,side=4,line=3) Figure 5.9: Trimming and Common Support With trimming and the optimal bandwidth, the estimated value of the \\(TT\\) parameter using LLR Matching on the propensity score is equal to 0.168. Remember that the LLR Matching on the propensity score estimate using the optimal bandwidth but no trimming is equal to 0.17. Using LLR Matching on \\(y_i^B\\) directly, the estimated \\(TT\\) is equal to 0.192 with a bandwidth of \\(1\\) and to 0.164 with a bandwidth of \\(0.5\\), while the true value of the parameter in the population is equal to 0.175. Let us run Monte Carlo simulations for this estimator: monte.carlo.llr.trim &lt;- function(s,N,param,t,bw,kernel){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) probit.Ds &lt;- glm(Ds~yB, family=binomial(link=&quot;probit&quot;)) pscore &lt;- predict(probit.Ds,type=&quot;response&quot;) ww.llr &lt;- llr.match.trim(y,Ds,pscore,t=t,bw=bw,kernel=kernel) return(ww.llr) } simuls.llr.trim.N &lt;- function(N,Nsim,param,t,bw,kernel){ simuls.llr.trim &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.llr.trim,N=N,param=param,t=t,bw=bw,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.llr.trim) &lt;- c(&#39;LLR Trim&#39;) return(simuls.llr.trim) } sf.simuls.llr.trim.N &lt;- function(N,Nsim,param,t,bw,kernel){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr.match.trim&#39;,&#39;llr&#39;,&#39;dens.fun.point&#39;,&#39;dens.fun&#39;,&#39;com.supp&#39;) sim.llr.trim &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.llr.trim,N=N,param=param,t=t,bw=bw,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.llr.trim) &lt;- c(&#39;LLR Trim&#39;) return(sim.llr.trim) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) #simuls.llr.trim &lt;- lapply(N.sample,simuls.llr.trim.N,Nsim=Nsim,param=param,t=t,bw=bw,kernel=kernel) simuls.llr.trim &lt;- lapply(N.sample,sf.simuls.llr.trim.N,Nsim=Nsim,param=param,t=t,bw=bw,kernel=kernel) names(simuls.llr.trim) &lt;- N.sample Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations): par(mfrow=c(2,2)) for (i in 1:length(simuls.llr.trim)){ hist(simuls.llr.trim[[i]][,&#39;LLR Trim&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yLLRTrim)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.com.supp(param),col=&quot;red&quot;) } Figure 5.10: Distribution of the trimmed \\(LLR\\) estimator over replications of samples of different sizes 5.2.2.2 Nearest neighbor matching With Nearest Neighbor Matching (NNM), we choose the \\(M\\) closest untreated units for each treated observation \\(i\\) on the common support, we compute the average outcome of the \\(M\\) twins to be the imputed counterfactual mean for unit \\(i\\), take the difference with the observed outcome for \\(i\\), \\(Y_i\\), and we take the average of this difference over all treated \\(i\\) on the common support to obtain the treatment effect estimate: The \\(m^{\\text{th}}\\) closest neighbor is defined as follows: \\[ j_m(i) = \\left\\{j:D_j=1-D_i \\text{ } \\&amp;\\sum_{k:D_k=1-D_i}\\uns{d(i,k)\\leq d(i,j)}=m\\right\\} \\] 2. The set of \\(M\\) closest neighbors is thus: \\[ \\mathcal{J}_M(i) = \\left\\{j_1(i),\\dots,j_M(i)\\right\\} \\] 3. The number of times observation \\(j\\) is used as a neighbor (when matching is with replacement) is: \\[ \\mathcal{K}_M(j) = \\sum_{i=1}^N\\uns{j\\in\\mathcal{J}_M(i)}. \\] \\(M\\) nearest-neighbors pair matching with replacement has the following weights: \\[ w_{i,j} = \\begin{cases} \\frac{1}{M} &amp; \\text{ if } j\\in\\mathcal{J}_M(i)\\\\ 0 &amp; \\text{ if } j\\notin\\mathcal{J}_M(i) \\end{cases} \\] 5. We can rewrite the estimator of \\(M\\) nearest-neighbors matching with replacement as follows: \\[\\begin{align*} \\hat{\\Delta}^Y_{NNM} &amp; = \\frac{1}{N_1^S}\\sum_{i\\in\\mathcal{I}^1\\cap S}\\left(Y_i-\\sum_{j\\in\\mathcal{I}^0}w_{i,j}Y_j\\right)\\\\ &amp; = \\frac{1}{N_1^S}\\sum_{i\\in S}\\left(D_i-(1-D_i)\\frac{\\mathcal{K}_M(i)}{M}\\right)Y_i \\end{align*}\\] A key issue with how we have implemented NNM is the choice of the metric \\(d(i,j)\\). Several can be used among the following: Euclidean distance \\[ d(i,j) = \\sqrt{\\sum_k(X^k_i-X^k_j)^2} \\] 2. Normalized Euclidean distance \\[ d(i,j) = \\sqrt{\\sum_k\\frac{(X^k_i-X^k_j)^2}{\\var{X^k}}} \\] 3. Mahalanobis distance \\[ d(i,j) = \\sqrt{(X-\\bar{X})&#39;S^{-1}(X-\\bar{X})} \\] with \\(S\\) the covariance matrix of \\(X\\) 4. Propensity score distance \\[ d(i,j) = \\sqrt{(P(X_i)-P(X_j))^2}= \\left|P(X_i)-P(X_j)\\right| \\] 5. Genetic distance (Sekhon) Remark. When \\(d(i,k)\\leq d(i,j)\\) we break ties at random to maintain the integrity of NNM definition. Remark. Euclidean distance is a bad choice for matching since it gives mucg more weight to covariates observed on a large scale. You are much better off using Normalized Euclidean distance or Mahalanobis distance. Example 5.11 Let’s see how Nearest Neighbor Matching can be implemented in our example. The two R packages that can be used for implementing NNM estimators are Matching by Jasjeet Sekhon and MatchIt by Ho, Imai, King and Stuart. As MatchIt is more general and includes most Matching options, I’ll focus on MatchIt. # building a dataset with treatment, control and outcome match.data &lt;- data.frame(y=y,Ds=Ds,yB=yB) # NNM with euclidean distance and 1 to 1 matching with replacement # selecting the neighbors nnm.euclid.1.1 &lt;- matchit(Ds~yB,ratio=1,method=&quot;nearest&quot;,distance=&#39;euclidean&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.euclid.1.1 &lt;- match.data(nnm.euclid.1.1) # estimating tt on the matched data using the weights tt.nnm.euclid.1.1 &lt;- coef(lm(y~Ds,data=data.nnm.euclid.1.1,weights=weights))[[2]] # NNM with euclidean distance and 5 to 1 matching with replacement # selecting the neighbors nnm.euclid.5.1 &lt;- matchit(Ds~yB,ratio=5,method=&quot;nearest&quot;,distance=&#39;euclidean&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.euclid.5.1 &lt;- match.data(nnm.euclid.5.1) # estimating tt on the matched data using the weights tt.nnm.euclid.5.1 &lt;- coef(lm(y~Ds,data=data.nnm.euclid.5.1,weights=weights))[[2]] # NNM with propensity score distance and 1 to 1 matching with replacement # selecting the neighbors nnm.pscore.1.1 &lt;- matchit(Ds~yB,ratio=1,method=&quot;nearest&quot;,distance=&#39;glm&#39;,link=&#39;probit&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.pscore.1.1 &lt;- match.data(nnm.pscore.1.1) # estimating tt on the matched data using the weights tt.nnm.pscore.1.1 &lt;- coef(lm(y~Ds,data=data.nnm.pscore.1.1,weights=weights))[[2]] # NNM with propensity score distance and 5 to 1 matching with replacement # selecting the neighbors nnm.pscore.5.1 &lt;- matchit(Ds~yB,ratio=5,method=&quot;nearest&quot;,distance=&#39;glm&#39;,link=&#39;probit&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.pscore.5.1 &lt;- match.data(nnm.pscore.5.1) # estimating tt on the matched data using the weights tt.nnm.pscore.5.1 &lt;- coef(lm(y~Ds,data=data.nnm.pscore.5.1,weights=weights))[[2]] # NNM with Mahalanobis distance and 1 to 1 matching with replacement # selecting the neighbors nnm.maha.1.1 &lt;- matchit(Ds~yB,ratio=1,method=&quot;nearest&quot;,distance=&#39;mahalanobis&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.maha.1.1 &lt;- match.data(nnm.maha.1.1) # estimating tt on the matched data using the weights tt.nnm.maha.1.1 &lt;- coef(lm(y~Ds,data=data.nnm.maha.1.1,weights=weights))[[2]] # NNM with Mahalanobis distance and 5 to 1 matching with replacement # selecting the neighbors nnm.maha.5.1 &lt;- matchit(Ds~yB,ratio=5,method=&quot;nearest&quot;,distance=&#39;mahalanobis&#39;,replace=TRUE,data=match.data) # generating the data with neighbors and weights data.nnm.maha.5.1 &lt;- match.data(nnm.maha.5.1) # estimating tt on the matched data using the weights tt.nnm.maha.5.1 &lt;- coef(lm(y~Ds,data=data.nnm.maha.5.1,weights=weights))[[2]] The estimates are going to be pretty similar among all the methods in our example. For example, 5 to 1 NNM with the Mahalanobis distance yields an estimate of \\(TT\\) of 0.147. The MatchIt package offers some pretty cool visualization tools. For example, we can visualize the standardized distance (mean difference in units of standard deviation) between the treated and control units before and after matching, and the distribution of covariates before and after matching: # plot of standardized distance plot(summary(nnm.euclid.1.1),xlim=c(0,2)) # plot of distribution of covariates plot(nnm.euclid.1.1, type = &quot;density&quot;, interactive = FALSE) Figure 5.11: Trimming and Common Support As Figure 5.11 shows, the Matching procedure is pretty effective in that it completely aligns treated and control units in terms of the pre-treatment covariate. MatchIt is much reacher than I can do it justice here. See its amazing documentation for inspiration and guidance. Let us run Monte Carlo simulations for this estimator: monte.carlo.nnm &lt;- function(s,N,param,...){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) # building a dataset with treatment, control and outcome match.data &lt;- data.frame(y=y,Ds=Ds,yB=yB) # NNM with euclidean distance and 1 to 1 matching with replacement # selecting the neighbors nnm.euclid.1.1 &lt;- matchit(Ds~yB,data=match.data,...) # generating the data with neighbors and weights data.nnm.euclid.1.1 &lt;- match.data(nnm.euclid.1.1) # estimating tt on the matched data using the weights tt.nnm.euclid.1.1 &lt;- coef(lm(y~Ds,data=data.nnm.euclid.1.1,weights=weights))[[2]] return(tt.nnm.euclid.1.1) } simuls.nnm.N &lt;- function(N,Nsim,param,...){ simuls.nnm &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.nnm,N=N,param=param,...)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.nnm) &lt;- c(&#39;NNM&#39;) return(simuls.nnm) } sf.simuls.nnm.N &lt;- function(N,Nsim,param,...){ sfInit(parallel=TRUE,cpus=8) sfLibrary(MatchIt) sim.nnm &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.nnm,N=N,param=param,...)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.nnm) &lt;- c(&#39;NNM&#39;) return(sim.nnm) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) #simuls.nnm &lt;- lapply(N.sample,simuls.nnm.N,Nsim=Nsim,param=param,ratio=1,method=&quot;nearest&quot;,distance=&#39;euclidean&#39;,replace=TRUE) simuls.nnm &lt;- lapply(N.sample,sf.simuls.nnm.N,Nsim=Nsim,param=param,ratio=1,method=&quot;nearest&quot;,distance=&#39;euclidean&#39;,replace=TRUE) names(simuls.nnm) &lt;- N.sample Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations): par(mfrow=c(2,2)) for (i in 1:length(simuls.nnm)){ hist(simuls.nnm[[i]][,&#39;NNM&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yNNM)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.com.supp(param),col=&quot;red&quot;) } Figure 5.12: Distribution of the NNM estimator over replications of samples of different sizes 5.2.2.3 Reweighting matching Reweighting matching uses the following set of weigths: \\[\\begin{align*} w_{i,j} &amp; = \\frac{\\frac{\\hat{P}(X_j)}{1-\\hat{P}(X_j)}}{\\sum_{j\\in\\mathcal{I}_0}\\frac{\\hat{P}(X_j)}{1-\\hat{P}(X_j)}} = w_j. \\end{align*}\\] Since these weights do not depend on \\(i\\), we can thus write: \\[\\begin{align*} \\hat{\\Delta}^Y_{TT} &amp; = \\frac{1}{N_1}\\sum_{i\\in\\mathcal{I}_1}\\left(Y_i-\\sum_{j\\in\\mathcal{I}_0}w_{i,j}Y_j\\right)\\\\ &amp; = \\frac{1}{N_1}\\sum_{i\\in\\mathcal{I}_1}Y_i - \\sum_{j\\in\\mathcal{I}_0}w_{j}Y_j \\end{align*}\\] The Reweighting estimator is thus very simple and quick: it only needs two separate summations instead of two nested summations. Example 5.12 Let’s see how the reweighting estimator works in practice. The main object that we have to build are the weights. They stem directly from the propensity score estimates. # computing weights pscore.weights &lt;- (pscore/(1-pscore))*(1-mean(Ds))/mean(Ds) # get rid of weights for the treated pscore.weights[Ds==1] &lt;- 0 # normalize by sum of weights for the untreated pscore.weights &lt;- pscore.weights/sum(pscore.weights) # counterfactual estimation using reweighting: y0.D1.reweighting &lt;- weighted.mean(y[Ds==0],w=pscore.weights[Ds==0]) # TT estimation TT.reweighting &lt;- mean(y[Ds==1])-y0.D1.reweighting The \\(TT\\) estimated by the reweighting estimator is equal to 0.297. Remember that the true value of the parameter in the population is equal to 0.175. Let us run Monte Carlo simulations for this estimator: monte.carlo.reweight &lt;- function(s,N,param){ set.seed(s) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- rnorm(N,0,sqrt(param[&quot;sigma2mu&quot;]+param[&quot;sigma2U&quot;])) Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] + param[&quot;gamma&quot;]*(yB-param[&quot;baryB&quot;])^2 alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) y &lt;- y1*Ds+y0*(1-Ds) Y &lt;- Y1*Ds+Y0*(1-Ds) # pscore estimation probit.Ds &lt;- glm(Ds~yB, family=binomial(link=&quot;probit&quot;)) pscore &lt;- predict(probit.Ds,type=&quot;response&quot;) # computing weights pscore.weights &lt;- pscore/(1-pscore)*(1-mean(Ds))/mean(Ds) # get rid of weights for the treated pscore.weights[Ds==1] &lt;- 0 # normalize by sum of weights for the untreated pscore.weights &lt;- pscore.weights/sum(pscore.weights) # counterfactual estimation using reweighting: y0.D1.reweighting &lt;- weighted.mean(y[Ds==0],w=pscore.weights[Ds==0]) # TT estimation TT.reweighting &lt;- mean(y[Ds==1])-y0.D1.reweighting return(TT.reweighting) } simuls.reweight.N &lt;- function(N,Nsim,param){ simuls.reweight &lt;- matrix(unlist(lapply(1:Nsim,monte.carlo.reweight,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) colnames(simuls.reweight) &lt;- c(&#39;Reweighting Matching&#39;) return(simuls.reweight) } sf.simuls.reweight.N &lt;- function(N,Nsim,param){ sfInit(parallel=TRUE,cpus=8) sim.reweight &lt;- matrix(unlist(sfLapply(1:Nsim,monte.carlo.reweight,N=N,param=param)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.reweight) &lt;- c(&#39;Reweighting Matching&#39;) return(sim.reweight) } Nsim &lt;- 1000 #Nsim &lt;- 10 #N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) #simuls.reweight &lt;- lapply(N.sample,simuls.reweight.N,Nsim=Nsim,param=param) simuls.reweight&lt;- lapply(N.sample,sf.simuls.reweight.N,Nsim=Nsim,param=param) names(simuls.reweight) &lt;- N.sample Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations): par(mfrow=c(2,2)) for (i in 1:length(simuls.reweight)){ hist(simuls.reweight[[i]][,&#39;Reweighting Matching&#39;],main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^yReweight)),xlim=c(-0.15,0.55)) abline(v=delta.y.tt.com.supp(param),col=&quot;red&quot;) } Figure 5.13: Distribution of the Reweighting Matching estimator over replications of samples of different sizes 5.2.2.4 Doubly robust matching Doubly robust matching combines regression adjusted matching and weighting matching. Its main property is that it is robust to misspecification of the regression functions for the outcomes or for the treatment: even if one of these functions is misspecified, the doubly robust matching estimator will be consistent as long as the other one is correctly specified. TO DO 5.2.3 Estimating precision There are several ways to estimate of the precision of matching estimators. In practice, we end up using the bootstrap for LLR, reweighting and doubly robust matching and to use CLT-based approximations for NNM. This is because of the combination of several factors: The bootstrap is inconsistent for NNM: Abadie and Imbens (2008) show that the bootstrap fails to approximate the distribution of the NNM estimator. The CLT-based formulae for LLR and reweighting matching are in general difficult to compute or take too much time to run, or are attached to specific estimators. The CLT-based formula developped by Abadie and Imbens (2006) for NNM are simple to compute. Here, we are going to first give a sense of the maximum possible precision of matching estimators. Then we will see how this result applies to teh CLT-based formulae for LLR and reweighting matching. We will then describe the CLT-based formulae for NNM. 5.2.3.1 Maxium precision of matching estimators The maximum level of precision that any estimator relying on the matching assumptions can hope to reach is the minimum asymptotic variance that any such estimator cannot get under. The derivation of this bound (called the semiparametric efficiency bound of matching estimators) is due to Hahn (1998). Theorem 5.8 (Efficiency Bound under Conditional Independence) Under Assumption 5.2, we have, for all consistent estimators \\(\\hat{\\Delta^Y_{ATE}}\\) and \\(\\hat{\\Delta^Y_{TT}}\\) of \\(\\Delta^Y_{ATE}\\) and \\(\\Delta^Y_{TT}\\): \\[\\begin{align*} \\asym\\var{\\hat{\\Delta^Y_{ATE}}} &amp; \\geq \\frac{1}{N}\\esp{\\frac{\\var{Y_i^1|X_i}}{\\Pr(D_i=1|X_i)}+\\frac{\\var{Y_i^0|X_i}}{1-\\Pr(D_i=1|X_i)}+(\\Delta^Y_{ATE}(X_i)-\\Delta^Y_{ATE})^2} \\\\ \\asym\\var{\\hat{\\Delta^Y_{TT}}} &amp; \\geq \\frac{1}{N}\\esp{\\frac{\\Pr(D_i=1|X_i)\\var{Y_i^1|X_i}}{\\Pr(D_i=1)}+\\frac{\\Pr(D_i=1|X_i)^2\\var{Y_i^0|X_i}}{\\Pr(D_i=1)(1-\\Pr(D_i=1|X_i))}}\\\\ &amp; \\phantom{\\geq} +\\frac{1}{N}\\esp{\\frac{(\\Delta^Y_{TT}(X_i)-\\Delta^Y_{TT})^2\\Pr(D_i=1|X_i)}{\\Pr(D_i=1)}}. \\end{align*}\\] Proof. See Hahn (1998). Theorem 5.8 enables to compute a lower bound on the variance of any matching estimator. Moreover, if it can be shown that a given estimator reaches the semi-parametric efficiency bound (i.e. is efficient), then Theorem 5.8 enables to compute its precision using a CLT-based approximation (and not only a lower bound). There are thus two key issues with using Theorem 5.8 in practice: Is it the case that our candidate matching estimator is efficient? How can we operationalize the formula in Theorem 5.8? Question 1 is a theoretical question about properties of estimators while question 2 is a practical question. Theorem 5.8 shows that estimating the variance of efficient matching estimators requires to estimate the propensity score, but also two conditional variance terms and the conditional treatment on the treated parameter. Thus Theorem 5.8 requires the estimation of multiple nonparametric functions. It might sometimes be preferable to rey on the bootstrap, if the bootstrap is consistent (which it is when the estimator is efficient, hence the relevance of question 1). 5.2.3.2 Estimating precision of LLR and reweighting matching It is in general believed that LLR and Reweighting Matching estimators are efficient, and thus that they reach the semi-parametric efficiency bound derived by Hahn (1998). The devil is in the details though, since the particular form of the estimators and the conditions imposed on the d.g.p. are crucial for these results to hold. Let’s state the results that hold for the reweighting and LLR matching estimators. Theorem 5.9 (Asymptotic Distribution of Reweighting and LLR Matching) Under Assumption 5.2 and technical conditions made clear in Hahn (1998) and Mammen et al (2016), the Reweighting matching estimator and the LLR matching estimator based on the propensity score of the Average Effect of the Treatment on the Treated are consistent, asymptotically normally distributed and reach the nonparametric efficiency bound. Proof. See Hahn (1998) and Mammen et al (2016). Remark. Mammen et al (2016) only prove the consistency and efficiency of the LLR matching estimator using the propensity score for the ATE. Extension to the TT is assumed here but should be checked rigorously. Remark. Heckman et al (1998) derive the distribution of the LLR Matching estimator based on the propensity score, but their derivation does not seem to reach the semiparametric efficiency bound. More investigation is needed to reconcile this result with the one in Mammen et al (2016). In practice, we do not use CLT-based approximations to estimate the precision of LLR Matching on the propensity score, since these estimators require rather complex computations. We rather rely on the nonparametric bootstrap, we is justified by the existence of the CLT-based results. Remark. Mammen et al (2016) show that the nonparametric bootstrap can be used to estimate the distribution of LLR matching on the propensity score under technical conditions. Example 5.13 Let us see how we can use the bootstrap in our example. Let’s first write a function to generate a bootstrap estimate: # function for the bootstrap of LLR bootstrap.llr.trim &lt;- function(s,y,D,x,t,bw,kernel){ set.seed(s) boot.samp &lt;- sample(N,replace=TRUE) y.boot &lt;- y[boot.samp] D.boot &lt;- D[boot.samp] x.boot &lt;- x[boot.samp] llr.match.trim.boot &lt;- llr.match.trim(y.boot,D.boot,x.boot,t=t,bw=bw,kernel=kernel) return(llr.match.trim.boot) } # function for the bootstrap of Reweighting bootstrap.reweigthing &lt;- function(s,y,D,x){ set.seed(s) boot.samp &lt;- sample(N,replace=TRUE) y.boot &lt;- y[boot.samp] D.boot &lt;- D[boot.samp] x.boot &lt;- x[boot.samp] # pscore estimation probit.Ds &lt;- glm(D.boot~x.boot, family=binomial(link=&quot;probit&quot;)) pscore &lt;- predict(probit.Ds,type=&quot;response&quot;) # computing weights pscore.weights &lt;- pscore/(1-pscore)*(1-mean(D.boot))/mean(D.boot) # get rid of weights for the treated pscore.weights[D.boot==1] &lt;- 0 # normalize by sum of weights for the untreated pscore.weights &lt;- pscore.weights/sum(pscore.weights) # counterfactual estimation using reweighting: y0.D1.reweighting &lt;- weighted.mean(y.boot[D.boot==0],w=pscore.weights[D.boot==0]) # TT estimation TT.reweighting &lt;- mean(y.boot[D.boot==1])-y0.D1.reweighting return(TT.reweighting) } # testing test.boot.llr &lt;- bootstrap.llr.trim(1234,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel) test.boot.reweight &lt;- bootstrap.reweigthing(1234,y=y,D=Ds,x=yB) # parallelized computation of bootstrap sf.boot.llr.N &lt;- function(Nsim,...){ sfInit(parallel=TRUE,cpus=8) sfExport(&#39;llr.match.trim&#39;,&#39;llr&#39;,&#39;dens.fun.point&#39;,&#39;dens.fun&#39;,&#39;com.supp&#39;,&#39;bootstrap.llr.trim&#39;) sim.boot.llr &lt;- matrix(unlist(sfLapply(1:Nsim,bootstrap.llr.trim,...)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.boot.llr) &lt;- c(&#39;BootLLR&#39;) return(sim.boot.llr) } sf.boot.reweight.N &lt;- function(Nsim,...){ sfInit(parallel=TRUE,cpus=8) sim.boot.reweight &lt;- matrix(unlist(sfLapply(1:Nsim,bootstrap.reweighting,...)),nrow=Nsim,ncol=1,byrow=TRUE) sfStop() colnames(sim.boot.reweight) &lt;- c(&#39;BootReweight&#39;) return(sim.boot.reweight) } t &lt;- 0.05 kernel &lt;- &#39;gaussian&#39; N.boot &lt;- 1000 bw &lt;- 0.5 boot.llr &lt;- sapply(1:N.boot,bootstrap.llr.trim,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel) boot.reweight &lt;- sapply(1:N.boot,bootstrap.reweigthing,y=y,D=Ds,x=yB) #boot.llr &lt;- sf.boot.llr.N(Nsim=N.boot,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel) #boot.reweight &lt;- sf.boot.reweight.N(Nsim=N.boot,y=y,D=Ds,x=yB) # sfInit(parallel=TRUE,cpus=8) # sfExport(&#39;llr.match.trim&#39;,&#39;llr&#39;,&#39;dens.fun.point&#39;,&#39;dens.fun&#39;,&#39;com.supp&#39;,&#39;bootstrap.llr.trim&#39;,&#39;y&#39;,&#39;Ds&#39;,&#39;yB&#39;) # sim.boot.reweight &lt;- sfLapply(1:2,bootstrap.llr.trim,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel) # sim.boot.reweight &lt;- lapply(1:2,bootstrap.llr.trim,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel) # sfStop() Let’s now compute the precision estimators: delta &lt;- 0.99 precision.llr &lt;- function(k){ return(2*quantile(abs(simuls.llr[[k]][,&#39;LLR&#39;]-delta.y.tt.com.supp(param)),probs=c(delta))) } precision.llr.trim &lt;- function(k){ return(2*quantile(abs(simuls.llr.trim[[k]][,&#39;LLR Trim&#39;]-delta.y.tt.com.supp(param)),probs=c(delta))) } precision.reweighting &lt;- function(k){ return(2*quantile(abs(simuls.reweight[[k]][,&#39;Reweighting Matching&#39;]-delta.y.tt.com.supp(param)),probs=c(delta))) } precision.nnm &lt;- function(k){ return(2*quantile(abs(simuls.nnm[[k]][,&#39;NNM&#39;]-delta.y.tt.com.supp(param)),probs=c(delta))) } precision.nnm.100 &lt;- precision.nnm(1) precision.nnm.1000 &lt;- precision.nnm(2) precision.llr.100 &lt;- precision.llr(1) precision.llr.1000 &lt;- precision.llr(2) precision.llr.trim.100 &lt;- precision.llr.trim(1) precision.llr.trim.1000 &lt;- precision.llr.trim(2) precision.reweighting.100 &lt;- precision.reweighting(1) precision.reweighting.1000 &lt;- precision.reweighting(2) precision.llr.trim.boot.1000 &lt;- 2*quantile(abs(boot.llr-delta.y.tt.com.supp(param)),probs=c(delta)) precision.reweighting.boot.1000 &lt;- 2*quantile(abs(boot.reweight-delta.y.tt.com.supp(param)),probs=c(delta)) With 100 obs, the true precision of LLR Matching is 0.61, while it is of 4.81 with trimming and of 0.9 with reweighting. With 1000 observation, the true precision of LLR Matching without trimming is 0.15 and with trimming is 0.3 and the precision of reweighting matching is 0.43. Using the bootstrap with 1000 replications, the estimated precision of LLR with trimming is 0.14 while the estimated precision of reweighting matching is 0.86. 5.2.3.3 Estimating the precision of Nearest Neighbour Matching Abadie and Imbens (2006) propose a variance estimator for Nearest Neighbor Matching based on the CLT. But before that, Abadie and Imbens (2006) prove several fundamental results on the properties of NNM. They show that NNM is not \\(\\sqrt{N}\\)-consistent for ATE nor for TT. It means that, in general, NNM is affected by a bias term that is larger than \\(\\frac{1}{\\sqrt{N}}\\) even when sample size grows large. Fortunately, Abadie and Imbens (2006) show that this bias term goes to zero as sample size grows large, so that NNM is always consistent. They also show that, under reasonable conditions, this bias term goes to zero faster than \\(\\sqrt{N}\\) when the number of untreated units is much larger than the number of treated units. It means that under these conditions, this term can be ignored and the distribution of NNM converges to a standard normal at a \\(\\sqrt{N}\\) rate. They also show that the NNM estimator does not reach the semi-parametric efficiency bound of Theorem 5.8, but they also that the difference between the two variances is smaller than \\(\\frac{1}{2M}\\) where \\(M\\) is the number of matches used. With NNM on one neighbor, the increase in variance relative to the most efficient estimator is of at most 50%, while with 5 neighbors, the increase in asymptotic variance is of at most 10%. Finally, Abadie and Imbens (2008) show that even when NNM is asymptotically normal and \\(\\sqrt{N}\\)-consistent, the bootstrap might fail to approximate its distribution. Note that the bootstrap recovers its value if we allow the number of matched neighbors to increase with sample size. So, now, what is the CLT-based estimator for the variance of NNM proposed by Abadie and Imbens (2006)? It is a clever use of the matching method to compute a variance estilmate using pairwise comparisons. Note that this estimator is correct only when NNM is asymptotically normal and \\(\\sqrt{N}\\)-consistent, so when there are many more control than treated observations, or when the number of neighbors is large enough. Let us first derive the asymptotic distribution of the NNM estimator. We need to assume something about the data generating process (in general that the data are i.i.d.). The assumption needed for NNM to be consistent is slightly more involved and requires restrictions on the ratio of treated to untreated observations \\(\\frac{N_1}{N_0}\\): Hypothesis 5.8 (i.i.d. distribution for matching) Conditional on \\(D_i=d\\), the sample consists of independent draws from \\(Y,X|D=d\\), \\(d\\in\\left\\{0,1\\right\\}\\). For some \\(r\\geq 1\\), \\(\\frac{N^r_1}{N_0}\\rightarrow \\theta\\), with \\(0&lt;\\theta&lt;\\infty\\). Theorem 5.10 (Asymptotic Distribution of NNM) Under Assumptions 5.2, 5.7, 5.8 and Assumption 4 in Abadie and Imbens (2006), we have: \\[\\begin{align*} \\sqrt{N_1}(\\hat{\\Delta}^Y_{NNM}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,V^{E,TT}+V^{\\Delta^Y_{TT}(X)}\\right), \\end{align*}\\] where: \\[\\begin{align*} V^{E,TT} &amp; = \\frac{1}{N_1}\\sum_{i=1}^N\\left(D_i-(1-D_i)\\frac{\\mathcal{K}_M(i)}{M}\\right)^2\\var{Y_i|D_i,X_i}\\\\ V^{\\Delta^Y_{TT}(X)} &amp; = \\esp{(\\Delta^Y_{TT}(X_i)-\\Delta^Y_{TT})^2|D_i=1}. \\end{align*}\\] Proof. See Corollary 1 in Abadie and Imbens (2006). Remark. The general formula for the precision of the NNM estimator is close to all the same estimators we have seen so far: its is a sum of the variance of the outcome conditional on \\(X_i\\) among the treated and among the untreated weighted by their relative importance in the estimation. In addition, a term reflecting the variance of treatment effects due to \\(X_i\\) has appeared. The key to Abadie and Imbens (2006) estimator is to find a way to estimate \\(\\var{Y_i|D_i,X_i}\\). We could use the residuals from linear regressions or from non-parametric regressions, but that would be extremely burdensome. Abadie and Imbens (2006) propose a very clever trick to simplify the estimation of \\(\\var{Y_i|D_i,X_i}\\) by using a variation of the matching estimator. Define \\(l_m(i)\\) the \\(m^{\\text{th}}\\) closest unit to \\(i\\) among the units with the same value for the treatment indicator. Abadie and Imbens (2006)’s estimator for \\(\\var{Y_i|D_i,X_i}\\) is: \\[\\begin{align*} \\hatvar{Y_i|D_i,X_i} &amp; = \\frac{J}{J+1}\\left(Y_i-\\frac{1}{J}\\sum_{m=1}^JY_{l_j(i)}\\right)^2. \\end{align*}\\] Abadie and Imbens (2006) then combine this estimator with an estimator for \\(V^{\\Delta^Y_{TT}(X)}\\) which has to be corrected by the size of the variance of outcomes given \\(X_i\\). Eventually, after some algebra, we have: \\[\\begin{align*} \\hat{V}^{E,TT}+\\hat{V}^{\\Delta^Y_{TT}(X)} &amp; = \\frac{1}{N_1}\\sum_{i:D_i=1}\\left(Y_i-\\frac{1}{M}\\sum_{j\\in\\mathcal{J}_M(i)}Y_j-\\Delta^Y_{TT}\\right)^2 \\\\ &amp; \\phantom{=}+\\frac{1}{N_1}\\sum_{i=1}^N(1-D_i)\\left(\\frac{\\mathcal{K}_M(i)(\\mathcal{K}_M(i)-1)}{M^2}\\right)\\hatvar{Y_i|D_i,X_i}. \\end{align*}\\] Theorem 7 in Abadie and Imbens (2006) shows that this is a consistent estimator of the variance terms of NNM under the same assumptions as the one stated in Theorem 5.10. Example 5.14 Let us see how the Abadie and Imbens (2006)’estimator for the precision of NNM performs in our dataset. Unfortunately, MatchIt does not include this estimator. We thus have to resort to the Matching package which relies on these estiamtors by default. Let’s go: # Estimating ATT and its variance using Matching: # M=1 NNM.Match.yB.1 &lt;- Match(y,Ds,yB,estimand=&quot;ATT&quot;,M=1,replace=TRUE,CommonSupport=FALSE,Weight=1,Var.calc=1,sample=FALSE) NNM.Match.pscore.1 &lt;- Match(y,Ds,pscore,estimand=&quot;ATT&quot;,M=1,replace=TRUE,CommonSupport=FALSE,Weight=1,Var.calc=1,sample=FALSE) # M=5 NNM.Match.yB.5 &lt;- Match(y,Ds,yB,estimand=&quot;ATT&quot;,M=5,replace=TRUE,CommonSupport=FALSE,Weight=1,Var.calc=5,sample=FALSE) NNM.Match.pscore.5 &lt;- Match(y,Ds,pscore,estimand=&quot;ATT&quot;,M=5,replace=TRUE,CommonSupport=FALSE,Weight=1,Var.calc=5,sample=FALSE) # precision se.NNM.Match.yB.1 &lt;- NNM.Match.yB.1$se se.NNM.Match.pscore.1 &lt;- NNM.Match.pscore.1$se se.NNM.Match.yB.5 &lt;- NNM.Match.yB.5$se se.NNM.Match.pscore.5 &lt;- NNM.Match.pscore.5$se The estimated precision of matching on the propensity score with one neighbor is equal to 0.152 while the true precision stemming from the simulations is 0.211. 5.3 Imputation methods Generalized fixed effects methods "],["threats.html", "Chapter 6 Threats to the validity of Causal Inference 6.1 Threats to internal validity 6.2 Threats to the measurement of precision 6.3 Threats to external validity", " Chapter 6 Threats to the validity of Causal Inference In this final section, I want to discuss more generally about the possible threats to the validity of methods of causaliInference. Most of these threast stem from the fact that, much as particles do when physicists try to measure their position and velocity, human beings react to our experimental devices in sometimes unexpected ways. It is classical to make a disctinction between two threat and one specific set of problems: Threats to internal validity: these are the threats that vitiate the result of the experiment in the sample at hand, even when only looking at the Intention to Treat Effect. They also include threats to the exclusion restriction assumption. Threats to the measurement of precision Threats to external validity: these are the threats that make the extension of the results from one experiment to the same population at another period of to another population dubious. Ethical and political issues 6.1 Threats to internal validity Threats to internal validity are the problems that might make the results of the experiment not measure the effect of the treatment of interest in the ongoing sample. Let’s examine the most important ones in turn. 6.1.1 Survey bias There is survey bias if the mere fact of having to answer to a survey alters the outcomes of the surveyed individuals. For example, administering a health survey might make you pay more attention to your health and as a consequence improve it. Survey bias alters the measured impact of the treatment since it alters the behavior of the control group. As a result, the estimated effect of the treatment might be biased. Remark. Note that survey bias might affect all the estimators presented in this book, including natural experimental and observational estimators. All estimators rely on measuring something and thus might be affected by survey bias. Actually, RCTs might be able to avoid survey bias whereas other methods generally cannot. Indeed, survey bias generally occurs with repeated sampling: surveying at baseline might trigger a response by individuals, and thus bias the measurement at the end of the experiment. RCTs can avoid this issue by bypassing the baseline survey, or at least collecting baseline information on a subsample of the experimental sample. Other estimators that might be able to avoid this problem are DID, where the repeated cross section estimator eschews survey bias, and RDD and IV, which generally use only cross sectional information. Matching in general requires observations for the same individual over time, so that avoiding possible survey bias is impossible. Remark. Do we have evidence of the existence and extent of survey bias? A paper by Zwane et al (2010) shows that there is extensive survey bias in 2 out of 5 experiments. In the first example, the authors show that being surveyed more frequently (every two weeks vs every six months) for the extent of diarrhea prevalence and use of chlorine decontamination increases the use of chlorine, decreases diarrhea prevalence and decreases the effect of a spring protection program, to the extent that it becomes null in the frequent survey sample, whereas it is large and positive in the infrequent survey sample. The authors speculate that the frequent surveys act as a reminder for chlorinating water, which is a substitute for well protection. In a second experiment, the authors randomly run a baseline survey on 80% of the households tha would be later included in a RCT where health insurance would be offered at randomly selected prices. The baseline survey includes questions about health and health insurance, but does not mention the particular product that will be offered later. The authors find a small imprecise increase in insurance take up in the group having undergone the baseline survey (5% \\(\\pm\\) 6.8), non significant at usual levels of confidence. They also find no evidence of impact of the baseline survey on the response of households to the price incentive. In a third experiment, the authors report on the effect of being surveyed with a survey continaing questions on health status and health insurance on the subsequent adoption of health insurance. They find evidence that the baseline survey has increased the adoption of health insurance by 6.7% \\(\\pm\\) 6.6, from a mean of 26.4% in the control group. The effect dissipates over time though and becomes much smaller 15 to 18 months after the treatment. In a fourth experiment, the authors randomly selected 60% of targeted households to be included in a baseline survey including wuestions on household finances and borrowing opportunities. The sample was then prospected by a micro-credit firm. The aurhors do not find higher micro-credit take-up among households surveyed at baseline (-0.009 \\(\\pm\\) 0.048, with a baseline take up rate of 0.166). Note that the estimates are imprecise though. In a fifth experiment, the authors randomly assigned the order in which households had to be contacted for a baseline survey, along with a fixed number of households to be sruveyed by village. The survey contained questions about finance and microfinancne use. Also, the survey explicitely mentioned that househods were interviewed because they were patrons of a micro-finance provider. Sunbsequently, households had to decide whether or not to renew their loans from the micro-finance provider. The authors do not evidence of an effect of being surveyed on the subsequent decision to renew the loan (-0.005 \\(\\pm\\) 0.026 from a baseline rate of 0.769). 6.1.2 Experimenter bias 6.1.3 Substitution bias 6.1.4 Diffusion bias 6.2 Threats to the measurement of precision 6.2.1 Insufficient precision 6.2.2 Clustering 6.3 Threats to external validity 6.3.1 Randomization bias 6.3.2 Equilibrium effects 6.3.3 Context effects 6.3.4 Site selection bias 6.3.5 Publication bias 6.3.6 Ethical and political issues "],["Power.html", "Chapter 7 Power Analysis 7.1 Basics of traditional power analysis using test statistics 7.2 Traditional power analysis in practice 7.3 Limitations of and alternatives to traditional power analysis", " Chapter 7 Power Analysis In this chapter, we are going to study how to choose the size of our sample and how to gauge the size of sampling noise before conducting a study. This is important because we might decide not to conduct a study if it is not going to bring us precise enough information on the impact in view of its anticipated size. In practice, there are two ways to run a power analysis: Using test statistics (power study per se) Gauging sampling noise or choosing sample size to reach a given sampling noise Let me first start by describing the usual approach before moving to my more personal proposal. 7.1 Basics of traditional power analysis using test statistics Traditional power analysis is based on test-statistics and p-values. Intuitively, the approach to power analysis based on test statistics computes the sample size required so that a test of a given size \\(\\alpha\\) (in general \\(\\alpha=0.05\\)) can reject the null of a true effect \\(\\beta_A\\) in a pre-specified proportion of samples \\(\\kappa\\) (in general \\(\\kappa=0.8\\)). \\(\\kappa\\) is called the power of the test and \\(\\beta_A\\) the Minimum Detectable Effect (MDE). Let’s define these quantities more formally: Here, we first define power, then minimum detectable effect then the minimum required sample size. 7.1.1 Power Definition 7.1 (Power) Power \\(\\kappa\\) is the probability of rejecting the null hypothesis of a negative or null (for a one-sided test) or null (for a two-sided test) average treatment effect when the true effect is of at least \\(\\beta_A\\) applying a test of size \\(\\alpha\\) to an estimator \\(\\hat{E}\\) with a sample of size \\(N\\). \\(\\beta_A\\) is called the Minimum Detectable Effect (MDE). for a One-Sided Test: \\(H_0\\): \\(E\\leq0\\) \\(H_A\\): \\(E=\\beta_A&gt;0\\) For a Two-Sided Test: \\(H_0\\): \\(E=0\\) \\(H_A\\): \\(E=\\beta_A\\neq0\\) Now, if we can assume that the distribution of our estimator \\(\\hat{E}\\) can be well approximated by a normal distribution (which is the case of most estimators we have seen so far) and that moreover they are \\(\\sqrt{N}\\)-consistent (that is that their variance is of the same magnitude as \\(\\sqrt{N}\\)), we can derive useful formulae for the power parameter, the MDE and the minimum sample size. Let’s first state our assumption: Hypothesis 7.1 (Asymptotically Normal Estimator) We assume that the estimator \\(\\hat{E}\\) is such that there exists a constant (independent of \\(N\\)) \\(C(\\hat{E})\\) such that: \\[\\begin{align*} \\lim_{N\\rightarrow\\infty}\\Pr\\left(\\frac{\\hat{E}-E}{\\sqrt{\\var{\\hat{E}}}}\\leq u\\right) &amp; = \\Phi\\left(u\\right), \\end{align*}\\] with \\(\\var{\\hat{E}}=\\frac{C(\\hat{E})}{N}\\). Equipped with Assumption 7.1, we can now derive a closed-form formula for power \\(\\kappa\\): Theorem 7.1 (Power with an Asymptotically Normal Estimator) With \\(\\hat{E}\\) complying with Assumption 7.1, and with \\(\\beta_A&gt;0\\), we have: For a One-Sided Test: \\(H_0\\): \\(E\\leq0\\) \\(H_A\\): \\(E=\\beta_A&gt;0\\) \\[\\begin{align*} \\kappa_{\\text{oneside}} &amp; = \\Phi\\left(\\frac{\\beta_A}{\\sqrt{\\var{\\hat{E}}}}-\\Phi^{-1}\\left(1-\\alpha\\right)\\right), \\end{align*}\\] For a Two-Sided Test: \\(H_0\\): \\(E=0\\) \\(H_A\\): \\(E=\\beta_A\\neq0\\) \\[\\begin{align*} \\kappa_{\\text{twoside}} &amp; \\approx \\Phi\\left(\\frac{\\beta_A}{\\sqrt{\\var{\\hat{E}}}}-\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right). \\end{align*}\\] Proof. Let us start with a one-sided test first. We want to build a test statistic \\(t\\) such that, under \\(H_0\\), \\(\\Pr(\\hat{E}\\geq t)=\\alpha\\). Under \\(H_0\\) and using Assumption 7.1, we have: \\[\\begin{align*} \\Pr(\\hat{E}\\geq t) &amp; = \\Pr\\left(\\frac{\\hat{E}-0}{\\sqrt{\\var{\\hat{E}}}}\\geq\\frac{t-0}{\\sqrt{\\var{\\hat{E}}}}\\right) \\approx 1-\\Phi\\left(\\frac{t}{\\sqrt{\\var{\\hat{E}}}}\\right) \\end{align*}\\] As a consequence of \\(\\Pr(\\hat{E}\\geq t)=\\alpha\\), we have: \\[\\begin{align*} t &amp; \\approx\\Phi^{-1}\\left(1-\\alpha\\right)\\sqrt{\\var{\\hat{E}}}. \\end{align*}\\] Power is \\(\\Pr(\\hat{E}\\geq t)\\) under \\(H_A\\). Using Assumption 7.1 again: \\[\\begin{align*} \\Pr(\\hat{E}\\geq t) &amp; = \\Pr\\left(\\frac{\\hat{E}-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\geq\\frac{t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right) \\approx 1-\\Phi\\left(\\frac{t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right) = \\Phi\\left(\\frac{\\beta_A-t}{\\sqrt{\\var{\\hat{E}}}}\\right), \\end{align*}\\] which proves the first part of the result. With a two-sided test, we want a test statistic \\(t\\) such that, under \\(H_0\\), \\(\\Pr(\\hat{E}\\leq -t\\lor\\hat{E}\\geq t)=\\alpha\\). Because the events are disjoint, under \\(H_0\\) and using Assumption 7.1, we have: \\[\\begin{align*} \\Pr(\\hat{E}\\leq -t\\lor\\hat{E}\\geq t) &amp; = \\Pr(\\hat{E}\\leq -t) + \\Pr(\\hat{E}\\geq t) \\\\ &amp; = \\Pr\\left(\\frac{\\hat{E}-0}{\\sqrt{\\var{\\hat{E}}}}\\leq\\frac{-t-0}{\\sqrt{\\var{\\hat{E}}}}\\right)+ \\Pr\\left(\\frac{\\hat{E}-0}{\\sqrt{\\var{\\hat{E}}}}\\geq\\frac{t-0}{\\sqrt{\\var{\\hat{E}}}}\\right) \\\\ &amp; \\approx \\Phi\\left(-\\frac{t}{\\sqrt{\\var{\\hat{E}}}}\\right) + 1-\\Phi\\left(\\frac{t}{\\sqrt{\\var{\\hat{E}}}}\\right)\\\\ &amp; = 2\\left(1-\\Phi\\left(\\frac{t}{\\sqrt{\\var{\\hat{E}}}}\\right)\\right), \\end{align*}\\] where the last equality uses the symmetry of the normal distribution. As a consequence of \\(\\Pr(\\hat{E}\\leq -t\\lor\\hat{E}\\geq t)=\\alpha\\), we have: \\[\\begin{align*} t &amp; \\approx\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\sqrt{\\var{\\hat{E}}}. \\end{align*}\\] Power is \\(\\Pr(\\hat{E}\\leq -t\\lor\\hat{E}\\geq t)\\) under \\(H_A\\). Using Assumption 7.1 and the fact that the two events are disjoint again: \\[\\begin{align*} \\Pr(\\hat{E}\\leq -t\\lor\\hat{E}\\geq t) &amp; = \\Pr(\\hat{E}\\leq -t) + \\Pr(\\hat{E}\\geq t) \\\\ &amp; = \\Pr\\left(\\frac{\\hat{E}-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\leq\\frac{-t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right) + \\Pr\\left(\\frac{\\hat{E}-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\geq\\frac{t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right) \\\\ &amp; \\approx \\Phi\\left(\\frac{-t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right) + \\Phi\\left(\\frac{t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right). \\end{align*}\\] When \\(\\beta_A\\) is positive, the first part of the power formula is negligible with respect to the second part. Hence the result. Example 7.1 Let us see how these notions work in our example. Let us first write functions to compute the power according to Theorem 7.1: power &lt;- function(betaA,alpha,varE){ return(pnorm(betaA/sqrt(varE)-qnorm(1-alpha))) } power.twoside &lt;- function(betaA,alpha,varE){ return(pnorm(-betaA/sqrt(varE)-qnorm(1-alpha/2))+pnorm(betaA/sqrt(varE)-qnorm(1-alpha/2))) } Let us now choose values for the parameters. For the variance, we are going to choose the Monte Carlo estimate of the variance of the WW estimator in a Brute Force design that we have studied in Chapter 3 and \\(\\beta_A=0.2\\). param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) alpha &lt;- 0.05 betaA &lt;- 0.2 varE &lt;- var(simuls.brute.force.ww[[&#39;1000&#39;]][,&#39;WW&#39;]) Let us first plot the distributions under the null and under the alternative hypothesis: hist(simuls.brute.force.ww[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.ate(param)+betaA,breaks=30,main=&#39;N=1000&#39;,xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55),probability=T) curve(dnorm(x, mean=betaA, sd=sqrt(varE)),col=&quot;darkblue&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) curve(dnorm(x, mean=0, sd=sqrt(varE)),col=&quot;green&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) abline(v=betaA,col=&quot;red&quot;) abline(v=qnorm(1-alpha)*sqrt(varE),col=&quot;green&quot;) abline(v=qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=-qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=0,col=&quot;green&quot;) text(x=c(qnorm(1-alpha)*sqrt(varE),qnorm(1-alpha/2)*sqrt(varE)),y=c(adj+3,adj+4),labels=c(&#39;t_oneside&#39;,&#39;t_twoside&#39;),pos=c(2,2),col=c(&#39;green&#39;,&#39;green&#39;),lty=c(lty.obs,lty.unobs)) Figure 7.1: Power with \\(\\beta_A=0.2\\) Figure 7.1 shows the distribution of \\(\\hat{E}\\) under the null in green and the distribution under the alternativein blue. In black is the distribution stemming from the Monte Carlo simulations recentered at \\(\\beta_A=0.2\\). All of these distributions have the same shape (they are normal with variance 0.003) and differ only by their mean. Under the null of no effect, \\(\\hat{E}\\) would be distributed as the green curve, centered at \\(0\\). The green continuous vertical line materializes the threshold \\(t_{\\text{oneside}}=\\Phi^{-1}\\left(1-\\alpha\\right)\\sqrt{\\var{\\hat{E}}}\\) of the one-sided test (as defined in the proof of Theorem 7.1). The green discontinuous vertical lines materialize the thresholds \\(t_{\\text{twoside}}=\\pm\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\sqrt{\\var{\\hat{E}}}\\) of the two-sided test (as defined in the proof of Theorem 7.1). We are more accustomed to seeing these thresholds standardized by \\(\\sqrt{\\var{\\hat{E}}}\\). I find it simpler to visualize their nonstandardized versions. It enables to position the test statistics on the actual distribution of \\(\\hat{E}\\) and to compare their values with the values of the parameter estimates. Note that you can easily go back between the classical standardized thresholds for the test statistics and the nonstandardized ones by dividing and multiplying by \\(\\sqrt{\\var{\\hat{E}}}\\). As a result, we find that the standardized threshold for the one sided test, \\(\\frac{t_{\\text{oneside}}}{\\sqrt{\\var{\\hat{E}}}}=\\Phi^{-1}\\left(1-\\alpha\\right)\\), is equal to 1.64, for \\(\\alpha=\\) 0.05. For the two-sided test, the absolute value of the standardized threshold is equal to \\(\\left|\\frac{t_{\\text{twoside}}}{\\sqrt{\\var{\\hat{E}}}}\\right|=\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\), which is equal to 1.96, for \\(\\alpha=\\) 0.05. You probably already know these threshold values, especially the second one, as the classical threshold for 5% statistical significance in t-tests for the null of an estimated parameter being zero. What we are doing here is express the thresholds of the test statistics as multiples of the standard error of the estimated parameter. For a one-sided test, we consider as statistically significant an estimated effect that is 1.64 times larger than its standard error, and for a two-sided test, an estimated effect whose larger in absolute value than 1.96 its standard error. Because the distribution of \\(\\hat{E}\\) is normal, under Assumption 7.1, the probability that the value of \\(\\hat{E}\\) falls above these thresholds under the null is equal to \\(\\alpha=\\) 0.05. More precisely, for the one sided test, the probability that \\(\\hat{E}\\) falls above \\(t_{\\text{oneside}}\\) under the null is 5%. For the two-sided test, it is the probability that \\(\\hat{E}\\) falls above \\(t_{\\text{twoside}}\\) or below \\(-t_{\\text{twoside}}\\) under the null that is equal to 5%. Or, stated otherwise, it is the probability that \\(|\\hat{E}|&gt;t_{\\text{twoside}}\\) which is equal to 5% under the null for the two-sided test. In practice, with our current choice of parameter values (especially the variance of \\(\\hat{E}\\)), we have \\(t_{\\text{oneside}}=\\) 0.09 and \\(t_{\\text{twoside}}=\\) 0.11. If the estimated treatment effect falls above these threshold values, a one-sided and a two-sided test respectively will find that these effects are statistically significantly different from zero at 5%. Power computation does not stop there. It asks the following question: if the true value of \\(E\\) is actually \\(E=\\beta_A\\), what is the probability that our estimator \\(\\hat{E}\\) will fall above \\(t_{\\text{oneside}}\\) or \\(t_{\\text{twoside}}\\)? Before going further, note that if \\(\\beta_A&gt;0\\) and \\(\\var{\\hat{E}}\\) is not too large, the probability that \\(\\hat{E}\\) falls below \\(-t_{\\text{twoside}}\\) under the alternative hypothesis is negligible. It is materialized on Figure 7.1 as the area under the the portion of the blue curve below the lower discontinuous vertical green line positioned at \\(-t_{\\text{twoside}}=\\) -0.11. It is obviously very small. We know from Assumption 7.1 that this probability is equal to \\(\\Pr(\\hat{E}\\leq -t_{\\text{twoside}})=\\Phi\\left(\\frac{-t_{\\text{twoside}}-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right)=\\) 1.2224593^{-8}. So now, what is the probability that \\(\\hat{E}\\) falls above \\(t_{\\text{oneside}}\\) or \\(t_{\\text{twoside}}\\) under the assumption that \\(E=\\beta_A&gt;0\\)? Intuitively, it is the area under the portion of the blue curve which is above the continuous green vertical line positioned at \\(t_{\\text{oneside}}=\\) 0.09 or above the discontinuous green vertical line positioned at \\(t_{\\text{twoside}}=\\) 0.11. Because we know that \\(\\hat{E}\\) follows a normal with mean \\(\\beta_A\\) and variance \\(\\var{\\hat{E}}\\) under the alternative, we can compute these quantities as equal to \\(\\kappa_{t}=1-\\Phi\\left(\\frac{t-\\beta_A}{\\sqrt{\\var{\\hat{E}}}}\\right)=\\Phi\\left(\\frac{\\beta_A-t}{\\sqrt{\\var{\\hat{E}}}}\\right)\\), for \\(t\\in\\left\\{\\text{oneside},\\text{twoside}\\right\\}\\). Note that using the formulae for \\(t_{\\text{oneside}}\\) and \\(t_{\\text{twoside}}\\) yields the results in Theorem 7.1. In practice, we have \\(\\kappa_{\\text{oneside}}=\\) 0.98 and \\(\\kappa_{\\text{twoside}}=\\) 0.95. What would happen to power if \\(\\beta_A\\) was lower? For example, what if \\(\\beta_A=0.1\\)? betaA &lt;- 0.1 hist(simuls.brute.force.ww[[&#39;1000&#39;]][,&#39;WW&#39;]-delta.y.ate(param)+betaA,breaks=30,main=&#39;N=1000&#39;,xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55),probability=T) curve(dnorm(x, mean=betaA, sd=sqrt(varE)),col=&quot;darkblue&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) curve(dnorm(x, mean=0, sd=sqrt(varE)),col=&quot;green&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) abline(v=betaA,col=&quot;red&quot;) abline(v=qnorm(1-alpha)*sqrt(varE),col=&quot;green&quot;) abline(v=qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=-qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=0,col=&quot;green&quot;) text(x=c(qnorm(1-alpha)*sqrt(varE),qnorm(1-alpha/2)*sqrt(varE)),y=c(adj+3,adj+4),labels=c(&#39;t_oneside&#39;,&#39;t_twoside&#39;),pos=c(2,2),col=c(&#39;green&#39;,&#39;green&#39;),lty=c(lty.obs,lty.unobs)) Figure 7.2: Power with \\(\\beta_A=0.1\\) Figure 7.2 shows what would happen with \\(\\beta_A=0.1\\). It becomes much harder to tell the green curve from the blue curve. As a consequence, power decreases, since the portion of the blue curve located below the thresholds increases. It is a consequence less likely that a t-test will reject the assumption that the treatment effect is zero, even when it is not zero but equal to \\(0.1\\). How less likely? Well, power is now equal to \\(\\kappa_{\\text{oneside}}=\\) 0.57 and \\(\\kappa_{\\text{twoside}}=\\) 0.44. What would happen now if our estimator was way more precise? For example, what would happen if we could reach the precision of the With/Without estimator with a sample size of \\(N=10000\\) instead of \\(N=1000\\) as we have assumed up to now? betaA &lt;- 0.2 varE.10000 &lt;- var(simuls.brute.force.ww[[&#39;10000&#39;]][,&#39;WW&#39;]) hist(simuls.brute.force.ww[[&#39;10000&#39;]][,&#39;WW&#39;]-delta.y.ate(param)+betaA,breaks=30,main=&#39;N=10000&#39;,xlab=expression(hat(Delta^yWW)),xlim=c(-0.15,0.55),probability=T) curve(dnorm(x, mean=betaA, sd=sqrt(varE)),col=&quot;darkblue&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) curve(dnorm(x, mean=betaA, sd=sqrt(varE.10000)),col=&quot;darkblue&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) curve(dnorm(x, mean=0, sd=sqrt(varE)),col=&quot;green&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) curve(dnorm(x, mean=0, sd=sqrt(varE.10000)),col=&quot;green&quot;, lwd=2, add=TRUE, yaxt=&quot;n&quot;) abline(v=betaA,col=&quot;red&quot;) abline(v=qnorm(1-alpha)*sqrt(varE),col=&quot;green&quot;) abline(v=qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=-qnorm(1-alpha/2)*sqrt(varE),col=&quot;green&quot;,lty=lty.unobs) abline(v=qnorm(1-alpha)*sqrt(varE.10000),col=&quot;green&quot;) abline(v=qnorm(1-alpha/2)*sqrt(varE.10000),col=&quot;green&quot;,lty=lty.unobs) abline(v=-qnorm(1-alpha/2)*sqrt(varE.10000),col=&quot;green&quot;,lty=lty.unobs) abline(v=0,col=&quot;green&quot;) text(x=c(qnorm(1-alpha)*sqrt(varE),qnorm(1-alpha/2)*sqrt(varE)),y=c(adj+3,adj+4),labels=c(&#39;t_oneside&#39;,&#39;t_twoside&#39;),pos=c(2,2),col=c(&#39;green&#39;,&#39;green&#39;),lty=c(lty.obs,lty.unobs)) Figure 7.3: Power with \\(N=10000\\) Figure 7.3 shows what would happen with \\(\\beta_A=0.2\\) and \\(N=10000\\). There are two effects of increased precision on power. First, the blue curve is thinner, which means that less of its area lies before the thresholds of the test statisics. Second, the green curve is also thinner, which means that the threshold are smaller. With \\(N=10000\\), \\(t_{\\text{oneside}}=\\) 0.029 and \\(t_{\\text{twoside}}=\\) 0.034. As a consequence, power increases sharply with \\(N=10000\\). For \\(\\beta_A=0.2\\), power is now \\(\\kappa_{\\text{oneside}}=\\) 1 and \\(\\kappa_{\\text{twoside}}=\\) 1. For \\(\\beta_A=0.1\\), power is now \\(\\kappa_{\\text{oneside}}=\\) 1 and \\(\\kappa_{\\text{twoside}}=\\) 1. Finally, let us see how power changes with \\(\\var{\\hat{E}}\\) (through sample size), \\(\\beta_A\\) and \\(\\alpha\\). Let us first run some simulations: varE.N &lt;- c(var(simuls.brute.force.ww[[&#39;100&#39;]][,&#39;WW&#39;]),var(simuls.brute.force.ww[[&#39;1000&#39;]][,&#39;WW&#39;]),var(simuls.brute.force.ww[[&#39;10000&#39;]][,&#39;WW&#39;]),var(simuls.brute.force.ww[[4]][,&#39;WW&#39;])) alpha &lt;- 0.05 betaA &lt;- 0.2 power.N.05.02 &lt;- sapply(varE.N,power,alpha=alpha,betaA=betaA) power.N.twoside.05.02 &lt;- sapply(varE.N,power.twoside,alpha=alpha,betaA=betaA) betaA &lt;- 0.1 power.N.05.01 &lt;- sapply(varE.N,power,alpha=alpha,betaA=betaA) power.N.twoside.05.01 &lt;- sapply(varE.N,power.twoside,alpha=alpha,betaA=betaA) alpha &lt;- 0.01 power.N.01.01 &lt;- sapply(varE.N,power,alpha=alpha,betaA=betaA) power.N.twoside.01.01 &lt;- sapply(varE.N,power.twoside,alpha=alpha,betaA=betaA) betaA &lt;- 0.2 power.N.01.02 &lt;- sapply(varE.N,power,alpha=alpha,betaA=betaA) power.N.twoside.01.02 &lt;- sapply(varE.N,power.twoside,alpha=alpha,betaA=betaA) N.sample &lt;- c(100,1000,10000,100000) power.sample &lt;- data.frame(&quot;N&quot;=rep(N.sample,8),&quot;Power&quot;=c(power.N.05.02,power.N.twoside.05.02,power.N.05.01,power.N.twoside.05.01,power.N.01.01,power.N.twoside.01.01,power.N.01.02,power.N.twoside.01.02)) colnames(power.sample) &lt;- c(&#39;N&#39;,&#39;Power&#39;) power.sample$Test &lt;- rep(c(rep(&#39;One-sided&#39;,length(N.sample)),rep(&#39;Two-sided&#39;,length(N.sample))),4) power.sample$betaA &lt;- c(rep(0.2,2*length(N.sample)),rep(0.1,4*length(N.sample)),rep(0.2,2*length(N.sample))) power.sample$alpha &lt;- c(rep(0.05,4*length(N.sample)),rep(0.01,4*length(N.sample))) Let us now plot the resulting estimates: ggplot(power.sample, aes(x=as.factor(N), y=Power, fill=Test)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;) + xlab(&quot;Sample Size&quot;) + theme_bw()+ facet_grid(betaA~alpha) Figure 7.4: Power and Sample Size as a function of \\(\\alpha\\) (left vs right) and \\(\\beta_A\\) (top vs bottom) Figure 7.4 shows that sample size is a key determinant of power, but that \\(\\alpha\\) and \\(\\beta_A\\) are as well. For example, with \\(\\beta_A=0.1\\) and \\(\\alpha=0.01\\), \\(N=1000\\) has low power (around \\(0.25\\)). Moving to sample size \\(N=10000\\) would ensure very effective power, but let us keep \\(N=1000\\) for now. We can see that simply increasing \\(\\alpha\\) to \\(0.05\\) increases power to around \\(0.5\\). But it is increasing \\(\\beta_A\\) to \\(0.2\\) that has the strongest effect: power is now around \\(0.9\\), whatever \\(\\alpha\\). As a consequence, choosing \\(\\beta_A\\) correctly is key to ensure a correct power analysis. 7.1.2 Minimum Detectable Effect In general power analysis does not stop after computing power. We also might want to compute the Minimum Detectable Effect (or MDE) that we can detect with a sample of size \\(N\\) and a (one- or two-sided) test of size \\(\\alpha\\) with power \\(\\kappa\\). The following theorem enables us to do just that: Theorem 7.2 (Minimum Detectable Effect with an Asymptotically Normal Estimator) With \\(\\hat{E}\\) complying with Assumption 7.1, the Minimum Detectable Effect of a one- or two-sided test is: For a One-Sided Test: \\(H_0\\): \\(E\\leq0\\) \\(H_A\\): \\(E=\\beta_A&gt;0\\) \\[\\begin{align*} \\beta_A^{\\text{oneside}} &amp; = \\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\alpha\\right)\\right)\\sqrt{\\var{\\hat{E}}}, \\end{align*}\\] For a Two-Sided Test: \\(H_0\\): \\(E=0\\) \\(H_A\\): \\(E=\\beta_A\\neq0\\) \\[\\begin{align*} \\beta_A^{\\text{twoside}} &amp; \\approx \\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right)\\sqrt{\\var{\\hat{E}}}. \\end{align*}\\] Proof. Using Theorem 7.1, inverting the power formula yields the result. With Theorem 7.2, we have a way to compute the MDE for a wide range of applications, as long as we know \\(\\var{\\hat{E}}\\) and that we have choosen properly \\(\\alpha\\) and \\(\\kappa\\). In most applications, researchers choose \\(\\alpha=0.05\\) and \\(\\kappa=0.8\\), so that they compute the effect that they have 80% chance to detect with a test of size 5%. Example 7.2 In our example, we can try to see what the MDE looks for various sample sizes. Let us first write functions to compute the MDE: MDE.var &lt;- function(alpha,kappa,varE,oneside){ if (oneside==TRUE){ MDE &lt;- (qnorm(kappa)+qnorm(1-alpha))*sqrt(varE) } if (oneside==FALSE){ MDE &lt;- (qnorm(kappa)+qnorm(1-alpha/2))*sqrt(varE) } return(MDE) } MDE &lt;- function(N,alpha,kappa,CE,oneside){ if (oneside==TRUE){ MDE &lt;- (qnorm(kappa)+qnorm(1-alpha))*sqrt(CE/N) } if (oneside==FALSE){ MDE &lt;- (qnorm(kappa)+qnorm(1-alpha/2))*sqrt(CE/N) } return(MDE) } alpha &lt;- 0.05 kappa &lt;- 0.8 MDE.N.oneside &lt;- sapply(varE.N,MDE.var,alpha=alpha,kappa=kappa,oneside=TRUE) MDE.N.twoside &lt;- sapply(varE.N,MDE.var,alpha=alpha,kappa=kappa,oneside=FALSE) power.sample$MDE &lt;- c(MDE.N.oneside,MDE.N.twoside) Let us now plot the results: ggplot(power.sample, aes(x=as.factor(N), y=MDE,fill=Test)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;) + xlab(&quot;Sample Size&quot;) + theme_bw() Figure 7.5: MDE and Sample Size Figure 7.5 shows that, with \\(\\alpha=\\) 0.05 and \\(\\kappa=\\) 0.8 and a two-sided test, we can detect a minimum effect of 0.5 with \\(N=\\) 100, whereas the MDE decreases to 0.15 with \\(N=\\) 1000 and even further to 0.05 with \\(N=\\) 10^{4} and 0.02 with \\(N=\\) 10^{5}. 7.1.3 Minimum Required Sample Size Finally, we can also estimate the minimum sample size required to estimate an effect with given size and power. The following theorem shows how: Theorem 7.3 (Minimum Required Sample Size with an Asymptotically Normal Estimator) With \\(\\hat{E}\\) complying with Assumption 7.1, the Minimum Required Sample Size to estimate an effect \\(\\beta_A\\) with a one- or two-sided test is: For a One-Sided Test: \\(H_0\\): \\(E\\leq0\\) \\(H_A\\): \\(E=\\beta_A&gt;0\\) \\[\\begin{align*} N_{\\text{oneside}} &amp; = \\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\alpha\\right)\\right)^2\\frac{C(\\hat{E})}{\\beta_A^2}, \\end{align*}\\] For a Two-Sided Test: \\(H_0\\): \\(E=0\\) \\(H_A\\): \\(E=\\beta_A\\neq0\\) \\[\\begin{align*} N_{\\text{twoside}} &amp; = \\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right)^2\\frac{C(\\hat{E})}{\\beta_A^2}. \\end{align*}\\] Proof. Using Theorem 7.2, and inverting the formula for MDE yields the result. Example 7.3 Let us see how this works in our example. Let us first write a function to compute the required formulae and then set up \\(C(\\hat{E})\\) and finally the minimum reauired sample size for a given treatment effect: # formula sample.size &lt;- function(betaA,alpha,kappa,CE,oneside){ if (oneside==TRUE){ N &lt;- (qnorm(kappa)+qnorm(1-alpha))^2*(CE/(betaA^2)) } if (oneside==FALSE){ N &lt;- (qnorm(kappa)+qnorm(1-alpha/2))^2*(CE/(betaA^2)) } return(round(N)) } # C(E) C.E.N &lt;- varE.N*N.sample # choose set of MDEs MDE.set &lt;- c(1,0.5,0.2,0.1,0.02) # compute set of MDEs for a given C(E) (let&#39;s choose the one for 1000) N.mini.oneside &lt;- sapply(MDE.set,sample.size,alpha=alpha,kappa=kappa,CE=C.E.N[[2]],oneside=TRUE) N.mini.twoside &lt;- sapply(MDE.set,sample.size,alpha=alpha,kappa=kappa,CE=C.E.N[[2]],oneside=FALSE) # Data frame MDE.N.sample &lt;- data.frame(&quot;betaA&quot;=rep(MDE.set,2),&quot;N&quot;=c(N.mini.oneside,N.mini.twoside),&quot;Test&quot;=rep(c(rep(&#39;One-sided&#39;,length(MDE.set)),rep(&#39;Two-sided&#39;,length(MDE.set))))) Let us now plot the results: ggplot(MDE.N.sample, aes(x=as.factor(betaA), y=N,fill=Test)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;) + xlab(&quot;betaA&quot;) + ylab(&quot;Sample size (log scale)&quot;)+ yscale(&quot;log10&quot;,.format=TRUE)+ theme_bw() Figure 7.6: Minimum required sample size Figure 7.6 shows that Minimum Required Sample Size increases very fast as \\(\\beta_A\\), the minimum effect to detect, decreases. For \\(\\beta_A=\\) 1, the Minimum Required Sample Size is equal to 24. For \\(\\beta_A=\\) 0.5, the Minimum Required Sample Size is equal to 96. For \\(\\beta_A=\\) 0.2, the Minimum Required Sample Size is equal to 600. For \\(\\beta_A=\\) 0.1, the Minimum Required Sample Size is equal to 2400. For \\(\\beta_A=\\) 0.02, the Minimum Required Sample Size is equal to 5.9988^{4}. 7.2 Traditional power analysis in practice In the previous section, we have covered the basics of power analysis. In order to implement it in practice, we still need an estimate of \\(\\var{\\hat{E}}\\) or of \\(C(\\hat{E})\\). When we want to compute power after we have estimated an effect, both of these quantities can easily be recovered from most estimators we have covered in this book. One problem, though, is when we want to conduct a power analysis before running a study (for example, before collecting the data). There, we need a way to find a reasonable estimate of \\(\\var{\\hat{E}}\\) and \\(C(\\hat{E})\\). We are going to see several ways of doing that, but basically, we need prior information on the properties of our outcomes and covariates. They can come from baseline data or from data take in a similar population as our target population. Sometimes, we have to make strong assumptions to move the results from one population to our target population. Let’s examine in practice how to do that, in the context of all the econometric methods we have studied so far. 7.2.1 Power Analysis for Randomized Controlled Trials We are going to decompose what needs to be done for each of the four RCT designs we have studied in Section 3. 7.2.1.1 Power Analysis for Brute Force Designs For Brute Force designs, the mosts straightforward way to do a power analysis is to rely on the CLT-based approximation for the precision of our estimator. Using Theorem 2.5 and especially Lemma A.5, we have, in a Brute Force design: \\[\\begin{align*} \\var{\\hat{\\Delta}^Y_{WW^{BF}}} &amp; \\approx \\frac{1}{N}\\left(\\frac{\\var{Y_i^1|R_i=1}}{\\Pr(R_i=1)}+\\frac{\\var{Y_i^0|R_i=0}}{1-\\Pr(R_i=1)}\\right). \\end{align*}\\] We can see that Assumption 7.1 is valid for this estimator. In order to compute \\(\\var{\\hat{\\Delta}^Y_{WW}}\\) of \\(C(\\hat{\\Delta}^Y_{WW})\\), we need to come up with reasonable estimates of \\(\\var{Y_i^1|R_i=1}\\) and \\(\\var{Y_i^0|R_i=0}\\). The problem is that these quantities will only be revealed after the treatment has been given. It is fine for ex-post power analysis but is not feasible for ex-ante power analysis. One way around this issue is to use an estimate of the variance of \\(Y_i\\) in a related or similar sample to benchmark our formula. In our case, we can use the variance of \\(Y_i^B\\), outcomes observed in the period before the treatment is taken, as a source of estimates. Since we cannot know who will get the treatment and who will not, we are going to use the same benchmark for both (\\(\\var{Y_i^B}\\)). This is not perfect but this is what we have. As a result, our estimate of \\(C(\\hat{\\Delta}^Y_{WW})\\) in the brute force design is: \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{WW^{BF}}) &amp; = \\frac{\\var{Y_i^B}}{p(1-p)}, \\end{align*}\\] where \\(p\\) is the proportion of individuals in our sample who will be allocated to the treatment. Example 7.4 Let us see how this formula works out in our example. First, we need to generate a sample: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha.i &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha.i Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # randomized allocation of 50% of individuals Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) Let us now compute the minimum detectable effect for various sample sizes and proportions of treated individuals, using \\(\\hatvar{y^B_i}=\\) 0.78 as an estimate of \\(\\hatvar{y_i^1|R_i=1}=\\) 0.85 and \\(\\hatvar{y_i^0|R_i=0}=\\) 0.78. CE.BF.fun &lt;- function(p,varYb){ return(varYb/(p*(1-p))) } MDE.BF.fun &lt;- function(p,varYb,...){ return(MDE(CE=CE.BF.fun(p=p,varYb=varYb),...)) } Let us finally check what Minimum Detectable Effect looks like as a function of \\(p\\) and of sample size. ggplot() + xlim(0,1) + ylim(0,1) + geom_function(aes(color=&quot;100&quot;),fun=MDE.BF.fun,args=list(N=100,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.BF.fun,args=list(N=1000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.BF.fun,args=list(N=10000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.BF.fun,args=list(N=100000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() Figure 7.7: Minimum detectable effect for the Brute Force design As figure 7.7 shows, the Minimum Detectable Effect is minimized, for a given sample size, at \\(p=0.5\\). This makes sense since it is where we get the most precision out of our treated and control samples. This results depends crucially on the fact that we have assumed no heteroskedasticity (i.e. that we have assumed that the variance of outcomes does not change with treatment status). We also can see that MDE decreases with sample size, but slower than proportionally. Again, it makes sense, since power and MDE depend on the square root of sample size. With a sample size of \\(N=100\\), we now reach a MDE of 0.5. With a sample size of \\(N=1000\\), we now reach a MDE of 0.16. With a sample size of \\(N=10000\\), we now reach a MDE of 0.05. With a sample size of \\(N=100000\\), we now reach a MDE of 0.02. 7.2.1.2 Power Analysis for Self-Selection Designs For self-selection designs, the approach is similar to that of brute force designs, except that, since randomization occurs after self-selection, you have to make a guess on the proportion of people who will take the treatment. We have: \\[\\begin{align*} \\var{\\hat{\\Delta}^Y_{WW^{SS}}} &amp; \\approx \\frac{1}{N}\\frac{1}{\\Pr(D_i=1)}\\left(\\frac{\\var{Y_i^1|D_i=1,R_i=1}}{\\Pr(R_i=1|D_i=1)}+\\frac{\\var{Y_i^0|D_i=1,R_i=0}}{1-\\Pr(R_i=1|D_i=1)}\\right), \\end{align*}\\] with \\(N\\) the total number of individuals in the sample, including the inegilible individuals and the individuals who do not self-select into the program. Estimates of the MDE and of the Minimum Required Sample Size can be expressed in terms of \\(N\\) or of \\(N^D=N\\Pr(D_i=1)\\), the number of individuals who self-select into the program and among which randomization is run. The estimates we need to compute these quantities are more complex than with brute force designs: we need \\(\\Pr(D_i=1)\\), but also variances conditional on \\(D_i=1\\). If the program was operating before randomization, we can have some pretty good ideas of these numbers. Otherwise, we have to use either surveys on intentions to participate, or evidence from similar programs, or at least try to enforce the eligibility criteria as much as we can. Example 7.5 Let’s see how we can make this work in our example. Let us first update our parameters for modelling self-selection, as we did in Chapter 3: param &lt;- c(param,-6.25,0.9,0.5) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;barc&quot;,&quot;gamma&quot;,&quot;sigma2V&quot;) and let’s generate a new dataset: set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) E &lt;- ifelse(YB&lt;=param[&quot;barY&quot;],1,0) V &lt;- rnorm(N,0,param[&quot;sigma2V&quot;]) Dstar &lt;- param[&quot;baralpha&quot;]+param[&quot;theta&quot;]*param[&quot;barmu&quot;]-param[&quot;barc&quot;]-param[&quot;gamma&quot;]*mu-V Ds &lt;- ifelse(Dstar&gt;=0 &amp; E==1,1,0) epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) #random allocation among self-selected Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5 &amp; Ds==1,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) # computing application rate pDhat &lt;- mean(Ds) We are going to assume that all conditional variances are equal to the pre-treatment variance: we use \\(\\hatvar{y^B_i}=\\) 0.78 as an estimate of \\(\\hatvar{y_i^1|D_i=1,R_i=1}=\\) 0.3 and \\(\\hatvar{y_i^0|D_i=1,R_i=0}=\\) 0.23. This is obviously not a great choice since people with \\(D_i=1\\) have lower variance in outcomes than the overall population. What happens if we choose instead \\(\\hatvar{y^B_i|y^B_i\\leq\\bar{y}}\\). Well, \\(\\hatvar{y^B_i|y^B_i\\leq\\bar{y}}=\\) 0.18, which is a much better guess. So trying to approximate the selection process (at least enforcing the eligibility criteria) is a good idea when doing a power analysis for self-selection designs. We are going to use: \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{WW^{SS}}) &amp; = \\frac{1}{\\Pr(D_i=1)}\\frac{\\hatvar{y^B_i|y^B_i\\leq\\bar{y}}}{p(1-p)}, \\end{align*}\\] with \\(p\\) the proportion of applicants randomized into the program. Let’s write a function to compute the MDE in self-selection designs: CE.SS.fun &lt;- function(p,varYb,pD){ return(var(yB)/(pD*p*(1-p))) } MDE.SS.fun &lt;- function(p,varYb,pD,...){ return(MDE(CE=CE.SS.fun(p=p,varYb=varYb,pD=pD),...)) } alpha &lt;- 0.05 kappa &lt;- 0.8 Let us finally check what Minimum Detectable Effect looks like as a function of \\(p\\) and of sample size. # total sample size (including ineligibles and non applicants) ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.SS.fun,args=list(N=100,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.SS.fun,args=list(N=1000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.SS.fun,args=list(N=10000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.SS.fun,args=list(N=100000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() # Applicants sample size pDhat &lt;- 1 ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.SS.fun,args=list(N=100,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.SS.fun,args=list(N=1000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.SS.fun,args=list(N=10000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.SS.fun,args=list(N=100000,pD=pDhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=expression(N^D)) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() # computing application rate pDhat &lt;- mean(Ds) Figure 7.8: Minimum detectable effect for the self-selection design With a total sample size of \\(N=100\\), we now reach a MDE of 1.71. With a total sample size of \\(N=1000\\), we now reach a MDE of 0.54. With a total sample size of \\(N=10000\\), we now reach a MDE of 0.17. With a total sample size of \\(N=100000\\), we now reach a MDE of 0.05. Remember that these sample sizes include ineligible units and units that do not apply for the program. Figure 7.8 also shows what happens when sample size corresponds to only applicants to the program (plot on the right). MDEs in that case look much more like the ones in the brute force design presented in Figure 7.7. With a total sample size of \\(N^D=100\\), we now reach a MDE of 0.5. With a total sample size of \\(N^D=1000\\), we now reach a MDE of 0.16. With a total sample size of \\(N^D=10000\\), we now reach a MDE of 0.05. With a total sample size of \\(N^D=100000\\), we now reach a MDE of 0.02. 7.2.1.3 Power Analysis for Eligibility Designs In eligibility designs, we can make use Theorem 3.8 to show that: \\[\\begin{align*} \\var{\\hat{\\Delta}^Y_{Bloom}} &amp; \\approx \\frac{1}{N}\\frac{1}{p^{E}}\\frac{1}{(p^{D}_1)^2}\\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\var{Y_i|R_i=0,E_i=1}}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\var{Y_i|R_i=1,E_i=1}}{p^R}\\right], \\end{align*}\\] with \\(p^E=\\Pr(E_i=1)\\), \\(p^D=\\Pr(D_i=1|E_i=1)\\), \\(p^R=\\Pr(R_i=1|E_i=1)\\) and \\(p^{D}_1=\\Pr(D_i=1|R_i=1,E_i=1)\\). Note that \\(N\\) corresponds to the size of the sample including the ineligible individuals which do not enter in the estimation of the treatment effect of the program. MDEs and minimum required sample size can also be expressed in terms of \\(N^E=Np^E\\), the size of the sample of eligible units. There is a large number of parameters to find in order to compute this variance estimator. We need to postulate a value for \\(p^{E}\\) (unless we look for information on the sample size of the eligible population participating in the experiment, in which case we set \\(p^{E}=1\\) and \\(N=N^E\\) in the above formula), a value for \\(p^D\\), for \\(p^R\\) and for \\(p^D_1\\). For estimating \\(p^E\\), we are going to choose the proportion of individuals eligible to the program (\\(\\hat{p}^E=\\Pr(y_i^B\\leq\\bar{y})\\)). For \\(p^D\\), we know that: \\(p^D=\\Pr(D_i=1|E_i=1)=\\Pr(D_i=1|R_i=1,E_i=1)\\Pr(R_i=1|E_i=1)=p^{D}_1p^R\\). Since we can vary \\(p^R\\), we only need to settle on a value for \\(p^{D}_1\\). We are going to choose the actual value of \\(\\Pr(D_i=1|R_i=1,E_i=1)\\), or \\(\\hat{p}^{D}_1=\\) 1. Finally, we are going to assume that all conditional variances are equal to the pre-treatment variance among eligibles: we use \\(\\hatvar{y^B_i|E_i=1}=\\) 0.18 as an estimate of \\(\\hatvar{y_i|R_i=1,E_i=1}=\\) 0.29 and \\(\\hatvar{y_i|R_i=0,E_i=1}=\\) 0.18. We can now write \\(C(E)\\) for the total sample size \\(N\\) (set \\(p^{E}=1\\) for \\(N=N^E\\)): \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{Bloom}) &amp; = \\frac{1}{\\hat{p}^{E}}\\frac{1}{(\\hat{p}^{D}_1)^2}\\left[\\left(\\frac{\\hat{p}^D}{p^R}\\right)^2\\frac{\\hatvar{y^B_i|E_i=1}}{1-p^R}+\\left(\\frac{1-\\hat{p}^D}{1-p^R}\\right)^2\\frac{\\hatvar{y^B_i|E_i=1}}{p^R}\\right]. \\end{align*}\\] Let’s write a function to compute the MDE in eligibility designs: CE.Elig.fun &lt;- function(pR,varYb,pE,p1D){ return((1/pE)*(1/p1D)^2*((p1D)^2*varYb/(1-pR)+(((1-p1D*pR)/(1-pR))^2*var(yB)/pR))) } MDE.Elig.fun &lt;- function(pR,varYb,pE,p1D,...){ return(MDE(CE=CE.Elig.fun(pR=pR,varYb=varYb,pE=pE,p1D=p1D),...)) } # computing candidate participation rate, using the observed proportion below baryB pEhat &lt;- mean(E) p1Dhat &lt;- mean(Ds[E==1 &amp; R==1]) alpha &lt;- 0.05 kappa &lt;- 0.8 Let us finally check what Minimum Detectable Effect looks like as a function of \\(p^R\\) and of sample size. # total sample size (including ineligibles) ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.Elig.fun,args=list(N=100,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.Elig.fun,args=list(N=1000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.Elig.fun,args=list(N=10000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.Elig.fun,args=list(N=100000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(expression(p^R)) + theme_bw() # Applicants sample size pEhat &lt;- 1 ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.Elig.fun,args=list(N=100,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.Elig.fun,args=list(N=1000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.Elig.fun,args=list(N=10000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.Elig.fun,args=list(N=100000,pE=pEhat,p1D=p1Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=expression(N^E)) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() # computing application rate pEhat &lt;- mean(E) Figure 7.9: Minimum detectable effect for the eligibility design Note that the minimum detectable effect is no longer minimized at \\(p^R=0.5\\). We are still going to give the examples at this proportion anyway, since the difference with the optimal proportion of treated is small in our application. With a total sample size of \\(N=100\\), we now reach a MDE of 0.81. With a total sample size of \\(N=1000\\), we now reach a MDE of 0.26. With a total sample size of \\(N=10000\\), we now reach a MDE of 0.08. With a total sample size of \\(N=100000\\), we now reach a MDE of 0.03. Remember that these sample sizes include ineligible units. Figure 7.9 also shows what happens when sample size corresponds to only units eligibles to the program (plot on the right). With a total sample size of \\(N^E=100\\), we now reach a MDE of 0.39. With a total sample size of \\(N^E=1000\\), we now reach a MDE of 0.12. With a total sample size of \\(N^E=10000\\), we now reach a MDE of 0.04. With a total sample size of \\(N^E=100000\\), we now reach a MDE of 0.01. 7.2.1.4 Power Analysis for Encouragement Designs In encouragement designs, we can make use Theorem 3.16 to show that: \\[\\begin{align*} \\var{\\hat{\\Delta}^Y_{Wald}} &amp; \\approx \\frac{1}{N}\\frac{1}{p^{E}}\\frac{1}{(p^D_1-p^D_0)^2}\\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\var{Y_i|E_i=1,R_i=0}}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\var{Y_i|E_i=1,R_i=1}}{p^R}\\right], \\end{align*}\\] with \\(p^E=\\Pr(E_i=1)\\), \\(p^D=\\Pr(D_i=1|E_i=1)\\), \\(p^R=\\Pr(R_i=1|E_i=1)\\), \\(p^{D}_0=\\Pr(D_i=1|R_i=0,E_i=1)\\) and \\(p^{D}_1=\\Pr(D_i=1|R_i=1,E_i=1)\\). Note that \\(N\\) corresponds to the size of the sample including the ineligible individuals which do not enter in the estimation of the treatment effect of the program. MDEs and minimum required sample size can also be expressed in terms of \\(N^E=Np^E\\), the size of the sample in terms of eligible units. As with eligibility designs, there is a large number of parameters to find in order to compute this variance estimator. We need to postulate a value for \\(p^{E}\\) (unless we look for information on the sample size of the eligible population participating in the experiment, in which case we set \\(p^{E}=1\\) and \\(N=N^E\\) in the above formula), a value for \\(p^D\\), for \\(p^R\\) and for \\(p^D_1\\). For estimating \\(p^E\\), we are going to choose the proportion of individuals eligible to the program (\\(\\hat{p}^E=\\Pr(y_i^B\\leq\\bar{y})\\)). For \\(p^D\\), we know that: \\(p^D=\\Pr(D_i=1|E_i=1)=\\Pr(D_i=1|R_i=1,E_i=1)\\Pr(R_i=1|E_i=1)+\\Pr(D_i=1|R_i=0,E_i=1)\\Pr(R_i=0|E_i=1)=p^{D}_1p^R+p^{D}_0(1-p^R)\\). Since we can vary \\(p^R\\), we only need to settle on a value for \\(p^{D}_1\\) and \\(p^{D}_0\\). We are going to choose their actual values in the sample, \\(\\Pr(D_i=1|R_i=1,E_i=1)\\) and \\(\\Pr(D_i=1|R_i=0,E_i=1)\\), or \\(\\hat{p}^{D}_1=\\) 1 and \\(\\hat{p}^{D}_0=\\) 0.23. In real life applications, this choice is much more difficult. It can for example be based on pilot studies where the response rate to the encouragement is tested. Finally, we are going to assume that all conditional variances are equal to the pre-treatment variance among eligibles: we use \\(\\hatvar{y^B_i|E_i=1}=\\) 0.18 as an estimate of \\(\\hatvar{y_i|R_i=1,E_i=1}=\\) 0.29 and \\(\\hatvar{y_i|R_i=0,E_i=1}=\\) 0.18. We can now write \\(C(E)\\) for the total sample size \\(N\\) (set \\(p^{E}=1\\) for \\(N=N^E\\)): \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{Wald}) &amp; = \\frac{1}{\\hat{p}^{E}}\\frac{1}{(\\hat{p}^{D}_1-\\hat{p}^{D}_0)^2}\\left[\\left(\\frac{p^{D}_1p^R+p^{D}_0(1-p^R)}{p^R}\\right)^2\\frac{\\hatvar{y^B_i|E_i=1}}{1-p^R}\\right.\\\\ &amp; \\phantom{= \\frac{1}{\\hat{p}^{E}}\\frac{1}{(\\hat{p}^{D}_1-\\hat{p}^{D}_0)^2}\\left[\\right.}\\left.+\\left(\\frac{1-(p^{D}_1p^R+p^{D}_0(1-p^R))}{1-p^R}\\right)^2\\frac{\\hatvar{y^B_i|E_i=1}}{p^R}\\right]. \\end{align*}\\] Let’s write a function to compute the MDE in encouragement designs: CE.Encourage.fun &lt;- function(pR,varYb,pE,p1D,p0D){ return((1/pE)*(1/(p1D-p0D))^2*(((p1D*pR+p0D*(1-pR))/pR)^2*varYb/(1-pR)+((1-p1D*pR-p0D*(1-pR))/(1-pR))^2*var(yB)/pR)) } MDE.Encourage.fun &lt;- function(pR,varYb,pE,p1D,p0D,...){ return(MDE(CE=CE.Encourage.fun(pR=pR,varYb=varYb,pE=pE,p1D=p1D,p0D=p0D),...)) } # computing candidate participation rate, using the observed proportion below baryB pEhat &lt;- mean(E) p1Dhat &lt;- mean(Ds[E==1 &amp; R==1]) p0Dhat &lt;- mean(Ds[E==1 &amp; R==0]) alpha &lt;- 0.05 kappa &lt;- 0.8 Let us finally check what Minimum Detectable Effect looks like as a function of \\(p^R\\) and of sample size. # total sample size (including ineligibles) ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.Encourage.fun,args=list(N=100,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.Encourage.fun,args=list(N=1000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.Encourage.fun,args=list(N=10000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.Encourage.fun,args=list(N=100000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(expression(p^R)) + theme_bw() # Applicants sample size pEhat &lt;- 1 ggplot() + xlim(0,1) + ylim(0,2) + geom_function(aes(color=&quot;100&quot;),fun=MDE.Encourage.fun,args=list(N=100,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.Encourage.fun,args=list(N=1000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.Encourage.fun,args=list(N=10000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.Encourage.fun,args=list(N=100000,pE=pEhat,p1D=p1Dhat,p0D=p0Dhat,varYb=var(yB[E==1]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=expression(N^E)) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() # computing application rate pEhat &lt;- mean(E) Figure 7.10: Minimum detectable effect for the encouragement design Note that the minimum detectable effect is no longer minimized at \\(p^R=0.5\\). We are still going to give the examples at this proportion anyway, since the difference with the optimal proportion of treated is small in our application. With a total sample size of \\(N=100\\), we now reach a MDE of 0.91. With a total sample size of \\(N=1000\\), we now reach a MDE of 0.29. With a total sample size of \\(N=10000\\), we now reach a MDE of 0.09. With a total sample size of \\(N=100000\\), we now reach a MDE of 0.03. Remember that these sample sizes include ineligible units. Figure 7.10 also shows what happens when sample size corresponds to only units eligible to the program (plot on the right). With a total sample size of \\(N^E=100\\), we now reach a MDE of 0.44. With a total sample size of \\(N^E=1000\\), we now reach a MDE of 0.14. With a total sample size of \\(N^E=10000\\), we now reach a MDE of 0.04. With a total sample size of \\(N^E=100000\\), we now reach a MDE of 0.01. 7.2.2 Power Analysis for Natural Experiments Power analysis can be useful for natural experiments as well, especially to assess the level of precision we are likely to achieve with a given sample size. It is still possible to use Theorem 7.1 to conduct a power analysis for natural experiments, since they comply with Assumption 7.1. In this section, we are going to focus in Difference in Differences and Regression Discontinuity Designs, since the case Instrumental Variables is similar to the case of encouragement designs seen just above. 7.2.2.1 Power Analysis for RDD Let us start with power analysis for Regression Discontinuity designs. They are very similar to the case of instrumental variables, and thus to the case of encouragement designs. The only thing that differs is the size of the bandwidth around the discontinuity, which is going to be a major influence on the effective size of the sample. Let us study the case of sharp RDD first, and then move on to fuzzy RDD. 7.2.2.1.1 Power analysis for sharp RDD One way to conduct the power analysis for RDD in sharp designs would be to use the formula for the asymptotic variance of the RDD estimator derived in Theorem 4.5. This route requires to specify the density of the running variable at the threshold and the bandwidth. Another route simply uses the fact that the RDD estimator is equivalent to a with-without estimator on both sides of the threshold. Let’s first explore the first route. Following Theorem 4.5, we have that the variance of the simplified sharp RDD estimator can be approximated by: \\[\\begin{align*} \\var{\\hat{\\Delta}_{LLRRDD}} &amp; \\approx \\frac{1}{Nh}\\frac{4}{f_{Z}(\\bar{z})}\\left(\\lim_{e\\rightarrow 0^{\\text{+}}}\\var{Y_i|Z_i=\\bar{z}-e}+\\lim_{e\\rightarrow 0^{\\text{+}}}\\var{Y_i|Z_i=\\bar{z}+e}\\right), \\end{align*}\\] To implement this formula, we need to derive the variance of the outcome at the threshold, the optimal bandwidth and the density of the the running variable at the threshold. All these quantities can be derived or at least approximated using the available pre-treatment data. Example 7.6 Let us try to implement this in the example. In order to be able to implement the power computation on data observed before the treatment takes place, we need to have at least three treatment periods: two before and one after. Selection will take place in period \\(2\\). We will estimate power on the period before that (\\(1\\)). Treatment effects will be observed in period \\(3\\). We are going to use a setting similar to the one we used for staggered DID. Let us first choose some parameter values: param &lt;- c(8,.5,.28,1500,0.9, 0.01,0.01,0.01, 0.05,0.05, 0,0.1,0.2, 0.05,0.1,0.15, 0.25,0.1,0.05, 1.5,1.25,1, 0.5,0,-0.5, 0.1,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;, &quot;theta1&quot;,&quot;theta2&quot;,&quot;theta3&quot;, &quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;, &quot;delta1&quot;,&quot;delta2&quot;,&quot;delta3&quot;, &quot;baralpha1&quot;,&quot;baralpha2&quot;,&quot;baralpha3&quot;, &quot;barchi1&quot;,&quot;barchi2&quot;,&quot;barchi3&quot;, &quot;kappa1&quot;,&quot;kappa2&quot;,&quot;kappa3&quot;, &quot;xi1&quot;,&quot;xi2&quot;,&quot;xi3&quot;, &quot;gamma&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) Let us now generate the corresponding data (in long format): set.seed(1234) N &lt;- 1000 T &lt;- 3 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) data &lt;- as.data.frame(mvrnorm(N*T,c(0,0),cov.eta.omega)) colnames(data) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) # time and individual identifiers data$time &lt;- c(rep(1,N),rep(2,N),rep(3,N)) data$id &lt;- rep((1:N),T) # unit fixed effects data$mu &lt;- rep(rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])),T) # time fixed effects data$delta &lt;- c(rep(param[&quot;delta1&quot;],N),rep(param[&quot;delta2&quot;],N),rep(param[&quot;delta3&quot;],N)) data$baralphat &lt;- c(rep(param[&quot;baralpha1&quot;],N),rep(param[&quot;baralpha2&quot;],N),rep(param[&quot;baralpha3&quot;],N)) # building autocorrelated error terms data$epsilon &lt;- rnorm(N*T,0,sqrt(param[&quot;sigma2epsilon&quot;])) data$U[1:N] &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) data$U[(N+1):(2*N)] &lt;- param[&quot;rho&quot;]*data$U[1:N] + data$epsilon[(N+1):(2*N)] data$U[(2*N+1):(3*N)] &lt;- param[&quot;rho&quot;]*data$U[(N+1):(2*N)] + data$epsilon[(2*N+1):(3*N)] # potential outcomes in the absence of the treatment data$y0 &lt;- data$mu + data$delta + data$U data$Y0 &lt;- exp(data$y0) # treatment status Ds &lt;- if_else(data$y0[(N+1):(2*N)]&lt;=log(param[&quot;barY&quot;]),1,0) data$Ds &lt;- rep(Ds,T) With pre-treatment data (period \\(2\\)), we can compute a density of the outcomes at the threshold, and then we can use period \\(1\\) to compute the optimal bandwidth estimator and the variance of outcomes on each side of the threshold. Let’s start with the density estimation and bandwidth choice first. # density function estimated at one point densy2.ybar &lt;- density(data$y0[1:N],n=1,from=log(param[&quot;barY&quot;]),to=log(param[&quot;barY&quot;]),kernel=&quot;biweight&quot;,bw=&quot;nrd&quot;)[[2]] # optimal bandwidth by cross validation kernel &lt;- &#39;gaussian&#39; #bw &lt;- 0.1 MSE.grid &lt;- seq(0.1,1,by=.1) MSE.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=data$y0[1:N],D=Ds,x=data$y0[(N+1):(2*N)],kernel=kernel,d=0) MSE.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=data$y0[1:N],D=Ds,x=data$y0[(N+1):(2*N)],kernel=kernel,d=1) bw0 &lt;- MSE.grid[MSE.llr.0==min(MSE.llr.0)] bw1 &lt;- MSE.grid[MSE.llr.1==min(MSE.llr.1)] # final bandwidth choice: mean of the two bw &lt;- (bw1+bw0)/2 Let us now compute the conditional variance on both sides. We are going to assume that they are the same, as they are by construction on pre-treatment data. We could increase the variance of the outcome in the absence of the treatment by the variance of the treatment effect if we had any idea of the magnitude of this parameter. To compute the conditional variance, we need to estimate the regression function, then compute the residuals, then estimate the regression function ofthe squared residuals. Let’s go. # llr estimate for y1 y1.llr &lt;- llr(data$y0[1:N],data$y0[(N+1):(2*N)],data$y0[(N+1):(2*N)],bw=bw,kernel=kernel) # residuals y1residual &lt;- data$y0[1:N]-y1.llr # squared y1residual.sq &lt;- y1residual^2 test &lt;- rep(1,length(y1residual.sq)) # bandwidth choice MSE.llr.vary1 &lt;- sapply(MSE.grid,MSE.llr,y=y1residual.sq,D=test,x=data$y0[(N+1):(2*N)],kernel=kernel,d=1) bw.var &lt;- MSE.grid[MSE.llr.vary1==min(MSE.llr.vary1)] # computing conditional variance at bary var.y1.bary &lt;- llr(y1residual.sq,data$y0[(N+1):(2*N)],log(param[&quot;barY&quot;]),bw=bw.var,kernel=kernel) We now simply need to compute the variance of the LLRRDD estimator using our formula and then to generate the corresponding Minimum Detectable Effect. # variance formula var.LLRRDD &lt;- function(N,h,densZ,vary0,vary1){ return((1/(N*h)*(4/densZ)*(vary0+vary1))) } # variance of LLRRDD on y1: varLLRRDD.y1 &lt;- var.LLRRDD(N=N,h=bw,densZ=densy2.ybar,vary0=var.y1.bary,vary1=var.y1.bary) # MDE MDE.LLRRDD &lt;- MDE.var(varE=varLLRRDD.y1,alpha=alpha,kappa=kappa,oneside=FALSE) In our example, the Minimum Detectable Effect in a sharp Regression Discontinuity Design is thus 0.1. Remark. Another simpler approach would be to simply use the formula for the MDE of a brute force RCT and to vary the sample size as a function of the bandwidth. 7.2.2.1.2 Power analysis for fuzzy RDD With Fuzzy RRD designs we can now use the formula developed in Theorem 4.8: \\[\\begin{align*} \\var{\\hat{\\Delta}_{LLRRDDIV}} &amp; \\approx \\frac{1}{Nh}\\left(\\frac{1}{\\tau^2_{D}}V_{\\tau_Y}+\\frac{\\tau^2_{Y}}{\\tau^4_{D}}V_{\\tau_D}-2\\frac{\\tau_{Y}}{\\tau^3_{D}}C_{\\tau_Y,\\tau_D}\\right), \\end{align*}\\] with \\[\\begin{align*} \\tau_{D} &amp; = \\lim_{e\\rightarrow 0^{+}}\\esp{D_i|Z_i=\\bar{z}+e}-\\lim_{e\\rightarrow 0^{+}}\\esp{D_i|Z_i=\\bar{z}-e}\\\\ V_{\\tau_Y} &amp; = \\frac{4}{f_Z(\\bar{z})}\\left(\\sigma^2_{Y^r}+\\sigma^2_{Y^l}\\right) \\qquad V_{\\tau_D} = \\frac{4}{f_Z(\\bar{z})}\\left(\\sigma^2_{D^r}+\\sigma^2_{D^l}\\right)\\\\ C_{\\tau_Y,\\tau_D}&amp; = \\frac{4}{f_Z(\\bar{z})}\\left(C_{YD^r}+C_{YD^l}\\right) \\qquad \\sigma^2_{Y^r} = \\lim_{e\\rightarrow 0^{+}}\\var{Y_i|Z_i=\\bar{z}+e} \\\\ C_{YD^r} &amp; = \\lim_{e\\rightarrow 0^{+}}\\cov{Y_i,D_i|Z_i=\\bar{z}+e}. \\end{align*}\\] We need estimates of all of these quantities in order to be able to estimate the MDE. Example 7.7 Let’s see how this works in our example: We first need to simulate data with several periods. We are going to use the same data for outcomes as we the ones we used for the sharp RDD design. We simply are going to change the allocation to the treatment from a sharp to a fuzzy allocation rule. set.seed(1234) param &lt;- c(param,1) names(param)[[length(param)]] &lt;- &quot;kappa&quot; # error term data$V &lt;- param[&quot;gamma&quot;]*(data$mu-param[&quot;barmu&quot;])+data$omega # treament status DsFuzz &lt;- if_else(((data$y0[(N+1):(2*N)]&lt;=log(param[&quot;barY&quot;])) &amp; (data$V[(N+1):(2*N)]&lt;=param[&quot;kappa&quot;])) | ((data$y0[(N+1):(2*N)]&gt;log(param[&quot;barY&quot;])) &amp; (data$V[(N+1):(2*N)]&gt;param[&quot;kappa&quot;])),1,0) data$DsFuzz &lt;- rep(DsFuzz,T) We no need to compute each of the individual components of the formula. The density \\(f_Z\\) is the same has in the sharp design. We also need to estimate the conditional variances of \\(Y_{i,1}\\) and \\(D_i\\) on each side of the threshold. We need to estimate the conditional covariance between \\(Y_{i,1}\\) and \\(D_i\\) on each side of the threshold. We also need to choose a bandwidth, in general the minimum of all the bandwidths on each side of the threshold. \\(\\tau_D\\) and \\(\\tau_Y\\) are the denominator and numerator the Wald LLR estimator respectively. A problem that we have here is that we do not know the numerator of the Wald estimator for the true outcome, and the denominator for \\(y_{i,1}\\) is by definition zero. This difficulty is very broad since it implies that the we should take into account that the MDE parameter affects the precision of the estimator. Solving for the MDE then requires solving a non-linear equation. We are going to eschew this application and only compute the formula for various levels of the MDE, starting with the one for the Sharp estimator. Another approach would be to start with an MDE of zero and then iterate the formula until convergence. Tools exist to check whether that sequence would converge but we will study them another time. # indicator for being below the threshold S &lt;- Ds # optimal bandwidth by cross validation # for y MSE.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=data$y0[1:N],D=S,x=data$y0[(N+1):(2*N)],kernel=kernel,d=0) MSE.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=data$y0[1:N],D=S,x=data$y0[(N+1):(2*N)],kernel=kernel,d=1) bw0 &lt;- MSE.grid[MSE.llr.0==min(MSE.llr.0)] bw1 &lt;- MSE.grid[MSE.llr.1==min(MSE.llr.1)] # for D MSE.pr.llr.0 &lt;- sapply(MSE.grid,MSE.llr,y=data$DsFuzz[1:N],D=S,x=data$y0[(N+1):(2*N)],kernel=kernel,d=0) MSE.pr.llr.1 &lt;- sapply(MSE.grid,MSE.llr,y=data$DsFuzz[1:N],D=S,x=data$y0[(N+1):(2*N)],kernel=kernel,d=1) bwD0 &lt;- MSE.grid[MSE.pr.llr.0==min(MSE.pr.llr.0)] bwD1 &lt;- MSE.grid[MSE.pr.llr.1==min(MSE.pr.llr.1)] # treatment effects estimates # y tau.y &lt;- MDE.LLRRDD # we start with the sharp MDE estimate # DsFuzz DsFuzz.bary.llr.pred.0 &lt;- llr(y=DsFuzz[S==0],x=data$y0[(N+1):(2*N)][S==0],gridx=c(log(param[&#39;barY&#39;])),bw=bwD0,kernel=kernel) DsFuzz.bary.llr.pred.1 &lt;- llr(y=DsFuzz[S==1],x=data$y0[(N+1):(2*N)][S==1],gridx=c(log(param[&#39;barY&#39;])),bw=bwD1,kernel=kernel) tau.D &lt;- DsFuzz.bary.llr.pred.1-DsFuzz.bary.llr.pred.0 # conditional expectations estimates on both sides # LLR estoimate of conditional expectation of DFuzz on y2 Pr.D0.llr &lt;- llr(DsFuzz[S==0],data$y0[(N+1):(2*N)][S==0],data$y0[(N+1):(2*N)][S==0],bw=bwD0,kernel=kernel) Pr.D1.llr &lt;- llr(DsFuzz[S==1],data$y0[(N+1):(2*N)][S==1],data$y0[(N+1):(2*N)][S==1],bw=bwD1,kernel=kernel) # llr estimate for y1 y.S0.llr &lt;- llr(data$y0[1:N][S==0],data$y0[(N+1):(2*N)][S==0],data$y0[(N+1):(2*N)][S==0],bw=bw0,kernel=kernel) y.S1.llr &lt;- llr(data$y0[1:N][S==1],data$y0[(N+1):(2*N)][S==1],data$y0[(N+1):(2*N)][S==1],bw=bw1,kernel=kernel) # conditional variance estimates on both sides # residuals yresidual.S0.sq &lt;- (data$y0[1:N][S==0]-y.S0.llr)^2 yresidual.S1.sq &lt;- (data$y0[1:N][S==1]-y.S1.llr)^2 Dresidual.S0.sq &lt;- (DsFuzz[S==0]-Pr.D0.llr)^2 Dresidual.S1.sq &lt;- (DsFuzz[S==1]-Pr.D1.llr)^2 # bandwidth choice for variance estimates MSE.llr.vary.S0 &lt;- sapply(MSE.grid,MSE.llr,y=yresidual.S0.sq,D=S[S==0],x=data$y0[(N+1):(2*N)][S==0],kernel=kernel,d=0) MSE.llr.vary.S1 &lt;- sapply(MSE.grid,MSE.llr,y=yresidual.S1.sq,D=S[S==1],x=data$y0[(N+1):(2*N)][S==1],kernel=kernel,d=1) bw.vary.S0 &lt;- MSE.grid[MSE.llr.vary.S0==min(MSE.llr.vary.S0)] bw.vary.S1 &lt;- MSE.grid[MSE.llr.vary.S1==min(MSE.llr.vary.S1)] # computing conditional variance at bary var.y0.bary &lt;- llr(yresidual.S0.sq,data$y0[(N+1):(2*N)][S==0],log(param[&quot;barY&quot;]),bw=bw.vary.S0,kernel=kernel) var.y1.bary &lt;- llr(yresidual.S1.sq,data$y0[(N+1):(2*N)][S==1],log(param[&quot;barY&quot;]),bw=bw.vary.S1,kernel=kernel) # bandwidth choice for variance estimates for D MSE.llr.varD.S0 &lt;- sapply(MSE.grid,MSE.llr,y=Dresidual.S0.sq,D=S[S==0],x=data$y0[(N+1):(2*N)][S==0],kernel=kernel,d=0) MSE.llr.varD.S1 &lt;- sapply(MSE.grid,MSE.llr,y=Dresidual.S1.sq,D=S[S==1],x=data$y0[(N+1):(2*N)][S==1],kernel=kernel,d=1) bw.varD.S0 &lt;- MSE.grid[MSE.llr.varD.S0==min(MSE.llr.varD.S0)] bw.varD.S1 &lt;- MSE.grid[MSE.llr.varD.S1==min(MSE.llr.varD.S1)] # computing conditional variance at bary for D var.D0.bary &lt;- llr(Dresidual.S0.sq,data$y0[(N+1):(2*N)][S==0],log(param[&quot;barY&quot;]),bw=bw.varD.S0,kernel=kernel) var.D1.bary &lt;- llr(Dresidual.S1.sq,data$y0[(N+1):(2*N)][S==1],log(param[&quot;barY&quot;]),bw=bw.varD.S1,kernel=kernel) # conditional covariance estimates on both sides # deviations with respect to conditional expectation yresidual.S0 &lt;- (data$y0[1:N][S==0]-y.S0.llr) yresidual.S1 &lt;- (data$y0[1:N][S==1]-y.S1.llr) Dresidual.S0 &lt;- (DsFuzz[S==0]-Pr.D0.llr) Dresidual.S1 &lt;- (DsFuzz[S==1]-Pr.D1.llr) # product of deviations on each side yDresidual.S0 &lt;- yresidual.S0*Dresidual.S0 yDresidual.S1 &lt;- yresidual.S1*Dresidual.S1 # bandwidth choice for covariance estimates MSE.llr.covyD.S0 &lt;- sapply(MSE.grid,MSE.llr,y=yDresidual.S0,D=S[S==0],x=data$y0[(N+1):(2*N)][S==0],kernel=kernel,d=0) MSE.llr.covyD.S1 &lt;- sapply(MSE.grid,MSE.llr,y=yDresidual.S1,D=S[S==1],x=data$y0[(N+1):(2*N)][S==1],kernel=kernel,d=1) bw.covyD.S0 &lt;- MSE.grid[MSE.llr.covyD.S0==min(MSE.llr.covyD.S0)] bw.covyD.S1 &lt;- MSE.grid[MSE.llr.covyD.S1==min(MSE.llr.covyD.S1)] # computing conditional variance at bary cov.yD0.bary &lt;- llr(yDresidual.S0,data$y0[(N+1):(2*N)][S==0],log(param[&quot;barY&quot;]),bw=bw.covyD.S0,kernel=kernel) cov.yD1.bary &lt;- llr(yDresidual.S1,data$y0[(N+1):(2*N)][S==1],log(param[&quot;barY&quot;]),bw=bw.covyD.S1,kernel=kernel) # computing the minimum bandwidth h.Fuzz &lt;- min(bw.covyD.S1,bw.covyD.S0,bw.vary.S0,bw.vary.S1,bwD0,bwD1,bw0,bw1) We now simply need to compute the variance of the LLRRDDIV estimator using our formula and then to generate the corresponding Minimum Detectable Effect. # variance formula var.LLRRDD.IV &lt;- function(N,h,tauD,tauY,densZ,vary0,vary1,varD0,varD1,covyD0,covyD1){ VtauY &lt;- (4/densZ)*(vary0+vary1) VtauD &lt;- (4/densZ)*(varD0+varD1) CtauYtauD &lt;- (4/densZ)*(covyD0+covyD1) return((1/(N*h)*(VtauY/tauD^2+VtauD*tauY^2/tauD^4-2*tauY*CtauYtauD/tauD^3))) } # variance of LLRRDD on y1: varLLRRDD.IV.tauY &lt;- var.LLRRDD.IV(N=N,h=h.Fuzz,tauD=tau.D,tauY=tau.y,densZ=densy2.ybar,vary0=var.y0.bary,vary1=var.y1.bary,varD0=var.D0.bary,varD1=var.D1.bary,covyD0=cov.yD0.bary,covyD1=cov.yD1.bary) # MDE MDE.LLRRDD.IV &lt;- MDE.var(varE=varLLRRDD.IV.tauY,alpha=alpha,kappa=kappa,oneside=FALSE) # second iteration varLLRRDD.IV.tauY.2 &lt;- var.LLRRDD.IV(N=N,h=h.Fuzz,tauD=tau.D,tauY=MDE.LLRRDD.IV,densZ=densy2.ybar,vary0=var.y0.bary,vary1=var.y1.bary,varD0=var.D0.bary,varD1=var.D1.bary,covyD0=cov.yD0.bary,covyD1=cov.yD1.bary) MDE.LLRRDD.IV.2 &lt;- MDE.var(varE=varLLRRDD.IV.tauY.2,alpha=alpha,kappa=kappa,oneside=FALSE) In our example, the Minimum Detectable Effect in a Fuzzy Regression Discontinuity Design is thus 0.13. With a second iteration, using this value in the variance formula, we get a new MDE estimate of 0.13. 7.2.2.2 Power Analysis for DID With the DID estimator, the two key questions is whether we are in a repeated cross section or in a panel, and whether we want to estimate power for a simple 2$$2 DID estimate, or for an aggregate treatment effect. 7.2.2.2.1 Power estimation for simple DID estimators 7.2.2.2.1.1 With panel data In panel data, we can use Theorem 4.11 which says that: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{DID_{panel}}-\\Delta^Y_{DID}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y_{i,A}^1-Y_{i,B}^0|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_{i,A}^0-Y_{i,B}^0|D_i=0}}{1-\\Pr(D_i=1)}\\right). \\end{align*}\\] We thus simply need an estimate of the probability of receiving the treatment and of the variance of the changes in outcomes between two time periods to compute power, MDE and the minimum required sample size. If there are two pre-treatment periods (and treatment is allocated at period \\(2\\)), we can compute all members of the power computation. As a result, our estimate of \\(C(\\hat{\\Delta}^Y_{DID})\\) in panel data is: \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{DID_{panel}}) &amp; = \\frac{\\var{Y_{i,2}-Y_{i,1}|D_i=1}}{p}+\\frac{\\var{Y_{i,2}-Y_{i,1}|D_i=0}}{1-p}, \\end{align*}\\] where \\(p\\) is the proportion of individuals in our sample who will be allocated to the treatment. The corresponding functions in R are: CE.DID.panel.fun &lt;- function(p,varDeltaY1b,varDeltaY0b){ return((varDeltaY1b/p)+(varDeltaY0b/(1-p))) } MDE.DID.panel.fun &lt;- function(p,varDeltaY1b,varDeltaY0b,...){ return(MDE(CE=CE.DID.panel.fun(p=p,varDeltaY1b=varDeltaY1b,varDeltaY0b=varDeltaY0b),...)) } Example 7.8 Let us see how this formula works out in our example. First, we need to generate a sample: param &lt;- c(8,.5,.28,1500,0.9, 0.01,0.01,0.01,0.01, 0.05,0.05, 0,0.1,0.2,0.3, 0.05,0.1,0.15,0.2, 0.25,0.1,0.05,0, 1.5,1.25,1,0.75, 0.5,0,-0.5,-1, 0.1,0.28,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;, &quot;theta1&quot;,&quot;theta2&quot;,&quot;theta3&quot;,&quot;theta4&quot;, &quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;, &quot;delta1&quot;,&quot;delta2&quot;,&quot;delta3&quot;,&quot;delta4&quot;, &quot;baralpha1&quot;,&quot;baralpha2&quot;,&quot;baralpha3&quot;,&quot;baralpha4&quot;, &quot;barchi1&quot;,&quot;barchi2&quot;,&quot;barchi3&quot;,&quot;barchi4&quot;, &quot;kappa1&quot;,&quot;kappa2&quot;,&quot;kappa3&quot;,&quot;kappa4&quot;, &quot;xi1&quot;,&quot;xi2&quot;,&quot;xi3&quot;,&quot;xi4&quot;, &quot;gamma&quot;,&quot;sigma2omega&quot;,&quot;rhoetaomega&quot;) set.seed(1234) N &lt;- 1000 T &lt;- 4 cov.eta.omega &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;]),ncol=2,nrow=2) data &lt;- as.data.frame(mvrnorm(N*T,c(0,0),cov.eta.omega)) colnames(data) &lt;- c(&#39;eta&#39;,&#39;omega&#39;) # time and individual identifiers data$time &lt;- c(rep(1,N),rep(2,N),rep(3,N),rep(4,N)) data$id &lt;- rep((1:N),T) # unit fixed effects data$mu &lt;- rep(rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])),T) # time fixed effects data$delta &lt;- c(rep(param[&quot;delta1&quot;],N),rep(param[&quot;delta2&quot;],N),rep(param[&quot;delta3&quot;],N),rep(param[&quot;delta4&quot;],N)) data$baralphat &lt;- c(rep(param[&quot;baralpha1&quot;],N),rep(param[&quot;baralpha2&quot;],N),rep(param[&quot;baralpha3&quot;],N),rep(param[&quot;baralpha4&quot;],N)) # building autocorrelated error terms data$epsilon &lt;- rnorm(N*T,0,sqrt(param[&quot;sigma2epsilon&quot;])) data$U[1:N] &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) data$U[(N+1):(2*N)] &lt;- param[&quot;rho&quot;]*data$U[1:N] + data$epsilon[(N+1):(2*N)] data$U[(2*N+1):(3*N)] &lt;- param[&quot;rho&quot;]*data$U[(N+1):(2*N)] + data$epsilon[(2*N+1):(3*N)] data$U[(3*N+1):(T*N)] &lt;- param[&quot;rho&quot;]*data$U[(2*N+1):(3*N)] + data$epsilon[(3*N+1):(T*N)] # potential outcomes in the absence of the treatment data$y0 &lt;- data$mu + data$delta + data$U data$Y0 &lt;- exp(data$y0) # treatment timing # error term data$V &lt;- param[&quot;gamma&quot;]*(data$mu-param[&quot;barmu&quot;])+data$omega # treatment group, with 99 for the never treated instead of infinity Ds &lt;- if_else(data$y0[1:N]+param[&quot;xi1&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),1, if_else(data$y0[1:N]+param[&quot;xi2&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),2, if_else(data$y0[1:N]+param[&quot;xi3&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),3, if_else(data$y0[1:N]+param[&quot;xi4&quot;]+data$V[1:N]&lt;=log(param[&quot;barY&quot;]),4,99)))) data$Ds &lt;- rep(Ds,T) # Treatment status data$D &lt;- if_else(data$Ds&gt;data$time,0,1) # potential outcomes with the treatment # effect of the treatment by group data$baralphatd &lt;- if_else(data$Ds==1,param[&quot;barchi1&quot;], if_else(data$Ds==2,param[&quot;barchi2&quot;], if_else(data$Ds==3,param[&quot;barchi3&quot;], if_else(data$Ds==4,param[&quot;barchi4&quot;],0))))+ if_else(data$Ds==1,param[&quot;kappa1&quot;], if_else(data$Ds==2,param[&quot;kappa2&quot;], if_else(data$Ds==3,param[&quot;kappa3&quot;], if_else(data$Ds==4,param[&quot;kappa4&quot;],0))))*(data$t-data$Ds)*if_else(data$time&gt;=data$Ds,1,0) data$y1 &lt;- data$y0 + data$baralphat + data$baralphatd + if_else(data$Ds==1,param[&quot;theta1&quot;],if_else(data$Ds==2,param[&quot;theta2&quot;],if_else(data$Ds==3,param[&quot;theta3&quot;],param[&quot;theta4&quot;])))*data$mu + data$eta data$Y1 &lt;- exp(data$y1) data$y &lt;- data$y1*data$D+data$y0*(1-data$D) data$Y &lt;- data$Y1*data$D+data$Y0*(1-data$D) Let us estimate the MDE effect for the effect of treatment assigned in period 2. The DID estimator will compare what happens in period 2 and 3 to those assigned to this treatment with what happens to the never treated at the same time. A useful way to get at this issue is to use the same treatment and control groups between periods 1 and 2. Let’s go. # estimating the variances # There are several ways to do thay, but I&#39;m going to use reshape to create variables indexed by time var.y.D &lt;- data %&gt;% filter(time&lt;=2,Ds==2 | Ds==99) %&gt;% select(id,time,y,Ds) %&gt;% pivot_wider(names_from = &quot;time&quot;,values_from = &quot;y&quot;,names_prefix = &quot;y&quot;) %&gt;% mutate( Deltay12 = y2-y1 ) %&gt;% group_by(Ds) %&gt;% summarise( var.Deltay12 = var(Deltay12) ) # proportion of treated p2 &lt;- data %&gt;% filter(time==2,Ds==2 | Ds==99) %&gt;% summarize(pD2=mean(D)) %&gt;% pull(pD2) We can thus compute the minimum detectable effect for various sample sizes and proportions of treated individuals, using \\(\\hatvar{y_{i,2}-y_{i,1}|D_i=1}=\\) 0.09 and \\(\\hatvar{y_{i,2}-y_{i,1}|D_i=0}=\\) 0.06. Let us finally check what Minimum Detectable Effect looks like as a function of \\(p\\) and of sample size. ggplot() + xlim(0,1) + ylim(0,1) + geom_function(aes(color=&quot;100&quot;),fun=MDE.DID.panel.fun,args=list(N=100,varDeltaY1b=as.numeric(var.y.D[1,2]),varDeltaY0b=as.numeric(var.y.D[2,2]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.DID.panel.fun,args=list(N=1000,varDeltaY1b=as.numeric(var.y.D[1,2]),varDeltaY0b=as.numeric(var.y.D[2,2]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.DID.panel.fun,args=list(N=10000,varDeltaY1b=as.numeric(var.y.D[1,2]),varDeltaY0b=as.numeric(var.y.D[2,2]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.DID.panel.fun,args=list(N=100000,varDeltaY1b=as.numeric(var.y.D[1,2]),varDeltaY0b=as.numeric(var.y.D[2,2]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() Figure 7.11: Minimum detectable effect for the 2 periods, 2 groups DID design in panel data The actual proportion of treated in period 2 (vs never treated) is equal, in our sample, to 0.24. With a sample size of \\(N=100\\), we reach a MDE of 0.19. With a sample size of \\(N=1000\\), we reach a MDE of 0.06. With a sample size of \\(N=10000\\), we reach a MDE of 0.02. With a sample size of \\(N=100000\\), we reach a MDE of 0.006. 7.2.2.2.1.2 With repeated cross sections In repeated cross sections, we can use Theorem 4.12 which says that: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta}^Y_{DID_{cs}}-\\Delta^Y_{DID}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y^0_{i,B}|D_i=0}}{(1-p)(1-p_A)} +\\frac{\\var{Y^0_{i,B}|D_i=1}}{p(1-p_A)}\\right.\\\\ &amp; \\phantom{\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(0,\\right.} \\left. +\\frac{\\var{Y^0_{i,A}|D_i=0}}{(1-p)p_A} +\\frac{\\var{Y^1_{i,A}|D_i=1}}{pp_A}\\right). \\end{align*}\\] where \\(p=\\Pr(D_i=1)\\) and \\(p_A\\) is the proportion of observations belonging to the After period. As a result, our estimate of \\(C(\\hat{\\Delta}^Y_{DID_{cs}})\\) in repeated cross sections is: \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{DID_{cs}}) &amp; = \\frac{\\var{Y_{i,2}|D_i=1}}{pp_A}+ \\frac{\\var{Y_{i,1}|D_i=1}}{p(1-p_A)}+\\frac{\\var{Y_{i,2}|D_i=0}}{(1-p)p_A}+ \\frac{\\var{Y_{i,1}|D_i=0}}{(1-p)(1-p_A)}. \\end{align*}\\] The corresponding functions in R are: CE.DID.cs.fun &lt;- function(p,pA,varY1b,varY0b,varY1a,varY0a){ return((varY1a/(p*pA))+(varY0a/((1-p)*pA))+(varY1b/(p*(1-pA)))+(varY0b/((1-p)*(1-pA)))) } MDE.DID.cs.fun &lt;- function(p,pA,varY1b,varY0b,varY1a,varY0a,...){ return(MDE(CE=CE.DID.cs.fun(p=p,pA=pA,varY1b=varY1b,varY0b=varY0b,varY1a=varY1a,varY0a=varY0a),...)) } Example 7.9 Let us see how this formula works out in our example. We are going to keep the same sample and simply ignore the panel data dimension. # estimating the variances var.y.D.cs &lt;- data %&gt;% filter(time&lt;=2,Ds==2 | Ds==99) %&gt;% select(id,time,y,Ds) %&gt;% group_by(time,Ds) %&gt;% summarise( var.y = var(y) ) We can now compute the minimum detectable effect for various sample sizes and proportions of treated individuals, using \\(\\hatvar{y_{i,2}|D_i=1}=\\) 0.27, \\(\\hatvar{y_{i,1}|D_i=1}=\\) 0.19, \\(\\hatvar{y_{i,2}|D_i=0}=\\) 0.38, and \\(\\hatvar{y_{i,1}|D_i=0}=\\) 0.35. Let us finally check what Minimum Detectable Effect looks like as a function of \\(p\\) and of sample size, using \\(p_A=0.5\\). Remark. In order to be fully comparable with the panel data case, we have to account for the fact that \\(N\\) in Theorem 4.12 is \\(N\\times T\\) in Theorem 4.11. For that, we are going to multiply each entry of sample size in the MDE function by \\(T=2\\). # pA pA &lt;- 0.5 Tmult &lt;- 2 # plot ggplot() + xlim(0,1) + ylim(0,1) + geom_function(aes(color=&quot;100&quot;),fun=MDE.DID.cs.fun,args=list(N=Tmult*100,pA=pA,varY1b=as.numeric(var.y.D.cs[1,3]),varY0b=as.numeric(var.y.D.cs[2,3]),varY1a=as.numeric(var.y.D.cs[3,3]),varY0a=as.numeric(var.y.D.cs[4,3]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.DID.cs.fun,args=list(N=Tmult*1000,pA=pA,varY1b=as.numeric(var.y.D.cs[1,3]),varY0b=as.numeric(var.y.D.cs[2,3]),varY1a=as.numeric(var.y.D.cs[3,3]),varY0a=as.numeric(var.y.D.cs[4,3]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.DID.cs.fun,args=list(N=Tmult*10000,pA=pA,varY1b=as.numeric(var.y.D.cs[1,3]),varY0b=as.numeric(var.y.D.cs[2,3]),varY1a=as.numeric(var.y.D.cs[3,3]),varY0a=as.numeric(var.y.D.cs[4,3]),alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.DID.cs.fun,args=list(N=Tmult*100000,pA=pA,varY1b=as.numeric(var.y.D.cs[1,3]),varY0b=as.numeric(var.y.D.cs[2,3]),varY1a=as.numeric(var.y.D.cs[3,3]),varY0a=as.numeric(var.y.D.cs[4,3]),alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() Figure 7.12: Minimum detectable effect for the 2 periods, 2 groups DID design in repeated cross sections The actual proportion of treated in period 2 (vs never treated) is equal, in our sample, to 0.24. With a sample size of \\(N\\times T=200\\), we reach a MDE of 0.47. With a sample size of \\(N\\times T=2000\\), we reach a MDE of 0.15. With a sample size of \\(N\\times T=20000\\), we reach a MDE of 0.05. With a sample size of \\(N\\times T=200000\\), we reach a MDE of 0.015. 7.2.2.2.2 Power estimation for aggregate treatment effects from DID estimators To Do 7.2.3 Power Analysis for Observational Methods Power analysis for observational methods can be based on the results of Theorems 5.4 or 5.8. Let us start with the first one: \\[\\begin{align*} \\sqrt{N}(\\hat\\Delta^Y_{OLS(X)}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y^0_i|X_i,D_i=0}}{1-\\Pr(D_i=1)}+\\frac{\\var{Y^1_i|X_i,D_i=1}}{\\Pr(D_i=1)}\\right). \\end{align*}\\] As a result, our estimate of \\(C(\\hat{\\Delta}^Y_{OM})\\) is: \\[\\begin{align*} \\hat{C}(\\hat{\\Delta}^Y_{OM}) &amp; = \\frac{\\var{Y_{i}|X_i,D_i=0}}{1-\\Pr(D_i=1)}+\\frac{\\var{Y_{i}|X_i,D_i=1}}{\\Pr(D_i=1)}. \\end{align*}\\] The corresponding functions in R are: CE.OM.fun &lt;- function(p,varY1bX,varY0bX){ return((varY1bX/p)+(varY0bX/(1-p))) } MDE.OM.fun &lt;- function(p,varY1bX,varY0bX,...){ return(MDE(CE=CE.OM.fun(p=p,varY1bX=varY1bX,varY0bX=varY0bX),...)) } A key component to compute \\(C(\\hat{\\Delta}^Y_{OM})\\) is the variance of \\(Y_{i}\\) conditional on observed covariates. Example 7.10 Let’s see how this works in our example. We are going to use the same dataset as the one for the fuzzy regression discontinuity design. In order to be able to implement the MDE estimator with observational methods, we need to have access to one date of selection into the treatment and one outcome observed without the treatment (to be credible that no treatment has been given yet). We use as treatment, the treatment decided in period \\(3\\), as outcomes, the ones observed in period \\(2\\) and as controls, the outcomes observed in period \\(1\\). We need to estimate the variance of outcomes \\(Y_{i,2}\\) conditional on \\(Y_{i,1}\\) and \\(D_i\\). One way to do that is to regress \\(Y_{i,2}\\) on \\(Y_{i,1}\\) in both the treated and control groups, and then to compute the variance of the residuals. Let’s do just that. # estimating the conditional variance # putting the data in wide format data.wide &lt;- data %&gt;% select(id,time,y,Ds) %&gt;% pivot_wider(names_from = &quot;time&quot;,values_from = &quot;y&quot;,names_prefix = &quot;y&quot;) # in the treated group regy2y1D1 &lt;- lm(y2 ~ y1,data=filter(data.wide,Ds==3)) vary2y1D1 &lt;- var(regy2y1D1$residuals) # in the control group regy2y1D0 &lt;- lm(y2 ~ y1,data=filter(data.wide,Ds==99)) vary2y1D0 &lt;- var(regy2y1D0$residuals) # proportion of treated p3 &lt;- data %&gt;% filter(time==3,Ds==3 | Ds==99) %&gt;% summarize(pD3=mean(D)) %&gt;% pull(pD3) We can now compute the minimum detectable effect for various sample sizes and proportions of treated individuals, using \\(\\hatvar{y_{i,2}|y_{i,1},D_i=1}=\\) 0.06 and \\(\\hatvar{y_{i,2}|y_{i,1},D_i=0}=\\) 0.06. Let us finally check what Minimum Detectable Effect looks like as a function of \\(p\\) and of sample size. # plot ggplot() + xlim(0,1) + ylim(0,1) + geom_function(aes(color=&quot;100&quot;),fun=MDE.OM.fun,args=list(N=100,varY1bX=vary2y1D1,varY0bX=vary2y1D0,alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;1000&quot;),fun=MDE.OM.fun,args=list(N=1000,varY1bX=vary2y1D1,varY0bX=vary2y1D0,alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;10000&quot;),fun=MDE.OM.fun,args=list(N=10000,varY1bX=vary2y1D1,varY0bX=vary2y1D0,alpha=alpha,kappa=kappa,oneside=FALSE)) + geom_function(aes(color=&quot;100000&quot;),fun=MDE.OM.fun,args=list(N=100000,varY1bX=vary2y1D1,varY0bX=vary2y1D0,alpha=alpha,kappa=kappa,oneside=FALSE)) + scale_color_discrete(name=&quot;N&quot;) + ylab(&quot;MDE&quot;) + xlab(&quot;p&quot;) + theme_bw() Figure 7.13: Minimum detectable effect of observational methods The actual proportion of treated (vs never treated) is equal, in our sample, to 0.31. With a sample size of \\(N=100\\), we reach a MDE of 0.15. With a sample size of \\(N=1000\\), we reach a MDE of 0.05. With a sample size of \\(N=10000\\), we reach a MDE of 0.01. With a sample size of \\(N=100000\\), we reach a MDE of 0.005. 7.3 Limitations of and alternatives to traditional power analysis Up to now, we have focused on traditional power analysis. There are several limitations with that approach that we are going to detail before describing two alternative approaches. What is fun is the alternative approaches I propose can be related to traditional power analysis ex-post and give rise to the same interpretations. 7.3.1 Limitations of traditional power analysis Traditional power analysis suffers from several limitations that we are going to detail here. 7.3.1.1 Traditional power analysis favors publication bias Traditional power analysis is based on Null Hypothesis Significance Testing (NHST): we assume that we are going to use a test for deciding whether the treatment effect of interest is significantly different from zero or not. NHST contributes to publication bias (see Chapter 13): by putting emphasis on results that are statistically significant, NHST contributes to populate the published record with an over-representation of statistically significant results. Since significant effects are larger than the average effect, summaries of the published record using meta-analysis will over-estimate the effect of programs, sometimes severely. Eschewing NHST, including when conducting power analysis, is one of the many ways to curb publication bias. Remark. This is my own position on this and it is not shared widely. My priority is for users of statistical tools to focus on the order of magnitude of sampling noise, not on the position of a noisy measurement (a treatment effect estimate) relative to an arbitrary threshold. Of course, other tools are needed to get rid of publication bias, among registered reports, and they are detailed in Chapter 13. 7.3.1.2 With default settings, traditional power analysis has a very low signal to noise ratio One of my main issues with traditional power analysis is that, with its basic settings that everyone uses, it actually settles on a very low value for the signal to noise ratio. Let me show you why. Let’s take \\(2\\epsilon\\) as our measure of sampling noise, with \\(2\\epsilon=2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\var{\\hat{E}}\\), following Assumption 7.1, with \\(\\delta\\) the confidence level used to build the confidence interval. Let’s use \\(\\beta_A\\) as our measure of the size of the treatment effect, which seems a good idea: it is the value of the treatment effect which seems ex ante most likely. Then we have: Theorem 7.4 (Signal to Noise Ratio of Traditional Power Analysis) With \\(\\hat{E}\\) complying with Assumption 7.1, for a one-sided test of size \\(\\alpha\\) and power \\(\\kappa\\), with a minimum detectable effect of \\(\\beta_A\\), we have: \\[\\begin{align*} \\frac{\\beta_A}{2\\epsilon} &amp; \\approx \\frac{\\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\alpha\\right)\\right)} {2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)} \\end{align*}\\] Proof. Using Theorems 7.2 and Definition 2.1, we have: \\[\\begin{align*} \\frac{\\beta_A}{2\\epsilon} &amp; \\approx \\frac{\\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\alpha\\right)\\right)\\sqrt{\\var{\\hat{E}}}} {2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\sqrt{\\var{\\hat{E}}}} \\\\ &amp; = \\frac{\\left(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\alpha\\right)\\right)} {2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)} \\end{align*}\\] Remark. For a two-sided test, simply replace \\(\\alpha\\) by \\(\\frac{\\alpha}{2}\\) in the formula of Theorem 7.4. Theorem 7.4 shows that the signal to noise ratio of traditional approach power analysis is independent of \\(\\var{\\hat{E}}\\), the precision of the estimator. The signal to noise ratio will always be the same, whatever the precision of the estimator. This is a very strange property: it means that if we follow the advice of traditional power analysis, we will never have an incentive to increase the signal to noise ratio. This could very well not be a problem if the signal to noise ratio implied by traditional power analysis with its default settings (\\(\\alpha=0.05\\) and \\(\\kappa=0.80\\)) was large. What is its size in practice? Let’s compute it. In order to so, let’s define first a function which will compute the signal to noise ratio of traditional power analysis. # functino computing signal to noise ratio signal.to.noise &lt;- function(alpha,kappa,delta,oneside=FALSE){ if (oneside==TRUE){ StoN &lt;- (qnorm(kappa)+qnorm(1-alpha))/(2*qnorm((delta+1)/2)) } if (oneside==FALSE){ StoN &lt;- (qnorm(kappa)+qnorm(1-alpha/2))/(2*qnorm((delta+1)/2)) } return(StoN) } With the basic settings of traditional power analysis (\\(\\alpha=0.05\\) and \\(\\kappa=0.80\\)) and with \\(\\delta=0.95\\), we thus have a signal to noise ratio equal to 0.63 with a one-sided test and to 0.71 with a two-sided test. With the same basic settings and \\(\\delta=0.99\\), we have a signal to noise ratio of 0.48 with a one-sided test and to 0.54 with a two-sided test. So, depending on how we define sampling noise and on the details of the power analysis, traditional power analysis gives rise to estimates with a signal to noise ratio between 0.5 and 0.7. A signal to noise ratio of 0.5 to 0.7 is very imprecise. It means that we accept a procedure which gives us, routinely, estimates of treatment effects where the signal (the treatment effect) is equal to 50% to 70% of the sampling noise. Physicists like to express their estimates as multiples of \\(\\sigma=\\sqrt{\\var{\\hat{E}}}\\), the standard error of the estimated treatment effect. Using the proof of Theorem 7.4, we can show that \\(\\beta_A=\\frac{\\beta_A}{2\\epsilon}2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\sigma\\), with traditional power analysis. When \\(\\frac{\\beta_A}{2\\epsilon}=0.5\\), as with the default settings of traditional power analysis, we have \\(\\beta_A=\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\sigma\\), that is \\(\\beta_A=\\) 2.58 \\(\\sigma\\) with \\(\\delta=0.99\\) and \\(\\beta_A=\\) 1.96 \\(\\sigma\\) with \\(\\delta=0.95\\). So we operate at levels of 2 to 2.5 \\(\\sigma\\), whereas physicists like to operate at \\(5\\sigma\\), that is at levels of precision at least twice as large. How could we reach levels of precision similar to the ones the physicists use? One way would be to require a lower \\(\\alpha\\) as a default setting of power analysis. Using \\(\\alpha=0.01\\) for example gives rise to signal to noise ratios of 0.81 with a one-sided test and to 0.87 with a two-sided test \\(\\delta=0.95\\) and to 0.61 with a one-sided test and to 0.66 with a two-sided test and \\(\\delta=0.99\\). These are insufficient to reach the required precision. Indeed, we are at precision levels of \\(\\beta_A=\\) 3.42 \\(\\sigma\\) with \\(\\delta=0.99\\) and \\(\\beta_A=\\) 3.42 \\(\\sigma\\) with \\(\\delta=0.95\\). If we set \\(\\kappa=0.95\\), we will be operating in precision levels that are closer to the pysicists’ one: \\(\\beta_A=\\) 4.22 \\(\\sigma\\) with \\(\\delta=0.99\\) and \\(\\beta_A=\\) 4.22 \\(\\sigma\\) with \\(\\delta=0.95\\). Remark. All of this analysis is not to say that we should change our default settings for power analysis to \\(\\alpha=0.01\\) and \\(\\kappa=0.95\\). The sample size requirements for this settings might be daunting. In the absence of publication bias, running small experiments is fine since we aim to learn from their aggregation in a meta-analysis and not from any single study. 7.3.1.3 Traditional power analysis is complex Traditional power analysis is not easy to understand and it is actually even harder to communicate to research partners. I once tried to explain the results of our power computations to a partner in the policy sphere. She could not understand the concept of minimum detectable effect. This idea that you’re postulating an effect that you will be able to detect with 80% chance was very weird to her. In our application (as is the case in a lot of applications), we did not have much choice on sample size. The most important thing she was trying to get was the threshold effect above which we would detect statistically significant estimates at the usual rates (5% for a two-sided t-test). She kept asking me for the minimum effect we needed to find that will be deemed different from zero. After thinking about it, I decided to communicate that effect to her, because she was correct in that the success of an intervention is generally measured in terms of statistical significance (much to my chagrin, as will be detailed in Chapter 13). Her requirement actually made a lot of sense, knowing the way statistical testing is used in practice. Remark. In order to find the minimum effect that will trigger a statistically significant result, you can use the formulae in Theorem 7.2 by replacing \\(\\Phi^{-1}\\left(\\kappa\\right)\\) by zero. A related issue with traditional power analysis is that it requires to specify a lot of different parameters. For example, in order to spit out a required sample size, you need to choose the size of the test \\(\\alpha\\), whether it is one-sided or two-sided, its power \\(\\kappa\\) and the MDE you’re trying to detect (or the most plausible effect size ex-ante). In general, researchers and practitioners have no idea how to choose these parameters or how to tailor them to their needs. That is why they rely on default settings most of the time, which gives rise to low precision and signal to noise ratios. 7.3.1.4 Traditional power analysis requires a closed form formula for sampling noise A final limitation of traditional power analysis is that it only applies to estimators that comply with Assumption 7.1: they need to be asymptotically normal and we need to know their asymptotic distribution. That is why I spent a lot of time deriving these closed form formulae when I introduced the properties of each method. Most of these closed form formula do not exist in the literature, but without them, you cannot run traditional power analysis. The problem is that some estimators might not be asymptotically normally distributed or we might not be able to derive the features of their asymptotic distribution. What to do in that case? Let’s see. 7.3.2 An alternative to traditional power analysis The alternative that I propose to traditional power analysis rests on two pillars. Let’s review them before studying three ways to implement them in practice. 7.3.2.1 The first pillar: choosing the level of sampling noise directly I propose to eschew the use of NHST and to focus instead on quantifying sampling noise and the sample size required to reach a given level of precision. This has several advantages. First, we have much less parameters to set. For a given sample size, we can directly estimate the corresponding level of sampling noise. For a given target level of sampling noise, we can directly compute the sample size required to reach it. Second, by eschewing NHST, we also help to focus on the size of sampling noise, a qualitative measure, and not on the position of the estimated effect relative to an arbitrarily set threshold. Third and finally, our approach does not set the signal to noise ratio in stone. It only focuses on the size of sampling noise and leaves completely unspecified the likely size of the effect. In a sense, it asks the researcher and her partners what is the level of noise that they are comfortable with. If the funds are limited and sample size cannot be increased by much, my proposal makes it clear which type precision of we can expect. In practice, the user of my proposal selects a level of sampling noise, either by specifying \\(2\\epsilon\\) or simply \\(\\epsilon\\), and recovers the required sample size. The user can alternatively select a given sample size \\(N\\) and recover the implied sampling noise (either \\(2\\epsilon\\) or \\(\\epsilon\\)). I tend to prefer using \\(\\epsilon\\) as a measure of sampling noise since it can be put on the same level as the treatment effect itself by using \\(\\pm\\epsilon\\) to present precision. But this is a matter of taste, and using \\(2\\epsilon\\) is also fine Under Assumption 7.1, we can derive the sampling noise for a given sample size and the required sample size to reach a given level of sampling noise if we have an asymptotically normal estimator: Theorem 7.5 (Alternative to Traditional Power Analysis) With \\(\\hat{E}\\) complying with Assumption 7.1, we have: \\[\\begin{align*} 2\\epsilon &amp; = 2\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\sqrt{\\var{\\hat{E}}}\\\\ N &amp; = 4\\left(\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\right)^2\\frac{C(\\hat{E})}{(2\\epsilon)^2}, \\end{align*}\\] with \\(\\var{\\hat{E}}=\\frac{C(\\hat{E})}{N}\\). Proof. The proof is a straighforward application of Theorem 7.2 and Definition 2.1. Example 7.11 Let’s see how Theorem 7.5 works in practice. We are going to focus on the case of the brute force randomized controlled trial, but the approach works similarly with all the other estimators we have examined above. Let us first generate some data: param &lt;- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;) set.seed(1234) N &lt;-1000 mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) Ds[YB&lt;=param[&quot;barY&quot;]] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) eta&lt;- rnorm(N,0,sqrt(param[&quot;sigma2eta&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon y0 &lt;- mu + U0 + param[&quot;delta&quot;] alpha.i &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta y1 &lt;- y0+alpha.i Y0 &lt;- exp(y0) Y1 &lt;- exp(y1) # randomized allocation of 50% of individuals Rs &lt;- runif(N) R &lt;- ifelse(Rs&lt;=.5,1,0) y &lt;- y1*R+y0*(1-R) Y &lt;- Y1*R+Y0*(1-R) Let us now compute the required sample size to reach a given precision level \\(\\epsilon\\). # basic formulas sample.size.alt &lt;- function(epsilon,CE,delta){ N &lt;- 4*(qnorm((delta+1)/2)^2)*CE/(2*epsilon)^2 return(round(N)) } epsilon.alt &lt;- function(N,CE,delta){ epsilon &lt;- qnorm((delta+1)/2)*sqrt(CE/N) return(epsilon) } # formulas for the BF design sample.size.alt.BF.fun &lt;- function(p,varYb,...){ return(sample.size.alt(CE=CE.BF.fun(p=p,varYb=varYb),...)) } epsilon.alt.BF.fun &lt;- function(p,varYb,...){ return(epsilon.alt(CE=CE.BF.fun(p=p,varYb=varYb),...)) } Let us now plot the sample size as a function of the required precision in the brute force design for several values of \\(p\\): ggplot() + xlim(0,1) + ylim(0,100000) + geom_function(aes(color=&quot;0.5&quot;),fun=sample.size.alt.BF.fun,args=list(p=0.5,varYb=var(yB),delta=0.99)) + geom_function(aes(color=&quot;0.25&quot;),fun=sample.size.alt.BF.fun,args=list(p=0.25,varYb=var(yB),delta=0.99)) + geom_function(aes(color=&quot;0.1&quot;),fun=sample.size.alt.BF.fun,args=list(p=0.1,varYb=var(yB),delta=0.99)) + scale_color_discrete(name=&quot;p&quot;) + ylab(&quot;N&quot;) + xlab(expression(epsilon)) + scale_y_continuous(trans=log10_trans())+ theme_bw() Figure 7.14: Required sample size for a given level of precision for the Brute Force design As we can see from Figure 7.14, in order to reach a precision level of \\(\\pm 0.5\\) with \\(p=0.5\\), we need a sample size of 83. To reach a precision level of \\(\\pm 0.2\\) with \\(p=0.5\\), we need a sample size of 521. To reach a precision level of \\(\\pm 0.1\\) with \\(p=0.5\\), we need a sample size of 2083. To reach a precision level of \\(\\pm 0.02\\) with \\(p=0.5\\), we need a sample size of 5.2079^{4}. 7.3.2.2 The second pillar: simulating treatment allocation Relying on Theorem 7.5 to implement my proposed approach solves several issues with traditional power analysis, but it still relies on the existence of an asymptotically normal approximation to sampling noise. The second pillar of my proposed approach uses randomly selected sample(s) as a way to estimate sampling noise without resorting to the closed form of an asymptotically normal approximation. I propose to use two distinct approaches: either using one unique random sample or using multiple random samples. Let’s detail these approaches in turn. 7.3.2.2.1 Power analysis using one random sample This approach works well when we have a correct estimator of the sampling noise of our treatment effect but we have not derived its closed form in our particular case, or we have but we do not want to use it because it is too intricate or some components are too difficult to compute. This is the case for example when we use heteroskedasticity-robust standard errors without deriving how they apply to a treatment setting. This approach applies well when we have clustering as well, since most statistical software are able to account for clustering for most estimators, but we generally have not derived the precise formulae in a treatment effect context. In practice, the proposed approach works as follows: We resample the baseline data (with replacement) in order to obtain the target sample size. We allocate the treatment among units as if we were actually implementing the actual selection rule. We estimate the treatment effect \\(\\hat{E}\\) using the estimator \\(E\\) and recover its standard error \\(\\sqrt{\\var{\\hat{E}}}\\). We use our estiamte of \\(\\sqrt{\\var{\\hat{E}}}\\) in order to compute an estimate of \\(\\epsilon\\) (using Theorem 7.5) or an estimate of MDE (using Theorem 7.2). As a consequence, this approach works either with traditional power analysis (it uses a regression to estmate the sandard error instead of the closed form formula) or with my own proposal. Remark. If the survey is clustered or stratified, step 1 above has to account for that. If the treatment allocation is clustered or stratified, both step 2 and step 3 have to account for that. Example 7.12 Let us see how this approach works in our example. I am going to focus again on the brute force design, but there is a lot to learn by using the same approach for other designs and estimators. Let us first write a function that resamples the available data with replacement and then that computes the MDE (for the traditional approach to power analysis) and sampling noise \\(\\epsilon\\) (for my proposed approach). MDE.indirect.BF &lt;- function(N.simul,y,p,alpha,kappa,delta,...){ set.seed &lt;- 1234 resample &lt;- sample(length(y),N.simul,replace=TRUE) y.simul &lt;- y[resample] # randomized allocation of 50% of individuals Rs.simul &lt;- runif(N.simul) R.simul &lt;- ifelse(Rs.simul&lt;=p,1,0) reg.ols.ww.bf.simul &lt;- lm(y.simul~R.simul) varE.simul &lt;- vcovHC(reg.ols.ww.bf.simul,type=&#39;HC2&#39;)[2,2] MDE.simul &lt;- MDE.var(alpha=alpha,kappa=kappa,varE=varE.simul,...) epsilon.simul &lt;- epsilon.alt(N=N.simul,CE=varE.simul*N.simul,delta=delta) results &lt;- c(MDE.simul,epsilon.simul) names(results) &lt;- c(&#39;MDE_simul&#39;,&#39;Epsilon_simul&#39;) return(results) } # computations p&lt;- 0.5 test.indirect &lt;- as.data.frame(t(sapply(N.sample,MDE.indirect.BF,alpha=0.05,kappa=0.8,y=y,p=p,delta=0.99,oneside=FALSE))) test.indirect$N.simul &lt;- N.sample # adding results of traditional approach for comparison test.indirect$MDE_tradi &lt;-sapply(N.sample,MDE.BF.fun,p=p,varYb=var(yB),alpha=0.05,kappa=0.8,oneside=FALSE) test.indirect$Epsilon_tradi &lt;-sapply(N.sample,epsilon.alt.BF.fun,p=p,varYb=var(yB),delta=0.99) # putting results in long form to enable plotting test.indirect.long &lt;- test.indirect %&gt;% pivot_longer(cols=!N.simul,names_to=c(&#39;Type&#39;,&#39;Method&#39;),names_sep=c(&quot;_&quot;),values_to=&#39;Estimate&#39;) %&gt;% mutate( Type=factor(Type,levels=c(&#39;MDE&#39;,&#39;Epsilon&#39;)), Method=recode_factor(Method,&quot;simul&quot;=&quot;Simulation&quot;,&quot;tradi&quot;=&quot;Traditional&quot;), Method=factor(Method,levels=c(&#39;Traditional&#39;,&#39;Simulation&#39;)) ) ggplot(test.indirect.long, aes(x=as.factor(N.simul), y=Estimate, fill=Method)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;) + xlab(&quot;Sample Size&quot;) + theme_bw()+ facet_grid(.~Type) Figure 7.15: MDE, and sample size for the Brute Force design using traditional and novel power analysis What is pretty cool is that both approaches find very similar results for both MDE and \\(\\epsilon\\). What is less expected is that actually MDE and \\(\\epsilon\\) are extremely similar, although they relate to profoundly different concepts: MDE refers to a minimum effect size for detection using NHST with \\(\\alpha=0.05\\) and \\(\\kappa=0.80\\) while \\(\\epsilon\\) refers to the sampling noise to be expected with a given sample size for \\(\\delta=0.99\\). Why does the measure of sampling noise stemming out of my proposed approach ends up being so close to the measure of minimum detectable effect stemming from the traditional approach? Well, this does make sense once you examine the formulae for both terms in Theorems 7.2 and 7.5: both MDE and \\(\\epsilon\\) depend on \\(\\sqrt{\\var{\\hat{E}}}\\). The formula for MDE multiplies \\(\\sqrt{\\var{\\hat{E}}}\\) by \\(\\Phi^{-1}\\left(\\kappa\\right)+\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\) (in the two-sided case) while the formula for \\(\\epsilon\\) multiplies \\(\\sqrt{\\var{\\hat{E}}}\\) by \\(\\Phi^{-1}\\left(\\frac{\\delta+1}{2}\\right)\\). What happens is that these two terms are extremely close to each other with the parameters we have chosen so far. With \\(\\alpha=0.05\\) and \\(\\kappa=0.80\\), the first term is equal to 2.8. With \\(\\delta=0.99\\), the second term is equal to 2.58. Overall, my feeling is that even if the results of two approaches are miraculously similar, they have completely different implications. The traditional approach basically amounts to say that, when you estimate an effect \\(\\beta_A\\pm\\epsilon\\), it is perfectly fine (and actually best practice) that \\(\\beta_A\\) is of the same order of magnitude as \\(\\epsilon\\). In the best case scenario where \\(\\delta=0.95\\), \\(\\frac{\\beta_A}{\\epsilon}=\\) 1.43 so that is \\(\\beta_A\\) is 43% larger than \\(\\epsilon\\). In the case where \\(\\delta=0.99\\), \\(\\frac{\\beta_A}{\\epsilon}=\\) 1.09 so that is \\(\\beta_A\\) is only 33% larger than \\(\\epsilon\\). With the novel approach, you would probably find these settings appalling and utterly insufficient. It means that you are accepting a situation in which \\(\\epsilon\\) is barely smaller than \\(\\beta_A\\). You are in a \\(2\\sigma\\) world. The signal to noise ratio is well below one (\\(\\frac{\\beta_A}{2\\epsilon}=\\) 0.71 with \\(\\delta=0.95\\) and 0.54 with \\(\\delta=0.99\\)). This is a situation in which you have a 20% chance of not detecting the true effect if it has size \\(\\beta_A\\). 20%! Why even run the experiment in that case? I’d be much more comfortable with a 1% to 5% chance. With these settings, you are adding 0.8 to 1.48 \\(\\sigma\\) to your precision. But, even deeper, my proposed approach wants you to stop thinking about probabilities of detection. Just think about noise. Are you fine with an uncertainty of \\(\\pm\\epsilon\\) around your main estimate? Does it make sense for you to run this experiment? If you have no choice (that is sample size has been chosen and the experiment will run), my proposed approach tells you simply that \\(\\pm\\epsilon\\) is the best you can do and that you have to live with it. Maybe it will be insufficient for now, but publishing this result and collecting similar ones will get us closer and closer to the truth. 7.3.2.2.2 Power analysis using randomization inference One final limitation of the previous approach is that it is only valid when we have an estimator of sampling noise that is already built-in out statistical software. What if we do not have such an estimator, or we do not know which one is correct? Well, here, it might help tremendously to use randomization inference. We are going to measure of much the treatment effect varies over randomized allocations of the treatment. This is going to be a good approximation of the magnitude of the sampling noise we will be facing in the real experiment. Remark. One might want to associate ranoomization inference with the bootstrap. That is, draw a new sample with replacement each time you selevct a new treatment allocation. Not using the bootstrap will estimate sampling noise for the sample average treatment effect, while combining the bootstrap with randomization inference will estimate sampling noise for the population treatment effect. Example 7.13 Let’s see how this approach works in our example. Let’s write the code to produce a randomization inference estimate. # treatment effect estimate for one randomized sample MDE.indirect.BF.RI &lt;- function(seed,N.simul,y,p,alpha,kappa,delta,...){ set.seed(seed) resample &lt;- sample(length(y),N.simul,replace=TRUE) y.simul &lt;- y[resample] # randomized allocation of 50% of individuals Rs.simul &lt;- runif(N.simul) R.simul &lt;- ifelse(Rs.simul&lt;=p,1,0) reg.ols.ww.bf.simul &lt;- lm(y.simul~R.simul) estim.RI &lt;- reg.ols.ww.bf.simul$coefficients[[2]] return(estim.RI) } simuls.MDE.indirect.BF.RI &lt;- function(Nsim,...){ MDE.indirect.BF.RI.N &lt;- unlist(lapply(1:Nsim,MDE.indirect.BF.RI,...)) return(MDE.indirect.BF.RI.N) } sf.simuls.MDE.indirect.BF.RI &lt;- function(Nsim,...){ sfInit(parallel=TRUE,cpus=2*ncpus) MDE.indirect.BF.RI.N &lt;- unlist(sfLapply(1:Nsim,MDE.indirect.BF.RI,...)) sfStop() return(MDE.indirect.BF.RI.N) } Nsim &lt;- 1000 #Nsim &lt;- 10 N.sample &lt;- c(100,1000,10000,100000) #N.sample &lt;- c(100,1000,10000) #N.sample &lt;- c(100,1000) #N.sample &lt;- c(100) simuls.sampling.noise.BF.RI &lt;- matrix(unlist(lapply(N.sample,sf.simuls.MDE.indirect.BF.RI,Nsim=Nsim,y=y,p=0.5,alpha=0.05,kappa=0.8,delta=0.99,oneside=FALSE)),ncol=length(N.sample),nrow=Nsim,byrow = FALSE) ## R Version: R version 4.1.1 (2021-08-10) colnames(simuls.sampling.noise.BF.RI) &lt;- N.sample Let’s plot the resulting estimates: par(mfrow=c(2,2)) for (i in 1:length(N.sample)){ hist(simuls.sampling.noise.BF.RI[[i]],breaks=30,main=paste(&#39;N=&#39;,as.character(N.sample[i])),xlab=expression(hat(Delta^y)[WW]),xlim=c(-0.55,0.55)) } Figure 7.16: Distribution of the Brute Force estimator using randomization inference And the resulting estimates of sampling noise: # summary stat simuls.sampling.noise.BF.RI.summary &lt;- as.data.frame(simuls.sampling.noise.BF.RI) %&gt;% pivot_longer(1:4,names_to=&quot;SampleSize&quot;,values_to=&quot;Estimate&quot;) %&gt;% group_by(SampleSize) %&gt;% summarize( Se = sqrt(var(Estimate)) ) %&gt;% mutate( TT = 0, SampleSize=as.numeric(SampleSize) ) ggplot(simuls.sampling.noise.BF.RI.summary, aes(x=as.factor(SampleSize), y=TT)) + geom_pointrange(aes(ymin=TT-Se*1.96, ymax=TT+Se*1.96),color=&#39;red&#39;) + xlab(&quot;Sample Size&quot;)+ theme_bw() Figure 7.17: Sampling noise of the Brute Force estimator using randomization inference We can also compare sampling noise estimated using randomization inference to the one estimated by using only one sample and the one estimated using the traditional approach. # preparing the data test.indirect &lt;- test.indirect %&gt;% left_join(simuls.sampling.noise.BF.RI.summary,by=c(&#39;N.simul&#39;=&#39;SampleSize&#39;)) %&gt;% rename( Epsilon_RI=Se, MDE_RI=TT )%&gt;% mutate( Epsilon_RI = qnorm((0.99+1)/2)*Epsilon_RI ) # putting results in long form to enable plotting test.indirect.long &lt;- test.indirect %&gt;% pivot_longer(cols=!N.simul,names_to=c(&#39;Type&#39;,&#39;Method&#39;),names_sep=c(&quot;_&quot;),values_to=&#39;Estimate&#39;) %&gt;% mutate( Type=factor(Type,levels=c(&#39;MDE&#39;,&#39;Epsilon&#39;)), Method=recode_factor(Method,&quot;simul&quot;=&quot;Simulation&quot;,&quot;tradi&quot;=&quot;Traditional&quot;,&quot;RI&quot;=&quot;Randomization Inference&quot;), Method=factor(Method,levels=c(&#39;Traditional&#39;,&#39;Simulation&#39;,&quot;Randomization Inference&quot;)) ) Let’s plot the result: ggplot(filter(test.indirect.long,Type==&#39;Epsilon&#39;), aes(x=as.factor(N.simul), y=Estimate, fill=Method)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;) + xlab(&quot;Sample Size&quot;) + theme_bw() Figure 7.18: MDE, and sample size for the Brute Force design using traditional, one simulation and randomization inference for power analysis We can see that our estimates of sampling noise using the various approaches are very similar, which is great. "],["sec:placebo.html", "Chapter 8 Placebo Tests", " Chapter 8 Placebo Tests "],["cluster.html", "Chapter 9 Clustering", " Chapter 9 Clustering "],["LaLonde.html", "Chapter 10 LaLonde Tests", " Chapter 10 LaLonde Tests "],["Diffusion.html", "Chapter 11 Diffusion effects", " Chapter 11 Diffusion effects "],["Distribution.html", "Chapter 12 Distributional effects", " Chapter 12 Distributional effects "],["meta.html", "Chapter 13 Meta-analysis and Publication Bias 13.1 Meta-analysis 13.2 Publication bias and site selection bias", " Chapter 13 Meta-analysis and Publication Bias When several research teams work on a similar topic, they obtain and publish several estimates for the same program of for similar programs. For example, teams of doctors regularly test the same treatment on different samples or populations in order to refine the estimated effect. Similarly, economists report on the effects of similar types of programs (Conditional and Unconditional Cash Transfers, Job Training Programs, microcredit, etc) implemented in different countries. Meta-analysis aims at summarizing and synthetizing the available evidence with two main goals in mind: Increasing precision by providing an average estimated effect combining several estimates Explaining variations in treatment effectiveness by relating changes in effect size to changes in sample characteristics. One key issue that meta-analysis has to face – actually, we all have to face it, meta-analysis simply makes it more apparent – is that of publication bias. Publication bias is due to the fact that referees and editors have a marked preference for publishing statistically significant results. The problem with this approach is that the distribution of published results is going to be censored on the left: we will have more statistically significant results in the published record, and as a consequence, the average published result will be an upward biased estimate of the true treatment effect in the population. This is potentially a very severe problem if the amount of censoring due to publication bias is large. Eventually, this hinges on the true distribution of treatment effects: if it is centered on zero or close to zero, we run the risk of having very large publication bias. In this chapter, I present first the tools for meta-analysis, and I then move on to testing and correcting for publication bias. Most of the material presented here stems from the reference book by Hedges and Olkin. When needed, I update this book with new references that I then cite. the R code comes mainly from a wonderful set of slides explaining of the metafor package works. 13.1 Meta-analysis There are several approaches and refinements to meta-analysis. In this section, I am going to present only the most important ones. I’ll defer the reader to other more specialized publications if needed. I first present the basics of meta-analysis: the constitution and structure of the sample. Second, I present the problems of the intuitive “vote-counting” method. Third, I present the methods used when treatment effects are homogeneous across studies, called fixed effects models. Fourth, I move to the methods used when effects are heterogeneous across studies, or random effects models, and the tests used to decide whether we are in a fixed or random effects framework. Fifth, I present meta-regression, that tries to capture treatment effect heterogeneity by including covariates. Finally, I present constantly updated meta-analysis, a way to aggregate results of individual studies as they come. 13.1.1 Basic setting The basic setting for a meta-analysis is that you have access to a list of estimates for the effect of a given program and for their precision. These estimates come from the literature, searching published and unpublished sources alike. This data is usually collected after an extensive search of bibliographic databases. Then, one has to select among all the studies selected by the search the ones that are actualy relevant. This is the most excruciating part of a meta-analysis, since a lot of the studies selected by hte search algorithm are actually irrelevant. Finally, one has to extract from each relevant paper an estimate of the effect of the treatment and of its precision. In general, one tries to choose standardized estimates such as the effect size (see Section 2.1.6 for a definition) and its standard error. After all this process, we should end up with a dataset like: \\(\\left\\{(\\hat{\\theta}_k,\\hat{\\sigma}_k)\\right\\}_{k=1}^N\\), with \\(\\hat{\\theta}_k\\) the estimated effect size, \\(\\hat{\\sigma}_k\\) its estimated standard error, and \\(N\\) the number of included studies. Example 13.1 Let’s see how such a dataset would look like? Let’s build one from our simulations. N.sample &lt;- c(100,1000,10000,100000) N.plot.ES.CLT &lt;- c(10,7,2,1) data.meta &lt;- data.frame(ES=numeric(), se=numeric()) se.ww.CLT.ES &lt;- function(N,v1,v0,p){ return(sqrt((v1/p+v0/(1-p))/N)/v0) } for (k in 1:length(N.sample)){ set.seed(1234) simuls.ww[[k]]$se.ES &lt;- se.ww.CLT.ES(N.sample[[k]],simuls.ww[[k]][,&#39;V1&#39;],simuls.ww[[k]][,&#39;V0&#39;],simuls.ww[[k]][,&#39;p&#39;]) test.ES &lt;- simuls.ww[[k]][sample(N.plot.ES.CLT[[k]]),c(&#39;ES&#39;,&#39;se.ES&#39;)] test.ES$N &lt;- rep(N.sample[[k]],N.plot.ES.CLT[[k]]) data.meta &lt;- rbind(data.meta,test.ES) } data.meta$id &lt;- 1:nrow(data.meta) #data.meta$N &lt;- factor(data.meta$N,levels(N.sample)) ggplot(data.meta, aes(x=as.factor(id), y=ES)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Studies&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() Figure 13.1: Example data set: effect sizes and confidence intervals with \\(\\delta=\\) 0.95 Figure 13.1 shows the resulting sample. I’ve selected 10 studies with \\(N=\\) 100, 7 studies with \\(N=\\) 1000, 2 studies with \\(N=\\) 10^{4}, and 1 study with \\(N=\\) 10^{5}. The studies are represented in that order, mimicking the increasing sample size of studies that accumulate evidence on a treatment, probably with studies with a small sample size at first, and only large studies at the end for the most promising treatments. 13.1.2 Why vote-counting does not work Vote-counting is an alternative to weighted average or meta-regression. The term, coined by Light and Smith (1971), refers to the practice of counting the number of studies that fall under one of three categories: Significant and positive, Insignificant, Significant and negative. A vote-counting approach concludes that there is evidence in favor of the treatment when the majority of effects fall in the first category, that there is no evidence that the treatment has an impact whenthe majority of studies fall in the second category, and that there is evidence that the treatment is defavorable when the majority of studies fall in the third category. In general, majority is evaluated at 33%. The main problem with the vote counting approach is that it does not give more weight to more precise studies. As a consequence, there is a very realistic possibility that the probability of finding the truth decrease as we add more studies to the meta-analysis. Let’s see how this could happen with a simulation taken from HEdges and Olkin’s book. Let \\(p\\) be the probaility that a given result is significant and positive. \\(p\\) depends on the sample size \\(n\\) of the study, and on the true treatment effect, \\(\\theta\\): \\[\\begin{align*} p &amp; = \\int_{C_{\\alpha}}^{\\infty}f(t;\\theta,n), \\end{align*}\\] where \\(f\\) is the density of the test statistic \\(T\\) used to evaluate whether the effect is significant or not, and \\(C_{\\alpha}\\) is the critical value of the test \\(T\\). If \\(n\\) and \\(\\theta\\) are constant over studies (for simplicity), the process of accumulating significant results can be modelled as a binomial with parameter \\(p\\). The probability that over \\(K\\) studies, we have a proportion of significant results larger than a pre-specified threshold (let’s say \\(C_0\\)) is equal to: \\[\\begin{align*} \\Pr(\\frac{X}{K}&gt;C_0) &amp; = \\sum_{k=\\text{int}(C_{0}k)+1}^{K}\\left(\\begin{array}{c}K\\\\k\\end{array}\\right)p^k(1-p)^{K-k}, \\end{align*}\\] where \\(\\text{int}(a)\\) is the greatest integer larger or equal to \\(a\\) and \\(0\\leq C_0\\leq 1\\). In order to use this formula, we simply have to choose a test. Let’s choose the two-sided t-test of a zero treatment effect in an RCT with equal tozes for treated and control groups. In that case, \\(p\\) is simply the power of the test. In Chapter 7, we have derived a formula for the power of this test when \\(N\\) is large: \\[\\begin{align*} \\kappa &amp; = \\Phi\\left(\\frac{\\beta_A}{\\sqrt{\\var{\\hat{E}}}}-\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right), \\end{align*}\\] with \\(\\var{\\hat{E}}=\\frac{C(\\hat{E})}{N}\\) and \\(C(\\hat{E})\\) the variance of the estimator across sampling replications. Let’s make the simplifying assumption that the treatment effect is constant, so that the variance of the estimator is basically the variance of the outcomes. Let’s also assume that we are working with effect sizes, so that our outcomes are normalized to have mean zero and variance one. Under these assumptions, \\(C(\\hat{E})=1\\) and we can implement the power formula: PowerTwoside &lt;- function(betaA,alpha,N,CE=1){ return(pnorm(-betaA/sqrt(CE/N)-qnorm(1-alpha/2))+pnorm(betaA/sqrt(CE/N)-qnorm(1-alpha/2))) } PowerTwosideStudent &lt;- function(betaA,alpha,N,CE=1){ return(pt(-betaA/sqrt(CE/N)-qnorm(1-alpha/2),df=N-1)+pt(betaA/sqrt(CE/N)-qnorm(1-alpha/2),df=N-1)) } VoteCounting &lt;- function(betaA,C0,K,...){ return(pbinom(q=C0*K,size=K,prob=PowerTwosideStudent(betaA=betaA,...),lower.tail = FALSE)) } PowerTwosideStudent(betaA=0.1,alpha=0.05,N=300) VoteCounting(C0=.33,K=3000,betaA=0.1,alpha=0.05,N=300) Sample.size &lt;- c(20,50,100,200,300) BetaA &lt;- seq(0.1,1.5,by=0.1) K.list &lt;- c(10,20,30,50,100,1000) power.vote &lt;- data.frame(&quot;Power&quot;= 0,&#39;BetaA&#39;= 0,&#39;N&#39;= 0,&#39;K&#39;= 0) #power.vote &lt;- sapply(BetaA,VoteCounting,C0=.33,K=K.list[[1]],alpha=0.05,N=Sample.size[[1]]) #power.vote &lt;- cbind(power.vote,BetaA,Sample.size[[1]],K.list[[1]]) for (j in (1:length(K.list))){ for (k in (1:length(Sample.size))){ power.vote.int &lt;- sapply(BetaA,VoteCounting,C0=.33,K=K.list[[j]],alpha=0.05,N=Sample.size[[k]]) power.vote.int &lt;- cbind(power.vote.int,BetaA,Sample.size[[k]],K.list[[j]]) colnames(power.vote.int) &lt;- c(&#39;Power&#39;,&#39;BetaA&#39;,&#39;N&#39;,&#39;K&#39;) power.vote &lt;- rbind(power.vote,power.vote.int) } } power.vote &lt;- power.vote[-1,] power.vote$K.int &lt;- power.vote$K power.vote$K &lt;- as.factor(power.vote$K) #ggplot(data=filter(power.vote,K==10),aes(x=N,y=Power,group=as.factor(BetaA),shape=as.factor(BetaA),color=as.factor(BetaA)))+ # geom_line()+ # geom_point() ggplot(data=filter(power.vote,BetaA==0.1),aes(x=N,y=Power,group=K,shape=K,color=K))+ geom_line()+ geom_point()+ xlab(&quot;N (BetaA=0.1)&quot;)+ ylab(&quot;Detection probability of the vote counting rule&quot;)+ theme_bw() + scale_fill_discrete(name=&quot;K&quot;) ggplot(data=filter(power.vote,BetaA==0.2),aes(x=N,y=Power,group=K,shape=K,color=K))+ geom_line()+ geom_point()+ xlab(&quot;N (BetaA=0.2)&quot;)+ ylab(&quot;Detection probability of the vote counting rule&quot;)+ theme_bw() Figure 13.2: Detection probability of the vote counting rule Figure 13.2 shows that the vote counting rule has a very inconvenient property: when the power of the test is lower than 33%, the probability that the vote counting rule detects a true effect decreases with the number of studies included in the meta-analysis, and converges to zero when the number of studies gets large. For example, when \\(N=100\\) and \\(\\beta_A=0.1\\), the probability of detecting the effect using the vote counting method is equal to 0.076 with \\(K=10\\) studies and decreases to 0.043 when \\(K=20\\), and 0 when \\(K=100\\). The pattern is reverse for more powerful studies, such as when \\(N=300\\) and \\(\\beta_A=0.1\\) or when \\(N=100\\) and \\(\\beta_A=0.2\\). The intuition for this result is that the vote counting method does not average out the sampling noise in each individual study. 13.1.3 Meta-analysis when treatment effects are homogeneous: the fixed effects approach The key idea of meta-analysis with fixed effects is to combine the effect size estimates stemming from different studies, weighing them by their relative precision. Definition 13.1 (Weighted Meta-Analytic Estimator) The weighted meta-analytic estimator is \\[ \\bar{\\theta} = \\sum_{k=1}^Nw_k\\hat{\\theta}_k \\text{ with } w_k=\\frac{\\frac{1}{\\hat{\\sigma}^2_k}}{\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k}}. \\] Under some assumptions, the estimator \\(\\bar{\\theta}\\) converges to the true effect of the treatment. Let’s delineate these assumptions. Definition 13.2 (Homogeneous Treatment Effect) Each \\(\\hat{\\theta}_k\\) converges to the same treatment effect \\(\\theta\\). Assumption 13.2 imposes that all the studies have been drawn from the same population, where the treatment effect is a constant. Definition 13.3 (Independence of Estimates) The \\(\\hat{\\theta}_k\\) are independent from each other. Assumption 13.3 imposes that all the studies estimates are independent from each other. That means that they do not share sampling units and that they are not affected by common shocks. Under these assumptions, we can show two important results. Theorem 13.1 (Consistency of the Weighted Meta-Analytic Estimator) Under Assumptions 13.2 and 13.3, when the sample size of each study goes to infinity, \\(\\bar{\\theta}\\approx\\theta\\). Proof. The Law of Large Number applied to each sample gives the fact that the estimator is a weighted sum of \\(\\theta\\) with weights summing to one. Hence the result. Theorem 13.1 says that the error we are making around the true effect of the treatment goes to zero as the sample size in each study decrease. This is great: aggregating the studies is thus going to get us to the truth. Remark. One interesting question is whether Theorem 13.1 also holds when the size of the individual studies remains fixed and the number of studies goes to infinity, which seems a more natural way to do asymptotics in a meta-analysis. I’m pretty sure that is the case. Indeed, the studies constitute an enormous sample in which we take the average outcomes of the treated on the one hand and of the untreated on the other. These averages differ from the usual ones in the Law of Large Numbers only by the fact that the weights are not equal to one. But they (i) are independent from the outcomes and (ii) sum to one. As a consequence, I’m pretty sure the Law of Large Numbers also apply in this dimension. Check if this is a consequence of Kolmogorov’s Law of Large Numbers. Theorem 13.2 (Asymptotic Distribution of the Weighted Meta-Analytic Estimator) Under Assumptions 13.2 and 13.3, when the sample size of each study goes to infinity, \\(\\bar{\\theta}\\stackrel{d}{\\rightarrow}\\mathcal{N}(\\theta,\\sigma^2)\\), with \\[ \\sigma^2 = \\frac{1}{\\sum_{k=1}^N\\frac{1}{\\sigma^2_k}}. \\] Proof. To do using the Lindenberg-Levy version of the Central Limit Theorem. Theorem 13.2 shows that the distribution of the weighted meta-analytic estimator converges to a normal, which is very convenient in order to compute sampling noise. In order to obtain an estimator \\(\\hat{\\sigma}^2\\) of the variance of the meta-analytic estimator, we can simply replace the individual variance terms by their estimates: \\(\\hat{\\sigma}_k^2\\). Remark. I’ve taken Theorem 13.2 from Hedges and Olkin, but I think it is much more interesting and correct when the asymptotics goes in the number of studies. Remark. According to Hedges and Olkin, the weighted meta-analytic estimator is the most efficient estimator available. wmae &lt;- function(theta,sigma2){ return(c(weighted.mean(theta,(1/sigma2)/(sum(1/sigma2))),1/sum(1/sigma2))) } Example 13.2 Let’s use our meta-analytic estimator to estimate the effect size of our treatment. The estimated treatment effect size with our sample is 0.19 \\(\\pm\\) 0.02. A very simple way to implement such an estimator in R is to use the rma command of the metafor package. data.meta$var.ES &lt;- data.meta$se.ES^2 meta.example.FE &lt;- rma(yi = data.meta$ES,vi=data.meta$var.ES,method=&quot;FE&quot;) summary(meta.example.FE) ## ## Fixed-Effects Model (k = 20) ## ## logLik deviance AIC BIC AICc ​ ## 16.1375 12.7060 -30.2751 -29.2793 -30.0529 ## ## I^2 (total heterogeneity / total variability): 0.00% ## H^2 (total variability / sampling variability): 0.67 ## ## Test for Heterogeneity: ## Q(df = 19) = 12.7060, p-val = 0.8533 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## 0.1950 0.0079 24.6975 &lt;.0001 0.1795 0.2104 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 As seen above, the metafor package yields a meta-analytic estimate of 0.19 \\(\\pm\\) 0.02, as we have found using the weighted meta-analytic estimator. It is customary to present the results of a meta-analysis using a forest plot. A forest plows all the individual estimates along with the aggregated estimate. Figure 13.3 presents the forest plot for our example using the very convenient forest function in the metafor package: forest(meta.example.FE,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=&#39;Estimated Meta-analytic Parameter&#39;) Figure 13.3: Example data set: forest plot 13.1.4 Meta-analysis when treatment effects are heterogeneous: the random effects approach One key assumption that we have just made so far is that of homogeneous treatment effect. We have worked under the assumption that each study was drawn from the same population, where the treatment effect is a constant. Why would the treatment effects differ in each study? We do not study exactly the same treatment, but a family of similar treatments. Each individual study covers a particular iteration of the treatment, each with its idiosyncratic parameterization. The particular value of the transfer in a Cash Transfer program, or of the conditions to receive it, or the length of payment, whether it is in one time or over some period, might make a difference, for example. The same is true for Job Training Programs, Payments for Environmental Services, microcredit, graduation programs, nudges, etc. Actually, most programs that economists study differ from one implementation to the next. In psychology and medecine, most treatments are accompanied by a rigorous protocol that makes them much more homogeneous. The population on which the treatment is applied varies. For example, similar Job Training Programs or microcredit initiatives might have very different outcomes depending on the business cycle. Education interventions might have very different effects depending on the background of the students on which they are tested. A drug might interact with patients’ phenotype and genotype to generate different effects, and the populations from which the experimental samples are drawn do not have to be similar. As an extreme example, think of a vaccine tested in a population where the prevalence of a disease is null. The treatment effect is zero. Now, test the vaccine in a population where the disease is endemic: the treatment effect might be huge. When each study draws a treatment effect from a distinct population, meta-analysis has to take into account that treatment effects are heterogeneous. The main consequence of treatment effect heterogeneity is that the weighting approach we have used so far underestimates the uncertainty around the true effect, since it does not acknowledge that there is additional variation within each study. There are two main ways to account for heterogeneity in meta-analysis: Random effects allowing for additional random noise in each study. Meta-regression trying to capture the heterogeneity in treatment effects with observed covariates. In this section, we study the random effects estimator, and the next section will cover the meta-regression estimator. Before implementing the random effects estimator, we need to decide whether there is heterogeneity in treatment effects or not. Generate noise right now and show the plot. 13.1.4.1 Estimating the heterogeneity of treatment effects A necessary first step is to estimate the variance in treatment effects that is due to treatment effect heterogeneity, beyond sampling noise. The observed effect size estimate for a given study \\(k\\) is modelled as follows: \\[\\begin{align*} \\hat{\\theta}_k &amp; = \\alpha + \\epsilon_k + \\nu_k, \\end{align*}\\] where \\(\\epsilon_k\\) is due to sampling noise and \\(\\nu_k\\) is due to the heterogeneity in effect sizes across sites, while \\(\\alpha\\) is the average of the effect size accross all populations. We denote the variance of \\(\\nu_k\\) as \\(\\tau^2\\). \\(\\nu_k\\) is the random effect that gives the random effects approach its name. There are several ways to estimate this variation. I’m gooing to start with the most intuitive one, Hedges’ estimator, and I’ll then move on to the other ones available. I’ll conclude with the formal statistical tests used to decide whether treatment effects are heterogeneous or not. 13.1.4.1.1 Hedges’ estimator of treatment effect heterogeneity Since Hedges, \\(\\tau^2\\) is estimated as the residual variance in effect sizes that is not explained by sampling noise. In order to compute this estimator, first estimate the overall variance in \\(\\hat{\\theta}_k\\), then estimate the component of the variance due to sampling noise and finally take the difference between the two. Hedges’ estimator of the overall variance in effect sizes is: \\[\\begin{align*} \\hat{\\tau}^2 &amp; = \\hat{\\sigma}^2_{tot}-\\hat{\\sigma}^2_{\\epsilon}, \\end{align*}\\] with \\[\\begin{align*} \\hat{\\sigma^2_{tot}} &amp; = \\frac{1}{N}\\sum_{k=1}^N(\\hat{\\theta}_k-\\bar{\\theta}_u)^2\\\\ \\bar{\\theta}_u &amp; = \\frac{1}{N}\\sum_{k=1}^N\\hat{\\theta}_k \\\\ \\hat{\\sigma^2_{\\epsilon}} &amp; = \\frac{1}{N}\\sum_{k=1}^N\\hat{\\sigma}_k^2. \\end{align*}\\] Remark. Hedges actually uses the unbiased estimator adapted to small samples and thus replaces \\(N\\) by \\(N-1\\) in the first equation. Example 13.3 Let’s compute Hedges’ esimator for \\(\\tau^2\\) in our numerical example. Let’s first define a few functions to compute each part: tau.2 &lt;- function(theta,vartheta){ return(var(theta)-mean(vartheta)) } tau.2.theta &lt;- tau.2(data.meta$ES,data.meta$se.ES^2) Our estimate of \\(\\tau^2\\) in our example is thus -0.03. This estimate is small, suggesting that there is no additional variance in the treatment effects on top of sammling variation, as we know is the case and has already been suggested by the results of the \\(Q\\) statistic. Let’s now create a new sample of effect sizes where we add noise to each estimate stemming not from sampling, but from heterogeneity in treatment effects across sites and studies. tau &lt;- c(0.5,1) set.seed(1234) data.meta$theta.1 &lt;- data.meta$ES + rnorm(nrow(data.meta),mean=0,sd=tau[[1]]) data.meta$theta.2 &lt;- data.meta$ES + rnorm(nrow(data.meta),mean=0,sd=tau[[2]]) I’ve simulated two new vectors of estimates for \\(\\theta\\), both obtained adding a mean-zero normally distributed noise to the initial estimates of \\(\\theta\\), one with a standard deviation of 0.5 and the other of 1. Let’s visualize our two new datasets: ggplot(data.meta, aes(x=as.factor(id), y=ES)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(expression(paste(&#39;Studies&#39;,tau^2,&#39;=&#39;,0,sep=&#39; &#39;)))+ ylab(&quot;Effect size&quot;)+ theme_bw()+ ylim(-2,2) ggplot(data.meta, aes(x=as.factor(id), y=theta.1)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=theta.1-qnorm((delta.2+1)/2)*se.ES, ymax=theta.1+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(expression(paste(&#39;Studies&#39;,tau^2,&#39;=&#39;,tau[[1]],sep=&#39; &#39;)))+ ylab(&quot;Effect size&quot;)+ theme_bw()+ ylim(-2,2) ggplot(data.meta, aes(x=as.factor(id), y=theta.2)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=theta.2-qnorm((delta.2+1)/2)*se.ES, ymax=theta.2+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(expression(paste(&#39;Studies&#39;,tau^2,&#39;=&#39;,tau[[2]],sep=&#39; &#39;)))+ ylab(&quot;Effect size&quot;)+ theme_bw()+ ylim(-2,2) Figure 13.4: Datasets with treatment effect heterogeneity Let’s see now how Hedge’s estimator performs: tau.2.theta.1 &lt;- tau.2(data.meta$theta.1,data.meta$se.ES^2) tau.2.theta.2 &lt;- tau.2(data.meta$theta.2,data.meta$se.ES^2) Hedges’ estimates of \\(\\tau^2\\) in our examples are thus 0.21 and 0.73 respectively, while the true values are, respectively 0.25 and 1. 13.1.4.1.2 Other estimators of treatment effects heterogeneity \\(\\tau^2\\) is a pretty difficult measure of treatment effect heterogeneity to interpret. That’s why other indicators have been built that are easier to interpret. We are going to review several of them in this section. The first alternative or complement to \\(\\tau^2\\) is Higgin’s \\(I^2\\): \\[\\begin{align*} I^2 &amp; = \\frac{Q-(N-1)}{Q}*100 \\end{align*}\\] The interpretation of \\(I^2\\) is pretty straightforward: it is the distance between the actual value of the \\(Q\\) statistic and its value under the null of treatment effect homogeneity (it is equal to the number of studies \\(N\\), with a correction for degress of freedom). It can also be interpreted as the fraction of the overall variance (remember that \\(Q\\) is the sum of variance ratios) that is not explained by within study sampling noise. Another complement to \\(\\tau^2\\) is \\(H^2\\): \\[\\begin{align*} H^2 &amp; = \\frac{Q}{N-1} \\end{align*}\\] If \\(H^2\\) is above one, then there is unexplained heterogeneity, again by the fact that \\(Q\\) has mean \\(N-1\\) under the null of treatment effect homogeneity. Finally, we can also define the Intra Class Correlation (\\(ICC\\)), which precisely measures the share of total variance attributable to treatment effect heterogeneity: \\[\\begin{align*} ICC &amp; = \\frac{\\tau^2}{\\tau^2+S^2} \\end{align*}\\] Where \\(S^2\\) is the amount of variance due to sampling noise. An estimator for \\(S^2\\) is: \\[\\begin{align*} S^2 &amp; = \\frac{(N-1)\\sum_{k=1}^N\\frac{1}{\\sigma^2_k}}{(\\sum_{k=1}^N\\frac{1}{\\sigma^2_k})^2-\\sum_{k=1}^N(\\frac{1}{\\sigma^2_k})^2}. \\end{align*}\\] I do not understand the formula for \\(S^2\\). Why does it estimate what we want? I’d take the average variance. \\(ICC\\) and \\(I^2\\) are related by the following very simple relation: \\(I^2=ICC*100\\). Example 13.4 Let’s see how these three estimators look like in our example. The cool thing is that rma computes these estimators by default, so that a simple call to summary() is going to show them. The default random effects estimator is REML, which is deemed to be the best of them all according to simulations (Viechtbauer, 2002). meta.example.RE.ES &lt;- rma(yi = data.meta$ES,vi=data.meta$var.ES) meta.example.RE.theta.1 &lt;- rma(yi = data.meta$theta.1,vi=data.meta$var.ES) meta.example.RE.theta.2 &lt;- rma(yi = data.meta$theta.2,vi=data.meta$var.ES) tau2.hat &lt;- c(meta.example.RE.ES$tau2,meta.example.RE.theta.1$tau2,meta.example.RE.theta.2$tau2) I2 &lt;- c(meta.example.RE.theta.1$I2,meta.example.RE.theta.2$I2,meta.example.RE.ES$I2) H2 &lt;- c(meta.example.RE.theta.1$H2,meta.example.RE.theta.2$H2,meta.example.RE.ES$H2) # illustration of results returned by summary summary(meta.example.RE.theta.2) ## ## Random-Effects Model (k = 20; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## -24.7342 49.4684 53.4684 55.3573 54.2184 ## ## tau^2 (estimated amount of total heterogeneity): 0.7582 (SE = 0.2608) ## tau (square root of estimated tau^2 value): 0.8708 ## I^2 (total heterogeneity / total variability): 99.59% ## H^2 (total variability / sampling variability): 244.24 ## ## Test for Heterogeneity: ## Q(df = 19) = 1932.1460, p-val &lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## 0.5964 0.2006 2.9728 0.0030 0.2032 0.9896 ** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The estimate of \\(I^2\\) in our example is of 0 when \\(\\tau^2\\) is equal to 0, of 98.77 when \\(\\tau^2\\) is equal to 0.25 and of 99.59 when \\(\\tau^2\\) is equal to 1. The estimate of \\(H^2\\) in our example is of 1 when \\(\\tau^2\\) is equal to 0, of 81.45 when \\(\\tau^2\\) is equal to 0.25 and of 244.24 when \\(\\tau^2\\) is equal to 1. 13.1.4.1.3 Testing for the homogeneity of treatment effects What can we do in order to test whether there is heterogeneity in treatment effects? One way is to build an index comparing the usual variation in treatment effects stemming from sampling noise to the one stemming from variation between studies. If we find that the variation between studies dwarves the variation due to sampling noise in each study, then there is some heterogeneity for sure. One statistics that does that is the \\(Q\\) statistic where the variation in treatment effects between studies is estimated using the difference between the individual effect size and the average one squared: \\[\\begin{align*} Q &amp; = \\sum_{k=1}^N\\frac{(\\hat{\\theta}_k-\\bar{\\theta})^2}{\\hat{\\sigma}^2_k}. \\end{align*}\\] What is great with the \\(Q\\) statistic is that, under the Null hypothesis that all the treatment effects are equal to the same constant, it is distributed asymptotically as a \\(\\chi^2\\) distribution with \\(N-1\\) degrees of freedom, and thus it can directly be used to test for the hypothesis of homogeneous treatment effects. Example 13.5 In our example, we have already computed the \\(Q\\) statistic when we have used the rma function in the metafor package. In order to access it, we just need to extract it using meta.example.FE$QE for the \\(Q\\) statistic and meta.example.FE$QEp for its p-value. The \\(Q\\) statistic in our example has value 12.71, with associated p-value 0.85. We end up not rejecting homogeneity, which is correct. Remark. The problem with using test statistics for testing for treatment effect homogeneity is that, when precision increases, we might end up rejecting homogeneity despite the fact that it is there. Test with \\(N=10^5\\). Remark. The \\(\\chi^2\\) distribution with \\(k\\) degrees of freedom is asymptotically distributed as a normal with mean \\(k\\) and variance \\(2k\\). So, when \\(k\\) is large, a good rule of thumb for assessing the homogeneity of the treatment effect estimates is to compare the \\(Q\\) statistic to the number of studies. If it is much larger, homogeneity is probably not guaranteed. 13.1.4.2 Random effects models Hedges proposes a new estimator for the average effect of the treatment, an estimator that accounts for the additional noise due to heterogeneous treatment effects accross sites. Definition 13.4 (Hedges Weighted Meta-Analytic Estimator) Hedges weighted meta-analytic estimator for in the presence of random effects is \\[ \\bar{\\theta}_H = \\sum_{k=1}^Nv_k\\hat{\\theta}_k \\text{ with } v_k=\\frac{\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}}{\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}}. \\] Hwmae &lt;- function(theta,sigma2,tau2){ return(c(weighted.mean(theta,(1/sigma2)/(sum(1/(sigma2+tau2))),1/sum(1/sigma2+tau2)))) } ES.H.theta.1 &lt;- Hwmae(data.meta$theta.1,data.meta$se.ES^2,tau.2.theta.1) ES.H.theta.2 &lt;- Hwmae(data.meta$theta.2,data.meta$se.ES^2,tau.2.theta.2) Example 13.6 Let’s see how Hedges estimator performs in our example. Hedges’ estimates of the average effect size is equal to 0.3 and 0.65 respectively, while the true value is 0.2. The main problem with Hedges’ estimator when treatment effects are heterogeneous is that very large effects for the more precise estimators dramatically affect the estimate. Remark. Hedges’ estimate of \\(\\tau^2\\) is slightly negative, which is problem, since a variance is always positive. Other estimators of \\(\\tau^2\\) have been proposed in the literature to account for this fact and to respond to various shortcomings of Hedges’ approach. We will present them succinctly since they are part of the metafor package. These other estimators have bames such as . They are very well described in this amazing set of slides. Besides Hedges’ (denoted ‘HE’ in R), the other estimators are named: DerSimonian-Laird (‘DL’) Hunter-Schmidt (‘HS’) Sidik-Jonkman (‘SJ’) Maximum-likelihood (‘ML’) Restricted maximum-likelihood (‘REML’) Empirical Bayes (‘EB’) I’ll detail how they work later. Detail other estimators of tau. Example 13.7 For the moment, let’s see how they perform in our numerical example. estimators &lt;- c(&quot;DL&quot;, &quot;REML&quot;, &quot;HE&quot;, &quot;HS&quot;, &quot;SJ&quot;, &quot;ML&quot;, &quot;EB&quot;) meta.example.RE.theta.1.tau2 &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=method)$tau2)}) meta.example.RE.theta.2.tau2 &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.2,vi=data.meta$var.ES,method=method)$tau2)}) #meta.example.RE &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=method))}) #meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;)) result.RE &lt;- data.frame(Method=rep(estimators,2),tau2hat=c(meta.example.RE.theta.1.tau2,meta.example.RE.theta.2.tau2),tau2=c(rep(tau[[1]]^2,length(estimators)),rep(tau[[2]]^2,length(estimators)))) ggplot(data=result.RE, aes(x=Method, y=tau2hat, fill=as.factor(tau2))) + geom_bar(stat=&quot;identity&quot;, position=position_dodge())+ ylim(0,1) Figure 13.5: Various estimators of \\(\\tau^2\\) We are ready to estimate the overall treatment effect using random effects. estimators &lt;- c(&quot;DL&quot;, &quot;REML&quot;, &quot;HE&quot;, &quot;HS&quot;, &quot;SJ&quot;, &quot;ML&quot;, &quot;EB&quot;) meta.example.RE.theta.1.ES &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=method)$beta)}) meta.example.RE.theta.2.ES &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.2,vi=data.meta$var.ES,method=method)$beta)}) #meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;)) result.RE$ES.RE &lt;- c(meta.example.RE.theta.1.ES,meta.example.RE.theta.2.ES) ggplot(data=result.RE, aes(x=Method, y=ES.RE, fill=as.factor(tau2))) + geom_bar(stat=&quot;identity&quot;, position=position_dodge()) Figure 13.6: Various estimators of the treatment effect with random effects Add error bars here. 13.1.4.2.1 Presenting the results of a random effects meta-analysis In order to illustrate the results of a random effects meta-analysis, you can first show the forest plot. Let’s see how it works in our example: forest(meta.example.RE.ES,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=expression(paste(&#39;Estimated Meta-analytic Parameter,&#39;,tau^2,0,sep=&#39; &#39;))) forest(meta.example.RE.theta.1,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=expression(paste(&#39;Estimated Meta-analytic Parameter,&#39;,tau^2,&#39;=&#39;,&#39;0.25&#39;,sep=&#39; &#39;))) forest(meta.example.RE.theta.2,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=expression(paste(&#39;Estimated Meta-analytic Parameter,&#39;,tau^2,&#39;=&#39;,&#39;1&#39;,sep=&#39; &#39;))) Figure 13.7: Forest plots with random effects Another very nice and useful graphical presentation device is a radial (or Galbraith) plot. It relates the invserse of the standard errors to the effect sizes normalized by their standard errors. Each data point is also related a radius by the line passing through the origin. The Radial plot enables to visualize the noise in the dataset, and is especially useful when comparing a fixed and a random effects estimator for the same study. meta.example.FE.theta.1 &lt;- rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=&quot;FE&quot;) radial(meta.example.FE.theta.1) radial(meta.example.RE.theta.1) Figure 13.8: Radial plots with fixed and random effects \\(\\tau^2=\\) 0.25 Figure 13.8 shows how the mechanics of the fixed effects estimator differs from the mechanics of the random effects one. In the presence of treatment effect heterogeneity, the fixed effect estimator faces two issues: It gives too much weight to very precise estimators. The random effects estimator undoes part of this importance by adding \\(\\tau^2\\) to the weights of each observation. It overestimates overall precision by ignoring the sampling variance stemming from treatment effect heterogeneity across sites. The random effects estimator corrects for that by estimating \\(\\tau^2\\) and adding it to the estimate of the total variance of the treatment effect. Example 13.8 Let’s see how big a difference using random versus fixed effects does to the estimation of treatment effects. Let’s plot the two forest plots for the example with \\(\\tau=\\) 0.25. forest(meta.example.FE.theta.1,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=&#39;Estimated Meta-analytic Parameter&#39;) forest(meta.example.RE.theta.1,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=&#39;Estimated Meta-analytic Parameter&#39;) Figure 13.9: Fixed vs random effects with \\(\\tau^2=\\) 0.25 Figure 13.9 clearly shows that the inclusion of \\(\\tau^2\\) in the weights and precision estimates makes a huge difference to the meta-analytic estimate. The fixed effects estimator yields an estimate of our treatment effect of 0.3 \\(\\pm\\) 0.02. The random effects estimator yields an estimate of our treatment effect of 0.13 \\(\\pm\\) 0.24. With \\(\\tau^2=\\) 1, the random effects estimator yields an estimate of our treatment effect of 0.6 \\(\\pm\\) 0.39. Remember that the true effect size of our treatment is 0.2. With \\(\\tau^2=\\) 1, the random effects estimator barely contains the truth in its 95 \\(\\%\\) confidence interval. 13.1.5 Meta-regression A Meta-regression tries to explain the heterogeneity in treatment effects across studies using observed covariates. The idea is to identify characteristics of the studies or of the sites that are correlated with how treatment effects vary. 13.1.5.1 The Meta-regression model The main equation that we want to estimate is as follows (Raudenbusch, 2009): \\[\\begin{align} \\hat{\\theta}_k &amp; = \\mathbf{X}_k \\mathbf{\\beta} + \\epsilon_k + \\nu_k, \\end{align}\\] Center regressors at the mean? where \\(\\mathbf{X}_k\\) is a line vector containing the value of the variables suspected to be correlated with treatment effect heterogeneity for study \\(k\\) and \\(\\mathbf{\\beta}\\) is a column vector of the corresponding coefficients, of the same dimension as \\(\\mathbf{X}_k\\). \\(\\mathbf{X}_k\\) contains a \\(1\\) as its first term, so that \\(\\beta_0\\), the first component of the vector \\(\\mathbf{\\beta}\\) measures the effect of the treatment when all other regressors are set to zero. It might thus be a good idea to set the regressors as deviations around their means if we want \\(\\beta_0\\) to capture the average effect of the treatment. The error term \\(\\epsilon_k\\) captures the heterogeneity in estimated effect sizes that is due to sampling noise. The error term \\(\\nu_k\\) captures the heterogeneity in effect sizes across sites that remains after conditioning on \\(\\mathbf{X}_k\\). In addition, it is generally assumed that \\(\\epsilon_k\\sim\\mathbf{N}(0,\\hat{\\sigma}^2_k)\\) and \\(\\nu_k\\sim\\mathbf{N}(0,\\tau^2)\\). This model is in general called the mixed effects linear model. It contains at the same time fixed effects captured by \\(\\mathbf{X}_k \\mathbf{\\beta}\\) and random effects captured by \\(\\nu_k\\). Setting \\(\\tau^2\\) to zero generates a fixed effects linear model. It is possible, as usual, to test for whether \\(\\tau^2\\) is null or not, which is a test of whether the added covariates fully capture the heterogeneity in treatment effects across studies. 13.1.5.2 Estimating the meta-regression model There are at least four ways to estimate the meta-regression model: Weighted Least squares (WLS): mostly used for fixed effects models, where \\(\\tau^2\\) is assumed to be zero. Full Maximum Likelihood Estimator (FMLE) Restricted Maximum Likelihood Estimator (RMLE) Method Of Moments (MOM) 13.1.5.2.1 Weighted Least Squares The Weighted Least Squares (WLS) estimator imposes that \\(\\tau^2=0\\). It is thus appropriate when we have a fixed effects linear model. It is also used as a starting point for estimating the other models. The WLS estimator of \\(\\mathbf{\\beta}\\) is written as follows: \\[\\begin{align*} \\mathbf{\\hat{\\beta}}_{WLS} &amp; = \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k}\\mathbf{X}_k&#39;\\hat{\\theta}_k. \\end{align*}\\] The WLS estimator is similar to the standard OLS estimator, except that it gives more weight to mmore precise estimates of the treatment effect. This is a generalization of the weighted average that we have studied in Section 13.1.3. 13.1.5.2.2 Full Maximum Likelihood Estimator The Full Maximum Likelihood Estimator (FMLE) is also a weighted estimator, but, as the random effects estimator presented in Section 13.1.4.2, it uses as weigths not only the precision estimates (\\(\\frac{1}{\\hat{\\sigma}^2_k}\\)), but the inverse of the sum of the variance due to sampling noise and the variance due to variation in treatment effects across sites. In order to make all of this clearer, let’s define \\(\\omega_k = \\epsilon_k + \\nu_k\\), and let’s denote \\(\\zeta^2_{k}=\\hat{\\sigma}^2_k+\\tau^2\\) the variance of \\(\\omega_k\\). The estimatingn equations for the FMLE estimator are: \\[\\begin{align*} \\mathbf{\\hat{\\beta}}_{FMLE} &amp; = \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\hat{\\theta}_k,\\\\ \\hat{\\tau}^2_{FMLE} &amp; = \\frac{\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^4_k}\\left((\\hat{\\theta}_k -\\mathbf{X}_k\\mathbf{\\beta})^2-\\hat{\\sigma}^2_k\\right)}{\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^4_k}} \\end{align*}\\] where \\(\\hat{\\zeta}^2_k\\) is an estimate of \\(\\zeta^2_{k}\\). In general, the FEML model is estimated by using a first guess for \\(\\mathbf{\\beta}\\), for example \\(\\mathbf{\\hat{\\beta}}_{WLS}\\). Using this first estimate, we can compute a first estimate of \\(\\hat{\\tau}^2\\) and update the set of weights, and iterate until convergence. 13.1.5.2.3 Restricted Maximum Likelihood Estimator The Restricted Maximum Likelihood Estimator (RMLE) is a weigthed estimator that is very similar to the FMLE estimator, except that the estimation procedure focuses on estimating \\(\\tau^2\\) first. As a consequence, the formula for the \\(\\tau^2\\) estimator is different: \\[\\begin{align*} \\mathbf{\\hat{\\beta}}_{RMLE} &amp; = \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\hat{\\theta}_k,\\\\ \\hat{\\tau}^2_{RMLE} &amp; = \\frac{\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^4_k}\\left((\\hat{\\theta}_k -\\mathbf{X}_k\\mathbf{\\beta})^2-\\hat{\\sigma}^2_k\\right) +\\text{tr}\\left[\\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right]} {\\sum_{k=1}^N\\frac{1}{\\hat{\\zeta}^4_k}}. \\end{align*}\\] Again, this estimator an be computed in a recursive way, starting with an initial guesstimate for the parameters \\(\\beta\\), for example the simple \\(WLS\\) estimator. 13.1.5.2.4 Method Of Moments (MOM) The Methods Of Moments estimator (MOM) does not require to assume that the distirbution of \\(\\nu_k\\) is normal. MOM only assumes that the distribution of \\(\\nu_k\\) is i.i.d. with mean zero and variance \\(\\tau^2\\). The MOM estimator is a three-step estimator: Estimate \\(\\beta\\) using a simple regression that does require knowing \\(\\tau^2\\). Estimate \\(\\tau^2\\) from the residuals of this regression. Run a Weighted Least Squares regression including the new estimate of \\(\\tau^2\\) in the weights. When the first step uses a simple OLS estimator, we have: \\[\\begin{align*} \\mathbf{\\hat{\\beta}}_{OLS} &amp; = \\left(\\sum_{k=1}^N\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\mathbf{X}_k&#39;\\hat{\\theta}_k \\\\ \\hat{\\tau}^2_{OLS} &amp; = \\frac{RSS-\\sum_{k=1}^N\\hat{\\sigma}^2_k-\\text{tr}(S)}{k-p-1}, \\end{align*}\\] where \\(RSS\\) is the Residual Sum of Squares of the OLS regression, \\(p\\) is the number of covariates and: \\[\\begin{align*} S &amp; = \\left(\\sum_{k=1}^N\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\mathbf{X}_k&#39;\\mathbf{X}_k. \\end{align*}\\] When the first step uses the WLS estimator, we have: \\[\\begin{align*} \\hat{\\tau}^2_{WLS} &amp; = \\frac{WRSS-(k-p-1)}{\\text{tr}(M)}, \\end{align*}\\] where \\(WRSS\\) is the Residual Sum of Squares of the WLS regression and: \\[\\begin{align*} \\text{tr}(M) &amp; = \\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k} -\\text{tr}\\left(\\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^4_k}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right). \\end{align*}\\] 13.1.5.3 Estimating sampling noise in the meta-regression model 13.1.5.3.1 Under homoskedasticity Under homoskedasticity, we’re assuming that the variance of the treatment effect at various sites does not depend on the site characteristics \\(\\mathbf{X}_k\\). In that case, the variance of the estimated coefficients is estimated by: \\[\\begin{align*} \\hat{\\text{Var}}_{Homo}(\\hat{\\mathbf{\\beta}}) &amp; = \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}. \\end{align*}\\] 13.1.5.3.2 Under heteroskedasticity Under heteroskedasticity, we allow the variance \\(\\tau^2\\) to depend on \\(\\mathbf{X}_k\\). One correct estimator under that assumption is the Huber-White sandwich estimator: \\[\\begin{align*} \\hat{\\text{Var}}_{HW}(\\hat{\\mathbf{\\beta}}) &amp; = \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1} \\sum_{k=1}^N\\left(\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}\\right)^2 \\mathbf{X}_k&#39;(\\hat{\\theta}_k-\\mathbf{X}_k\\hat{\\mathbf{\\beta}})^2\\mathbf{X}_k \\left(\\sum_{k=1}^N\\frac{1}{\\hat{\\sigma}^2_k+\\hat{\\tau}^2}\\mathbf{X}_k&#39;\\mathbf{X}_k\\right)^{-1}. \\end{align*}\\] Example 13.9 Let’s see how all of these estimators work in our example. In order to run a regression, I first need a covariate. I’m going to use the exact value of the noise that I’ve added to the regressions, so that I should be able to perfectly capture the heterogeneity in treatment effects. Let’s see how this works. # Let me generate the noise as a deviation from the true treatment effect data.meta$nu.1 &lt;- data.meta$theta.1 - data.meta$ES data.meta$nu.2 &lt;- data.meta$theta.2 - data.meta$ES # Let me now run a meta regression metaReg.example.RE.theta.1.ES &lt;- lapply(estimators,function(method){return(rma(theta.1 ~ nu.1,data=data.meta,vi=data.meta$var.ES,method=method))}) metaReg.example.RE.theta.2.ES &lt;- lapply(estimators,function(method){return(rma(theta.2 ~ nu.2,data=data.meta,vi=data.meta$var.ES,method=method))}) #Let&#39;s see what the estimation looks like when we ran an REML regression: summary(metaReg.example.RE.theta.1.ES[[2]]) ## ## Mixed-Effects Model (k = 20; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## 11.9242 -23.8485 -17.8485 -15.1774 -16.1342 ## ## tau^2 (estimated amount of residual heterogeneity): 0 (SE = 0.0005) ## tau (square root of estimated tau^2 value): 0 ## I^2 (residual heterogeneity / unaccounted variability): 0.00% ## H^2 (unaccounted variability / sampling variability): 1.00 ## R^2 (amount of heterogeneity accounted for): 100.00% ## ## Test for Residual Heterogeneity: ## QE(df = 18) = 12.6914, p-val = 0.8096 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 1065.4316, p-val &lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.1954 0.0085 22.8649 &lt;.0001 0.1786 0.2121 *** ## nu.1 0.9963 0.0305 32.6409 &lt;.0001 0.9365 1.0561 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can see that the estimated coefficient for the noise is large and almost equal to one, that the estimation of residual inter-site variance becomes zero and that the precision of our estimared treatment effect becomes much greater (since all variance due to site effects has been absorbed by the regressor). Let’s now look at the estimated coefficients. For that, we are going to use the function coef(summary()) that extracts a dataframe of the coefficients along with their standard errors. list.coef.tot.1 &lt;- lapply(metaReg.example.RE.theta.1.ES,function(res){return(coef(summary(res)))}) list.coef.tot.2 &lt;- lapply(metaReg.example.RE.theta.2.ES,function(res){return(coef(summary(res)))}) list.coef.1 &lt;- unlist(lapply(list.coef.tot.1,&#39;[[&#39;,c(1,1))) list.se.1 &lt;- unlist(lapply(list.coef.tot.1,&#39;[[&#39;,c(2,1))) list.coef.2 &lt;- unlist(lapply(list.coef.tot.2,&#39;[[&#39;,c(1,1))) list.se.2 &lt;- unlist(lapply(list.coef.tot.2,&#39;[[&#39;,c(2,1))) result.Meta &lt;- data.frame(Method=rep(estimators,2),ES.Meta=c(list.coef.1,list.coef.2),se.ES=c(list.se.1,list.se.2),tau2=c(rep(tau[[1]]^2,length(estimators)),rep(tau[[2]]^2,length(estimators)))) ggplot(data=result.Meta, aes(x=Method, y=ES.Meta, group=as.factor(tau2), color=as.factor(tau2))) + geom_point(stat=&quot;identity&quot;, position=position_dodge(0.7))+ geom_errorbar(aes(min=ES.Meta-qnorm((1+delta.2)/2)*se.ES,max=ES.Meta+qnorm((1+delta.2)/2)*se.ES),position=position_dodge(0.7),width=0.1)+ geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ expand_limits(y=0) Figure 13.10: Various estimators of Effect Size in a Meta-Regression Figure 13.10 shows that all estimators perform very well and deliver a precise estimate of the true effect. I think SJn is the MOM estimator, check that. 13.1.6 Constantly updated meta-analysis Constantly updated meta-analysis performs the meta-analysis in a progressive manner, as the results keep arriving. This is a very important tool that enables us to aggregate constantly the information coming from different studies. Moreover, restrospectively, it helps us to assess when we would have reached enough precision so that we could have foregone an additional study. The way constantly updated meta-analysis works is simply by performing a new meta-analysis each time a new results pops up. Example 13.10 Figure 13.11 shows how constantly updated meta-analysis works in our example. cum.wmae.1 &lt;- function(k,theta,sigma2){ return(c(weighted.mean(theta[1:k],(1/sigma2[1:k])/(sum(1/sigma2[1:k]))),1/sum(1/sigma2[1:k]))) } cum.wmae &lt;- function(theta,sigma2){ return(sapply(1:length(theta),cum.wmae.1,theta=theta,sigma2=sigma2)) } cum.test &lt;- as.data.frame(t(cum.wmae(data.meta$ES,data.meta$se.ES^2))) colnames(cum.test) &lt;- c(&#39;cum.ES&#39;,&#39;cum.var&#39;) cum.test$id &lt;- 1:nrow(cum.test) cum.test$cum.se.ES &lt;- sqrt(cum.test$cum.var) ggplot(data.meta, aes(x=forcats::fct_rev(as.factor(id)), y=ES)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Studies&quot;)+ ylab(&quot;Initial effect size&quot;)+ theme_bw()+ coord_flip() ggplot(cum.test, aes(x=forcats::fct_rev(as.factor(id)), y=cum.ES)) + geom_bar(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;black&#39;) + geom_errorbar(aes(ymin=cum.ES-qnorm((delta.2+1)/2)*cum.se.ES, ymax=cum.ES+qnorm((delta.2+1)/2)*cum.se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ xlab(&quot;Studies&quot;)+ ylab(&quot;Cumulative effect size&quot;)+ theme_bw()+ coord_flip() Figure 13.11: Constantly updated meta-analysis Figure 13.11 shows that combining several imprecise estimates might help you reach the same precision as running a larger experiment. For instance, cumulating the first 10 studies with a small sample size (\\(N=\\) 100), the meta-analytic effect is estimated at 0.2 \\(\\pm\\) 0.18. This is very close to the individual estimate obtained from the first estimate with a larger sample size (sample 11 on Figure 13.11, with \\(N=\\) 1000): 0.17 \\(\\pm\\) 0.18. Both estimates actually have the exact same precision (because they actually have the same sample size). The same is true when combining the first 17 studies. The meta-analytic effect is estimated at 0.24 \\(\\pm\\) 0.06, while the effect estimated using one unique RCT with a larger sample size (sample 18 on Figure 13.11, with \\(N=\\) 10^{4}) is 0.21 \\(\\pm\\) 0.05. Finally, the same result occurs when combining the first 19 studies. The meta-analytic effect is estimated at 0.21 \\(\\pm\\) 0.03, while the effect estimated using one unique RCT with a larger sample size (sample 20 on Figure 13.11, with \\(N=\\) 10^{5}) is 0.19 \\(\\pm\\) 0.02. As a conclusion, constantly updated meta-analysis would have each time delivered the same result than the one found with a much larger study, rendering this additional study almost irrelevant. This is a very important result: beyond the apparent messiness of the first noisy estimates in Figures 13.1 and 13.3 lies an order that can be retrieved and made apparent using constantly updated meta-analysis. Sometimes, the answer is right there in front of our eyes, we just lack the ability to see it. Constantly updated meta-analysis serves as a binocular to magnify what is there. Think about how costly it woud be to run a very large study, just to find out that the we did not really need it because we had known the result all along. Remark. Something pretty cool is that I can reproduce Figure 13.11 using the metafor package with much less lines of code. forest(meta.example.FE,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=&#39;Estimated Meta-analytic Parameter&#39;) cumul.meta.example.FE &lt;- cumul(meta.example.FE, order=data.meta$id) forest(cumul.meta.example.FE,slab = paste(&#39;Study&#39;,data.meta$id,sep=&#39; &#39;),xlab=&#39;Estimated Meta-analytic Cumulated Parameter&#39;) Figure 13.12: Constantly updated meta-analysis with the metafor package You can also call each of the individual results of the cumulative meta-analysis using cumul.meta.example.FE$estimate. For example, the cumulated effect size after the 10 first studies is equal to 0.2 \\(\\pm\\) 0.18. 13.2 Publication bias and site selection bias Up to now, we have made the assumption that a meta-analysis can access the results of ALL of the studies conducted on a topic. Problems appear when the publisehd record does not contain ALL of the studies conducted on a topic, but only a non-representative sample of them. In the first section below, I detail the two main types of biases: publication bias and site selection bias. In the second section, I present methods that help to detect and correct for publication bias. In the third section, I present methods tha help to detect and correct for site selection bias. In the last section, I take a step back and ask whether publication bias can be somehow optimal. 13.2.1 Sources of publication bias and of site selection bias and Questionable Research Practices This section explains the sources of publication bias and site selection bias. I also expalin how they trigger the use of Questionable Research Practices that bias the published record even more. 13.2.1.1 Publication bias There is publication bias when the eventual publication of the results of a research project depends on the results themselves. In general, the probability that a result is published increases drastically when the results reach the usual levels of statistical significance. On the contrary, the probability that a non significant result is published decreases drastically. Give evidence of that behavior. The reasons for this behavior are pretty well understood: editors and referees consider that only statistically significant results are of scientific interest, and that non significant results bring close to no information on a topic, especially if they are imprecise. Knowing this, most researchers choose not to invest time in trying to send a paper with a non significant result for publication. What are the consequences of publishing only statistically significant results? Well, among imprecisely estimated effects, only the largest ones are going to reach publication, generating a pattern of overestimation of the true treatment effect. They key trade-off is whether the resulting bias is very large or not. Example 13.11 What does publication bias look like in our example? Let’s assume that only statistically significant effects are published. Would it change our estimate? In order to see whether that is the case, let’s build Figure 13.1 with the addition of fixed effects estimator using all results and using only statistically significant results. meta.example.FE.pubbias &lt;- rma(yi = data.meta$ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=data.meta$var.ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;FE&quot;) meta.example.FE.small &lt;- rma(yi = filter(data.meta,id&lt;=10)$ES,vi=filter(data.meta,id&lt;=10)$var.ES,method=&quot;FE&quot;) meta.example.FE.small.pubbias &lt;- rma(yi = filter(data.meta,id&lt;=10)$ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=filter(data.meta,id&lt;=10)$var.ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;FE&quot;) meta.example.FE.interm &lt;- rma(yi = filter(data.meta,id&lt;=17)$ES,vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;FE&quot;) meta.example.FE.interm.pubbias &lt;- rma(yi = filter(data.meta,id&lt;=17)$ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=filter(data.meta,id&lt;=17)$var.ES[abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;FE&quot;) ggplot(filter(data.meta,id&lt;=10), aes(x=as.factor(id), y=ES)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE.small)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE.small.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (only small sample size)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() ggplot(filter(data.meta,id&lt;=17), aes(x=as.factor(id), y=ES)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE.interm)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE.interm.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (only small and intermediate sample size)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() ggplot(data.meta, aes(x=as.factor(id), y=ES)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=ES-qnorm((delta.2+1)/2)*se.ES, ymax=ES+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.FE.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (all)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() Figure 13.13: Illustration of publication bias Figure 13.13 shows that publication bias can be a sizable problem. Remember that the true effect that we are trying to estimate is 0.2. When only imprecise studies with small sample size are available, the effect estimated using only the statistically significant studies (actually, the only study that reports a statistically significant result) is equal to 0.51 \\(\\pm\\) 0.5, while the effect estimated all the 10 studies with a small sample size is 0.2 \\(\\pm\\) 0.18. When studies with small and intermediate sample size are available, the effect estimated using only the statistically significant studies is equal to 0.29 \\(\\pm\\) 0.08, while the effect estimated all the 17 studies with a small and intermediate sample size is 0.24 \\(\\pm\\) 0.06. It is only when studies with large and very large sample size are added to the estimation that publication bias is not a problem anymore. The effect estimated using only the statistically significant studies is equal to 0.2 \\(\\pm\\) 0.02, while the effect estimated all the studies is 0.19 \\(\\pm\\) 0.02. As a conclusion of Figure 13.13, publication bias biases the true effect by: 148 %, or 0.3 of a standard deviation, with studies with a small sample size, 40 %, or 0.08 of a standard deviation, with studies with a small or intermediate sample size, 4 %, or 0.01 of a standard deviation, with all studies. With random effects, this behavior becomes even more severe, since only the sites at which the program has worked are going to appear in the published record, thereby biasing downards the true heterogeneity in treatment effects. Example 13.12 Here is how that impacts the truth in our example: meta.example.RE &lt;- rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=&quot;REML&quot;) meta.example.RE.pubbias &lt;- rma(yi = data.meta$theta.1[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=data.meta$var.ES[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;REML&quot;) meta.example.RE.small &lt;- rma(yi = filter(data.meta,id&lt;=10)$theta.1,vi=filter(data.meta,id&lt;=10)$var.ES,method=&quot;REML&quot;) meta.example.RE.small.pubbias &lt;- rma(yi = filter(data.meta,id&lt;=10)$theta.1[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=filter(data.meta,id&lt;=10)$var.ES[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;REML&quot;) meta.example.RE.interm &lt;- rma(yi = filter(data.meta,id&lt;=17)$theta.1,vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;REML&quot;) meta.example.RE.interm.pubbias &lt;- rma(yi = filter(data.meta,id&lt;=17)$theta.1[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)],vi=filter(data.meta,id&lt;=17)$var.ES[abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;qnorm((1+delta.2)/2)],method=&quot;REML&quot;) ggplot(filter(data.meta,id&lt;=10), aes(x=as.factor(id), y=theta.1)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=theta.1-qnorm((delta.2+1)/2)*se.ES, ymax=theta.1+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE.small)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE.small.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (only small sample size)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() ggplot(filter(data.meta,id&lt;=17), aes(x=as.factor(id), y=theta.1)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=theta.1-qnorm((delta.2+1)/2)*se.ES, ymax=theta.1+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE.interm)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE.interm.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (only small and intermediate sample size)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() ggplot(data.meta, aes(x=as.factor(id), y=theta.1)) + geom_point(position=position_dodge(), stat=&quot;identity&quot;, colour=&#39;blue&#39;) + geom_errorbar(aes(ymin=theta.1-qnorm((delta.2+1)/2)*se.ES, ymax=theta.1+qnorm((delta.2+1)/2)*se.ES), width=.2,position=position_dodge(.9),color=&#39;blue&#39;) + geom_hline(aes(yintercept=ES(param)), colour=&quot;#990000&quot;, linetype=&quot;dashed&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE)), colour=&quot;#990000&quot;, linetype=&quot;dotted&quot;)+ geom_hline(aes(yintercept=coef(meta.example.RE.pubbias)), colour=&quot;green&quot;, linetype=&quot;dotted&quot;)+ xlab(&quot;Studies (all)&quot;)+ ylab(&quot;Effect size&quot;)+ theme_bw() Figure 13.14: Illustration of publication bias with Random Effects Figure 13.14 shows that publication bias can be a sizable problem with random effects as well. Remember that the true effect that we are trying to estimate is 0.2. When only imprecise studies with small sample size are available, the effect estimated using only the statistically significant studies is equal to 0.86 \\(\\pm\\) 0.5, while the effect estimated all the 10 studies with a small sample size is 0.16 \\(\\pm\\) 0.24. When studies with small and intermediate sample size are available, the effect estimated using only the statistically significant studies is equal to 0.22 \\(\\pm\\) 0.58, while the effect estimated all the 17 studies with a small and intermediate sample size is 0.13 \\(\\pm\\) 0.28. It is only when studies with large and very large sample size are added to the estimation that publication bias is not a problem anymore. The effect estimated using only the statisticaly significant studies is equal to 0.18 \\(\\pm\\) 0.41, while the effect estimated all the studies is 0.13 \\(\\pm\\) 0.24. As a conclusion of Figure 13.13, publication bias biases the true effect by: 319 %, or 0.65 of a standard deviation, with studies with a small sample size, 6 %, or 0.01 of a standard deviation, with studies with a small or intermediate sample size, 10 %, or 0.02 of a standard deviation, with all studies. 13.2.1.2 Site selection bias There is site selection bias when researchers only implement an intervention in sites where they expect it to work. How can they do so? There are several informations that one can use to select sites for implementing a treatment and maximizing its effectiveness. First, researchers might only be able to work with highly motivated implementation agents. This might generate larger effects of the treatment. Second, researchers might have an informal knowledge on the types of individuals who react to the treatment well, and might decide to include them preferentially in the experimental study. Third, researchers might try out several different treatments in small informal pilots, and choose to run at scale only the most effective one(s). Finally, researchers, by conducting an extensive diagnosis of the problem that they face on the ground, might end up selecting a treatment that is more appropriate than a randomly selected treatment. What are the consequences of site selection bias? If the selection process remains undocumented, a policy-maker trying to implement a treatment with a proven track record might fail to obtain the expected results because the site on which she decides to implement it is not representative of the distribution of sites in which the program has been evaluated. Ommitting to detail the process of site selection is akin to not explaining the recommendations of use, or worse the diagnosis of the disease, for a drug. If we do not know which disease the drug is effective against, we might end up expecting great results of a cold medecine against cancer. Simulations. 13.2.1.3 Questionable Research Practices Publication bias triggers and is aggravated by the use of Questionable Research Practices (QRPs). QRPs enable researchers (sometimes unknowingly) to obtain more statistically significant results than should be the case in view of the true effect of the treatment that they are looking at and the power of their test. Normally, when a treatment has no effect, only 5% of the treatment effects are going to turn out positive and significant when using a standard two-sided t-test. But, with QRPs, this figure can increase to 10, 20 or even, 50% in some cases. References. What are the most usual QRPs? Choosing a sample that generates significant effects: that includes stopping data collection when an effet of interest is found or deciding on critera of inclusion of observations based on statistical singificance. Sometimes, simply stopping to do robustness checks when results are significant is enough to bias usual tests of statistical significance. Choosing an outcome because the effect of the treatment is statistically significant. If we test a treatment on 100 outcomes for which the true effect of the treatment is null, between 2 and 3 outcomes are expected to turn out with positive effects just by the sheer property of the tests that we are using. Choosing an identification strategy that generates significant treatment effects. Researcher smight try out various instruments and various natural experiments before settling down on the one that yields a statistically significant result. Choosing a subgroup for which significant effects are obtained. Analysis by subgroups offers a lot of opportunities for finding spurious significant effects. The key question is whether these QRPs only move borderline significant results into the realm of significance, and thus have small effects of the size of the treatment effect, or if they enable to transform small effects into much larger ones. Note though that even if the QRPs only transform barely non-significant results in barely significant ones, the sheer repetition of these results in a meta-analysis is going to overestimate precision and might yield eventually to a confidence interval that does not contain the true effect, maybe by a large margin. Simulations. 13.2.2 Detection of and correction for publication bias Over the years, researchers have become aware of the problem that publication bias raises for meta-analyses and they have developed methods to detect and correct for it. 13.2.2.1 Funnel plot asymmetry The first tool to identify the extent of publication bias is the funnel plot. The funnel plot plots the effect size as a function of its precision (or standard error). In the absence of publication bias, results should be distributed symetrically around the mean treatment effect estimate. We say that in this case the funnel plot is symmetric. In the presence of publication bias, results that are not statistically significant will be missing. They will be concentrated on the lower left part of the plot, were standard errors are large and estimated effects small. Missing results generate an asymetric funnel plot. Example 13.13 Let’s see how the funnel plot works in our example. funnel(meta.example.FE.interm,xlab=&#39;Effect size (without publication bias)&#39;,xlim=c(-0.5,1),ylim=c(0.382,0),refline=0) abline(v=ES(param),col=&quot;red&quot;) abline(v=coef(meta.example.FE.interm),col=&quot;blue&quot;) funnel(meta.example.FE.interm.pubbias,xlab=&#39;Effect size (with publication bias)&#39;,xlim=c(-0.5,1),ylim=c(0.382,0),refline=0) abline(v=ES(param),col=&quot;red&quot;) abline(v=coef(meta.example.FE.interm.pubbias),col=&quot;green&quot;) Figure 13.15: Funnel plot with and without publication bias (homogeneous treatment effects, small and intermediate precision) Figure 13.15 shows how a funnel plot works. The x-axis presents the effect size of each study (here, in the homogeneous treatment effect case, analyzed using fixed effects). The y-axis presents the standard error, in an inverted scale, so that the most precise studies appear at the top of the graph. The two diagonal lines stemming out of zero present the 95% confidence intervals arounf zero, a.k.a. the two sided tests of statistical significance. In the plot, we focus of studies with small to intermediate precision. In our example, very precise studies are so much more precise that they make the problem of publication bias vanish. When there is no publication bias, the funnel plot does not seem to exhibit asymmetry: there are as many imprecise studies on the left and on the right of the average effect. When there is publication bias, all the studies that fall within the confidence interval compatible with a zero treatment effect disappear. As a consequence, the remaining treatment effects are inflated versions of the truth. Moreover, we see that there is an increasing relationship between standard error and effect size. This is a sign of funnel plot asymmetry. For the sake of completeness, Figure 13.16 shows what the funnel plot looks like with heterogeneous treatment effects analyzed using a random effects approach. funnel(meta.example.RE.interm,xlab=&#39;Effect size (without publication bias)&#39;,xlim=c(-1,1),ylim=c(0.382,0),refline=0) abline(v=ES(param),col=&quot;red&quot;) abline(v=coef(meta.example.RE.interm),col=&quot;blue&quot;) funnel(meta.example.RE.interm.pubbias,xlab=&#39;Effect size (with publication bias)&#39;,xlim=c(-1,1),ylim=c(0.382,0),refline=0) abline(v=ES(param),col=&quot;red&quot;) abline(v=coef(meta.example.RE.interm.pubbias),col=&quot;green&quot;) Figure 13.16: Funnel plot with and without publication bias (heterogeneous treatment effects, small and intermediate precision) How do we implement these intuitions rigorously? The next section present the tools developed to do just that. 13.2.2.2 FAT-PET-PEESE Docouliagos and Stanley (2012) have developed a method based on funnel plot asymmetry to detect publication bias and correct for it. Their approach is based on three steps: The Funnel Asymmetry Test (FAT) that tests whether there is a relationship between effect sizes and their precision. The Precision-Effect Test (PET) that estimates the effect corrected for publication bias and tests for its existence. The Precision-Effect Estimate with Standard Error (PEESE) that estimates the effect corrected for publication bias using a non-linear model for the standard error. When there is a genuine effect, PEESE offers a less biased estimate than PET. The authors suggest to implement these procedures in a sequence, starting with the existence of publication bias, evidence for the existence of a non-zero effect once publication bias is accounted for and then estimate the bias-corrected effect when it is detected to be non-zero. Let’s examine these approaches in turn. The FAT and the PET are based on the following meta-regression: \\[\\begin{align*} \\hat{\\theta}_k &amp; = \\alpha_0 + \\alpha_1\\hat{\\sigma}_k + \\epsilon_k + \\nu_k, \\end{align*}\\] The PEESE is based on the following meta-regression: \\[\\begin{align*} \\hat{\\theta}_k &amp; = \\beta_0 + \\beta_1\\hat{\\sigma}^2_k + \\epsilon_k + \\nu_k, \\end{align*}\\] Whether we assume that \\(\\tau^2\\), the variance of \\(\\nu_k\\) is zero or not makes the FAT model a fixed or a random effects model. We run this regression with either Weighted Least Squares (in the fixed effects model) or with one of the methods appropriate for random effects (I’m going to use REML in what follows). The FAT tests the assumption that \\(\\alpha_1=0\\) using a standard two-sided t-test. Rejecting the null means that there is sign of publication bias. The PET tests whether \\(\\alpha_0=0\\). Rejecting the null means that there is evidence of a true effect. The PEESE estimates the bias-corrected effect size by using \\(\\hat{\\beta}_1\\). Example 13.14 Let’s see in practice how FAT, PET and PEESE work in our example. We are going first to run the regressions on the sample with homogeneous treatment effects, and thus we are going to use the simple Weighted Least Squares approach. I’m focusing on the case with only small and intermediate precision estimates, as in the funnel plots in Figure 13.15. FAT.PET.FE.interm &lt;- rma(ES ~ sqrt(var.ES), data= filter(data.meta,id&lt;=17),vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;FE&quot;) FAT.PET.FE.interm.pubbias &lt;- rma(ES ~ sqrt(var.ES), data = filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)),vi=filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES,method=&quot;FE&quot;) PEESE.FE.interm &lt;- rma(ES ~ var.ES, data= filter(data.meta,id&lt;=17),vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;FE&quot;) PEESE.FE.interm.pubbias &lt;- rma(ES ~ var.ES, data = filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)),vi=filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES,method=&quot;FE&quot;) summary(FAT.PET.FE.interm) ## ## Fixed-Effects with Moderators Model (k = 17) ## ## logLik deviance AIC BIC AICc ​ ## 8.6124 9.5293 -13.2247 -11.5583 -12.3676 ## ## I^2 (residual heterogeneity / unaccounted variability): 0.00% ## H^2 (unaccounted variability / sampling variability): 0.64 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 15) = 9.5293, p-val = 0.8483 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.4952, p-val = 0.4816 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.2791 0.0634 4.4053 &lt;.0001 0.1549 0.4033 *** ## sqrt(var.ES) -0.3397 0.4828 -0.7037 0.4816 -1.2861 0.6066 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(FAT.PET.FE.interm.pubbias) ## ## Fixed-Effects with Moderators Model (k = 6) ## ## logLik deviance AIC BIC AICc ​ ## 6.4279 3.0645 -8.8557 -9.2722 -4.8557 ## ## I^2 (residual heterogeneity / unaccounted variability): 0.00% ## H^2 (unaccounted variability / sampling variability): 0.77 ## R^2 (amount of heterogeneity accounted for): 8.85% ## ## Test for Residual Heterogeneity: ## QE(df = 4) = 3.0645, p-val = 0.5471 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 1.1380, p-val = 0.2861 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.1352 0.1470 0.9195 0.3578 -0.1530 0.4233 ## sqrt(var.ES) 1.6351 1.5327 1.0668 0.2861 -1.3691 4.6392 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(PEESE.FE.interm) ## ## Fixed-Effects with Moderators Model (k = 17) ## ## logLik deviance AIC BIC AICc ​ ## 8.6741 9.4058 -13.3483 -11.6818 -12.4911 ## ## I^2 (residual heterogeneity / unaccounted variability): 0.00% ## H^2 (unaccounted variability / sampling variability): 0.63 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 15) = 9.4058, p-val = 0.8554 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.6187, p-val = 0.4315 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.2568 0.0379 6.7699 &lt;.0001 0.1825 0.3312 *** ## var.ES -0.9426 1.1983 -0.7866 0.4315 -3.2912 1.4061 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(PEESE.FE.interm.pubbias) ## ## Fixed-Effects with Moderators Model (k = 6) ## ## logLik deviance AIC BIC AICc ​ ## 6.3347 3.2508 -8.6694 -9.0859 -4.6694 ## ## I^2 (residual heterogeneity / unaccounted variability): 0.00% ## H^2 (unaccounted variability / sampling variability): 0.81 ## R^2 (amount of heterogeneity accounted for): 3.31% ## ## Test for Residual Heterogeneity: ## QE(df = 4) = 3.2508, p-val = 0.5168 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.9516, p-val = 0.3293 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.2460 0.0569 4.3210 &lt;.0001 0.1344 0.3576 *** ## var.ES 4.3828 4.4928 0.9755 0.3293 -4.4229 13.1885 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The results of the analysis are as expected, even though the small sample size prevents us from drawing conclusive results. When running the regression on the whole sample, in the absence of publication bias, we find that the estimated coefficient for the standard error in the meta-analytic regression is -0.34 \\(\\pm\\) 0.95. As a consequence, the FAT detects no sign of publication bias, with a pretty decent precision level. When running the regression on the sample with publication bias, we find that the estimated coefficient for the standard error in the meta-analytic regression is 1.64 \\(\\pm\\) 3. The coefficient is positive, as expected if larger results occur with smaller sample size, but the precision of this coefficient is too low for the FAT to be able to detect publication bias. This is a characteristic of the FAT to have low power, especially in our case where only one observation with small sample size drives all the results. In the absence of publication bias, the PET detects a positive effect (0.28 \\(\\pm\\) 0.12) that is significantly different from zero, which is a sign of existence of a true effect. The PEESE is of 0.26 \\(\\pm\\) 0.07 . Following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.24 \\(\\pm\\) 0.06), since the FAT has not detected signs of publication bias. In the presence of publication bias, the PET does not detect a positive effect (0.14 \\(\\pm\\) 0.29). The PEESE is of 0.25 \\(\\pm\\) 0.11 . Again, following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.29 \\(\\pm\\) 0.08), since the FAT has not detected signs of publication bias. Note nevertheless that in both cases the PEESE is almost as good as the meta-analytic estimate. Let’s now look at what happens when we are in a random effects world. FAT.PET.RE.interm &lt;- rma(theta.1 ~ sqrt(var.ES), data= filter(data.meta,id&lt;=17),vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;REML&quot;) FAT.PET.RE.interm.pubbias &lt;- rma(theta.1 ~ sqrt(var.ES), data = filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)),vi=filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES,method=&quot;REML&quot;) FAT.PET.RE.interm.pubbias.pos &lt;- rma(theta.1 ~ sqrt(var.ES), data = filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2),data.meta$theta.1&gt;0),vi=filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2),data.meta$theta.1&gt;0)$var.ES,method=&quot;REML&quot;) PEESE.RE.interm &lt;- rma(theta.1 ~ var.ES, data= filter(data.meta,id&lt;=17),vi=filter(data.meta,id&lt;=17)$var.ES,method=&quot;REML&quot;) PEESE.RE.interm.pubbias &lt;- rma(theta.1 ~ var.ES, data = filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2)),vi=filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES,method=&quot;REML&quot;) PEESE.RE.interm.pubbias.pos &lt;- rma(theta.1 ~ var.ES, data = filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2),data.meta$theta.1&gt;0),vi=filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2),data.meta$theta.1&gt;0)$var.ES,method=&quot;REML&quot;) summary(FAT.PET.RE.interm) ## ## Mixed-Effects Model (k = 17; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## -12.9481 25.8963 31.8963 34.0204 34.0781 ## ## tau^2 (estimated amount of residual heterogeneity): 0.3020 (SE = 0.1283) ## tau (square root of estimated tau^2 value): 0.5496 ## I^2 (residual heterogeneity / unaccounted variability): 94.49% ## H^2 (unaccounted variability / sampling variability): 18.14 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 15) = 447.9880, p-val &lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.0012, p-val = 0.9727 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.1421 0.2999 0.4738 0.6356 -0.4457 0.7300 ## sqrt(var.ES) -0.0450 1.3152 -0.0342 0.9727 -2.6227 2.5327 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(FAT.PET.RE.interm.pubbias) ## ## Mixed-Effects Model (k = 7; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## -5.9836 11.9671 17.9671 16.7954 41.9671 ## ## tau^2 (estimated amount of residual heterogeneity): 0.6336 (SE = 0.4058) ## tau (square root of estimated tau^2 value): 0.7960 ## I^2 (residual heterogeneity / unaccounted variability): 98.75% ## H^2 (unaccounted variability / sampling variability): 80.28 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 5) = 427.8228, p-val &lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.7196, p-val = 0.3963 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt -0.2927 0.6739 -0.4343 0.6641 -1.6135 1.0281 ## sqrt(var.ES) 4.5787 5.3976 0.8483 0.3963 -6.0005 15.1578 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(PEESE.RE.interm) ## ## Mixed-Effects Model (k = 17; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## -12.9242 25.8485 31.8485 33.9726 34.0303 ## ## tau^2 (estimated amount of residual heterogeneity): 0.3014 (SE = 0.1279) ## tau (square root of estimated tau^2 value): 0.5490 ## I^2 (residual heterogeneity / unaccounted variability): 94.49% ## H^2 (unaccounted variability / sampling variability): 18.15 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 15) = 448.3132, p-val &lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.0208, p-val = 0.8852 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.1563 0.2156 0.7247 0.4686 -0.2663 0.5789 ## var.ES -0.4451 3.0832 -0.1444 0.8852 -6.4881 5.5978 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(PEESE.RE.interm.pubbias) ## ## Mixed-Effects Model (k = 7; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ​ ## -5.9949 11.9899 17.9899 16.8182 41.9899 ## ## tau^2 (estimated amount of residual heterogeneity): 0.6366 (SE = 0.4077) ## tau (square root of estimated tau^2 value): 0.7979 ## I^2 (residual heterogeneity / unaccounted variability): 98.76% ## H^2 (unaccounted variability / sampling variability): 80.92 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 5) = 430.0992, p-val &lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.6936, p-val = 0.4049 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ​ ## intrcpt 0.0132 0.3914 0.0338 0.9730 -0.7539 0.7804 ## var.ES 13.0892 15.7165 0.8328 0.4049 -17.7147 43.8930 ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In the absence of publication bias, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is -0.04 \\(\\pm\\) 2.58. As a consequence, the FAT detects no sign of publication bias. The PET does not detect a positive effect but its estimate is close to the truth, even if imprecise (0.28 \\(\\pm\\) 0.59). We would interpret this as absence of evidence for an effect. The PEESE is of 0.16 \\(\\pm\\) 0.42, close to the truth but highly imprecise. Following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and should focus only on the simple meta-analytic one (0.13 \\(\\pm\\) 0.28), since the FAT has not detected signs of publication bias. In the presence of publication bias, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is 4.58 \\(\\pm\\) 10.58. The coefficient is positive, as expected if larger results occur with smaller sample size, but the precision of this coefficient is too low for the FAT to be able to detect publication bias. The PET does not detect a positive effect, and even returns a negative one (-0.29 \\(\\pm\\) 1.32), however extremely imprecise. The PEESE at least returns a positive even though imprecise effect of 0.01 \\(\\pm\\) 0.77. Again, following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.22 \\(\\pm\\) 0.58), since the FAT has not detected signs of publication bias. In both cases the PEESE contains the true value in its confidence interval, but it does much less well than in the fixed effects case. Some simulations would be great here in order to assess whether the estimated sampling noise of PEESE is actually of the same magnitude as what would stem from Monte Carlos. I’d like to end this section on FAT-PET-PEESE by giving a graphical intuition of how this estimator corrects for publication bias. I’ll supplement the graphical intuition with some intuition stemming from Heckman’s selection model. The key intuition for understanding the FAT-PET and especially the PEESE estimator is the fact that, in the presence of publication bias, the meta-regression is akin to a censored or truncated model. As a consequence, and as Stanley and Docouliagos explain, we have something like: \\[\\begin{align*} \\esp{\\hat{\\theta}_k||\\frac{\\hat{\\theta}_k}{\\hat{\\sigma}_k}|&gt;1.96} &amp; = \\alpha_0 + \\alpha_1\\hat{\\sigma}_k\\lambda(\\hat{\\theta}_k,\\hat{\\sigma}_k) + \\epsilon_k + \\nu_k, \\end{align*}\\] Do the derivation. with \\(\\lambda\\) the Inverted Mills Ratio. Approximating the nonlinear function of \\(\\hat{\\sigma}_k\\) by a second order polynomial whose minium is when \\(\\hat{\\sigma}_k=0\\) gives rise to PEESE. FAT-PET approximate this function linearly instead. One way to see how this operates is to add the FAT-PET and PEESE estimates to the funnel plots. Example 13.15 Let’s see how the funnel plot works in our example. plot(filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$ES ~ sqrt(filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES),xlim=c(0,0.382),ylim=c(-0.5,1),xlab=&#39;Standard error&#39;, ylab =&#39;Effect size&#39;, main=&#39;Homogeneous effects&#39;) abline(h=ES(param),col=&quot;red&quot;) abline(h=coef(meta.example.FE.interm.pubbias),col=&quot;green&quot;) curve((coef(FAT.PET.FE.interm.pubbias)[1]+coef(FAT.PET.FE.interm.pubbias)[2]*x),col=&quot;blue&quot;, add = TRUE) curve(expr=coef(PEESE.FE.interm.pubbias)[1]+coef(PEESE.FE.interm.pubbias)[2]*x^2,col=&quot;blue&quot;,lty=2,add = TRUE) legend(&quot;bottomright&quot;, legend = c(&quot;Truth&quot;, &quot;Meta&quot;,&quot;FAT-PET&quot;,&quot;PEESE&quot;), col = c(&#39;red&#39;, &#39;green&#39;,&#39;blue&#39;,&#39;blue&#39;), lty= c(1,1,1,2), bg = &quot;white&quot;) plot(filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$theta.1 ~ sqrt(filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES),xlim=c(0,0.382),ylim=c(-1,1),xlab=&#39;Standard error&#39;, ylab =&#39;Effect size&#39;, main=&#39;Heterogeneous effects&#39;) abline(h=ES(param),col=&quot;red&quot;) abline(h=coef(meta.example.RE.interm.pubbias),col=&quot;green&quot;) curve((coef(FAT.PET.RE.interm.pubbias)[1]+coef(FAT.PET.RE.interm.pubbias)[2]*x),col=&quot;blue&quot;, add = TRUE) curve((coef(FAT.PET.RE.interm.pubbias.pos)[1]+coef(FAT.PET.RE.interm.pubbias.pos)[2]*x),col=&quot;blue&quot;,lty=4, add = TRUE) curve(expr=coef(PEESE.RE.interm.pubbias)[1]+coef(PEESE.RE.interm.pubbias)[2]*x^2,col=&quot;blue&quot;,lty=2,add = TRUE) curve(expr=coef(PEESE.RE.interm.pubbias.pos)[1]+coef(PEESE.RE.interm.pubbias.pos)[2]*x^2,col=&quot;blue&quot;,lty=3,add = TRUE) legend(&quot;bottomright&quot;, legend = c(&quot;Truth&quot;, &quot;Meta&quot;,&quot;FAT-PET&quot;,&quot;FAT-PET+&quot;,&quot;PEESE&quot;,&quot;PEESE+&quot;), col = c(&#39;red&#39;, &#39;green&#39;,&#39;blue&#39;,&#39;blue&#39;,&#39;blue&#39;,&#39;blue&#39;), lty= c(1,1,1,4,2,3), bg = &quot;white&quot;) Figure 13.17: Funnel plot with PET and PEESE On Figure 13.17, we see how PET and PEESE operate to deliver an estimate corrected for publication bias: they fit a line (PET) or a curve (PEESE) and use the intercept of this line or curve as an estimate of the true treatment effect. The plot for the hetergeneous treatment effects case suggests that both FAT-PET and PEESE are biased by a statistically significant negative result. I think there is a good case to be made for focusing only on results of the same sign when using these tools. When we get rid of that observation from the sample, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is 1.37 \\(\\pm\\) 4.25. The PET estimate is now 0.48 \\(\\pm\\) 0.51. The PEESE estimates an effect of 0.57 \\(\\pm\\) 0.28. This correction does not seem to improve the estimator much in our example. Nevertheless, it is worth to investigate further how PEESE behaves when observations from the over side of zero enter the picture. They seem to introduce a lot of noise. I’d advocate for always using only values from one side, but we need theory and simulations to prove that intuition. 13.2.2.3 P-curving P-curving has been proposed by Uri Simonsohn, Leif Nelson and Joseph Simmons in order to measure the evidential value of a set of published results. The basic idea is rather simple: when there is a true effect, the distribution of p-values of statistically significant results should be denser at lower p-values. This is because when there is a true effect, the density of the distribution of the p-values of statistically significant results decreases with the p-values. When there is no effect and in the absence of QRPs, p-values of statistically significant results are uniformly distributed, and their density is thus flat. When there is no effect and there are QRPs, the density of the distribution of the p-values of statistically significant results increases with the p-values. P-curving interprets the shape of teh p-curve as showing signs of true effect (we say it has evidential value), no effect, or QRPs. P-curving has two applications: detection of publication bias and QRPs and correction for publication bias and QRPs. 13.2.2.3.1 Proof of evidential value using p-curving The basic idea behind using p-curving for measuring whether a result has evidential value rests on the fact that, when there is no effects and no QPRs, p-values of statistically significant results are distributed uniformly. This is because, in the absence of any effect and of QRPs, the p-value measures the probability that a result of the same size or higher happens. When the effect is non existent and there are no QRPs, a p-value of 0.05 will occur 5% of the time and a p-value of 0.04 will occur 4% of the time So, p-values between 0.05 and 0.04 will occur 1% of the time, as p-values between 0.04 and 0.03 and so on. When there is a true effect, more small p-values are observed than larger ones. When there is no effet and there are QRPs, more p-values are observed closer to 0.05 than further away. How to go from this intuition to testing for the existence of evidential value? One first very simple approach would simply be to separate the set of statistically significant p-values \\(\\left[0,0.05\\right]\\) in half. In the absence of effect and of QRPs, the probability that a statistically significant p-value falls into one of these two sets (\\(\\left[0,0.025\\right]\\) and \\(\\left]0.025,0.05\\right]\\)) is 0.5. Comparing the actual proportion of p-values falling in these sets to the theoretical uniform value gives a first simple test of evidential value. A rigorous test can be built by computing the probability that an event such as observed would have happened under the null of no effect and no QRPs. This can be done using the Binomial law, since under the null of no effect and no QRPs, \\(X\\), the number of results falling in the \\(\\left]0.025,0.05\\right]\\) set, follows a binomial \\(Bi(n,p)\\), with \\(n\\) the number of studies and \\(p=0.5\\). The probability of observing \\(x\\) studies among \\(n\\) in the \\(\\left]0.025,0.05\\right]\\) set is thus \\(\\Pr(X=x)=b(x,n,p)\\), where \\(b(x,n,p)\\) is the density of the binomial distribution. The probability of observing \\(x\\) studies or more among \\(n\\) in the \\(\\left]0.025,0.05\\right]\\) set is \\(\\Pr(X\\geq x)=1-B(x-1,n,p)\\), where \\(B(x,n,p)\\) is the cumulative of the binomial distribution. For example, if we have 6 studies, with five of them falling in the \\(\\left]0.025,0.05\\right]\\) set, we have \\(5/6=\\) 83 % of studies close to 0.05. Under the null of no effect and no QRPs, this would have happened with probability 0.09. If we define the alternative to be the existence of QRPs, this or something worse (meaning more QRPs) would have happened with probability 0.11. This is not definitive evidence against the null and in favor of QRPs, but we’re getting there. If we define the alternative as being a true effect, we would obtain the same results per symmetry of the binomail distribution. Let’s write a function that takes a vector of p-values and returns the binomial test statistic and p-value for the null of no effect and no QRPs. pcurve.binom &lt;- function(pvalues,alter=&#39;True&#39;){ p.upper &lt;- ifelse(pvalues&gt;0.025,1,0) p.lower &lt;- ifelse(pvalues&lt;=0.025,1,0) pbinom.True &lt;- pbinom(sum(p.lower),length(pvalues),0.5) if (alter==&#39;QRP&#39;){ pbinom.True &lt;- 1-pbinom(sum(p.upper)-1,length(pvalues),0.5) } return(pbinom.True) } Another test use the distribution of the p-values of the p-values, or pp-value. The test works as follows. Let’s say you have a set of p-values \\(p_i\\). For each \\(p_i\\), compute the probability to observe this p-value or a more extreme one if the null were true. This is not too hard since \\(p_i\\) is distributed uniformly on \\(\\left[0,0.05\\right]\\) under the null and thus both its density and cumulative are known. The only twist you have to pay attention to is how you define extreme. This depends on what is your alternative hypothesis. If you are comparing the null to a case with QRPs, then more extreme means a p-value closer to 0.05. If you are comparing the null to a case where there is a true effect, then more extreme means a p-value closer to 0. In the latter case, the pp-value of \\(p_i=p_k\\) is \\(pp^r_k=\\Pr(p_i\\leq p)=p_k/0.05\\), from the cumulative of a uniform. In the former case, the pp-value of \\(p_i=p_k\\) is \\(pp^l_k=\\Pr(p_i\\geq p)=1-p_k/0.05\\). Now, you can aggregate the pp-values using Fisher’s method: \\(F_{pp}^s=-2\\sum_k\\ln(pp^s_k)\\), for \\(s\\in\\left\\{l,r\\right\\}\\). \\(F_{pp}^s\\) is distributed \\(\\chi^2(2k)\\) under the null. pp.test &lt;- function(pvalues,alter=&#39;True&#39;){ pp &lt;- pvalues/0.05 if (alter==&#39;QRP&#39;){ pp &lt;- 1-pp } Fpp &lt;- -2*sum(log(pp)) dfChis &lt;- 2*length(pvalues) pChisquare.Fpp &lt;- pchisq(Fpp,dfChis,lower.tail=F) qChisquare.5 &lt;- qchisq(0.05,dfChis,lower.tail=F) return(c(pChisquare.Fpp,Fpp,dfChis,qChisquare.5)) } Imagine for example that we have three studies with p-values 0.001, 0.002 and 0.04. Let’s compute the test against both alternatives: pvalex &lt;- c(0.001,0.002,0.04) p.binom.test.True &lt;- pcurve.binom(pvalex,alter=&#39;True&#39;) p.binom.test.QRP &lt;- pcurve.binom(pvalex,alter=&#39;QRP&#39;) pp.ex.QRP &lt;- pp.test(pvalex,alter=&#39;QRP&#39;) pp.ex.True &lt;- pp.test(pvalex,alter=&#39;True&#39;) The Chi-square statistic against QRPs is 3.34 and the corresponding p-value is 0.76. The Chi-square statistic against a true effect is 14.71 and the corresponding p-value is 0.02. There is a last test based on the p-curve tool that compares the actual distribution of statistically significant p-values to that that would be generated by a real but small effect, one that we would be powered to detect in only 33% of the samples. The test simply reverses the null and alternative of the previous test when the alternative was that there exists a true effect. I do not really see what one has to gain from this additional test so I’m going to abstain from encoding for now. It uses non-central distributions to compute the pp-values. Code the additional pp-value test. Example 13.16 Let’s see how these tests work in our example. We first have to compute the p-values for each statistically significant effect. Then, we can implement our tests. data.meta$p.FE &lt;- 2*pnorm(abs(data.meta$ES/sqrt(data.meta$var.ES)),lower.tail=F) data.meta$p.RE &lt;- 2*pnorm(abs(data.meta$theta.1/sqrt(data.meta$var.ES)),lower.tail=F) pvalex.FE &lt;- filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$p.FE pvalex.RE &lt;- filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$p.RE p.binom.test.True.FE &lt;- pcurve.binom(pvalex.FE,alter=&#39;True&#39;) p.binom.test.QRP.FE &lt;- pcurve.binom(pvalex.FE,alter=&#39;QRP&#39;) pp.ex.QRP.FE &lt;- pp.test(pvalex.FE,alter=&#39;QRP&#39;) pp.ex.True.FE &lt;- pp.test(pvalex.FE,alter=&#39;True&#39;) p.binom.test.True.RE &lt;- pcurve.binom(pvalex.RE,alter=&#39;True&#39;) p.binom.test.QRP.RE &lt;- pcurve.binom(pvalex.RE,alter=&#39;QRP&#39;) pp.ex.QRP.RE &lt;- pp.test(pvalex.RE,alter=&#39;QRP&#39;) pp.ex.True.RE &lt;- pp.test(pvalex.RE,alter=&#39;True&#39;) In the homogeneous effects case, the p-value of the null of an absence of an effect versus QRPs is of 0.76. The p-value of a null of an absence of an effect versus a true effect is 0. In the heterogeneous effects case, the p-value of a null of an absence of an effect versus QRPs is of 1 while the test statistic of a null of an absence of an effect versus a true effect is 0. In both case, we clearly reject the absence of an effect. As a consequence, the set of p-values has evidential value. We also reject the existence of QRPs. That means that there is no p-hacking creating an undue mass of p-values close to 0.05, but that does not mean that there is no publicaiton bias. P-curving has nothing to say about publication bias. It can only say whether there is a true effect or not and whether there are signs of QRPs. A cool way to present the results of p-curving is to draw the density of the statistically significant p-values against a uniform and the density that would occur under 33% power. Let me try and build such a graph in our example. First, we have to split the overall set \\(\\left[0,0.05\\right]\\) into equal-sized p-values bins, lets say \\(\\left[0,0.01\\right[\\), \\(\\left[0.01,0.02\\right[\\), \\(\\left[0.02,0.03\\right[\\), \\(\\left[0.03,0.04\\right[\\), \\(\\left[0.04,0.05\\right]\\). I’m gonna name each interval after its higher end point. Second, we have to compute how many of our observations fall in each of the bins. Third, just plot the corresponding density. The addition of the density of p-values if the real test had 33% power is slightly more involved, because it requires the notions of power and MDE that we studied in Chapter 7. As in Chapter 7, we’re going to use the CLT approximation to the distribution of the treatment effect estimate over sampling replications. The key idea is to recognize that, with a power of \\(\\kappa\\) for a two-sided test, the distribution of the treatment effect divided by its standard error \\(\\sqrt{V[\\hat{E}]}\\) is a standard normal centered at \\(MDE^n_{\\kappa,\\alpha}=\\frac{MDE_{\\kappa,\\alpha}}{\\sqrt{V[\\hat{E}]}}=\\Phi^{-1}(\\kappa)+\\Phi^{-1}(1-\\alpha/2)\\). This is an approximation that assumes away the mass of the distribution that lies below zero. This appromixation is useful since it delivers closed form solutions and it most of the time is accurate enough. The lower below \\(\\kappa=\\) 33% we’re going, the likelier it is that this approximation is at fault. Now, the probability that this distribution gives a p-value of 0.05 or smaller for a two-sided test of the true effect being zero with size 5% is equal to \\(\\Phi(MDE^n_{\\kappa,\\alpha}-\\Phi^{-1}(1-\\alpha/2))=\\kappa\\) by definition. The probability that it gives a p-value of \\(p\\) for the same test is of \\(\\Phi(MDE^n_{\\kappa,\\alpha}-\\Phi^{-1}(1-p/2))\\). Conditionnal on having a p-value inferior to 5% ( a statistically significant result), the probability of having a p-value between \\(p_1\\) and \\(p_2\\) ( the pp-value) is thus: \\[\\begin{align*} pp_{\\kappa,\\alpha}(p_1,p_2) &amp; = \\frac{1}{\\kappa}\\left(\\Phi(MDE^n_{\\kappa,\\alpha}-\\Phi^{-1}(1-p_2/2))-\\Phi(MDE^n_{\\kappa,\\alpha}-\\Phi^{-1}(1-p_1/2))\\right). \\end{align*}\\] Let’s write a function that gives us this result. MDE.var &lt;- function(alpha=0.05,kappa=0.33,varE=1){ return((qnorm(kappa)+qnorm(1-alpha/2))*sqrt(varE)) } ppCurvePower &lt;- function(p1,p2,alpha=0.05,kappa=0.33,varE=1){ return((pnorm(MDE.var(alpha=alpha,kappa=kappa)-qnorm(1-p2/2)) -pnorm(MDE.var(alpha=alpha,kappa=kappa)-qnorm(1-p1/2)))/kappa) } Now, let’s plot the p-curve plot. pCurve.hist &lt;- function(pvalues,power=.33){ dens1 &lt;- sum(ifelse(abs(pvalues-0.005)&lt;0.005,1,0)/length(pvalues)) dens2 &lt;- sum(ifelse(abs(pvalues-0.015)&lt;0.005,1,0)/length(pvalues)) dens3 &lt;- sum(ifelse(abs(pvalues-0.025)&lt;0.005,1,0)/length(pvalues)) dens4 &lt;- sum(ifelse(abs(pvalues-0.035)&lt;0.005,1,0)/length(pvalues)) dens5 &lt;- sum(ifelse(abs(pvalues-0.045)&lt;0.005,1,0)/length(pvalues)) dens &lt;- c(dens1,dens2,dens3,dens4,dens5) p.hist.1 &lt;- cbind(c(0.01,0.02,0.03,0.04,0.05),dens) p.hist.1 &lt;- as.data.frame(p.hist.1) colnames(p.hist.1) &lt;- c(&#39;p&#39;,&#39;density&#39;) p.hist.1$Data &lt;- c(&quot;Observed&quot;) p.hist.2 &lt;- cbind(c(0.01,0.02,0.03,0.04,0.05),0.2) p.hist.2 &lt;- as.data.frame(p.hist.2) colnames(p.hist.2) &lt;- c(&#39;p&#39;,&#39;density&#39;) p.hist.2$Data &lt;- c(&quot;Uniform&quot;) dens331 &lt;- ppCurvePower(0,0.01) dens332 &lt;- ppCurvePower(0.01,0.02) dens333 &lt;- ppCurvePower(0.02,0.03) dens334 &lt;- ppCurvePower(0.03,0.04) dens335 &lt;- ppCurvePower(0.04,0.05) dens33 &lt;- c(dens331,dens332,dens333,dens334,dens335) p.hist.3 &lt;- cbind(c(0.01,0.02,0.03,0.04,0.05),dens33) p.hist.3 &lt;- as.data.frame(p.hist.3) colnames(p.hist.3) &lt;- c(&#39;p&#39;,&#39;density&#39;) p.hist.3$Data &lt;- c(&quot;Power33&quot;) p.hist &lt;- rbind(p.hist.1,p.hist.2,p.hist.3) return(p.hist) } p.hist.FE &lt;- pCurve.hist(pvalex.FE) p.hist.FE$Effect &lt;- &quot;Homogeneous&quot; p.hist.RE &lt;- pCurve.hist(pvalex.RE) p.hist.RE$Effect &lt;- &quot;Heterogeneous&quot; p.hist.ex &lt;- rbind(p.hist.FE,p.hist.RE) p.hist.ex$Effect &lt;- factor(p.hist.ex$Effect,levels=c(&quot;Homogeneous&quot;,&quot;Heterogeneous&quot;)) p.hist.ex$Data &lt;- factor(p.hist.ex$Data,levels=c(&quot;Observed&quot;,&quot;Uniform&quot;,&quot;Power33&quot;)) ggplot(data=p.hist.ex, aes(x=p, y=density, color=Data)) + geom_point() + geom_line() + facet_grid(. ~ Effect)+ theme_bw() Figure 13.18: P-curve plot in our example 13.2.2.3.2 Correction for publication bias using p-curving In a separate paper, Simonsohn, Nelson and Simmons proposed a way to use p-curve to correct treatment effect estimates from publication bias. The underlying idea is rather simple, but also brilliant: the shape of the p-curve changes with the true underlying effect. It goes from uniform in the absence of any effect to right-skewed when there is an effect. The strength of the right-skewness tells us something about the underlying strength of the measured effect. For a given sample size, an increase in right-skewness will mean an increasae in effect size. The key difficulty is to separate the impact of sample size from that of effect size on the shape of the p-curve. Since sample size is known, it should be doable. Let’s see how. The key technical intuition behind the p-curve approach to correction for publication bias is to notice that the pp-curve computed for the true treatment effect should be uniform on \\(\\left[0,1\\right]\\). We have seen in the previous section that the pp-curve (the proportion of p-values that fall within identical intervals) is uniform when the true effect is zero. If we compute the pp-curve with a different assumption and apply it to the actual p-values that we observe, it is going to be uniform only for the actual treatment effect. So the only thing to do is to take all of the significant p-values and to compute their pp-curve for various levels of treatment effect, or, better, to look for the treatment effect that minimizes the distance between the observed pp-curve and a uniform. The authors propose to minimize a Kolmogorov-Smirnov metric to do so. Let’s first explore the way the concept works. For each treatment effect \\(\\hat{\\theta}_k\\) and its estimated standard error \\(\\hat{\\sigma}_k\\) we know from the CLT that they are distributed approximately as a normal. If we assume that the true treatment effect is \\(\\theta_c\\), with \\(c\\) for candidate value, we know that \\(\\frac{\\hat{\\theta}_k-\\theta_c}{\\hat{\\sigma}_k}\\) is distributed as a centered standardized normal distribution, under the assumption of homogeneous treatment effect across studies. Homogeneity is a crucial assumption for the pp-curve approach to correction for publication bias. I’ll try to see how we can relax it later, but for now, I’m going to assume \\(\\tau^2=0\\). One way to compute the pp-value is to start directly with the treatment effect and its standard error, and to recover the pp-value from there. The pp-value is the probability that we have a draw of an estimator \\(\\hat{\\theta}\\) of mean \\(\\theta_c\\) and standard error \\(\\hat{\\sigma}_k\\) that is greater or equal to \\(\\hat{\\theta}_k\\) given that it is a statistically significant result: \\[\\begin{align*} pp(\\hat{\\theta}_k,\\hat{\\sigma}_k,\\theta_c) &amp; = \\Pr\\left(\\hat{\\theta}\\geq\\hat{\\theta}_k\\left| \\left|\\frac{\\hat{\\theta}}{\\hat{\\sigma}_k}\\right| \\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right.\\right). \\end{align*}\\] Let’s assume that we are only looking at statistically significant results for two-sided t-tests, but that are located on the positive side of the threshold: \\(\\frac{\\hat{\\theta}_k}{\\hat{\\sigma}_k}\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\). This assumption will be innocuous in most cases of homogeneous treatment effect when the true effect we examine is positive since the mass of the distribution will fall on the positive side of the threshold, especially for significant results. How do we compute the pp-value for a candidate value \\(\\theta_c\\)? Theorem 13.3 (pp-value with homogeneous positive treatment effect) Under the assumption that the treatment effect is homogeneous across studies and equal to \\(\\theta_c\\), that the estimated effects \\(\\hat{\\theta}_k\\) are approximately normally distributed with mean \\(\\theta_c\\) and standard error \\(\\hat{\\sigma}_k\\) and that we use only effects that are positive and significant at the level \\(\\alpha\\) following a two-sided test, the pp-value of a result with estimated effect \\(\\hat{\\theta}_k\\) and estimated standard error is \\(\\hat{\\sigma}_k\\): \\[\\begin{align*} pp(\\hat{\\theta}_k,\\hat{\\sigma}_k,\\theta_c) &amp; = \\frac{\\Phi\\left(\\frac{\\theta_c-\\hat{\\theta}_k}{\\hat{\\sigma}_k}\\right)} {\\Phi\\left(\\frac{\\theta_c}{\\hat{\\sigma}_k}-\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right)}. \\end{align*}\\] Proof. \\[\\begin{align*} pp(\\hat{\\theta}_k,\\hat{\\sigma}_k,\\theta_c) &amp; = \\Pr\\left(\\hat{\\theta}\\geq\\hat{\\theta}_k\\left|\\frac{\\hat{\\theta}}{\\hat{\\sigma}_k} \\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right.\\right)\\\\ &amp; = \\frac{\\Pr\\left(\\hat{\\theta}\\geq\\hat{\\theta}_k\\land\\hat{\\theta}\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k\\right)} {\\Pr\\left(\\hat{\\theta}\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k\\right)} \\\\ &amp; = \\frac{\\Pr\\left(\\hat{\\theta}\\geq\\hat{\\theta}_k\\right)} {\\Pr\\left(\\hat{\\theta}\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k\\right)} \\\\ &amp; \\approx \\frac{1-\\Phi\\left(\\frac{\\hat{\\theta}_k-\\theta_c}{\\hat{\\sigma}_k}\\right)} {1-\\Phi\\left(\\frac{\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k-\\theta_c} {\\hat{\\sigma}_k}\\right)}\\\\ &amp; \\approx \\frac{\\Phi\\left(\\frac{\\theta_c-\\hat{\\theta}_k}{\\hat{\\sigma}_k}\\right)} {\\Phi\\left(\\frac{\\theta_c}{\\hat{\\sigma}_k}-\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right)}. \\end{align*}\\] The second equality stems from Bayes theorem. The third equality stems from the fact that \\(\\hat{\\theta}\\geq\\hat{\\theta}_k\\Rightarrow\\hat{\\theta}\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k\\) since \\(\\hat{\\theta}_k\\geq\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\hat{\\sigma}_k\\) by assumption. The fourth equality stems from using the normality approximation to the distribution of \\(\\hat{\\theta}\\). The fifth equality uses the usual property of the cumulative of the standardized and centered normal distribution that \\(1-\\Phi(x)=\\Phi(-x)\\). Another way to compute the pp-value is to start from the p-value. This approach is especially useful when we do not have access to an estimate of the treatment effect, but only to the p-value of a two-sided t-test and to the sample size. In this case, we can generally only recover the effect size of the treatment effect \\(d_c\\), that is the treatment effect scaled by the standard error of the outcome \\(\\sigma_{Y}\\) (under the assumption of homogeneous treatment effects, there is no heteroskedasticity, and the variance of outcomes is identical in both the treatment and control groups). In order to do so, we use the fact that \\(d_c=\\frac{\\theta_c}{\\sqrt{N}\\hat{\\sigma_k}}\\) since \\(\\hat{\\sigma_k}\\approx\\frac{\\sigma_{Y}}{\\sqrt{N}}\\) for the With/Without estimator without control variables (using the CLT). Note that this is a highly restrictive assumption, excluding that the With/Without estimator controls for covariates, or the use of other estimators. Corollary 13.1 (Building pp-value from p-values) Under the assumption that the effect size is homogeneous across studies and equal to \\(d_c\\), that the estimated effects sizes \\(\\hat{d}_k\\) are approximately normally distributed with mean \\(d_c\\), that we use only effects are positive and significant at the level \\(\\alpha\\) following a two-sided test, and that \\(\\hat{\\sigma_k}\\approx\\frac{\\sigma_{Y}}{\\sqrt{N}}\\), the pp-value of a result with sample size \\(N_k\\) and p-value \\(\\hat{p}_k\\) is: \\[\\begin{align*} pp_p(\\hat{p}_k,N_k,d_c) &amp; \\approx \\frac{\\Phi\\left(\\sqrt{N}d_c-\\Phi^{-1}\\left(1-\\frac{p_k}{2}\\right)\\right)} {\\Phi\\left(\\sqrt{N}d_c-\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right)}. \\end{align*}\\] Proof. From the formula for two-sided t-tests, we have that: \\[\\begin{align*} p_k &amp; = 2\\left(1-\\Phi\\left(\\left|\\frac{\\hat{\\theta}_k}{\\hat{\\sigma}_k}\\right|\\right)\\right). \\end{align*}\\] As a consequence: \\[\\begin{align*} \\left|\\frac{\\hat{\\theta}_k}{\\hat{\\sigma}_k}\\right| &amp; = \\Phi^{-1}\\left(1-\\frac{p_k}{2}\\right). \\end{align*}\\] Using the assumption that all significant effects are positive, and the fact that \\(\\sqrt{N}d_c\\approx\\frac{\\theta_c}{\\hat{\\sigma}_k}\\) under the assumption that \\(\\hat{\\sigma_k}\\approx\\frac{\\sigma_{Y}}{\\sqrt{N}}\\), we obtain the result by using Theorem 13.3. Remark. Using only positive values is a benefit, since the preferred direction is less likely to have been slectively underreported. Remark. The authors use Student \\(t\\) distributions instead of a normal approximation. This will not matter as loong as sample size is large enough. Generalizing the results of this section to Student-\\(t\\) distributions is simple, but the normal approximation should work most of the time. Remark. There seems to be a mistake in the numerator in the original paper: the authors subtract power whereas it does not seem to be required. At least, I do not understand their derivation. Both appraoches yield similar results in their example, except for one case. Remark. The assumption of homogeneous treatment effects is key here: it enables to use the standard normal as an approximation. The test has to be modified to account for heterogeneous treatment effects. Heterogeneity in treatment effects might bias the estimate. In order to estimate the parameter \\(\\theta_c\\) (or \\(d_c\\) if using p-values only), the authors make use of the fact that, under the true \\(\\theta_c\\), the pp-values are uniformly distributed on \\(\\left[0,1\\right]\\). The authors propose to choose the value \\(\\hat{\\theta}_c\\) that makes the pp-curve as close to a uniform as possible as an estimator of \\(\\theta_c\\). As a metric for estimating the distance between the observed pp-curve and the uniform \\(\\left[0,1\\right]\\), the authors propose to use the Kolmogorov-Smirnov statistic: the maximum value of the absolute difference between the empirical cdf of pp-values and the theoretical values of the cdf of the uniform \\(\\left[0,1\\right]\\). The objective function proposed by the authors minimizes this distance. Let’s write the functions to compute just that: ppCurveEst &lt;- function(thetac,thetak,sigmak,alpha=0.05){ return((pnorm((thetac-thetak)/sigmak)/pnorm(thetac/sigmak-qnorm(1-alpha/2)))) } #KS statistic KS.stat.unif &lt;- function(vector){ return(ks.test(x=vector,y=punif)$statistic) } ppCurve.Loss.KS &lt;- function(thetac,thetak,sigmak,alpha=0.05){ ppvalues &lt;- ppCurveEst(thetac=thetac,thetak=thetak,sigmak=sigmak,alpha=alpha) return(KS.stat.unif(ppvalues)) } #Estimating thetac that minimizes the KS distance by brute grid search first # will program the optimize function after ppCurveEstES &lt;- function(thetak,sigmak,thetacl,thetach,alpha=0.05,ngrid=100){ # break thetac values in a grid thetac.grid &lt;- seq(from=thetacl,to=thetach,length.out=ngrid) # computes the ppcurve for each point of the grid: outputs a matrix where columns are the ppcurves at each values of thetac ppCurve.grid &lt;- sapply(thetac.grid,ppCurveEst,thetak=thetak,sigmak=sigmak,alpha=alpha) # compute KS stat for each value of thetac (over columns) KS.grid &lt;- apply(ppCurve.grid,2,KS.stat.unif) # computes the value of thetac for which the KS stat is minimum (match identifies the rank of the min in the KSgrid) min.theta.c &lt;- thetac.grid[match(min(KS.grid),KS.grid)] # optimizes over KS stat to find value of thetac that minimizes the KS stat thetahat &lt;- optimize(ppCurve.Loss.KS,c(min.theta.c-0.1,min.theta.c+0.1),thetak=thetak,sigmak=sigmak,alpha=alpha) # returns the optimal thetac, the grid of thetac, the KS stats on the grid, for potential plot, and the ecdf of ppvalues at the optimum theta for graph against the uniform return(list(thetahat$minimum,thetac.grid,KS.grid,ecdf(ppCurve.grid[,match(min(KS.grid),KS.grid)]))) } Example 13.17 Let’s see how this approach works in our example. Let’s start with the homogeneous treatment effect case # I&#39;m keeping only significant and positive estimates # Maybe this could be enforced within the function for ease of reading and use ppCurveBiasCorrFE &lt;- ppCurveEstES(thetak=filter(data.meta,id&lt;=17,data.meta$ES&gt;0,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$ES,sigmak=sqrt(filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES),thetacl=0,thetach=10,alpha=0.05,ngrid=100) plot(ppCurveBiasCorrFE[[2]],ppCurveBiasCorrFE[[3]],xlab=&quot;thetac&quot;,ylab=&quot;KS statistic&quot;) plot(ppCurveBiasCorrFE[[4]],xlab = &quot;ppvalues&quot;,ylab=&quot;cumulative density&quot;,main=&quot;Cumulative density of pp-values at the optimum&quot;) curve(punif,add=T) Figure 13.19: Correction for publication bias using p-curving with homogeneous effects The bias corrected estimate using p-curving in the homogeneous treatment effect case is equal to 0.2, which is spot on. Remember the true treatment effect is 0.2. Let’s see what happens when effects are heterogeneous. # I&#39;m keeping only significant and positive estimates # Maybe this could be enforced within the function for ease of reading and use ppCurveBiasCorrRE &lt;- ppCurveEstES(thetak=filter(data.meta,id&lt;=17,data.meta$ES&gt;0,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$theta.1,sigmak=sqrt(filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES),thetacl=0,thetach=10,alpha=0.05,ngrid=100) plot(ppCurveBiasCorrRE[[2]],ppCurveBiasCorrRE[[3]],xlab=&quot;thetac&quot;,ylab=&quot;KS statistic&quot;) plot(ppCurveBiasCorrRE[[4]],xlab = &quot;ppvalues&quot;,ylab=&quot;cumulative density&quot;,main=&quot;Cumulative density of pp-values at the optimum&quot;) curve(punif,add=T) Figure 13.20: Correction for publication bias using p-curving with heterogeneous effects The bias corrected estimate using p-curving in the heterogeneous treatment effect case is equal to 0.49. Remark. The approach might be incorrect in the heterogeneous treatment effect case since we do not normalize using \\(\\tau^2\\). I think using an estimate of \\(\\tau^2\\) to normalize the estimates would restore the validity of the procedure. It is also possible that the distribution of significant p-values is uniform even under heterogeneity of the treatment effect. In that case, the p-curve approach would still be valid. This is scope for further reasearch: first some simulations would be welcome. Simulations by the authors seem to suggest that p-curve does fine when treatment effects are heterogeneous: see here Remark. Anther problem with p-curving when correcting for publication bias is the existence of QRPs: QRPs might bias the bias correction because of an excess mass around 0.05. Simulations by the author in the original paper show that this biases the estimate downward. Remark. Another approach than using the KS statistic could use the distance between the observed pp-curve in Figure 13.18 and the pp-curve with various levels of power. Once the power is identified, the effect size is identified. Still another approach would be to use the standardized distribution of effects (distributed as a standardized normal) to estimate the mean of the distribution and then recover the treatment effect. 13.2.2.4 Z-curving See here. 13.2.2.5 Selection models Publication bias generates a usual pattern for economists: a selection model. The probability that a result is published depends on several properties, let’s say its significance, as measured for example by the t-statistic of a two-sided t-test of the estimated parameter being null. The resulting distribution of observed effect sizes is a truncated or censored distribution compared to the distribution of true effect sizes. It has been a long goal of statisticians and economists to try to recover properties of the distribution of a latent unobserved variable from what is observed (think distribution of wages for women, when labor force participation for women was far lower than it is today). Statisticians have been using selection models to try to correct for publication bias since at least Hedges. In this section, I’m going to follow closely Andrews and Kasy’s approach. Andrews and Kasy carefully delineate non-parameteric identification of a selection model in the case of heterogeneous treatment effects. They then present ways to estimate the parameters of this model and propose a web-app to perform their estimation strategy. Andrews and Kasy assume that there is a true treatment effect in all the populations that is equal to \\(\\theta^*_c\\). In each study \\(k\\), the true treatment effect \\(\\theta^*_k\\) is drawn from a distribution with mean \\(\\theta^*_c\\). If the distribution of \\(\\theta^*_k\\) is degenerate, then we have homogeneous treatment effects. The estimator of \\(\\theta^*_k\\) in each study, \\(\\hat{\\theta}^*_k\\), is distributed as a normal centered at \\(\\theta^*_k\\) with variance \\(\\sigma^{*2}_k\\), whose estimator in the sample \\(k\\) is \\(\\hat{\\sigma}^{*2}_k\\). The normality assumption is not too crazy here: it follows from the CLT. Andrews and Kasy posit that, because of selection bias, we observe only a subset of these latent effects, noted \\(\\hat{\\theta}_k\\), those for which \\(D_k=1\\). \\(D_k\\) is distributed as a Bernoulli random variable, with probability of success \\(p(\\hat{Z}_k^*)\\), where \\(\\hat{Z}_k^*=\\frac{\\hat{\\theta}^*_k}{\\hat{\\sigma}^{*}_k}\\) is the test statistic of t-test for the null assumption that \\(\\theta_k=0\\). So Andrews and Kasy assume that all publication bias is driven by the value of the t-statistic \\(\\hat{Z}_k^*\\). Note that it is equivalent to assuming that it is driven by the p-value of this test, since one is a monotone transformation of the other. As a consequence of the assumed selection model, the density of observed t-stats is (noting \\(Z_k^*=\\frac{\\theta^*_k}{\\sigma^{*}_k}\\) and \\(Z_k=\\frac{\\theta_k}{\\sigma_k}\\)): \\[\\begin{align*} f_{\\hat{Z}|Z}(\\hat{z}|z) &amp; = f_{\\hat{Z}^*|Z^*,D=1}(\\hat{z}|z)\\\\ &amp; = \\frac{\\Pr(D_k=1|\\hat{Z}_k^*=\\hat{z},Z_k^*=z)}{\\Pr(D_k=1|Z_k^*=z)}\\phi(\\hat{z}-z)\\\\ &amp; = \\frac{p(\\hat{z})}{\\esp{p(\\hat{Z}^*_k)|Z_k^*=z}}\\phi(\\hat{z}-z). \\end{align*}\\] The first equality is obtained by using Bayes’ equality twice (once to undo the conditioning on \\(D=1\\) and once to generate the conditioning on \\(Z^*_k=z\\)) and the fact that \\(f_{\\hat{Z}^*|Z^*}\\) is normally distributed with mean \\(Z^*\\) and variance 1. The key result in Andrews and Kasy is their Proposition 3: Proposition 13.1 (Identification of the true effect in meta-analysis) Under the assumption that \\(\\theta^*_k\\Ind\\sigma^*_k\\), and that the support of \\(\\sigma_k\\) contains an open interval, \\(p(.)\\) is identified up to scale and the distribution of \\(\\theta^*_k\\) is identified. Proof. See Andrews and Kasy’s supplementary material. Let’s detail the proof somehow. The proof works by using the way the density of observed \\(\\hat{Z}\\) changes with precision (\\(\\hat{\\pi_k}=\\frac{1}{\\hat{\\sigma}_k}\\)). Without loss of generality, the authors choose to look at the density of \\(\\hat{Z}\\) when \\(\\hat{\\sigma}_k=1\\). They define \\(h(z)=f_{\\hat{Z}^*|\\hat{\\sigma}^*_k}(z|1)\\). The first insight of the proof is that identifying \\(h(.)\\) identifies \\(p(.)\\) and the distribution of \\(\\theta^*_k\\), \\(f_{\\theta^*}\\). When \\(h(.)\\) is identified, \\(f_{\\theta^*}\\) is identified by deconvolution since \\(h=f_{\\theta^*}*\\phi\\), where \\(*\\) is the convolution operator. This is because we can think of \\(\\hat{\\theta}^*_k=\\theta^*_k+\\epsilon^*_k\\), where \\(\\epsilon^*_k\\) is independent from \\(\\theta^*_k\\) (since \\(\\theta^*_k\\Ind\\sigma^*_k\\)) and follows a normal with mean zero and variance \\(\\hat{\\sigma}^{*2}_k\\), here one. The density of a sum of independent random variables is the convolution of their densities, hence the result. Now, we have: \\[\\begin{align*} f_{\\hat{Z}|\\hat{\\sigma}}(z|s) &amp; = f_{\\hat{Z}^*|\\hat{\\sigma}^*,D=1}(z|z)\\\\ &amp; = \\frac{\\Pr(D_k=1|\\hat{Z}_k^*=z,\\hat{\\sigma}^*_k=s)}{\\Pr(D_k=1|\\hat{\\sigma}_k^*=s)}f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|s)\\\\ &amp; = \\frac{p(z)}{\\esp{p(\\hat{Z}^*_k)|\\hat{\\sigma}^*_k=s}}f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|s). \\end{align*}\\] As a consequence, we have: \\[\\begin{align*} p(z)&amp; = \\esp{p(\\hat{Z}^*_k)|\\hat{\\sigma}_k^*=s}\\frac{f_{\\hat{Z}|\\hat{\\sigma}}(z|s)}{h(z)}. \\end{align*}\\] So, once we know \\(h(z)\\), we know \\(p(z)\\) up to a constant, since \\(f_{\\hat{Z}|\\hat{\\sigma}}(z|s)\\) is known by definition, and \\(\\esp{p(\\hat{Z}^*_k)|\\hat{\\sigma}_k^*=s}\\) does not change with \\(z\\). In order to identify \\(h(z)\\), we look at how the density of observed effects changes when precision changes: \\[\\begin{align*} g(z) &amp; = \\partder{\\ln f_{\\hat{Z}|\\hat{\\sigma}}(z|\\frac{1}{\\pi})}{\\pi}|_{\\pi=1}\\\\ &amp; = C_1 + \\partder{\\ln f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|\\frac{1}{\\pi})}{\\pi}|_{\\pi=1}. \\end{align*}\\] \\(C_1\\) is a constant in \\(z\\). This is because \\(p(z)\\) does not depend on \\(\\pi\\) and because \\(\\esp{p(\\hat{Z}^*_k)|\\hat{\\sigma}_k^*=s}\\) does not depend on \\(z\\). Note that \\(g(z)\\) is identified in the population. Now, using the fact that, because \\(\\theta^*_k\\Ind\\sigma^*_k\\), we have \\(h=f_{\\theta^*}*\\phi\\), and thus \\(f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|\\frac{1}{\\pi})=\\int\\phi(z-t\\pi)df_{\\theta^*}(t)\\), and the fact that \\(\\phi&#39;(z)=-z\\phi(z)\\), we have: \\[\\begin{align*} \\partder{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)}{z} &amp; = -\\int(z-t)\\phi(z-t)df_{\\theta^*}(t)\\\\ \\partdersq{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)}{z} &amp; = - f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1) +\\int(z-t)^2\\phi(z-t)df_{\\theta^*}(t)\\\\ \\partder{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|\\frac{1}{\\pi})}{\\pi}|_{\\pi=1} &amp; = \\int t(z-t)\\phi(z-t)df_{\\theta^*}(t)\\\\ &amp; = - \\left[f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)+z\\partder{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)}{z} + \\partdersq{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)}{z}\\right]. \\end{align*}\\] The last equation comes from rearranging all the terms in the various terms and factoring what remains. Note that \\(f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)\\) disappears when you add \\(\\partdersq{f_{\\hat{Z}^*|\\hat{\\sigma}^*}(z|1)}{z}\\). REgrouping under the intergal sign, factoring and simplifying gives the result. Now, using the expression for \\(g(z)\\) above, we have a second order differential equation in \\(h(.)\\): \\[\\begin{align*} h&#39;&#39;(z) &amp; = (C_1-1-g(z))h(z)-zh&#39;(z). \\end{align*}\\] Given \\(C_1\\) and initial conditions \\(h(0)=h_0\\) and \\(h&#39;(0)=h&#39;_0\\), there is a unique solution to this equation, thereby identifying \\(h(.)\\), \\(p(.)\\) and \\(f_{\\theta^*}\\). The rest of the proof in Andrews and Kasy’s supplementary material shows that \\(C_1\\), \\(h_0\\) and \\(h&#39;_0\\) are all identified. The proof builds new differential equations involving the second order derivative of \\(f_{\\hat{Z}|\\frac{1}{\\pi}}\\) with respect to \\(\\pi\\). The constants are identified after successive derivations with respect to \\(z\\) so that we have an equation for them that depends on the third order derivative of \\(g\\). Remark. The authors derive an equation for the case where \\(\\theta^*\\) is normally distributed with mean \\(\\theta\\) and variance \\(\\tau^2\\). The second order differential equation becomes: \\[\\begin{align*} -\\frac{1}{\\tau^2+1} &amp; = C_1-g(z)-1+z\\frac{z-\\theta}{\\tau^2+1}-\\left(\\frac{z-\\theta}{\\tau^2+1}\\right). \\end{align*}\\] The authors argue that evaluating this equation for different values of \\(z\\) pins down \\(\\theta\\) and \\(\\tau^2\\). It seems not enough to prove identification since we need uniqueness of the parameter values obtained. There are already two values of \\(\\theta\\) compatible for agiven \\(z\\) and \\(\\tau^2\\). We need more to ensure uniqueness. Remark. Note that \\(p(z)\\) does not depend on \\(\\pi\\) is not a trivial assumption. It stems from assuming that the probability of publication only depends on \\(\\pi\\) through \\(\\hat{Z}^*\\). It means for example that editors and authors do not look at precision independently of its effect on the t-statistic. The authors study identification in this case, assuming independence of the probabilities of selection based on both approaches. For estimation, Andrews and Kasy follow the approach in Hedges and estimate their model by parametric maximum likelihood. They also propose in their supplementary material an approach based on a Generalized Method of Moments estimator that tries to emulate their identification strategy. Finally, they offer a web-app to implement their most straightforward estimators. The likelihood can be written as: \\[\\begin{align*} f_{\\hat{\\theta},\\hat{\\sigma}}(t,s) &amp; = \\frac{p\\left(\\frac{t}{s}\\right)\\int\\phi\\left(\\frac{t-\\theta}{s}\\right)f_{\\theta^*}(\\theta) d\\theta} {\\int p\\left(\\frac{t&#39;}{s}\\right)\\int\\phi\\left(\\frac{t&#39;-\\theta}{s}\\right)f_{\\theta^*}(\\theta) d\\theta dt&#39;}f_{\\sigma}(s). \\end{align*}\\] Under the assumption that \\(\\theta^*\\) is normally distributed with mean \\(\\theta^*_c\\) and variance \\(\\tau^2\\), we have the following likelihood: \\[\\begin{align*} f^n_{\\hat{\\theta},\\hat{\\sigma}}(t,s) &amp; = \\frac{p\\left(\\frac{t}{s}\\right)\\phi\\left(\\frac{t-\\theta^*_c}{\\sqrt{s^2+\\tau^2}}\\right)} {\\int p\\left(\\frac{t&#39;}{s}\\right)\\phi\\left(\\frac{t&#39;-\\theta^*_c}{\\sqrt{s^2+\\tau^2}}\\right)dt&#39;}f_{\\sigma}(s). \\end{align*}\\] Assuming that \\(p(.)\\) is a step function such that \\(p(z)=p_1\\) if \\(z&lt;1.96\\) and \\(p(z)=1\\) if \\(z\\geq1.96\\), we have: \\[\\begin{align*} f^n_{\\hat{\\theta},\\hat{\\sigma}}(t,s) &amp; = \\frac{p\\left(\\frac{t}{s}\\right)\\phi\\left(\\frac{t-\\theta^*_c}{\\sqrt{s^2+\\tau^2}}\\right)} {p_1\\Phi\\left(\\frac{1.96s-\\theta^*_c}{\\sqrt{s^2+\\tau^2}}\\right)+1-\\Phi\\left(\\frac{1.96s-\\theta^*_c}{\\sqrt{s^2+\\tau^2}}\\right)}f_{\\sigma}(s). \\end{align*}\\] The likelihood is simply the product of this term computed at each values \\(t=\\hat{\\theta}_k\\) and \\(s=\\hat{\\sigma}_k\\): \\[\\begin{align*} \\mathcal{L}(p_1,\\theta^*_c,\\tau^2)=\\Pi_{k=1}^Nf^n_{\\hat{\\theta},\\hat{\\sigma}}(\\hat{\\theta}_k,\\hat{\\sigma}_k) \\end{align*}\\] Taking logs, we see that \\(f_{\\sigma}(s)\\) is a constant that does not contribute to the likelihood. We solve for the optimal vector of parameters by using a nonlinear optimisation routine. The authors use nlminb. One could also probably use optim. What is nice with these procedures is that they do not require computing the first and second order derivatives of the objective function: they compute them numerically. Let’s write an R function that maximizes this log likelihood: # log-likelihood Lk &lt;- function(thetak,sigmak,p1,thetac,tau){ f &lt;- ifelse(thetak/sigmak&lt;qnorm(1-0.05/2),p1,1)*dnorm((thetak-thetac)/sqrt(sigmak^2+tau^2))/(1-pnorm(qnorm(1-0.05/2)*sigmak-thetac/sqrt(sigmak^2+tau^2))*(1-p1)) return(sum(log(f))) } #log-likelihood prepared for nlminb: vector of parameters and minimization Lk.param &lt;- function(param,thetak,sigmak){ f &lt;- Lk(thetak=thetak,sigmak=sigmak,p1=param[[1]],thetac=param[2],tau=param[3]) return(-f) } Example 13.18 Let’s see how this works in our example. Let’s first prepare the sample. We are going to simulate two procedures of censoring: one with \\(p_1=0.5\\) and one with \\(p_1=0\\). # sample with p1=0: only positive significant results # homogeneous effects thetak.FE.0 &lt;- filter(data.meta,id&lt;=17,data.meta$ES&gt;0,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$ES sigmak.FE.0 &lt;- sqrt(filter(data.meta,id&lt;=17,abs(data.meta$ES/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES) # heterogeneous effects thetak.RE.0 &lt;- filter(data.meta,id&lt;=17,data.meta$theta.1&gt;0,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$theta.1 sigmak.RE.0 &lt;- sqrt(filter(data.meta,id&lt;=17,abs(data.meta$theta.1/sqrt(data.meta$var.ES))&gt;=qnorm((1+delta.2)/2))$var.ES) # sample with p1=0.1, for insignificant or negative results p1 &lt;- 0.5 # drawing 10% among insignificant and negative observations set.seed(1234) set.FE &lt;- ifelse(runif(length(filter(data.meta,id&lt;=17,data.meta$ES/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$ES))&lt;=p1,1,0)==1 set.seed(1234) set.RE &lt;- ifelse(runif(length(filter(data.meta,id&lt;=17,data.meta$theta.1/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$theta.1))&lt;=p1,1,0)==1 # homogeneous effects thetak.FE.1 &lt;- c(thetak.FE.0,filter(data.meta,id&lt;=17,data.meta$ES/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$ES[which(set.FE)]) sigmak.FE.1 &lt;- c(sigmak.FE.0,sqrt(filter(data.meta,id&lt;=17,data.meta$ES/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$var.ES[which(set.FE)])) # heterogeneous effects thetak.RE.1 &lt;- c(thetak.RE.0,filter(data.meta,id&lt;=17,data.meta$theta.1/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$theta.1[which(set.RE)]) sigmak.RE.1 &lt;- c(sigmak.RE.0,sqrt(filter(data.meta,id&lt;=17,data.meta$theta.1/sqrt(data.meta$var.ES)&lt;qnorm((1+delta.2)/2))$var.ES[which(set.RE)])) # optimization procedure using nlminb MaxEval&lt;-10^5 MaxIter&lt;-10^5 Tol&lt;-10^(-8) stepsize&lt;-10^(-6) lower.b &lt;- c(0,-Inf,0) upper.b &lt;- c(1,Inf,Inf) start.val &lt;- c(0.5,1,1) optim.Lk.FE.0 &lt;- nlminb(objective=Lk.param, start=start.val,lower=lower.b,upper=upper.b,control=list(eval.max=MaxEval,iter.max=MaxIter,abs.tol=Tol),thetak=thetak.FE.0,sigmak=sigmak.FE.0) optim.Lk.FE.1 &lt;- nlminb(objective=Lk.param, start=start.val,lower=lower.b,upper=upper.b,control=list(eval.max=MaxEval,iter.max=MaxIter,abs.tol=Tol),thetak=thetak.FE.1,sigmak=sigmak.FE.1) optim.Lk.RE.0 &lt;- nlminb(objective=Lk.param, start=start.val,lower=lower.b,upper=upper.b,control=list(eval.max=MaxEval,iter.max=MaxIter,abs.tol=Tol),thetak=thetak.RE.0,sigmak=sigmak.RE.0) optim.Lk.RE.1 &lt;- nlminb(objective=Lk.param, start=start.val,lower=lower.b,upper=upper.b,control=list(eval.max=MaxEval,iter.max=MaxIter,abs.tol=Tol),thetak=thetak.RE.1,sigmak=sigmak.RE.1) paramAK &lt;- rbind(optim.Lk.FE.0$par,optim.Lk.FE.1$par,optim.Lk.RE.0$par,optim.Lk.RE.1$par) colnames(paramAK) &lt;- c(&quot;$p_1$&quot;,&quot;$\\\\theta_c$&quot;,&quot;$\\\\tau$&quot;) rownames(paramAK) &lt;- c(&quot;FE0&quot;,&quot;FE50&quot;,&quot;RE0&quot;,&quot;RE50&quot;) knitr::kable(paramAK,digits=2,caption=&#39;Parameter estimates of Andrews and Kasy selection model&#39;,align=c(&#39;l&#39;,&#39;c&#39;,&#39;c&#39;,&#39;c&#39;),booktabs=TRUE) Table 13.1: Parameter estimates of Andrews and Kasy selection model \\(p_1\\) \\(\\theta_c\\) \\(\\tau\\) FE0 0.00 -100842.04 15537.35 FE50 0.04 -281350.82 243482.43 RE0 0.00 -33.56 4.82 RE50 0.06 -202455.05 197821.07 Table shows the parameter estimates of the model for various data configurations (no treatment effect heterogeneity vs treatment effect heterogeneity and 0% or 50% of non significant observations published). The results do not look great. The estimates of \\(p_1\\) are correct when no non significant effects are published, by they are not nearly large enough when \\(50\\%\\) of insignificant observations are published. The estimates of \\(\\theta_c\\) are completely crazy: all negative and large in asbolute value while the true value of \\(\\theta_c\\) is \\(\\theta_c=\\) 0.2. The estimates of \\(\\tau\\) are also all misleading. For fixed effects, the estimates should be zero. For random effects, the true \\(\\tau\\) is \\(\\tau=\\) 0.5. The estimates are much too large, apart from the third one that is close to home. Overall, barring a coding error, selection models do not look super promising here. 13.2.2.6 Fukumura 13.2.2.7 Trim and fill 13.2.3 Getting rid of publication bias: registered reports and pre-analysis plans 13.2.4 Detection of and correction for site selection bias 13.2.5 Vote counting and publication bias 13.2.6 The value of a statistically significant result Publication bias and random effects "],["Bounds.html", "Chapter 14 Bounds", " Chapter 14 Bounds "],["mediation-analysis.html", "Chapter 15 Mediation Analysis 15.1 Mediation analysis: a framework 15.2 The Fundamental Problem of Mediation Analysis 15.3 Mediation analysis with experimental data 15.4 Mediation analysis under unconfoundedness 15.5 Mediation analysis with panel data 15.6 Mediation analysis with instruments", " Chapter 15 Mediation Analysis When we have estimated the treatment effect of a program, we sometimes wonder by which channels the program impact has been obtained. For example, has a Job Training Program been successful because it has increased the human capital of an agent, or simply by signalling to employers her motivation? The question of separating between the various channels into which a program impact can be decomposed becomes especially important when a program has several components, and we wish to ascertain which one is the more important. Another reason why we might be interested in which channel precisely is responsible for the program impact is because which channel dominates might give us indications about which theoretical mechanism is at play. In this chapter, I am going to first delineate the general framework for mediation analysis and the way mediation analysis can be undertaken in the ideal case of a Randomized Controlled Trial. Then, I am going to present the fundamental problem of mediation analysis (which turns out to be one version of the confounders problem we know all too well) and the various techniques that have been developed in order to solve for it. 15.1 Mediation analysis: a framework Mediation analysis posits the existence of a mediator, \\(M_i\\), which is driving part or the totality of the effect of the treatment on outcome \\(Y_i\\). One way to understand how a mediator works is to draw a Direct Acyclic Graph or DAG which represents the relationship between the variables. The ggdag package helps to draw a DAG easily. Let’s give it a try: Figure 15.1: DAG of the impact of D on Y partially mediated through M We are first going to define mediated and unmediated treatment effects and see how they work in our example and we’ll then try to understand better how exactly mediation works and the mechanisms that are behind these treatment effects. 15.1.1 Defining mediated and unmediated treatment effects Let’s start with a binary mediator, in order to keep things simple: \\(M_i\\in\\left\\{0,1\\right\\}\\). We can define four potential outcomes \\(Y_i^{d,m}\\), \\((d,m)\\in\\left\\{0,1\\right\\}^2\\). We can also define two potential outcomes for the mediator: \\(M^d_i\\), \\(d\\in\\left\\{0,1\\right\\}\\). The switching equation can now be written as follows: \\[\\begin{align*} Y_i &amp; = \\begin{cases} Y_i^{1,1} &amp; \\text{if } D_i=1 \\text{ and }M_i=1\\\\ Y_i^{1,0} &amp; \\text{if } D_i=1 \\text{ and }M_i=0\\\\ Y_i^{0,1} &amp; \\text{if } D_i=0 \\text{ and }M_i=1\\\\ Y_i^{0,0} &amp; \\text{if } D_i=0 \\text{ and }M_i=0 \\end{cases} \\\\ &amp; = Y_i^{1,1}D_iM_i + Y_i^{0,1}(1-D_i)M_i + Y_i^{1,0}D_i(1-M_i)+ Y_i^{0,0}(1-D_i)(1-M_i). \\end{align*}\\] We are now equipped to define two sets of causal mediation effects: the mediated (or indirect) effect and the unmediated (or direct) effect (we follow Imai, Keene and Tingley (2010)): \\[\\begin{align*} \\Delta^{Y_{m(d)}}_{i} &amp; = Y_i^{d,M_i^1}-Y_i^{d,M_i^0}\\\\ \\Delta^{Y_{u(d)}}_{i} &amp; = Y_i^{1,M_i^d}-Y_i^{0,M_i^d}. \\end{align*}\\] \\(\\Delta^{Y_{m(d)}}_{i}\\) is the causal effect of the treatment on the outcome acting through the mediator only, while keeping the value of the treatment fixed at \\(d\\). \\(\\Delta^{Y_{u(d)}}_{i}\\) is the causal effect of the treatment on the outcome acting through the treatment only, while keeping the value of the mediator fixed at \\(M_i(d)\\). In the absence of interaction effects between the treatment and the mediator, we have \\(\\Delta^{Y_{m(0)}}_{i}=\\Delta^{Y_{m(1)}}_{i}=\\Delta^{Y_{m}}_{i}\\) and \\(\\Delta^{Y_{u(0)}}_{i}=\\Delta^{Y_{u(1)}}_{i}=\\Delta^{Y_{u}}_{i}\\). What is nice is that the individual effect of the treatment can be decomposed in these two components: \\[\\begin{align*} \\Delta^Y_{i} &amp; = Y_i^{1,M_i^1}-Y_i^{0,M_i^0}\\\\ &amp; = Y_i^{1,M_i^1}-Y_i^{1,M_i^0}+Y_i^{1,M_i^0}-Y_i^{0,M_i^0}=\\Delta^{Y_{m(1)}}_{i}+\\Delta^{Y_{u(0)}}_{i}\\\\ &amp; = Y_i^{1,M_i^1}-Y_i^{0,M_i^1}+Y_i^{0,M_i^1}-Y_i^{0,M_i^0}=\\Delta^{Y_{u(1)}}_{i}+\\Delta^{Y_{m(0)}}_{i}. \\end{align*}\\] In the absence of interaction effects between the mediator and the treatment, this decomposition is unique. The decomposition can also be applied to the TT parameter: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^0}|D_i=1}\\\\ &amp; = \\Delta^{Y_{m(1)}}_{TT}+\\Delta^{Y_{u(0)}}_{TT}\\\\ &amp; = \\Delta^{Y_{u(1)}}_{TT}+\\Delta^{Y_{m(0)}}_{TT}, \\end{align*}\\] with: \\[\\begin{align*} \\Delta^{Y_{m(d)}}_{TT} &amp; = \\esp{\\Delta^{Y_{m(d)}}_{i}|D_i=1}\\\\ \\Delta^{Y_{u(d)}}_{TT} &amp; = \\esp{\\Delta^{Y_{u(d)}}_{i}|D_i=1}. \\end{align*}\\] Here again, the decomposition will be unique if there are no interactions between the treatment and the mediator variable. Some authors use an alternative definition of the unmediated or direct treatment effect: the controlled direct effect. It is defined as the average effect of the treatment while keeping the mediator at a predefined value: \\[\\begin{align*} \\Delta^{Y_u(m)}_{TT_c} &amp; = \\esp{Y_i^{1,m}-Y_i^{0,m}|D_i=1}. \\end{align*}\\] Example 15.1 Let’s see how this works in our example. The first order of business is to set up a model: \\[\\begin{align*} y_i^{1,1} &amp; = y_i^0+\\bar{\\alpha}+ \\tau_1 +\\theta\\mu_i+\\eta_i \\\\ y_i^{1,0} &amp; = y_i^0+\\bar{\\alpha}+\\theta\\mu_i+\\eta_i \\\\ y_i^{0,1} &amp; = \\mu_i+\\delta + \\tau_0+U_i^0 \\\\ y_i^{0,0} &amp; = \\mu_i+\\delta+U_i^0 \\\\ U_i^0 &amp; = \\rho U_i^B+\\epsilon_i \\\\ y_i^B &amp; =\\mu_i+U_i^B \\\\ U_i^B &amp; \\sim\\mathcal{N}(0,\\sigma^2_{U}) \\\\ M_i &amp; = \\uns{\\xi y_i^B + \\psi D_i+ V^M_i\\leq\\bar{y}_M} \\\\ V^M_i &amp; = \\gamma_M(\\mu_i-\\bar{\\mu}) + \\omega^M_i \\\\ D_i &amp; = \\uns{y_i^B+ V_i\\leq\\bar{y}} \\\\ V_i &amp; = \\gamma(\\mu_i-\\bar{\\mu}) + \\omega_i \\\\ (\\eta_i,\\omega_i,\\omega^M_i) &amp; \\sim\\mathcal{N}(0,0,0,\\sigma^2_{\\eta},\\sigma^2_{\\omega},\\sigma^2_{\\omega_M},\\rho_{\\eta,\\omega},\\rho_{\\eta,\\omega_M},\\rho_{\\omega,\\omega_M}) \\end{align*}\\] Let us choose some parameter values and simulate the model. param &lt;- c(8,.5,.28,1500,1500,0.9,0.01,0.05,0.05,0.05,0.1,0.2,0.1,1,-0.25,0.1,0.05,7.98,0.28,1,0,0,0) names(param) &lt;- c(&quot;barmu&quot;,&quot;sigma2mu&quot;,&quot;sigma2U&quot;,&quot;barY&quot;,&quot;barYM&quot;,&quot;rho&quot;,&quot;theta&quot;,&quot;sigma2epsilon&quot;,&quot;sigma2eta&quot;,&quot;delta&quot;,&quot;baralpha&quot;,&quot;tau1&quot;,&quot;tau0&quot;,&quot;xi&quot;,&quot;psi&quot;,&quot;gamma&quot;,&quot;gammaM&quot;,&quot;baryB&quot;,&quot;sigma2omega&quot;,&quot;sigma2omegaM&quot;,&quot;rhoetaomega&quot;,&quot;rhoetaomegaM&quot;,&quot;rhoomegaomegaM&quot;) Let us now simulate the data: set.seed(1234) N &lt;-1000 cov.eta.omega.omegaM &lt;- matrix(c(param[&quot;sigma2eta&quot;],param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;rhoetaomegaM&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omegaM&quot;]), param[&quot;rhoetaomega&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omega&quot;]),param[&quot;sigma2omega&quot;],param[&quot;rhoomegaomegaM&quot;]*sqrt(param[&quot;sigma2omega&quot;]*param[&quot;sigma2omegaM&quot;]), param[&quot;rhoetaomegaM&quot;]*sqrt(param[&quot;sigma2eta&quot;]*param[&quot;sigma2omegaM&quot;]),param[&quot;rhoomegaomegaM&quot;]*sqrt(param[&quot;sigma2omega&quot;]*param[&quot;sigma2omegaM&quot;]),param[&quot;sigma2omegaM&quot;]),ncol=3,nrow=3) eta.omega &lt;- as.data.frame(mvrnorm(N,c(0,0,0),cov.eta.omega.omegaM)) colnames(eta.omega) &lt;- c(&#39;eta&#39;,&#39;omega&#39;,&#39;omegaM&#39;) mu &lt;- rnorm(N,param[&quot;barmu&quot;],sqrt(param[&quot;sigma2mu&quot;])) UB &lt;- rnorm(N,0,sqrt(param[&quot;sigma2U&quot;])) yB &lt;- mu + UB YB &lt;- exp(yB) Ds &lt;- rep(0,N) V &lt;- param[&quot;gamma&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omega Ds[yB+V&lt;=log(param[&quot;barY&quot;])] &lt;- 1 VM &lt;- param[&quot;gammaM&quot;]*(mu-param[&quot;barmu&quot;])+eta.omega$omegaM M &lt;- rep(0,N) M[param[&#39;xi&#39;]*yB+param[&#39;psi&#39;]*Ds+VM&lt;=log(param[&quot;barYM&quot;])] &lt;- 1 M1 &lt;- rep(0,N) M1[param[&#39;xi&#39;]*yB+param[&#39;psi&#39;]+VM&lt;=log(param[&quot;barYM&quot;])] &lt;- 1 M0 &lt;- rep(0,N) M0[param[&#39;xi&#39;]*yB+VM&lt;=log(param[&quot;barYM&quot;])] &lt;- 1 epsilon &lt;- rnorm(N,0,sqrt(param[&quot;sigma2epsilon&quot;])) U0 &lt;- param[&quot;rho&quot;]*UB + epsilon alpha &lt;- param[&quot;baralpha&quot;]+ param[&quot;theta&quot;]*mu + eta.omega$eta y00 &lt;- mu + U0 + param[&quot;delta&quot;] y01 &lt;- mu + U0 + param[&#39;tau0&#39;]+ param[&quot;delta&quot;] y10 &lt;- y00+alpha y11 &lt;- y00+alpha+param[&#39;tau1&#39;] y1 &lt;- y11*M1+y10*(1-M1) y0 &lt;- y01*M0+y00*(1-M0) y1M1 &lt;- y00+alpha+param[&#39;tau1&#39;]*M1 y1M0 &lt;- y00+alpha+param[&#39;tau1&#39;]*M0 y0M1 &lt;- y00 + param[&#39;tau0&#39;]*M1 y0M0 &lt;- y00 + param[&#39;tau0&#39;]*M0 y &lt;- y11*Ds*M+y10*Ds*(1-M)+y01*(1-Ds)*M+y00*(1-Ds)*(1-M) Let us finally compute the values of TT and of the mediated and unmediated average treatment effects on the treated in the sample. # treatment on the treated TT &lt;- mean(y1[Ds==1]-y0[Ds==1]) # mediated treatment effects TTm1 &lt;- mean(y1M1[Ds==1]-y1M0[Ds==1]) TTm0 &lt;- mean(y0M1[Ds==1]-y0M0[Ds==1]) # unmediated treatment effects TTu1 &lt;- mean(y1M1[Ds==1]-y0M1[Ds==1]) TTu0 &lt;- mean(y1M0[Ds==1]-y0M0[Ds==1]) # preparing graph mediation.example &lt;- data.frame(TT=c(TTm1,TTu0,TTm0,TTu1),Effect=c(&quot;TTm1&quot;,&quot;TTu0&quot;,&quot;TTm0&quot;,&quot;TTu1&quot;),Type=c(&quot;Mediated&quot;,&quot;Unmediated&quot;,&quot;Mediated&quot;,&quot;Unmediated&quot;),Decomposition=c(&quot;m1u0&quot;,&quot;m1u0&quot;,&quot;m0u1&quot;,&quot;m0u1&quot;)) %&gt;% mutate( Effect=factor(Effect,levels=c(&quot;TTm1&quot;,&quot;TTu0&quot;,&quot;TTm0&quot;,&quot;TTu1&quot;)), Type=factor(Type,levels=c(&quot;Mediated&quot;,&quot;Unmediated&quot;)), Decomposition=factor(Decomposition,levels=c(&quot;m1u0&quot;,&quot;m0u1&quot;)) ) The average effect of the treatment on the treated is equal to 0.243. It can be decomposed in two ways. First, the impact mediated through the mediator \\(M_i\\) when \\(D_i\\) is fixed at 1 (0.014) and the effect not mediated through \\(M_i\\) (with \\(M_i\\) fixed at \\(M_i^0\\)) (0.228). Second, the impact mediated through the mediator \\(M_i\\) when \\(D_i\\) is fixed at 0 (0.007) and the effect not mediated through \\(M_i\\) (with \\(M_i\\) fixed at \\(M_i^1\\)) (0.235). Let us plot the results: # plotting the result ggplot(mediation.example, aes(x=Decomposition, y=TT,fill=Type)) + geom_bar(stat=&quot;identity&quot;)+ theme_bw() Figure 15.2: Decomposition of the Average Treatment Effect on the Treated in Mediated and Unmediated Effect As Figure 15.2 shows, most of the effect of the treatment on the outcome is not mediated through \\(M_i\\) in our example. We can also see that there seems to be limited interaction between the treatment and the mediator since both decompositions yield similar quantities. 15.1.2 Decomposing mediated and unmediated effects In order to understand better how mediation works, it is very useful to decompose the mediated and unmediated effects using the classical typology of Imbens and Angrist (1994). Let’s define four types by the reactions of their mediators to the treatment: Always takers, who always have the mediator set to 1: \\(M_i^{1}=M_i^{0}=1\\). I denote them \\(T_i=a\\). Never takers, who always have the mediator set to 0: \\(M_i^{1}=M_i^{0}=0\\). I denote them \\(T_i=n\\). Compliers, whose value of the mediator moves from 0 to 1 when the value of the treatment variable changes from 0 to 1: \\(M_i^{1}=1\\) and \\(M_i^{0}=0\\). I denote them \\(T_i=c\\). Defiers, whose value of the mediator switches from 1 to 0 when the value of the treatment variable changes from 0 to 1: \\(M_i^{1}=0\\) and \\(M_i^{0}=1\\). I denote them \\(T_i=d\\). \\(T_i\\) spans all the potential reactions of the mediator to the treatment, and thus \\(\\cup_{t\\in\\{a,n,c,d\\}}\\{T_i=t\\}\\) is a partition of the sampling space. It is very interesting to decompose both the full treatment effect on the treated but also the mediated and unmediated treatment effects on the treated in terms of the \\(T_i\\) variable. Let’s go. The Treatment on the Treated parameter first: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^0}|D_i=1}\\\\ &amp; = \\sum_{t\\in\\{a,n,c,d\\}}\\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^0}|T_i=t,D_i=1}\\Pr(T_i=t|D_i=1)\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=a,D_i=1}\\Pr(T_i=a|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=n,D_i=1}\\Pr(T_i=n|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,1}-Y_i^{0,0}|T_i=c,D_i=1}\\Pr(T_i=c|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{0,1}|T_i=d,D_i=1}\\Pr(T_i=d|D_i=1). \\end{align*}\\] Let us now look at the average mediated effect on the treated: \\[\\begin{align*} \\Delta^{Y_{m(1)}}_{TT} &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{1,M_i^0}|D_i=1}\\\\ &amp; = \\sum_{t\\in\\{a,n,c,d\\}}\\esp{Y_i^{1,M_i^1}-Y_i^{1,M_i^0}|T_i=t,D_i=1}\\Pr(T_i=t|D_i=1)\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,1}|T_i=a,D_i=1}\\Pr(T_i=a|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{1,0}|T_i=n,D_i=1}\\Pr(T_i=n|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=c,D_i=1}\\Pr(T_i=c|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{1,1}|T_i=d,D_i=1}\\Pr(T_i=d|D_i=1)\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=c,D_i=1}\\Pr(T_i=c|D_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=d,D_i=1}\\Pr(T_i=d|D_i=1). \\end{align*}\\] The result above is very useful and provides several fruitful insights. First, the average mediated effect on the treated only involves the effects on the compliers and the defiers. That is, only units whose value of the mediator is affected by the treatment are part of the mediated treatment effect. Second, their importance in the mediated treatment effect depends on their proportion in the (treated) population. That is, if few units have their value of the mediator affected by the treatment, the size of the mediated treatment effect decreases. Finally, the impact of the mediator on the defiers enters with a negative weight in the definition of the mediated treatment effect. This makes sense, since the treatment makes these units experience lower values of the mediator. Finally, let us decompose the unmediated treatment effect on the treated: \\[\\begin{align*} \\Delta^{Y_{u(0)}}_{TT} &amp; = \\esp{Y_i^{1,M_i^0}-Y_i^{0,M_i^0}|D_i=1}\\\\ &amp; = \\sum_{t\\in\\{a,n,c,d\\}}\\esp{Y_i^{1,M_i^0}-Y_i^{0,M_i^0}|T_i=t,D_i=1}\\Pr(T_i=t|D_i=1)\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=a,D_i=1}\\Pr(T_i=a|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=n,D_i=1}\\Pr(T_i=n|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=c,D_i=1}\\Pr(T_i=c|D_i=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=d,D_i=1}\\Pr(T_i=d|D_i=1). \\end{align*}\\] The unmediated treatment effect on the treated is equal to the direct effect of the treatment on each of the types multiplied by their proportion in the (treated) population, keeping the value of the mediator at its default value when the treatment is equal to 0. 15.2 The Fundamental Problem of Mediation Analysis In this section, we state the Fundamental Problem of Mediation Analysis (FPMA) and we then move on to examining the biases of intuitive comparisons that could be used to recover the mediated and unmediated effects of the treatment. 15.2.1 The Fundamental Problem of Mediation Analysis Mediation analysis is hard. It is even harder than identification and estimation of treatment effects. The following theorem shows formally why this is the case: Theorem 15.1 (Fundamental Problem of Mediation Analysis) The mediated and unmediated treatment effects are fundamentally unobservable. Proof. Let’s look at the mediated treatment effect first. It can be decomposed as follows: \\[\\begin{align*} \\Delta^{Y_{m(1)}}_{TT} &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{1,M_i^0}|D_i=1}\\\\ &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{1,M_i^0}|D_i=1,M_i=1}\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{1,M_i^1}-Y_i^{1,M_i^0}|D_i=1,M_i=0}\\Pr(M_i=0|D_i=1)\\\\ &amp; = \\esp{Y^{1,1}_i-Y_i^{1,M_i^0}|D_i=1,M_i=1}\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + \\esp{Y^{1,0}_i-Y_i^{1,M_i^0}|D_i=1,M_i=0}\\Pr(M_i=0|D_i=1)\\\\ &amp; = (\\esp{Y_i|D_i=1,M_i=1}-\\esp{Y_i^{1,M_i^0}|D_i=1,M_i=1})\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + (\\esp{Y_i|D_i=1,M_i=0}-\\esp{Y_i^{1,M_i^0}|D_i=1,M_i=0})\\Pr(M_i=0|D_i=1), \\end{align*}\\] where the second and third inequalities follow from the switching equation. Note that both \\(\\esp{Y_i^{1,M_i^0}|D_i=1,M_i=1}\\) and \\(\\esp{Y_i^{1,M_i^0}|D_i=1,M_i=0}\\) are counterfactual values that cannot be observed (they depend on the value of the mediator when \\(D_i=0\\), which is unobserved when \\(D_i=1\\)). Let us look at the unmediated treatment effect now: \\[\\begin{align*} \\Delta^{Y_{u(1)}}_{TT} &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^1}|D_i=1}\\\\ &amp; = \\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^1}|D_i=1,M_i=1}\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{1,M_i^1}-Y_i^{0,M_i^1}|D_i=1,M_i=0}\\Pr(M_i=0|D_i=1)\\\\ &amp; = \\esp{Y^{1,1}_i-Y_i^{0,M_i^1}|D_i=1,M_i=1}\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + \\esp{Y^{1,0}_i-Y_i^{0,M_i^1}|D_i=1,M_i=0}\\Pr(M_i=0|D_i=1)\\\\ &amp; = (\\esp{Y_i|D_i=1,M_i=1}-\\esp{Y_i^{0,M_i^1}|D_i=1,M_i=1})\\Pr(M_i=1|D_i=1)\\\\ &amp; \\phantom{=} + (\\esp{Y_i|D_i=1,M_i=0}-\\esp{Y_i^{0,M_i^1}|D_i=1,M_i=0})\\Pr(M_i=0|D_i=1), \\end{align*}\\] Note that both \\(\\esp{Y_i^{0,M_i^1}|D_i=1,M_i=1}\\) and \\(\\esp{Y_i^{0,M_i^1}|D_i=1,M_i=0}\\) are counterfactual values that cannot be observed (they depend on the value of the outcome when \\(D_i=0\\), which is unobserved when \\(D_i=1\\)). Remark. The key to understanding Theorem 15.1 is to see that the potential value of the mediator is unknown and this combines with the fact that the potential value of the outcome had the mediator or the treatment changed value is also unobserved. 15.2.2 Biases of Intuitive Comparisons Usual intuitive proxies for the mediated and unmediated effects are usually biased because of confounders. We can visualize the problem in a DAG, with the arcs indicating the existence of confounders between two variables: Figure 15.3: DAG of a confounded mediating relationship The most obvious intuitive comparison that could try to recover mediated and unmediated treatment effects is the conditional With/Without comparison: \\[\\begin{align*} \\Delta^Y_{WW|D_i=d} &amp; = \\esp{Y_i|D_i=d,M_i=1}-\\esp{Y_i|D_i=d,M_i=0}\\\\ \\Delta^Y_{WW|M_i=m} &amp; = \\esp{Y_i|D_i=1,M_i=m}-\\esp{Y_i|D_i=0,M_i=m}. \\end{align*}\\] Our hope is that \\(\\Delta^Y_{WW|D_i=d}\\) recovers the mediated treatment effect and \\(\\Delta^Y_{WW|M_i=d}\\) recovers the unmediated treatment effect. Unfortunately, that is not generally the case. The following theorem makes this point clear: Theorem 15.2 (Bias of the Conditional With/Without Comparisons) The conditional With/Without comparisons are biased estimators of the mediated and unmediated average effects of the treatment on the treated: \\[\\begin{align*} \\Delta^Y_{WW|D_i=1} &amp; = \\Delta^{Y_{m(1)}}_{TT|M_i=1}+\\Delta^{Y^{1,0}}_{SB^{m(1)}|D_i=1}\\\\ \\Delta^Y_{WW|M_i=1} &amp; = \\Delta^{Y_{u(1)}}_{TT|M_i=1}+\\Delta^{Y^{0,1}}_{SB^{u(1)}|M_i=1}. \\end{align*}\\] with \\[\\begin{align*} \\Delta^{Y_{m(1)}}_{TT|M_i=1} &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|D_i=1,M_i=1}\\\\ \\Delta^{Y^{1,0}}_{SB^{m(1)}|D_i=1} &amp; = \\esp{Y^{1,0}_i|D_i=1,M_i=1}-\\esp{Y^{1,0}_i|D_i=1,M_i=0}\\\\ \\Delta^{Y_{u(1)}}_{TT|M_i=1} &amp; = \\esp{Y_i^{1,1}-Y_i^{0,1}|D_i=1,M_i=1}\\\\ \\Delta^{Y^{0,1}}_{SB^{u(1)}|M_i=1} &amp; = \\esp{Y^{0,1}_i|D_i=1,M_i=1}-\\esp{Y^{0,1}_i|D_i=0,M_i=0}. \\end{align*}\\] Proof. The proof is straightforward using the switching equation and adding and subtracting the counterfactual part of the treatment effects. According to Theorem 15.2, Selection Bias biases the conditional With/Without estimators of the mediated and unmediated treatment effects. As Figure @(ref:DAGMediationConfounded) suggests, this is because confounders are correlated with both treatment, mediator and outcome. The most important confounder in our example is \\(\\mu_i\\), which is correlated with all three variables. Remark. Note that Theorem 15.2 shows the bias for the mediated and unmediated treatment effects conditional on \\(M_i=1\\). The same results with the unconditional version of the treatment effects would be somewhat more intricate since it would involve weights. Remark. Note also that Theorem 15.2 shows the bias for the mediated and unmediated treatment effects with \\(m(1)\\) and \\(u(1)\\) as indices. The same results with \\(m(0)\\) and \\(u(0)\\) are similar. Example 15.2 Let’s see how that works our in our example. # mediated treatment effect for M=1 TTm1M1 &lt;- mean(y11[Ds==1&amp;M==1])-mean(y10[Ds==1&amp;M==1]) # unmediated treatment effect for M==1 TTu1M1 &lt;- mean(y11[Ds==1&amp;M==1])-mean(y01[Ds==1&amp;M==1]) # selection bias for the mediated treatment effect SBm1D1 &lt;- mean(y10[Ds==1&amp;M==1])-mean(y10[Ds==1&amp;M==0]) # selection bias for the unmediated treatment effect SBu1M1 &lt;- mean(y01[Ds==1&amp;M==1])-mean(y01[Ds==0&amp;M==1]) # with/without comparison for the mediated treatment effect for M=1 WWD1 &lt;- mean(y[Ds==1&amp;M==1])-mean(y[Ds==1&amp;M==0]) # unmediated treatment effect for M==1 WWM1 &lt;- mean(y[Ds==1&amp;M==1])-mean(y[Ds==0&amp;M==1]) In our example, the With/Without estimator of the mediated treatment effect is equal to -0.239 (for \\(D_i=1\\)). The true mediated treatment effect for \\(D_i=1\\) and \\(M_i=1\\) is equal to 0.2. Selection bias for the mediated treatment effect for \\(D_i=1\\) is thus equal to -0.439. The With/Without estimator of the unmediated treatment effect is equal to -0.571 (for \\(M_i=1\\)). The true unmediated treatment effect for \\(D_i=1\\) and \\(M_i=1\\) is equal to 0.253. Selection bias for the unmediated treatment effect for \\(M_i=1\\) is thus equal to -0.824. 15.3 Mediation analysis with experimental data Imai, Tingleu and Yamamoto (2013) propose two experimental designs to recover the mediated and unmediated treatment effects: the parallel design and the crossover design. We are going to also study identification in a Sequential Self-Selection design, which I find slightly simpler. Let’s examine these approaches in turn. 15.3.1 Mediation analysis in the Parallel design In the parallel design, we run a three-step experiment. In the first step, we randomly allocate units either to the first or the second arm of the experiment. We denote \\(R^1_i=0\\) the first arm and \\(R^1_i=1\\) the second arm. In the first arm, we randomly allocate the treatment among units and we let the mediator take the corresponding value without interferring. We denote \\(R^2_i=1\\) when unit \\(i\\) is assigned to the treatment and \\(R^2_i=0\\) when unit \\(i\\) us not assigned to the treatment. In this design, we assume that units fully comply with the assignment. One way to do that is to run the whole parallel design only on units that are selected into the treatment (\\(D_i=1\\)). In the second arm, we run a two-step experiment. In the first step, we randomly allocate units either to the treatment or to the control. We denote \\(R_i^2=1\\) when unit \\(i\\) is assigned to the treatment and \\(R_i^2=0\\) when it is assigned to the control. In the second step, we randomly allocate units to the mediator. We denote \\(R_i^3=1\\) when unit \\(i\\) is assigned to the mediator value \\(M_i=1\\) and \\(R_i^3=0\\) when unit \\(i\\) is assigned to the mediator value of \\(M_i=0\\). In order to recover the treatment effect on the treated, we are going to assume that the experiment takes place among the units selected to participate in the treatment, i.e. among units with \\(D_i=1\\). If we abstract from this, the parameter we recover is the average effect of the treatment, ATE. Let us formalize the assumptions we make on the Parallel design Hypothesis 15.1 (Sequential Independence in the Parallel Design) We assume that the sequential randomized allocation of the program among applicants is well done: \\[\\begin{align*} R^1_i &amp; \\Ind(Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)|D_i=1\\\\ R^2_i &amp; \\Ind(Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)|R_i^1,D_i=1\\\\ R^3_i &amp; \\Ind(Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)|R_i^2,R_i^1=1,D_i=1. \\end{align*}\\] We need a second assumption: Hypothesis 15.2 (Validity of the Sequential Parallel Design) We assume that the sequential randomized allocation of the program does not interfere with how potential outcomes and potential treatment and mediator choices are generated: \\[\\begin{align*} Y_i &amp; = \\begin{cases} Y_i^{11} &amp; \\text{ if } D_i=1 \\text{ and } ((R^1_i=0 \\text{ and } R^2_i=1 \\text{ and } M_i=1) \\text{ or } (R^1_i=1 \\text{ and } R^2_i=1 \\text{ and } R^3_i=1)) \\\\ Y_i^{10} &amp; \\text{ if } D_i=1 \\text{ and } ((R^1_i=0 \\text{ and } R^2_i=1 \\text{ and } M_i=0) \\text{ or } (R^1_i=1 \\text{ and } R^2_i=1 \\text{ and } R^3_i=0)) \\\\ Y_i^{01} &amp; \\text{ if } D_i=1 \\text{ and } ((R^1_i=0 \\text{ and } R^2_i=0 \\text{ and } M_i=1) \\text{ or } (R^1_i=1 \\text{ and } R^2_i=0 \\text{ and } R^3_i=1)) \\\\ Y_i^{00} &amp; \\text{ if } D_i=1 \\text{ and } ((R^1_i=0 \\text{ and } R^2_i=0 \\text{ and } M_i=0) \\text{ or } (R^1_i=1 \\text{ and } R^2_i=0 \\text{ and } R^3_i=0)) \\\\ \\end{cases}\\\\ M_i &amp; = \\begin{cases} M_i^{1} &amp; \\text{ if } D_i=1 \\text{ and }R^1_i=0\\text{ and } R^2_i=1\\\\ M_i^{0} &amp; \\text{ if } D_i=1 \\text{ and }R^1_i=0\\text{ and } R^2_i=0 \\end{cases}, \\end{align*}\\] with \\((Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)\\) the same potential outcomes and potential treatment and mediator choices as in a routine allocation of the treatment. Remark. Assumption 15.2 imposes that the experimental setting does not alter the treatment, mediator and outcomes of the agents. For identification of the mediated and unmediated effects to go through, we need a final (strong) assumption: the absence of interaction effects: Hypothesis 15.3 (Absence of Interaction Effects) We assume that the treatment and the mediator do not interact: \\(Y_i^{d,m}-Y_i^{d,m&#39;}=Y_i^{d&#39;,m}-Y_i^{d&#39;,m&#39;}\\), \\(\\forall (d,m,d&#39;m&#39;)\\in\\{0,1\\}^4\\), \\(d\\neq d&#39;\\), \\(m\\neq m&#39;\\). Remark. Assumption 15.3 is actually too strong for our result. We only need that the assumption holds for the average effects on the never takers, defiers and compliers. Remark. Under Assumption 15.3, \\(\\Delta^{Y_{u(1)}}_{TT}=\\Delta^{Y_{u(0)}}_{TT}\\), which we denote \\(\\Delta^{Y_{u(d)}}_{TT}\\) and \\(\\Delta^{Y_{m(1)}}_{TT}=\\Delta^{Y_{m(0)}}_{TT}\\), which we denote \\(\\Delta^{Y_{m(d)}}_{TT}\\). Under these assumptions, we have the following result: Theorem 15.3 (Identification of Total, Mediated and Unmediated Effects in the Parallel Design) Under Assumptions 15.1, 15.2 and 15.3, the treatment effect on the treated and the mediated and unmediated effects on the treated are identified in the Parallel Design: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i|D_i=1,R^1_i=0,R_i^2=1}-\\esp{Y_i|D_i=1,R^1_i=0,R_i^2=0}\\\\ \\Delta^{Y_{u(d)}}_{TT} &amp; = \\esp{Y_i|D_i=1,R^1_i=1,R_i^2=1,R_i^3=1}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=0,R_i^3=1}\\\\ &amp; =\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=1,R_i^3=0}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=0,R_i^3=0}\\\\ \\Delta^{Y_{m(d)}}_{TT} &amp; = \\esp{Y_i|D_i=1,R^1_i=0,R_i^2=1}-\\esp{Y_i|D_i=1,R^1_i=0,R_i^2=0}\\\\ &amp; \\phantom{=}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=1,R_i^3=1}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=0,R_i^3=1}\\\\ &amp; = \\esp{Y_i|D_i=1,R^1_i=0,R_i^2=1}-\\esp{Y_i|D_i=1,R^1_i=0,R_i^2=0}\\\\ &amp; \\phantom{=}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=1,R_i^3=0}-\\esp{Y_i|D_i=1,R^1_i=1,R_i^2=0,R_i^3=0}. \\end{align*}\\] Proof. I omit conditioning on \\(D_i=1\\) to save notation. Let us start with the total effect: \\(\\esp{Y_i|R^1_i=0,R_i^2=1}-\\esp{Y_i|R^1_i=0,R_i^2=0}\\) is a With/Without estimator where the treatment has been randomized among a random sample of the units selected to receive the treatment. Theorem 3.2 proves that it identifies \\(\\Delta^Y_{TT}\\) under Assumptions 15.1 and 15.2. The unmediated treatment effect can be recovered as follows: \\[\\begin{align*} \\esp{Y_i|R^1_i=1,R_i^2=1,R_i^3=1} &amp; -\\esp{Y_i|R^1_i=1,R_i^2=0,R_i^3=1} \\\\ &amp; = \\sum_{t\\in\\{a,n,c,d\\}}\\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=t}\\Pr(T_i=t)\\\\ \\esp{Y_i|R^1_i=1,R_i^2=1,R_i^3=0} &amp; -\\esp{Y_i|R^1_i=1,R_i^2=0,R_i^3=0} \\\\ &amp; = \\sum_{t\\in\\{a,n,c,d\\}}\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=t}\\Pr(T_i=t), \\end{align*}\\] using Assumptions 15.1 and 15.2. Using the decomposition of \\(\\Delta^Y_{TT}\\) in the effects on each type, we have: \\[\\begin{align*} \\esp{Y_i|R^1_i=0,R_i^2=1} &amp; -\\esp{Y_i|R^1_i=0,R_i^2=0}\\\\ &amp; - (\\esp{Y_i|R^1_i=1,R_i^2=1,R_i^3=1} -\\esp{Y_i|R^1_i=1,R_i^2=0,R_i^3=1}) \\\\ &amp; = \\esp{Y_i^{0,1}-Y_i^{0,0}|T_i=c}\\Pr(T_i=c) \\\\ &amp; \\phantom{=}-\\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=d}\\Pr(T_i=d)\\\\ &amp; \\phantom{=}+(\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=n}-\\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=n})\\Pr(T_i=n). \\end{align*}\\] and \\[\\begin{align*} \\esp{Y_i|R^1_i=0,R_i^2=1} &amp; -\\esp{Y_i|R^1_i=0,R_i^2=0}\\\\ &amp; - (\\esp{Y_i|R^1_i=1,R_i^2=1,R_i^3=0} -\\esp{Y_i|R^1_i=1,R_i^2=0,R_i^3=0}) \\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=c}\\Pr(T_i=c) \\\\ &amp; \\phantom{=}-\\esp{Y_i^{0,1}-Y_i^{0,0}|T_i=d}\\Pr(T_i=d)\\\\ &amp; \\phantom{=}+(\\esp{Y_i^{1,1}-Y_i^{0,1}|T_i=a}-\\esp{Y_i^{1,0}-Y_i^{0,0}|T_i=a})\\Pr(T_i=a). \\end{align*}\\] Using Assumption 15.3 and the decomposition formulae for the mediated and unmediated treatment effects on the treated gives the result. Remark. The proof of Theorem 15.3 is more detailed and explanatory than the one in Imai, Tingleu and Yamamoto (2013). We understand why we need Assumption 15.3: the effects on the always takers and on the never takers estimated in the two treatment arms do not cancel out and the effects of the mediator on the compliers and defiers are not the correct combination in both comparisons unless we make Assumption 15.3. Remark. Note that the model is overidentified under Assumptions 15.1, 15.2 and 15.3. There are two different ways to estimate the unmediated treatment effect and thus one can test Assumption 15.3 by comparing these two estimates. Remark. Since the model is overidentified under Assumptions 15.1, 15.2 and 15.3, one wonders what can exactly be identified on the mediated and unmediated treatment effects under these assumptions. Maybe it is possible to bound the treatment effects. This is, to my knowledge, still an open question. Remark. Imai, Tingleu and Yamamoto (2013) also discuss a Parallel Encouragement design where units are not forced to take the assigned value of the mediator but can be randomly encouraged to do so. They derive sharp bounds on the mediated effect on the compliers in that design. 15.3.2 Mediation analysis in the Sequential Self-Selection design In a Sequential Self-Selection design, researchers run a Randomized Controlled Trial (RCT) in two-steps. In the first step, the treatment is randomized among those who applied for it. In the second step, the mediator is randomized among those who applied for it. We thus have two random variables \\(R_i^1\\) and \\(R_i^2\\) which take values zero or one for observations for which \\(D_i=1\\) for the first and \\(D_i=1\\) and \\(M_i=1\\) for the second. Let us formalize how the Sequential Self-Selection design works. Hypothesis 15.4 (Sequential Independence Among Self-Selected) We assume that the sequential randomized allocation of the program among applicants is well done: \\[\\begin{align*} R^1_i &amp; \\Ind(Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)|D_i=1\\\\ R^2_i &amp; \\Ind(Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)|R^1_i,M_i=1,D_i=1 \\end{align*}\\] We need a second assumption: Hypothesis 15.5 (Validity of the Sequential Self-Selection design) We assume that the sequential randomized allocation of the program does not interfere with how potential outcomes and self-selection are generated: \\[\\begin{align*} Y_i &amp; = \\begin{cases} Y_i^{11} &amp; \\text{ if } (D_i=1 \\text{ and } R^1_i=1 \\text{ and } M_i=1 \\text{ and } R^2_i=1) \\\\ Y_i^{10} &amp; \\text{ if } ((D_i=1 \\text{ and } R^1_i=1) \\text{ and } ((M_i=1 \\text{ and } R^2_i=0) \\text{ or } M_i=0)) \\\\ Y_i^{01} &amp; \\text{ if } (D_i=1 \\text{ and } R^1_i=0 \\text{ and } M_i=1 \\text{ and } R^2_i=1) \\\\ Y_i^{00} &amp; \\text{ if } ((D_i=1 \\text{ and } R^1_i=0) \\text{ and } ((M_i=1 \\text{ and } R^2_i=0) \\text{ or } M_i=0)) \\end{cases}\\\\ M_i &amp; = \\begin{cases} M_i^{1} &amp; \\text{ if } D_i=1 \\text{ and } R^1_i=1\\\\ M_i^{0} &amp; \\text{ if } D_i=1 \\text{ and } R^1_i=0 \\end{cases} \\end{align*}\\] with \\((Y_i^{00},Y_i^{01},Y_i^{10},Y_i^{11},M^1_i,M^0_i)\\) the same potential outcomes and self-selection decisions as in a routine allocation of the treatment. We finally need a monotonicity assumption: Hypothesis 15.6 (Monotonicity of the Effect of the Treatment on the Mediator) We assume that the effect of the treatment on the mediator is monotonous: \\[\\begin{align*} \\Pr(M_i^1-M_i^0&lt;0) &amp; =0. \\end{align*}\\] Remark. Assumption 15.6 is equivalent to the absence of defiers: \\(\\Pr(T_i=d)=0\\). Under these assumptions, we have the following result: Theorem 15.4 (Identification of Total, Mediated and Unmediated Effects in a Sequential Self-Selection design) Under Assumptions 15.4, 15.5 and 15.6, the treatment effect on the treated and the mediated and unmediated effects are identified in a Sequential Self-Selection Design: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i|D_i=1,R_i^1=1,M_i=1,R_i^2=1}\\Pr(M_i=1|D_i=1,R_i^1=1)\\\\ &amp; \\phantom{=}+\\esp{Y_i|D_i=1,R_i^1=1,M_i=0}\\Pr(M_i=0|D_i=1,R_i^1=1)\\\\ &amp; \\phantom{=}-\\left(\\esp{Y_i|D_i=1,R_i^1=0,M_i=1,R_i^2=1}\\Pr(M_i=1|D_i=1,R_i^1=0)\\right.\\\\ &amp; \\phantom{=-(}\\left.+\\esp{Y_i|D_i=1,R_i^1=0,M_i=0}\\Pr(M_i=0|D_i=1,R_i^1=0)\\right)\\\\ \\Delta^{Y_{m(1)}}_{TT} &amp; =\\left(\\esp{Y_i|D_i=1,R_i^1=1,M_i=1,R_i^2=1}\\right.\\\\ &amp;\\phantom{=-(}\\left.-\\esp{Y_i|D_i=1,R_i^1=1,M_i=1,R_i^2=0}\\right)\\Pr(M_i=1|D_i=1,R_i^1=1)\\\\ &amp; \\phantom{=}-\\left(\\esp{Y_i|D_i=1,R_i^1=0,M_i=1,R_i^2=1}\\right.\\\\ &amp;\\phantom{=-(}\\left.-\\esp{Y_i|D_i=1,R_i^1=0,M_i=1,R_i^2=0}\\right)\\Pr(M_i=1|D_i=1,R_i^1=0)\\\\ \\Delta^{Y_{u(0)}}_{TT} &amp; =\\Delta^Y_{TT}-\\Delta^{Y_{m(1)}}_{TT}. \\end{align*}\\] Proof. I omit conditioning on \\(D_i=1\\) all along to save on notation. Note that: \\[\\begin{align*} \\esp{Y_i|R_i^1=1,M_i=1,R_i^2=1} &amp; = \\esp{Y^{1,M_i^1}_i|R_i^1=1,M^1_i=1,R_i^2=1}\\\\ &amp; = \\esp{Y^{1,M_i^1}_i|M^1_i=1}\\\\ \\esp{Y_i|R_i^1=1,M_i=0} &amp; = \\esp{Y^{1,M_i^1}_i|M^1_i=0}\\\\ \\esp{Y_i|R_i^1=0,M_i=1,R_i^2=1} &amp; = \\esp{Y^{0,M_i^0}_i|M^0_i=1}\\\\ \\esp{Y_i|R_i^1=0,M_i=0} &amp; = \\esp{Y^{0,M_i^0}_i|M^0_i=0}\\\\ \\Pr(M_i=1|R_i^1=1) &amp; = \\Pr(M^1_i=1)\\\\ \\Pr(M_i=0|R_i^1=1) &amp; = \\Pr(M^1_i=0)\\\\ \\Pr(M_i=1|R_i^1=0) &amp; = \\Pr(M^0_i=1)\\\\ \\Pr(M_i=0|R_i^1=0) &amp; = \\Pr(M^0_i=0), \\end{align*}\\] using Assumptions 15.4 and 15.5. Because \\(M_i^1\\) and \\(M_i^0\\) are both partitions of the sampling space, we can use the Law of Iterated Expectations to find: \\[\\begin{align*} \\esp{Y^{1,M_i^1}_i} &amp;= \\esp{Y^{1,M_i^1}_i|M^1_i=1}\\Pr(M^1_i=1)+\\esp{Y^{1,M_i^1}_i|M^1_i=1}\\Pr(M^1_i=0)\\\\ \\esp{Y^{0,M_i^0}_i} &amp;= \\esp{Y^{0,M_i^0}_i|M^0_i=1}\\Pr(M^0_i=1)+\\esp{Y^{0,M_i^0}_i|M^1_i=1}\\Pr(M^0_i=0) \\end{align*}\\] The difference between the two terms is the definition of \\(\\Delta^Y_{TT}\\). This proves the first part of the theorem. Note that, under Assumptions 15.4, 15.5 and especially 15.6: \\[\\begin{align*} \\esp{Y_i|R_i^1=1,M_i=1,R_i^2=1} &amp; -\\esp{Y_i|R_i^1=1,M_i=1,R_i^2=0}\\\\ &amp; = \\esp{Y^{11}_i|M^1_i=1} -\\esp{Y^{10}_i|M^1_i=1}\\\\ &amp; = \\esp{Y^{11}_i|T_i=a}\\Pr(T_i=a|M_i^1=1)+\\esp{Y^{11}_i|T_i=c}\\Pr(T_i=c|M_i^1=1)\\\\ &amp; \\phantom{=}-\\esp{Y^{10}_i|T_i=a}\\Pr(T_i=a|M^1_i=1)-\\esp{Y^{10}_i|T_i=c}\\Pr(T_i=c|M^1_i=1)\\\\ &amp; = \\esp{Y^{11}_i-Y^{10}_i|T_i=a}\\Pr(T_i=a|M_i^1=1)\\\\ &amp; \\phantom{=}+\\esp{Y^{11}_i-Y^{10}_i|T_i=c}\\Pr(T_i=c|M_i^1=1). \\end{align*}\\] By the same reasoning, we also have: \\[\\begin{align*} \\esp{Y_i|R_i^1=0,M_i=1,R_i^2=1} &amp; -\\esp{Y_i|R_i^1=0,M_i=1,R_i^2=0}\\\\ &amp; = \\esp{Y^{11}_i|M^0_i=1} -\\esp{Y^{10}_i|M^0_i=1}\\\\ &amp; = \\esp{Y^{11}_i-Y^{10}_i|T_i=a}. \\end{align*}\\] Finally, using Bayes Law and the fact that: \\[\\begin{align*} \\Pr(M_i=1|R_i^1=1) &amp; = \\Pr(M^1_i=1) = \\Pr(T_i=a)+\\Pr(T_i=c)\\\\ \\Pr(M_i=1|R_i^1=0) &amp; = \\Pr(M^0_i=1) = \\Pr(T_i=a), \\end{align*}\\] we have that \\(\\Pr(T_i=a|M_i^1=1)=\\frac{\\Pr(T_i=a)}{\\Pr(T_i=a)+\\Pr(T_i=c)}\\) and \\(\\Pr(T_i=c|M_i^1=1)=\\frac{\\Pr(T_i=c)}{\\Pr(T_i=a)+\\Pr(T_i=c)}\\). Combining the results with the decomposition of \\(\\Delta^{Y_{m(1)}}_{TT}\\) under Assumption 15.6 proves the identification of \\(\\Delta^{Y_{m(1)}}_{TT}\\). The identification of \\(\\Delta^{Y_{u(0)}}_{TT}\\) comes directly from the decompositions of \\(\\Delta^Y_{TT}\\), \\(\\Delta^{Y_{m(1)}}_{TT}\\) and \\(\\Delta^{Y_{u(0)}}_{TT}\\) under Assumption 15.6. This proves the result. Remark. Intuitively, Theorem 15.4 works by using what happens in the voluntary parts of both experimental arms (the parts where the mediator value chosen by the units is given to them) to recover the treatment effect on the treated. Then, the With/Without estimators using \\(R_i^2\\) in each arm give the effect of the mediator, on the always treated and the compliers in the arm where \\(R_i^1=1\\) and on the compliers alone in the arm where \\(R_i^1=0\\). Taking the difference between these two estimators, appropriately reweighted, gives the effect of the mediator on the compliers times their proportion among the treated, which is equal to the mediated effect of the treatment on the treated. 15.3.3 Mediation analysis in the Crossover design The Crossover Design has been proposed by Imai, Tingleu and Yamamoto (2013). In the Crossover Design, each experimental unit is exposed both to the treatment and control conditions sequentially, over two periods, \\(t\\in\\{1,2\\}\\). The experimenter first randomly chooses the order in which each unit is assigned to the treatment and control conditions with \\(R_i=1\\) when the treatment is given in the first period and \\(R_i=0\\) when the treatment is given in the second period. After measuring the value of the mediator and of the outcome in the first period, each unit is assigned in the second period to the treatment status value opposite to the one they had in the first period but to the same mediator value that they had in the first period. Let’s see how this design identifies the effects of interest. Let us formalize how the Crossover design works. Hypothesis 15.7 (Independence in the Crossover Design) We assume that the randomized allocation of the program among applicants is well done: \\[\\begin{align*} R_i &amp; \\Ind\\left(\\left\\{Y_{i,t}^{00},Y_{i,t}^{01},Y_{i,t}^{10},Y_{i,t}^{11},M^1_{i,t},M^0_{i,t}\\right\\}_{t\\in\\{1,2\\}}\\right)|D_i=1. \\end{align*}\\] We need a second assumption: Hypothesis 15.8 (Validity of the Crossover Design) We assume that the randomized allocation of the program does not interfere with how potential outcomes and self-selection are generated: \\[\\begin{align*} Y_{i,t} &amp; = \\begin{cases} Y_{i,t}^{11} &amp; \\text{ if } D_i=1 \\text{ and } R_i=1 \\text{ and } M_{i}=1 \\\\ Y_{i,t}^{10} &amp; \\text{ if } D_i=1 \\text{ and } R_i=1 \\text{ and } M_{i}=0 \\\\ Y_{i,t}^{01} &amp; \\text{ if } D_i=1 \\text{ and } R_i=0 \\text{ and } M_{i}=1 \\\\ Y_{i,t}^{00} &amp; \\text{ if } D_i=1 \\text{ and } R_i=0 \\text{ and } M_{i}=0 \\end{cases}\\\\ M_{i} &amp; = \\begin{cases} M_{i,1}^{1} &amp; \\text{ if } D_i=1 \\text{ and } R_i=1\\\\ M_{i,1}^{0} &amp; \\text{ if } D_i=1 \\text{ and } R_i=0. \\end{cases} \\end{align*}\\] with \\((Y_{i,t}^{00},Y_{i,t}^{01},Y_{i,t}^{10},Y_{i,t}^{11},M^1_{i,t},M^0_{i,t})\\) the same potential outcomes and self-selection decisions as in a routine allocation of the treatment. Remark. Note that Assumption 15.8 implicitely assumes that the potential outcomes are period \\(t\\) only depend on the treatment and mediator value at period \\(t\\). This is a huge assumption that there are no persistent effects of either the treatment or the mediator value over time. We finally need a third assumption: Hypothesis 15.9 (No Changes in Potential Outcomes Over Time) We assume that time does not not interfere with how potential outcomes are generated: \\[\\begin{align*} \\esp{Y_{i,1}^{d,m}|D_i=1} &amp; = \\esp{Y_{i,2}^{d,m}|D_i=1}\\text{, }\\forall (d,m)\\in\\{0,1\\}^2. \\end{align*}\\] We can now prove identification under these assumptions: Theorem 15.5 (Identification of Total, Mediated and Unmediated Effects in a Crossover design) Under Assumptions 15.7, 15.8 and 15.9, the treatment effect on the treated and the mediated and unmediated effects are identified in a Crossover Design: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_{i,1}|D_i=1,R_i=1}-\\esp{Y_{i,1}|D_i=1,R_i=0}\\\\ \\Delta^{Y_{m(1)}}_{TT} &amp; =\\esp{Y_{i,1}|D_i=1,R_i=1}-\\esp{Y_{i,2}|D_i=1,R_i=0}\\\\ \\Delta^{Y_{u(0)}}_{TT} &amp; =\\esp{Y_{i,2}|D_i=1,R_i=0}-\\esp{Y_{i,1}|D_i=1,R_i=0}. \\end{align*}\\] Proof. I omit the conditioning on \\(D_i=1\\) for simplicity. Let us start with the first result: \\[\\begin{align*} \\esp{Y_{i,1}|R_i=1}-\\esp{Y_{i,1}|R_i=0} &amp; = \\esp{Y^{1,M_{i,1}^1}_{i,1}|R_i=1}-\\esp{Y^{0,M_{i,1}^0}_{i,1}|R_i=0} \\\\ &amp; = \\esp{Y^{1,M_{i,1}^1}_{i,1}-Y^{0,M_{i,1}^0}_{i,1}} \\\\ &amp; = \\Delta^{Y_1}_{TT} &amp; = \\Delta^{Y}_{TT}, \\end{align*}\\] where the first equality uses Assumption 15.8, the second uses Assumption 15.7 and the third uses Assumption 15.9. Let us now move on to the second result: \\[\\begin{align*} \\esp{Y_{i,1}|R_i=1}-\\esp{Y_{i,2}|R_i=0} &amp; = \\esp{Y^{1,M_{i,1}^1}_{i,1}|R_i=1}-\\esp{Y^{1,M_{i,1}^0}_{i,2}|R_i=0} \\\\ &amp; = \\esp{Y^{1,M_{i,1}^1}_{i,1}-Y^{1,M_{i,1}^0}_{i,1}} \\\\ &amp; = \\Delta^{Y_{m(1)}}_{TT}, \\end{align*}\\] where the first equality uses Assumption 15.8 and the second uses Assumptions 15.7 and 15.9. Let us now move on to the third result: \\[\\begin{align*} \\esp{Y_{i,2}|R_i=0}-\\esp{Y_{i,1}|R_i=0} &amp; = \\esp{Y^{1,M_{i,1}^0}_{i,2}|R_i=0}-\\esp{Y^{0,M_{i,1}^0}_{i,1}|R_i=0} \\\\ &amp; = \\esp{Y^{1,M_{i,1}^0}_{i,1}-Y^{0,M_{i,1}^0}_{i,1}} \\\\ &amp; = \\Delta^{Y_{u(0)}}_{TT}, \\end{align*}\\] where the first equality uses Assumption 15.8 and the second uses Assumptions 15.7 and 15.9. Remark. There seems to be some sense of a Brute Force design in the Crossover design. Indeed, this designs imposes the value of the mediator in the second period, contrary to the one some units would have chosen if left to their own choice. There does not seem to be another way of obtaining the mediated and unmediated effects. Note that this is similar to randomizing the mediator value in the Sequential Self-Selection Design. Imai, Tingleu and Yamamoto (2013) propose an Crossover Encouragement design to allow for only encouraging the units to change their value of the mediator. In that case, they prove identification of the mediated treatment effect for a subpopulation of units. Remark. Imai, Tingleu and Yamamoto (2013) offer a nice discussion of how the Crossover design could be used to help identify the effect of race not mediated through qualifications in audit studies. They also discuss an application of the Crossover Encouragement design to framing effects on preferences for immigration. 15.4 Mediation analysis under unconfoundedness Mediation analysis under unconfoundedness is covered in Imai, Keele and Yamamoto (2010) and summarized in Imai, Keene and Tingley (2010). The key assumption that the authors make is that of sequential ignorability, which is equivalent to the Conditional Independence Assumption used to establish matching methods in Chapter 5. We study first general non-parametric identification under sequential ignorability before looking at the special case of linear models. 15.4.1 Non-parametric identification under sequential ignorability Let’s make the assumption of sequential ignorability clearer: Hypothesis 15.10 (Sequential Ignorability) We assume that potential outcomes are sequentially ignorable conditional on observed covariates \\(X_i\\), \\(\\forall (d,d&#39;,m)\\in \\left\\{0,1\\right\\}^3\\) and \\(\\forall x\\in\\mathcal{X}\\): \\[\\begin{align*} \\left(Y_i^{d,m},M_i^{d&#39;}\\right) &amp; \\Ind D_i|X_i\\\\ Y_i^{d,m} &amp; \\Ind M_i|D_i,X_i. \\end{align*}\\] Assumption 15.10 imposes that the potential outcomes and potential mediator values are independent of the treatment conditional on observed covariates. That means that treatment is as good as randomly assigned. It also imposes that the potential outcomes are independent of the mediator conditional on the treatment and on observed covariates. That means that the mediator is as good as randomly assigned conditional on the treatment and on observed covariates. We also need a common support assumption in order to prove identification non-parametrically: Hypothesis 15.11 (Sequential Common Support) We assume that the probability of the treatment and of the mediator taking a given value are always positive conditional on observables, \\(\\forall (d,m)\\in \\left\\{0,1\\right\\}^2\\): \\[\\begin{align*} \\Pr(D_i=d|X_i) &amp; &gt;0\\\\ \\Pr(M_i=m|D_i,X_i) &amp; &gt;0. \\end{align*}\\] Under these assumptions, the mediated and unmediated effects of the treatment are identified: Theorem 15.6 (Identification of Total, Mediated and Unmediated Effects under Sequential Ignorability) Under Assumptions 15.10 and 15.11, the treatment effect on the treated and the mediated and unmediated effects are identified: \\[\\begin{align*} \\Delta^Y_{TT} &amp; = \\esp{Y_i|D_i=1}-\\esp{\\esp{Y_i|X_i,D_i=0}|D_i=1} \\\\ \\Delta^{Y_{m(1)}}_{TT} &amp; =\\mathbb{E}\\left[\\left(\\esp{Y_i|X_i,D_i=1,M_i=1}-\\esp{Y_i|X_i,D_i=1,M_i=0}\\right)\\right.\\\\ &amp; \\phantom{=\\mathbb{E}}\\left.\\left(\\Pr(M_i=1|X_i,D_i=1)-\\Pr(M_i=1|X_i,D_i=0)\\right)|D_i=1\\right]\\\\ \\Delta^{Y_{u(0)}}_{TT} &amp; =\\esp{\\esp{Y_i|X_i,D_i=1,M_i}-\\esp{Y_i|X_i,D_i=0,M_i}|D_i=1}. \\end{align*}\\] Proof. The proof of identification of the total average treatment effect on the treated is straightforward, using results from Chapter 5. The proof of the identification of the mediated treatment effect in Imai, Keele and Yamamoto (2010) is not very intuitive. I am following a different route based on types \\(T_i\\), using a somewhat stronger set of assumptions: \\((Y_i^{d,m},T_i)\\Ind D_i|X_i\\), which follows from the first part of Assumption 15.10, and \\(Y_i^{d,m}\\Ind T_i|X_i\\). This second assumption is somewhat stronger than the second part of Assumption 15.10, but not much more. Let us now prove the identification of \\(\\Delta^{Y_{m(1)}}_{TT}\\). In what follows, I omit conditioning on \\(X_i\\). Following Assumption 15.10, we have: \\[\\begin{align*} \\esp{Y_i|D_i,M_i=1} &amp; = \\esp{Y_i^{1,1}}\\\\ \\esp{Y_i|D_i,M_i=0} &amp; = \\esp{Y_i^{1,0}}. \\end{align*}\\] We also have, under the same assumption (and the fact that it implies \\(T_i\\Ind D_i|X_i\\)): \\[\\begin{align*} \\Pr(M_i=1|D_i=1)-\\Pr(M_i=1|D_i=0) &amp; =\\Pr(T_i=a) + \\Pr(T_i=c)-(\\Pr(T_i=a)+\\Pr(T_i=d)) \\\\ &amp; =\\Pr(T_i=c)-\\Pr(T_i=d). \\end{align*}\\] As a consequence, we have: \\[\\begin{align*} \\esp{Y_i|D_i,M_i=1}-\\esp{Y_i|D_i,M_i=0} &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}}(\\Pr(T_i=c)-\\Pr(T_i=d)) \\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=c}\\Pr(T_i=c)-\\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=d}\\Pr(T_i=d)\\\\ &amp; = \\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=c,D_i=1}\\Pr(T_i=c|D_i=1)\\\\ &amp; \\phantom{=}-\\esp{Y_i^{1,1}-Y_i^{1,0}|T_i=d,D_i=1}\\Pr(T_i=d|D_i=1)\\\\ &amp; = \\Delta^{Y_{m(1)}}_{TT}, \\end{align*}\\] where the second equality uses \\(Y_i^{d,m}\\Ind T_i|X_i\\), the third \\((Y_i^{d,m},T_i)\\Ind D_i|X_i\\) and the fourth the decomposition of \\(\\Delta^{Y_{m(1)}}_{TT}\\) by type. The expression is implicitely conditional on \\(X_i\\). Assumption 15.11 and the Law of Iterated Expectations prove the unconditional result. Let us now prove the identification of \\(\\Delta^{Y_{u(0)}}_{TT}\\). We have: \\[\\begin{align*} \\esp{Y_i|D_i=1,M_i=d} &amp; = \\esp{Y^{1,d}}\\\\ \\esp{Y_i|D_i=0,M_i=d} &amp; = \\esp{Y^{0,d}} \\end{align*}\\] because of Assumption 15.10. Using the Law of Iterated Expectations finalizes the proof. Remark. Under Assumption 15.10, the comparison of the outcomes in the treated groups between the individuals with \\(M_i=1\\) and \\(M_i=0\\) identifies the controlled mediated effect \\(\\esp{Y_i^{1,1}-Y_i^{1,0}}\\). This is not the mediated effect thought, since we need to account for the fact that the treatment only alters the effect of the mediator for a subset of the population. The impact of the treatment on the value of the mediator is estiamted y comparing the value of the mediator in the treated and control group. 15.4.2 Mediation analysis under sequential ignorability in linear models One classical and simple way to represent mediation analysis is to use a simple parametric linear structural model. Let’s write the mediator and the outcome equations in the following way: \\[\\begin{align*} Y_i &amp; = \\alpha_1 + \\beta_1 D_i + \\gamma_1 M_i + \\epsilon^1_{i}\\\\ M_i &amp; = \\alpha_2 + \\beta_2 D_i + \\epsilon^2_i, \\end{align*}\\] where \\((\\epsilon^1_{i},\\epsilon^2_{i})\\) are orthogonal i.i.d. random shocks. Note that this structural equation implies that \\(M_i\\) is not binary. We will study this case shortly after. Note also that the reduced form combining both equations yields the following equation for \\(Y_i\\): \\[\\begin{align*} Y_i &amp; = \\alpha_1 +\\gamma_1\\alpha_2 + (\\beta_1+\\gamma_1\\beta_2)D_i + \\epsilon^1_{i}+\\gamma_1\\epsilon^2_i. \\end{align*}\\] In this model, the total effect of the treatment on \\(Y_i\\) is equal to \\(\\beta_1+\\gamma_1\\beta_2\\). It can be decomposed between the direct (unmediated) effect of the treatment, \\(\\beta_1\\), and the indirect (mediated) effect of the treatment, \\(\\gamma_1\\beta_2\\). Under sequential ignorability, running both structural equations enables to identify the required parameters to identify these effects. Running the reduced form gives the total effect. Adding the mediator gives the unmediated effect. These usual practices are thus consistent, but only under these very stringent assumptions. 15.5 Mediation analysis with panel data Mediation analysis with panel data has scarcely been studied up to know. The only attack on this issue that I know of stems from Deuchert, Huber and Schelker (2017). 15.6 Mediation analysis with instruments "],["proofs.html", "A Proofs A.1 Proofs of results in Chapter 2 A.2 Proofs of results in Chapter 3 A.3 Proofs of results in Chapter 4 A.4 Proofs of results in Chapter 5", " A Proofs A.1 Proofs of results in Chapter 2 A.1.1 Proof of Theorem 2.3 In order to use Theorem 2.2 for studying the behavior of \\(\\hat{\\Delta^Y_{WW}}\\), we have to prove that it is unbiased and we have to compute \\(\\var{\\hat{\\Delta^Y_{WW}}}\\). Let’s first prove that the \\(WW\\) estimator is an unbiased estimator of \\(TT\\): Lemma A.1 (Unbiasedness of $\\hat{\\Delta^Y_{WW}}$) Under Assumptions 1.7, 2.1 and 2.2, \\[\\begin{align*} \\esp{\\hat{\\Delta^Y_{WW}}}&amp; = \\Delta^Y_{TT}. \\end{align*}\\] Proof. In order to prove Lemma A.1, we are going to use a trick. We are going to compute the expectation of the \\(WW\\) estimator conditional on a given treatment allocation. Because the resulting estimate is independent of treatment allocation, we will have our proof. This trick simplifies derivations a lot and is really natural: think first of all the samples with the same treatment allocation, then average your results over all possible treatment allocations. \\[\\begin{align*} \\esp{\\hat{\\Delta^Y_{WW}}} &amp; = \\esp{\\esp{\\hat{\\Delta^Y_{WW}}|\\mathbf{D}}}\\\\ &amp; = \\esp{\\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}}\\\\ &amp; = \\esp{\\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i|\\mathbf{D}}-\\esp{\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}}\\\\ &amp; = \\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\esp{\\sum_{i=1}^N Y_iD_i|\\mathbf{D}}-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\esp{\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}}\\\\ &amp; = \\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N \\esp{Y_iD_i|\\mathbf{D}}-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N \\esp{Y_i(1-D_i)|\\mathbf{D}}}\\\\ &amp; = \\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N \\esp{Y_iD_i|D_i}-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N \\esp{Y_i(1-D_i)|D_i}}\\\\ &amp; = \\esp{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N D_i\\esp{Y_i|D_i=1}-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N(1-D_i)\\esp{Y_i|D_i=0}}\\\\ &amp; = \\esp{\\frac{\\sum_{i=1}^N D_i}{\\sum_{i=1}^N D_i}\\esp{Y_i|D_i=1}-\\frac{\\sum_{i=1}^N(1-D_i)}{\\sum_{i=1}^N (1-D_i)}\\esp{Y_i|D_i=0}}\\\\ &amp; = \\esp{\\esp{Y_i|D_i=1}-\\esp{Y_i|D_i=0}}\\\\ &amp; = \\esp{Y_i|D_i=1}-\\esp{Y_i|D_i=0} \\\\ &amp; = \\Delta^Y_{TT}. \\end{align*}\\] The first equality uses the Law of Iterated Expectations (LIE). The second and fourth equalities use the linearity of conditional expectations. The third equality uses the fact that, conditional on \\(\\mathbf{D}\\), the number of treated and untreated is a constant. The fifth equality uses Assumption 2.2. The sixth equality uses the fact that \\(\\esp{Y_iD_i|D_i}=D_i\\esp{Y_i*1|D_i=1}+(1-D_i)\\esp{Y_i*0|D_i=0}\\). The seventh and ninth equalities use the fact that \\(\\esp{Y_i|D_i=1}\\) is a constant. The last equality uses Assumption 1.7. Let’s now compute the variance of the \\(WW\\) estimator: Lemma A.2 (Variance of $\\hat{\\Delta^Y_{WW}}$) Under Assumptions 1.7, ?? and 2.2, \\[\\begin{align*} \\var{{\\hat{\\Delta^Y_{WW}}}} &amp; = \\frac{1-(1-\\Pr(D_i=1))^N}{N\\Pr(D_i=1)}\\var{Y_i^1|D_i=1}+\\frac{1-\\Pr(D_i=1)^N}{N(1-\\Pr(D_i=1))}\\var{Y_i^0|D_i=0}. \\end{align*}\\] Proof. Same trick as before, but now using the Law of Total Variance (LTV): \\[\\begin{align*} \\var{{\\hat{\\Delta^Y_{WW}}}} &amp; = \\esp{\\var{\\hat{\\Delta^Y_{WW}}|\\mathbf{D}}}+\\var{\\esp{\\hat{\\Delta^Y_{WW}}|\\mathbf{D}}}\\\\ &amp; = \\esp{\\var{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i-\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}} \\\\ &amp; = \\esp{\\var{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i|\\mathbf{D}}}+\\esp{\\var{\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}}\\\\ &amp; \\phantom{=}+\\esp{\\cov{\\frac{1}{\\sum_{i=1}^N D_i}\\sum_{i=1}^N Y_iD_i,\\frac{1}{\\sum_{i=1}^N (1-D_i)}\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}} \\\\ &amp; = \\esp{\\frac{1}{(\\sum_{i=1}^N D_i)^2}\\var{\\sum_{i=1}^N Y_iD_i|\\mathbf{D}}}+\\esp{\\frac{1}{(\\sum_{i=1}^N (1-D_i))^2}\\var{\\sum_{i=1}^N Y_i(1-D_i)|\\mathbf{D}}} \\\\ &amp; = \\esp{\\frac{1}{(\\sum_{i=1}^N D_i)^2}\\var{\\sum_{i=1}^N Y_iD_i|D_i}}+\\esp{\\frac{1}{(\\sum_{i=1}^N (1-D_i))^2}\\var{\\sum_{i=1}^N Y_i(1-D_i)|D_i}} \\\\ &amp; = \\esp{\\frac{1}{(\\sum_{i=1}^N D_i)^2}\\sum_{i=1}^ND_i\\var{Y_i|D_i=1}}+\\esp{\\frac{1}{(\\sum_{i=1}^N (1-D_i))^2}\\sum_{i=1}^N(1-D_i)\\var{Y_i|D_i=0}} \\\\ &amp; = \\var{Y_i|D_i=1}\\esp{\\frac{1}{\\sum_{i=1}^N D_i}}+\\var{Y_i|D_i=0}\\esp{\\frac{1}{\\sum_{i=1}^N (1-D_i)}} \\\\ &amp; = \\frac{1-(1-\\Pr(D_i=1))^N}{N\\Pr(D_i=1)}\\var{Y_i^1|D_i=1}+\\frac{1-\\Pr(D_i=1)^N}{N(1-\\Pr(D_i=1))}\\var{Y_i^0|D_i=0}. \\end{align*}\\] The first equality stems from the LTV. The second and third equalities stems from the definition of the \\(WW\\) estimator and of the variance of a sum of random variables. The fourth equality stems from Assumption 2.2, which means that the covariance across observations is zero, and from the formula for a variance of a random variable multiplied by a constant. The fifth and sixth equalities stems from Assumption 2.2 and from \\(\\var{Y_iD_i|D_i}=D_i\\var{Y_i*1|D_i=1}+(1-D_i)\\var{Y_i*0|D_i=0}\\). The seventh equality stems from \\(\\var{Y_i|D_i=1}\\) and \\(\\var{Y_i|D_i=0}\\) being constant. The last equality stems from the formula for the expectation of the inverse of a sum of Bernoulli random variables with at least one of them taking value one which is the case under Assumption 2.1. Using Theorem 2.2, we have: \\[\\begin{align*} 2\\epsilon &amp; \\leq 2\\sqrt{\\frac{1}{N(1-\\delta)}\\left(\\frac{1-(1-\\Pr(D_i=1))^N}{\\Pr(D_i=1)}\\var{Y_i^1|D_i=1}+\\frac{1-\\Pr(D_i=1)^N}{(1-\\Pr(D_i=1))}\\var{Y_i^0|D_i=0}\\right)}\\\\ &amp; \\leq 2\\sqrt{\\frac{1}{N(1-\\delta)}\\left(\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{(1-\\Pr(D_i=1))}\\right)}, \\end{align*}\\] where the second equality stems from the fact that \\(\\frac{(1-\\Pr(D_i=1))^N}{\\Pr(D_i=1)}\\var{Y_i^1|D_i=1}+\\frac{\\Pr(D_i=1)^N}{(1-\\Pr(D_i=1))}\\var{Y_i^0|D_i=0}\\geq0\\). This proves the result. A.1.2 Proof of Theorem 2.5 Before proving Theorem 2.5, let me state a very useful result: \\(\\hat{WW}\\) can be computed using OLS: Lemma A.3 (WW is OLS) Under Assumption 2.1, the OLS coefficient \\(\\beta\\) in the following regression: \\[\\begin{align*} Y_i &amp; = \\alpha + \\beta D_i + U_i \\end{align*}\\] is the WW estimator: \\[\\begin{align*} \\hat{\\beta}_{OLS} &amp; = \\frac{\\frac{1}{N}\\sum_{i=1}^N\\left(Y_i-\\frac{1}{N}\\sum_{i=1}^NY_i\\right)\\left(D_i-\\frac{1}{N}\\sum_{i=1}^ND_i\\right)}{\\frac{1}{N}\\sum_{i=1}^N\\left(D_i-\\frac{1}{N}\\sum_{i=1}^ND_i\\right)^2} \\\\ &amp; = \\hat{\\Delta^Y_{WW}}. \\end{align*}\\] Proof. In matrix notation, we have: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_1 \\\\ \\vdots \\\\ Y_N \\end{array}\\right)}_{Y} &amp; = \\underbrace{\\left(\\begin{array}{cc} 1 &amp; D_1\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; D_N\\end{array}\\right)}_{X} \\underbrace{\\left(\\begin{array}{c} \\alpha \\\\ \\beta \\end{array}\\right)}_{\\Theta}+ \\underbrace{\\left(\\begin{array}{c} U_1 \\\\ \\vdots \\\\ U_N \\end{array}\\right)}_{U} \\end{align*}\\] The OLS estimator is: \\[\\begin{align*} \\hat{\\Theta}_{OLS} &amp; = (X&#39;X)^{-1}X&#39;Y \\end{align*}\\] Under the Full Rank Assumption, \\(X&#39;X\\) is invertible and we have: \\[\\begin{align*} (X&#39;X)^{-1} &amp; = \\left(\\begin{array}{cc} N &amp; \\sum_{i=1}^ND_i \\\\ \\sum_{i=1}^ND_i &amp; \\sum_{i=1}^ND_i^2 \\end{array}\\right)^{-1} \\\\ &amp; = \\frac{1}{N\\sum_{i=1}^ND_i^2-\\left(\\sum_{i=1}^ND_i\\right)^2}\\left(\\begin{array}{cc} \\sum_{i=1}^ND_i^2 &amp; -\\sum_{i=1}^ND_i \\\\ -\\sum_{i=1}^ND_i &amp; N \\end{array}\\right) \\end{align*}\\] For simplicity, I omit the summation index: \\[\\begin{align*} \\hat{\\Theta}_{OLS} &amp; = \\frac{1}{N\\sum D_i^2-\\left(\\sum D_i\\right)^2} \\left(\\begin{array}{cc} \\sum D_i^2 &amp; -\\sum D_i \\\\ -\\sum D_i &amp; N \\end{array}\\right) \\left(\\begin{array}{c} \\sum Y_i \\\\ \\sum Y_iD_i \\end{array}\\right) \\\\ &amp; = \\frac{1}{N\\sum D_i^2-\\left(\\sum D_i\\right)^2} \\left(\\begin{array}{c} \\sum D_i^2\\sum Y_i-\\sum D_i\\sum_{i=1}^NY_iD_i \\\\ -\\sum D_i\\sum Y_i+ N\\sum Y_iD_i \\end{array}\\right) \\\\ \\end{align*}\\] Using \\(D_i^2=D_i\\), we have: \\[\\begin{align*} \\hat{\\Theta}_{OLS} &amp; = \\left(\\begin{array}{c} \\frac{\\left(\\sum D_i\\right)\\left(\\sum Y_i-\\sum Y_iD_i\\right)}{\\left(\\sum D_i\\right)\\left(N-\\sum D_i\\right)} \\\\ \\frac{N\\sum Y_iD_i-\\sum D_i\\sum Y_i}{N\\sum D_i-\\left(\\sum D_i\\right)^2} \\end{array}\\right) = \\left(\\begin{array}{c} \\frac{\\sum (Y_iD_i+Y_i(1-D_i))-\\sum Y_iD_i}{\\sum(1-D_i)} \\\\ \\frac{N^2}{N^2}\\frac{\\frac{1}{N}\\sum Y_iD_i-\\frac{1}{N}\\sum D_i\\frac{1}{N}\\sum Y_i+\\frac{1}{N}\\sum D_i\\frac{1}{N}\\sum Y_i-\\frac{1}{N}\\sum D_i\\frac{1}{N}\\sum Y_i}{\\frac{1}{N}\\sum D_i-2\\left(\\frac{1}{N}\\sum D_i\\right)^2+\\left(\\frac{1}{N}\\sum D_i\\right)^2} \\end{array}\\right) \\\\ &amp; = \\left(\\begin{array}{c} \\frac{\\sum Y_i(1-D_i)}{\\sum(1-D_i)} \\\\ \\frac{\\frac{1}{N}\\sum \\left(Y_iD_i-D_i\\frac{1}{N}\\sum Y_i-Y_i\\frac{1}{N}\\sum D_i+\\frac{1}{N}\\sum D_i\\frac{1}{N}\\sum Y_i\\right)}{\\frac{1}{N}\\sum\\left(D_i-2D_i\\frac{1}{N}\\sum D_i+\\left(\\frac{1}{N}\\sum D_i\\right)^2\\right)} \\end{array}\\right) = \\left(\\begin{array}{c} \\frac{\\sum Y_i(1-D_i)}{\\sum(1-D_i)} \\\\ \\frac{\\frac{1}{N}\\sum\\left(Y_i-\\frac{1}{N}\\sum Y_i\\right)\\left(D_i-\\frac{1}{N}\\sum D_i\\right)}{\\frac{1}{N}\\sum \\left(D_i-\\frac{1}{N}\\sum D_i\\right)^2} \\end{array}\\right), \\end{align*}\\] which proves the first part of the lemma. Now for the second part of the lemma: \\[\\begin{align*} \\hat{\\beta}_{OLS} &amp; = \\frac{\\sum Y_iD_i-\\frac{1}{N}\\sum D_i\\sum Y_i}{\\sum D_i\\left(1-\\frac{1}{N}\\sum D_i\\right)} = \\frac{\\sum Y_iD_i-\\frac{1}{N}\\sum D_i\\sum\\left(Y_iD_i+(1-D_i)Y_i\\right)}{\\sum D_i\\left(1-\\frac{1}{N}\\sum D_i\\right)}\\\\ &amp; = \\frac{\\sum Y_iD_i\\left(1-\\frac{1}{N}\\sum D_i\\right)-\\frac{1}{N}\\sum D_i\\sum(1-D_i)Y_i}{\\sum D_i\\left(1-\\frac{1}{N}\\sum D_i\\right)}\\\\ &amp; = \\frac{\\sum Y_iD_i}{\\sum D_i}-\\frac{\\frac{1}{N}\\sum(1-D_i)Y_i}{\\left(1-\\frac{1}{N}\\sum D_i\\right)}\\\\ &amp; = \\frac{\\sum Y_iD_i}{\\sum D_i}-\\frac{\\frac{1}{N}\\sum(1-D_i)Y_i}{\\frac{1}{N}\\sum\\left(1-D_i\\right)}\\\\ &amp; = \\frac{\\sum Y_iD_i}{\\sum D_i}-\\frac{\\sum(1-D_i)Y_i}{\\sum\\left(1-D_i\\right)}\\\\ &amp; = \\hat{\\Delta^Y_{WW}}, \\end{align*}\\] which proves the result. Now, let me state the most important lemma behind the result in Theorem 2.5: Lemma A.4 (Asymptotic Distribution of the OLS Estimator) Under Assumptions 1.7, 2.1, 2.2 and 2.3, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(\\begin{array}{c} 0\\\\ 0\\end{array}, \\sigma_{XX}^{-1}\\mathbf{V_{xu}}\\sigma_{XX}^{-1}\\right), \\end{align*}\\] with \\[\\begin{align*} \\sigma_{XX}^{-1}&amp; = \\left(\\begin{array}{cc} \\frac{\\Pr(D_i=1)}{\\Pr(D_i=1)(1-\\Pr(D_i=1))} &amp; -\\frac{\\Pr(D_i=1)}{\\Pr(D_i=1)(1-\\Pr(D_i=1))}\\\\ -\\frac{\\Pr(D_i=1)}{\\Pr(D_i=1)(1-\\Pr(D_i=1))} &amp; \\frac{1}{\\Pr(D_i=1)(1-\\Pr(D_i=1))} \\end{array}\\right)\\\\ \\mathbf{V_{xu}}&amp;= \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; D_i\\\\ D_i &amp; D_i\\end{array}\\right)} \\end{align*}\\] Proof. \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta) &amp; = \\sqrt{N}((X&#39;X)^{-1}X&#39;Y-\\Theta) \\\\ &amp; = \\sqrt{N}((X&#39;X)^{-1}X&#39;(X\\Theta+U)-\\Theta) \\\\ &amp; = \\sqrt{N}((X&#39;X)^{-1}X&#39;X\\Theta+(X&#39;X)^{-1}X&#39;U)-\\Theta) \\\\ &amp; = \\sqrt{N}(X&#39;X)^{-1}X&#39;U \\\\ &amp; = N(X&#39;X)^{-1}\\frac{\\sqrt{N}}{N}X&#39;U \\end{align*}\\] Using Slutsky’s Theorem, we can study both terms separately. Before stating Slutsky’s Theorem, we need to define a new term: convergence in probability (this is a simpler version of convergence in distribution). We say that a sequence \\(X_N\\) converges in probability to the constant \\(x\\) if, \\(\\forall\\epsilon&gt;0\\), \\(\\lim_{N\\rightarrow\\infty}\\Pr(|X_N-x|&gt;\\epsilon)=0\\). We denote \\(X_N\\stackrel{p}{\\rightarrow}x\\) or \\(\\text{plim}(X_N)=x\\). Slutsky’s Theorem states that if \\(Y_N\\stackrel{d}{\\rightarrow}y\\) and \\(\\text{plim}(X_N)=x\\), then: \\(X_N+Y_N\\stackrel{d}{\\rightarrow}x+y\\) \\(X_NY_N\\stackrel{d}{\\rightarrow}xy\\) \\(\\frac{Y_N}{X_N}\\stackrel{d}{\\rightarrow}\\frac{x}{y}\\) if \\(x\\neq0\\) Using this theorem, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta) &amp; \\stackrel{d}{\\rightarrow} \\sigma_{XX}^{-1}xu, \\end{align*}\\] Where \\(\\sigma_{XX}^{-1}\\) is a matrix of constants and \\(xu\\) is a random variable. Let’s begin with \\(\\frac{\\sqrt{N}}{N}X&#39;U\\stackrel{d}{\\rightarrow}xu\\): \\[\\begin{align*} \\frac{\\sqrt{N}}{N}X&#39;U &amp; = \\sqrt{N}\\left(\\begin{array}{c} \\frac{1}{N}\\sum_{i=1}^{N}U_i\\\\ \\frac{1}{N}\\sum_{i=1}^{N}D_iU_i\\end{array}\\right) \\end{align*}\\] In order to determine the asymptotic distribution of \\(\\frac{\\sqrt{N}}{N}X&#39;U\\), we are going to use the vector version of the CLT: If \\(X_i\\) and \\(Y_i\\) are two i.i.d. random variables with finite first and second moments, we have: \\[\\begin{align*} \\sqrt{N} \\left( \\begin{array}{c} \\frac{1}{N}\\sum_{i=1}^NX_i-\\esp{X_i}\\\\ \\frac{1}{N}\\sum_{i=1}^NY_i-\\esp{Y_i} \\end{array} \\right) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N} \\left( \\begin{array}{c} 0\\\\ 0 \\end{array}, \\mathbf{V} \\right), \\end{align*}\\] where \\(\\mathbf{V}\\) is the population covariance matrix of \\(X_i\\) and \\(Y_i\\). We know that, under Assumption 1.7, both random variables have mean zero: \\[\\begin{align*} \\esp{U_i}&amp; = \\esp{U_i|D_i=1}\\Pr(D_i=1)+\\esp{U_i|D_i=0}\\Pr(D_i=0)=0 \\\\ \\esp{U_iD_i}&amp; = \\esp{U_i|D_i=1}\\Pr(D_i=1)=0 \\end{align*}\\] Their covariance matrix \\(\\mathbf{V_{xu}}\\) can be computed as follows: \\[\\begin{align*} \\mathbf{V_{xu}} &amp; = \\esp{\\left(\\begin{array}{c} U_i\\\\ UiD_i\\end{array}\\right)\\left(\\begin{array}{cc} U_i&amp; UiD_i\\end{array}\\right)} - \\esp{\\left(\\begin{array}{c} U_i\\\\ UiD_i\\end{array}\\right)}\\esp{\\left(\\begin{array}{cc} U_i&amp; UiD_i\\end{array}\\right)}\\\\ &amp; = \\esp{\\left(\\begin{array}{cc} U_i^2 &amp; U_i^2D_i\\\\ Ui^2D_i &amp; U_i^2D_i^2\\end{array}\\right)} = \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; D_i\\\\ D_i &amp; D_i^2\\end{array}\\right)} = \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; D_i\\\\ D_i &amp; D_i\\end{array}\\right)} \\end{align*}\\] Using the Vector CLT, we have that \\(\\frac{\\sqrt{N}}{N}X&#39;U\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(\\begin{array}{c} 0\\\\ 0\\end{array},\\mathbf{V_{xu}}\\right)\\). Let’s show now that \\(\\plims N(X&#39;X)^{-1}=\\sigma_{XX}^{-1}\\): \\[\\begin{align*} N(X&#39;X)^{-1} &amp; = \\frac{N}{N\\sum_{i=1}^ND_i-\\left(\\sum_{i=1}^ND_i\\right)^2} \\left(\\begin{array}{cc} \\sum_{i=1}^ND_i &amp; -\\sum_{i=1}^ND_i \\\\ -\\sum_{i=1}^ND_i &amp; N \\end{array}\\right) \\\\ &amp; = \\frac{1}{N}\\frac{1}{\\frac{1}{N}\\sum_{i=1}^ND_i-\\left(\\frac{1}{N}\\sum_{i=1}^ND_i\\right)^2} \\left(\\begin{array}{cc} \\sum_{i=1}^ND_i &amp; -\\sum_{i=1}^ND_i \\\\ -\\sum_{i=1}^ND_i &amp; N \\end{array}\\right)\\\\ &amp; = \\frac{1}{\\frac{1}{N}\\sum_{i=1}^ND_i-\\left(\\frac{1}{N}\\sum_{i=1}^ND_i\\right)^2} \\left(\\begin{array}{cc} \\frac{1}{N}\\sum_{i=1}^ND_i &amp; -\\frac{1}{N}\\sum_{i=1}^ND_i \\\\ -\\frac{1}{N}\\sum_{i=1}^ND_i &amp; 1 \\end{array}\\right)\\\\ \\plims N(X&#39;X)^{-1} &amp; = \\frac{1}{\\plims\\frac{1}{N}\\sum_{i=1}^ND_i-\\left(\\plims\\frac{1}{N}\\sum_{i=1}^ND_i\\right)^2} \\left(\\begin{array}{cc} \\plims\\frac{1}{N}\\sum_{i=1}^ND_i &amp; -\\plims\\frac{1}{N}\\sum_{i=1}^ND_i \\\\ -\\plims\\frac{1}{N}\\sum_{i=1}^ND_i &amp; 1 \\end{array}\\right)\\\\ &amp; = \\frac{1}{\\Pr(D_i=1)-\\Pr(D_i=1)^2} \\left(\\begin{array}{cc} \\Pr(D_i=1) &amp; -\\Pr(D_i=1) \\\\ -\\Pr(D_i=1) &amp; 1 \\end{array}\\right)\\\\ &amp; = \\sigma_{XX}^{-1} \\end{align*}\\] The fourth equality uses Slutsky’s Theorem. The fifth equality uses the Law of Large Numbers (LLN): if \\(Y_i\\) are i.i.d. variables with finite first and second moments, \\(\\plim{N}\\frac{1}{N}\\sum_{i=1}^NY_i = \\esp{Y_i}\\). In order to complete the proof, we have to use the Delta Method Theorem. This theorem states that: \\[\\begin{gather*} \\sqrt{N}(\\begin{array}{c} \\bar{X}_N-\\esp{X_i}\\\\ \\bar{Y}_N-\\esp{Y_i}\\end{array}) \\stackrel{d}{\\rightarrow}\\mathcal{N}(\\begin{array}{c} 0\\\\ 0\\end{array},\\mathbf{V}) \\\\ \\Rightarrow \\sqrt{N}(g(\\bar{X}_N,\\bar{Y}_N)-g(\\esp{X_i},\\esp{Y_i}) \\stackrel{d}{\\rightarrow}\\mathcal{N}(0,G&#39;\\mathbf{V}G) \\end{gather*}\\] where \\(G(u)=\\partder{g(u)}{u}\\) and \\(G=G(\\esp{X_i},\\esp{Y_i})\\). In our case, \\(g(xu)=\\sigma_{XX}^{-1}xu\\), so \\(G(xu)=\\sigma_{XX}^{-1}\\). The results follows from that and from the symmetry of \\(\\sigma_{XX}^{-1}\\). A last lemma uses the previous result to derive the asymptotic distribution of \\(\\hat{WW}\\): Lemma A.5 (Asymptotic Distribution of $\\hat{WW}$) Under Assumptions 1.7, 2.1, 2.2 and 2.3, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Delta^Y_{WW}}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}\\right). \\end{align*}\\] Proof. In order to derive the asymptotic distribution of WW, I use first Lemma A.3 which implies that the asymptotic distribution of WW is the same as that of \\(\\hat{\\beta}_{OLS}\\). Now, from Lemma A.4, we know that \\(\\sqrt{N}(\\hat{\\beta}_{OLS}-\\beta)\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,\\sigma^2_{\\beta})\\), where \\(\\sigma^2_{\\beta}\\) is the lower diagonal term of \\(\\sigma_{XX}^{-1}\\mathbf{V_{xu}}\\sigma_{XX}^{-1}\\). Using the convention \\(p=\\Pr(D_i=1)\\), we have: \\[\\begin{align*} \\sigma_{XX}^{-1}\\mathbf{V_{xu}}\\sigma_{XX}^{-1} &amp; = \\left(\\begin{array}{cc} \\frac{p}{p(1-p)} &amp; -\\frac{p}{p(1-p)}\\\\ -\\frac{p}{p(1-p)} &amp; \\frac{1}{p(1-p)} \\end{array}\\right) \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; D_i\\\\ D_i &amp; D_i\\end{array}\\right)} \\left(\\begin{array}{cc} \\frac{p}{p(1-p)} &amp; -\\frac{p}{p(1-p)}\\\\ -\\frac{p}{p(1-p)} &amp; \\frac{1}{p(1-p)} \\end{array}\\right)\\\\ &amp; = \\frac{1}{(p(1-p))^2} \\left(\\begin{array}{cc} p\\esp{U_i^2}-p\\esp{U_i^2D_i} &amp; p\\esp{U_i^2D_i}-p\\esp{U_i^2D_i}\\\\ -p\\esp{U_i^2}+\\esp{U_i^2D_i} &amp; -p\\esp{U_i^2D_i}+\\esp{U_i^2D_i} \\end{array}\\right) \\left(\\begin{array}{cc} p &amp; -p\\\\ -p &amp; 1 \\end{array}\\right)\\\\ &amp; = \\frac{1}{(p(1-p))^2} \\left(\\begin{array}{cc} p^2(\\esp{U_i^2}-\\esp{U_i^2D_i}) &amp; p^2(\\esp{U_i^2D_i}-\\esp{U_i^2})\\\\ p^2(\\esp{U_i^2D_i}-\\esp{U_i^2}) &amp; p^2\\esp{U_i^2}+(1-2p)\\esp{U_i^2D_i} \\end{array}\\right) \\end{align*}\\] The final result comes from the fact that: \\[\\begin{align*} \\esp{U_i^2} &amp; = \\esp{U_i^2|D_i=1}p + (1-p)\\esp{U_i^2|D_i=0}\\\\ &amp; = p\\var{Y_i^1|D_i=1}+(1-p)\\var{Y_i^0|D_i=0} \\\\ \\esp{U_i^2D_i} &amp; = \\esp{U_i^2|D_i=1}p \\\\ &amp; = p\\var{Y_i^1|D_i=1}. \\end{align*}\\] As a consequence: \\[\\begin{align*} \\sigma^2_{\\beta} &amp;= \\frac{1}{(p(1-p))^2}\\left(\\var{Y_i^1|D_i=1}p(p^2-2p+1) + p^2(1-p)\\var{Y_i^0|D_i=0}\\right) \\\\ &amp;= \\frac{1}{(p(1-p))^2}\\left(\\var{Y_i^1|D_i=1}p(1-p)^2 + p^2(1-p)\\var{Y_i^0|D_i=0}\\right)\\\\ &amp; = \\frac{\\var{Y_i^1|D_i=1}}{p}+\\frac{\\var{Y_i^0|D_i=0}}{1-p}. \\end{align*}\\] Using the previous lemma, we can now approximate the confidence level of \\(\\hat{WW}\\): \\[\\begin{align*} \\Pr&amp;(|\\hat{\\Delta^Y_{WW}}-\\Delta^Y_{TT}|\\leq\\epsilon) = \\Pr(-\\epsilon\\leq\\hat{\\Delta^Y_{WW}}-\\Delta^Y_{TT}\\leq\\epsilon) \\\\ &amp; = \\Pr\\left(-\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\leq\\frac{\\hat{\\Delta^Y_{WW}}-\\Delta^Y_{TT}}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\leq\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)\\\\ &amp; \\approx \\Phi\\left(\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)- \\Phi\\left(-\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)\\\\ &amp; = \\Phi\\left(\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)- 1 + \\Phi\\left(\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)\\\\ &amp; = 2\\Phi\\left(\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)-1. \\end{align*}\\] As a consequence, \\[\\begin{align*} \\delta &amp; \\approx 2\\Phi\\left(\\frac{\\epsilon}{\\frac{1}{\\sqrt{N}}\\sqrt{\\frac{\\var{Y_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{Y_i^0|D_i=0}}{1-\\Pr(D_i=1)}}}\\right)-1. \\end{align*}\\] Hence the result. A.2 Proofs of results in Chapter 3 A.2.1 Proof of Theorem 3.9 In order to prove the theorem, it is going to be very helpful to prove the following lemma: Lemma A.6 (Unconfounded Types) Under Assumptions 3.9 and 3.10, the types \\(T_i\\) are independent of the allocation of the treatment: \\[\\begin{align*} (Y_i^{1,1},Y_i^{0,1},Y_i^{0,0},Y_i^{1,0},T_i)\\Ind R_i|E_i=1. \\end{align*}\\] Proof. Lemma 4.2 in Dawid (1979) shows that if \\(X\\Ind Y|Z\\) and \\(U\\) is a function of \\(X\\) then \\(U\\Ind Y|Z\\). The fact that \\(T_i\\) is a function of \\((D_i^1,D^0_i)\\) proves the result. The four sets defined by \\(T_i\\) are a partition of the sample space. As a consequence, we have (ommitting the conditioning on \\(E_i=1\\) all along for simplicity): \\[\\begin{align*} \\esp{Y_i|R_i=1} &amp; = \\esp{Y_i|T_i=a,R_i=1}\\Pr(T_i=a|R_i=1)\\\\ &amp; \\phantom{=}+ \\esp{Y_i|T_i=c,R_i=1}\\Pr(T_i=c|R_i=1) \\\\ &amp; \\phantom{=} + \\esp{Y_i|T_i=d,R_i=1}\\Pr(T_i=d|R_i=1)\\\\ &amp; \\phantom{=} + \\esp{Y_i|T_i=n,R_i=1}\\Pr(T_i=n|R_i=1)\\\\ \\esp{Y_i|R_i=0} &amp; = \\esp{Y_i|T_i=a,R_i=0}\\Pr(T_i=a|R_i=0)\\\\ &amp; \\phantom{=} + \\esp{Y_i|T_i=c,R_i=0}\\Pr(T_i=c|R_i=0) \\\\ &amp; \\phantom{=} + \\esp{Y_i|T_i=d,R_i=0}\\Pr(T_i=d|R_i=0)\\\\ &amp; \\phantom{=}+ \\esp{Y_i|T_i=n,R_i=0}\\Pr(T_i=n|R_i=0). \\end{align*}\\] Let’s look at all these terms in turn: \\[\\begin{align*} \\esp{Y_i|T_i=a,R_i=1} &amp; = \\esp{Y_i^{1,1}D_iR_i+Y_i^{1,0}D_i(1-R_i)+Y_i^{0,1}(1-D_i)R_i+Y_i^{0,0}(1-D_i)(1-R_i)|T_i=a,R_i=1} \\\\ &amp; = \\esp{Y_i^{1,1}(D^1_iR_i+D_i^0(1-R_i))R_i+Y_i^{0,1}(1-(D^1_iR_i+D_i^0(1-R_i)))R_i|T_i=a,R_i=1} \\\\ &amp; = \\esp{Y_i^{1,1}D^1_iR_i^2+Y_i^{0,1}(1-D^1_iR_i)R_i|D_i^1=D_i^0=1,R_i=1} \\\\ &amp; = \\esp{Y_i^{1,1}|T_i=a,R_i=1} \\\\ &amp; = \\esp{Y_i^{1,1}|T_i=a}, \\\\ \\end{align*}\\] where the first equality uses Assumption 3.9, the second equality uses the fact that \\(R_i=1\\) in the conditional expectation and Assumption 3.9, the third equality uses the fact that \\(R_i=1\\), the fourth equality uses the fact that \\(T_i=a \\Leftrightarrow D_i^1=D_i^0=1\\) and the last equality uses Lemma A.6. Using a similar reasoning, we have: \\[\\begin{align*} \\esp{Y_i|T_i=c,R_i=1} &amp; = \\esp{Y_i^{1,1}|T_i=c} \\\\ \\esp{Y_i|T_i=d,R_i=1} &amp; = \\esp{Y_i^{0,1}|T_i=d} \\\\ \\esp{Y_i|T_i=n,R_i=1} &amp; = \\esp{Y_i^{0,1}|T_i=n} \\\\ \\esp{Y_i|T_i=a,R_i=0} &amp; = \\esp{Y_i^{1,0}|T_i=c} \\\\ \\esp{Y_i|T_i=c,R_i=0} &amp; = \\esp{Y_i^{0,0}|T_i=c} \\\\ \\esp{Y_i|T_i=d,R_i=0} &amp; = \\esp{Y_i^{1,0}|T_i=d} \\\\ \\esp{Y_i|T_i=n,R_i=0} &amp; = \\esp{Y_i^{0,0}|T_i=n}. \\end{align*}\\] Also, Lemma A.6 implies that \\(\\Pr(T_i=a|R_i)=\\Pr(T_i=a)\\), and the same is true for all other types. As a consequence, we have: \\[\\begin{align*} \\esp{Y_i|R_i=1} &amp; = \\esp{Y_i^{1,1}|T_i=a}\\Pr(T_i=a)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{1,1}|T_i=c}\\Pr(T_i=c) \\\\ &amp; \\phantom{=} + \\esp{Y_i^{0,1}|T_i=d}\\Pr(T_i=d)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{0,1}|T_i=n}\\Pr(T_i=n)\\\\ \\esp{Y_i|R_i=0} &amp; = \\esp{Y_i^{1,0}|T_i=a}\\Pr(T_i=a)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{0,0}|T_i=c}\\Pr(T_i=c) \\\\ &amp; \\phantom{=} + \\esp{Y_i^{1,0}|T_i=d}\\Pr(T_i=d)\\\\ &amp; \\phantom{=} + \\esp{Y_i^{0,0}|T_i=n}\\Pr(T_i=n). \\end{align*}\\] And thus: \\[\\begin{align*} \\esp{Y_i|R_i=1}-\\esp{Y_i|R_i=0} &amp; = (\\esp{Y_i^{1,1}|T_i=a}-\\esp{Y_i^{1,0}|T_i=a})\\Pr(T_i=a)\\\\ &amp; \\phantom{=}+ (\\esp{Y_i^{1,1}|T_i=c}-\\esp{Y_i^{0,0}|T_i=c})\\Pr(T_i=c) \\\\ &amp; \\phantom{=} - (\\esp{Y_i^{1,0}|T_i=d}-\\esp{Y_i^{0,1}|T_i=d})\\Pr(T_i=d)\\\\ &amp; \\phantom{=} + (\\esp{Y_i^{0,1}|T_i=n}-\\esp{Y_i^{0,0}|T_i=n})\\Pr(T_i=n). \\end{align*}\\] Using Assumption 3.11, we have: \\[\\begin{align*} \\esp{Y_i|R_i=1}-\\esp{Y_i|R_i=0} &amp; = (\\esp{Y_i^{1}|T_i=a}-\\esp{Y_i^{1}|T_i=a})\\Pr(T_i=a)\\\\ &amp; \\phantom{=}+ (\\esp{Y_i^{1}|T_i=c}-\\esp{Y_i^{0}|T_i=c})\\Pr(T_i=c) \\\\ &amp; \\phantom{=} - (\\esp{Y_i^{1}|T_i=d}-\\esp{Y_i^{0}|T_i=d})\\Pr(T_i=d)\\\\ &amp; \\phantom{=} + (\\esp{Y_i^{0}|T_i=n}-\\esp{Y_i^{0}|T_i=n})\\Pr(T_i=n)\\\\ &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=c}\\Pr(T_i=c) \\\\ &amp; \\phantom{=} - \\esp{Y_i^{1}-Y_i^{0}|T_i=d}\\Pr(T_i=d). \\end{align*}\\] Under Assumption 3.13, we have: \\[\\begin{align*} \\esp{Y_i|R_i=1}-\\esp{Y_i|R_i=0} &amp; = \\esp{Y_i^{1}-Y_i^{0}|T_i=c}\\Pr(T_i=c)\\\\ &amp; = \\Delta^Y_{LATE}\\Pr(T_i=c). \\end{align*}\\] We also have: \\[\\begin{align*} \\Pr(D_i=1|R_i=1) &amp; = \\Pr(D^1_i=1|R_i=1)\\\\ &amp; = \\Pr(D^1_i=1\\cap (D_i^0=1\\cup D_i^0=0) |R_i=1)\\\\ &amp; = \\Pr(D^1_i=1\\cap D_i^0=1\\cup D^1_i=1\\cap D_i^0=0 |R_i=1)\\\\ &amp; = \\Pr(D^1_i=D_i^0=1\\cup D^1_i-D_i^0=0 |R_i=1)\\\\ &amp; = \\Pr(T_i=a\\cup T_i=c |R_i=1)\\\\ &amp; = \\Pr(T_i=a|R_i=1)+\\Pr(T_i=c|R_i=1)\\\\ &amp; = \\Pr(T_i=a)+\\Pr(T_i=c), \\end{align*}\\] where the first equality follows from Assumption 3.9 and the fact that \\(D_i=R_iD_i^1+(1-R_i)D_i^0\\), so that \\(D_i|R_i=1=D_i^1\\). The second equality follows from the fact that \\(\\left\\{ D_i^0=1,D_i^0=0\\right\\}\\) is a partition of the sample space. The third equality follows from usual rules of logic and the fourth equality from the fact that \\(D_i^1\\) and \\(D_i^0\\) can only take values zero and one. The fifth equality follows from the definition of \\(T_i\\). The sixth equaity follows from the rule of addition in probability and the fact that \\(T_i=a\\) and \\(T_i=c\\) are disjoint. The final equality follows from Lemma A.6. Using a similar reasoning, we have: \\[\\begin{align*} \\Pr(D_i=1|R_i=0) &amp; = \\Pr(T_i=a)+ \\Pr(T_i=d). \\end{align*}\\] As a consequence, under Assumption 3.13, we have: \\[\\begin{align*} \\Pr(D_i=1|R_i=1)-\\Pr(D_i=1|R_i=0) &amp; = \\Pr(T_i=c). \\end{align*}\\] Using Assumption 3.12 proves the result. A.2.2 Proof of Theorem 3.15 In matrix notation, we have: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_1 \\\\ \\vdots \\\\ Y_N \\end{array}\\right)}_{Y} &amp; = \\underbrace{\\left(\\begin{array}{cc} 1 &amp; D_1\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; D_N\\end{array}\\right)}_{X} \\underbrace{\\left(\\begin{array}{c} \\alpha \\\\ \\beta \\end{array}\\right)}_{\\Theta}+ \\underbrace{\\left(\\begin{array}{c} U_1 \\\\ \\vdots \\\\ U_N \\end{array}\\right)}_{U} \\end{align*}\\] and \\[\\begin{align*} \\left(\\begin{array}{c} D_1 \\\\ \\vdots \\\\ D_N \\end{array}\\right) &amp; = \\underbrace{\\left(\\begin{array}{cc} 1 &amp; R_1\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; R_N\\end{array}\\right)}_{R} \\left(\\begin{array}{c} \\gamma \\\\ \\tau \\end{array}\\right)+ \\left(\\begin{array}{c} V_1 \\\\ \\vdots \\\\ V_N \\end{array}\\right) \\end{align*}\\] The IV estimator is: \\[\\begin{align*} \\hat{\\Theta}_{IV} &amp; = (R&#39;X)^{-1}R&#39;Y \\end{align*}\\] If there is at least one observation with \\(R_i=1\\) and \\(D_i=1\\), \\(R&#39;X\\) is invertible (its determinant is non null) and we have (ommitting the summation index for simplicity): \\[\\begin{align*} (R&#39;X)^{-1} &amp; = \\left(\\begin{array}{cc} N &amp; \\sum D_i \\\\ \\sum R_i &amp; \\sum D_iR_i \\end{array}\\right)^{-1} \\\\ &amp; = \\frac{1}{N\\sum D_iR_i-\\sum D_i\\sum R_i}\\left(\\begin{array}{cc} \\sum D_iR_i &amp; -\\sum D_i \\\\ -\\sum R_i &amp; N \\end{array}\\right) \\end{align*}\\] Since: \\[\\begin{align*} R&#39;Y &amp; = \\left(\\begin{array}{c} \\sum Y_i \\\\ \\sum Y_iR_i \\end{array}\\right), \\end{align*}\\] we have: \\[\\begin{align*} \\hat{\\Theta}_{IV} &amp; = \\left( \\begin{array}{c} \\frac{\\sum Y_i\\sum D_iR_i-\\sum D_i\\sum Y_iR_i}{N\\sum D_iR_i -\\sum D_iR_i}\\\\ \\frac{N\\sum Y_iR_i-\\sum R_i\\sum Y_i}{N\\sum D_iR_i-\\sum D_iR_i} \\end{array} \\right) \\end{align*}\\] As a consequence, \\(\\hat{\\beta}_{IV}\\) is equal to the ratio of two OLS estimators (\\(Y_i\\) on \\(R_i\\) and a constant and \\(D_i\\) on the same regressors) (see the proof of Lemma A.3 in section A.1.2, just after “Using \\(D_i^2=D_i\\)”). We can use Lemma A.3 stating that the OLS estimator is the WW estimator to prove the result. A.2.3 Proof of Theorem 3.16 In order to derive the asymptotic distribution of the Wald estimator, I first use Theorem 3.15 which implies that the asymptotic distribution of Wald is the same as that of \\(\\hat{\\beta}_{IV}\\). Now, I’m going to derive the asymptotic distribution of the IV estimator. Lemma A.7 (Asymptotic Distribution of the IV Estimator) Under Independence and Validity of the Instrument, Exclusion Restriction and Full Rank, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{IV}-\\Theta) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(\\begin{array}{c} 0\\\\ 0\\end{array}, (\\sigma_{RX}^{-1})&#39;\\mathbf{V_{ru}}\\sigma_{RX}^{-1}\\right), \\end{align*}\\] with \\[\\begin{align*} \\sigma_{RX}^{-1}&amp; = \\frac{\\left(\\begin{array}{cc} \\esp{D_iR_i} &amp; -\\Pr(D_i=1)\\\\ -\\Pr(R_i=1) &amp; 1 \\end{array}\\right)}{(\\Pr(D_i=1|R_i=1)-\\Pr(D_i=1|R_i=0))\\Pr(R_i=1)(1-\\Pr(R_i=1))} \\\\ \\mathbf{V_{ru}}&amp;= \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; R_i\\\\ R_i &amp; R_i\\end{array}\\right)} \\end{align*}\\] Proof. \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{IV}-\\Theta) &amp; = \\sqrt{N}((R&#39;X)^{-1}R&#39;Y-\\Theta) \\\\ &amp; = \\sqrt{N}((R&#39;X)^{-1}R&#39;(X\\Theta+U)-\\Theta) \\\\ &amp; = \\sqrt{N}((R&#39;X)^{-1}R&#39;X\\Theta+(X&#39;X)^{-1}X&#39;U)-\\Theta) \\\\ &amp; = \\sqrt{N}(R&#39;X)^{-1}R&#39;U \\\\ &amp; = N(R&#39;X)^{-1}\\frac{\\sqrt{N}}{N}R&#39;U \\end{align*}\\] Using Slutsky’s Theorem, we have: \\[\\begin{align*} \\sqrt{N}(\\hat{\\Theta}_{IV}-\\Theta) &amp; \\stackrel{d}{\\rightarrow} \\sigma_{RX}^{-1}ru, \\end{align*}\\] where \\(\\sigma_{RX}^{-1}\\) is a matrix of constants and \\(ru\\) is a random variable. We know that \\(\\plims N(R&#39;X)^{-1}=\\sigma_{RX}^{-1}\\). So: \\[\\begin{align*} N(R&#39;X)^{-1} &amp; = \\frac{N}{N\\sum D_iR_i-\\sum D_i\\sum R_i}\\left(\\begin{array}{cc} \\sum D_iR_i &amp; -\\sum D_i \\\\ -\\sum R_i &amp; N \\end{array}\\right) \\\\ &amp; = \\frac{1}{\\frac{\\sum D_iR_i}{N}-\\frac{\\sum D_i}{N}\\frac{\\sum R_i}{N}} \\left(\\begin{array}{cc} \\frac{\\sum D_iR_i}{N} &amp; -\\frac{\\sum D_i}{N} \\\\ -\\frac{\\sum R_i}{N} &amp; 1 \\end{array} \\right) \\end{align*}\\] \\(\\frac{\\sum D_iR_i}{N}-\\frac{\\sum D_i}{N}\\frac{\\sum R_i}{N}\\) is equal to the numerator of the OLS coefficient of a regression of \\(D_i\\) on \\(R_i\\) and a constant (Proof of Lemma 3 in Lecture 0). As a consequence of Lemma 3 in Lecture 0, it can be written as the With/Without estimator multiplied by the denominator of the OLS estimator, which is simply the variance of \\(R_i\\). Let’s turn to \\(\\frac{\\sqrt{N}}{N}R&#39;U\\stackrel{d}{\\rightarrow}xu\\): \\[\\begin{align*} \\frac{\\sqrt{N}}{N}R&#39;U &amp; = \\sqrt{N}\\left(\\begin{array}{c} \\frac{1}{N}\\sum^{i=1}_{N}U_i\\\\ \\frac{1}{N}\\sum^{i=1}_{N}R_iU_i\\end{array}\\right) \\end{align*}\\] We know that, under Validity of Randomization, both random variables have mean zero: \\[\\begin{align*} \\esp{U_i}&amp; = \\esp{U_i|R_i=1}\\Pr(R_i=1)+\\esp{U_i|R_i=0}\\Pr(R_i=0)=0 \\\\ \\esp{U_iR_i}&amp; = \\esp{U_i|R_i=1}\\Pr(R_i=1)=0 \\end{align*}\\] Their covariance matrix \\(\\mathbf{V_{ru}}\\) can be computed as follows: \\[\\begin{align*} \\mathbf{V_{ru}} &amp; = \\esp{\\left(\\begin{array}{c} U_i\\\\ UiR_i\\end{array}\\right)\\left(\\begin{array}{cc} U_i&amp; UiR_i\\end{array}\\right)} - \\esp{\\left(\\begin{array}{c} U_i\\\\ UiR_i\\end{array}\\right)}\\esp{\\left(\\begin{array}{cc} U_i&amp; UiR_i\\end{array}\\right)}\\\\ &amp; = \\esp{\\left(\\begin{array}{cc} U_i^2 &amp; U_i^2R_i\\\\ Ui^2R_i &amp; U_i^2R_i^2\\end{array}\\right)} = \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; R_i\\\\ R_i &amp; R_i^2\\end{array}\\right)} = \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; R_i\\\\ R_i &amp; R_i\\end{array}\\right)} \\end{align*}\\] Using the Vector CLT, we have that \\(\\frac{\\sqrt{N}}{N}R&#39;U\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(\\begin{array}{c} 0\\\\ 0\\end{array},\\mathbf{V_{ru}}\\right)\\). Using Slutsky’s theorem and the LLN gives the result. From Lemma A.7, we know that \\(\\sqrt{N}(\\hat{\\beta}_{IV}-\\beta)\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,\\sigma^2_{\\beta})\\), where \\(\\sigma^2_{\\beta}\\) is the lower diagonal term of \\((\\sigma_{RX}^{-1})&#39;\\mathbf{V_{ru}}\\sigma_{RX}^{-1}\\). Using the convention \\(p^R=\\Pr(R_i=1)\\), \\(p^D=\\Pr(D_i=1)\\), \\(p^D_1=\\Pr(D_i=1|R_i=1)\\), \\(p^D_0=\\Pr(D_i=1|R_i=0)\\) and \\(p^{DR}=\\esp{D_iR_i}\\), we have: \\[\\begin{align*} (&amp;\\sigma_{RX}^{-1})&#39;\\mathbf{V_{ru}}\\sigma_{RX}^{-1} \\\\ &amp; = \\frac{1}{((p^D_1-p^D_0)p^R(1-p^R))^2} \\left(\\begin{array}{cc} p^{DR} &amp; -p^R\\\\ -p^D &amp; 1 \\end{array}\\right) \\esp{U_i^2\\left(\\begin{array}{cc} 1 &amp; R_i\\\\ R_i &amp; R_i\\end{array}\\right)} \\left(\\begin{array}{cc} p^{DR} &amp; -p^D\\\\ -p^R &amp; 1 \\end{array}\\right)\\\\ &amp; = \\frac{1}{((p^D_1-p^D_0)p^R(1-p^R))^2} \\left(\\begin{array}{cc} p^{DR}\\esp{U_i^2}-p^R\\esp{U_i^2R_i} &amp; \\esp{U_i^2R_i}(p^{DR}-p^R)\\\\ \\esp{U_i^2R_i}-p^D\\esp{U_i^2} &amp; \\esp{U_i^2R_i}(1-p^D) \\end{array}\\right) \\left(\\begin{array}{cc} p^{DR} &amp; -p^D\\\\ -p^R &amp; 1 \\end{array}\\right)\\\\ &amp; = \\frac{\\left(\\begin{array}{cc} p^{DR}(p^{DR}\\esp{U_i^2}-p^R\\esp{U_i^2R_i})- p^R\\esp{U_i^2R_i}(p^{DR}-p^R) &amp; \\esp{U_i^2R_i}(p^{DR}-p^R)-p^{D}(p^{DR}\\esp{U_i^2}-p^R\\esp{U_i^2R_i})\\\\ p^{DR}(\\esp{U_i^2R_i}-p^D\\esp{U_i^2})-p^R\\esp{U_i^2R_i}(1-p^D) &amp; \\esp{U_i^2R_i}(1-p^D) - p^{D}(\\esp{U_i^2R_i}-p^D\\esp{U_i^2}) \\end{array}\\right)}{((p^D_1-p^D_0)p^R(1-p^R))^2} \\end{align*}\\] As a consequence: \\[\\begin{align*} \\sigma^2_{\\beta} &amp; = \\frac{\\esp{U_i^2R_i}(1-p^D) - p^{D}(\\esp{U_i^2R_i}-p^D\\esp{U_i^2})}{((p^D_1-p^D_0)p^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^D)^2\\esp{U_i^2}+(1-2p^D)\\esp{U_i^2R_i}}{((p^D_1-p^D_0)p^R(1-p^R))^2}\\\\ &amp; = \\frac{(p^D)^2(\\esp{U_i^2|R_i=1}p^R+\\esp{U_i^2|R_i=0}(1-p^R))+(1-2p^D)\\esp{U_i^2|R_i=1}p^R}{((p^D_1-p^D_0)p^R(1-p^R))^2}\\\\ &amp; = \\frac{(p^D)^2\\esp{U_i^2|R_i=0}(1-p^R)+(1-2p^D+(p^D)^2)\\esp{U_i^2|R_i=1}p^R}{((p^D_1-p^D_0)p^R(1-p^R))^2}\\\\ &amp; = \\frac{(p^D)^2\\esp{U_i^2|R_i=0}(1-p^R)+(1-p^D)^2\\esp{U_i^2|R_i=1}p^R}{((p^D_1-p^D_0)p^R(1-p^R))^2}\\\\ &amp; = \\frac{1}{(p^D_1-p^D_0)^2}\\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{\\esp{U_i^2|R_i=0}}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{\\esp{U_i^2|R_i=1}}{p^R}\\right]. \\end{align*}\\] Note that, under monotonicity, \\(p^C=p^D_1-p^D_0\\) and: \\[\\begin{align*} \\esp{U_i^2|R_i=1} &amp; = p^{AT}\\var{Y_i^1|T_i=AT}+p^C\\var{Y_i^1|T_i=C}+p^{NT}\\var{Y_i^0|T_i=NT} \\\\ \\esp{U_i^2|R_i=0} &amp; = p^{AT}\\var{Y_i^1|T_i=AT}+p^C\\var{Y_i^0|T_i=C}+p^{NT}\\var{Y_i^0|T_i=NT}. \\end{align*}\\] The final result comes from the fact that: \\[\\begin{align*} \\frac{1}{(p^C)^2} &amp; \\left[\\left(\\frac{p^D}{p^R}\\right)^2\\frac{1}{1-p^R}+\\left(\\frac{1-p^D}{1-p^R}\\right)^2\\frac{1}{p^R}\\right]\\\\ &amp; = \\frac{(p^D)^2(1-p^R)+(1-p^D)^2p^R}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^D)^2-(p^D)^2p^R+p^R-2p^Dp^R+(p^D)^2p^R}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^D)^2+p^R-2p^Dp^R}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^D-p^R)^2+p^R-(p^R)^2}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^D-p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^{AT}+p^Cp^R-p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^{AT}+(1-p^{AT}-p^{NT})p^R-p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^{AT}+(1-p^{AT}-p^{NT})p^R-p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^{AT}+p^R-p^{AT}p^R-p^{NT}p^R-p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2} \\\\ &amp; = \\frac{(p^{AT}(1-p^R)-p^{NT}p^R)^2+p^R(1-p^R)}{(p^Cp^R(1-p^R))^2}, \\end{align*}\\] where the seventh equality uses the fact that \\(p^C+p^{AT}+p^{NT}=1\\). A.3 Proofs of results in Chapter 4 A.3.1 Proof of Theorem 4.10 Let us start with the proof that \\(\\hat{\\beta}^{FD}=\\hat{\\Delta}^Y_{DID}\\). Using Lemma A.3, we have that \\(\\hat{\\beta}^{FD}=\\hat{\\Delta}^{Y_A-Y_B}_{WW}\\). From there, since \\(\\sum_{i=1}^N(Y_{i,A}-Y_{i,B})D_i= \\sum_{i=1}^NY_{i,A}D_i- \\sum_{i=1}^NY_{i,B}D_i\\), we have \\(\\hat{\\beta}^{FD}=\\hat{\\Delta}^Y_{DID}\\). In order to prove the result for the OLS DID estimator, it is convenient to write the model in matrix form (where we rank all the observations from the first period in the first lines of each matrix and vector): \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,B} \\\\ \\vdots \\\\ Y_{N,B} \\\\Y_{1,A} \\\\ \\vdots \\\\ Y_{N,A} \\end{array}\\right)}_{Y} &amp; = \\underbrace{\\left(\\begin{array}{cccc} 1 &amp; D_1 &amp; T_{1,B} &amp; D_1T_{1,B}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D_N &amp; T_{N,B} &amp; D_NT_{N,B} \\\\ 1 &amp; D_1 &amp; T_{1,A} &amp; D_1T_{1,A}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D_N &amp; T_{N,A} &amp; D_NT_{N,A}\\end{array}\\right)}_{X} \\underbrace{\\left(\\begin{array}{c} \\alpha \\\\ \\mu \\\\ \\delta \\\\ \\beta \\end{array}\\right)}_{\\Theta} + \\underbrace{\\left(\\begin{array}{c} \\epsilon_{1,B} \\\\ \\vdots \\\\ \\epsilon_{N,B} \\\\ \\epsilon_{1,A} \\\\ \\vdots \\\\ \\epsilon_{N,A} \\end{array}\\right)}_{\\epsilon} \\end{align*}\\] Now, using the fact that \\(T_{i,B}=0\\) and \\(T_{i,A}=1\\), \\(\\forall i\\), we can write matrix \\(X\\) as follows: \\[\\begin{align*} X &amp; = \\left(\\begin{array}{cccc} 1 &amp; D_1 &amp; 0 &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D_N &amp; 0 &amp; 0 \\\\ 1 &amp; D_1 &amp; 1 &amp; D_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D_N &amp; 1 &amp; D_N\\end{array}\\right) \\end{align*}\\] Doing some matrix multiplication and factoring \\(N\\), we have: \\[\\begin{align*} X&#39;X &amp; = N\\underbrace{\\left(\\begin{array}{cccc} 2 &amp; 2\\bar{D} &amp; 1 &amp; \\bar{D}\\\\ 2\\bar{D} &amp; 2\\bar{D} &amp; \\bar{D} &amp; \\bar{D} \\\\ 1 &amp; \\bar{D} &amp; 1 &amp; \\bar{D}\\\\ \\bar{D} &amp; \\bar{D} &amp; \\bar{D} &amp; \\bar{D} \\end{array}\\right)}_{x&#39;x} \\end{align*}\\] with \\(\\bar{D}=\\frac{1}{N}\\sum_{i=1}^ND_i\\), and using the fact that \\(D_i^2=D_i\\) since \\(D_i\\in\\left\\{0,1\\right\\}\\). Using results on the inverse of a 4 by 4 matrix presented here and collecting terms patiently, we find that the determinant of \\(xx\\) is equal to: \\[\\begin{align*} \\det(x&#39;x) &amp; = \\bar{D}^2(1-\\bar{D})^2 \\end{align*}\\] and its adjugate is equal to: \\[\\begin{align*} \\tilde{x&#39;x} &amp; = \\bar{D}(1-\\bar{D}) \\left(\\begin{array}{cccc} \\bar{D} &amp; -\\bar{D} &amp; -\\bar{D} &amp; \\bar{D}\\\\ -\\bar{D} &amp; 1 &amp; \\bar{D} &amp; -1 \\\\ -\\bar{D} &amp; \\bar{D} &amp; 2\\bar{D} &amp; -2\\bar{D}\\\\ \\bar{D} &amp; -1 &amp; -2\\bar{D} &amp; 2 \\end{array}\\right) \\end{align*}\\] We also have that: \\[\\begin{align*} X&#39;Y &amp; = N\\left(\\begin{array}{c} \\bar{Y}_B+\\bar{Y}_A \\\\ \\bar{D}(\\bar{Y}^1_B+\\bar{Y}^1_A)\\\\ \\bar{Y}_A \\\\ \\bar{D}\\bar{Y}^1_A \\end{array}\\right) \\end{align*}\\] with \\(\\bar{Y}_t=\\frac{1}{N}\\sum_{i=1}^NY_{i,t}\\) and \\(\\bar{Y}^1_t=\\frac{1}{\\sum_{i=1}^ND_i}\\sum_{i=1}^ND_iY_{i,t}\\) and \\(\\bar{Y}^0_t=\\frac{1}{\\sum_{i=1}^N(1-D_i)}\\sum_{i=1}^N(1-D_i)Y_{i,t}\\) and using the fact that \\(\\sum_{i=1}^ND_iY_{i,t}=N\\bar{D}\\bar{Y}^1_t\\). Using the fact that \\(Y_{i,t}=D_iY_{i,t}+(1-D_i)Y_{i,t}\\), we have: \\[\\begin{align*} \\bar{Y}_t &amp; = \\frac{\\sum_{i=1}^ND_i}{N}\\frac{\\sum_{i=1}^ND_iY_{i,t}}{\\sum_{i=1}^ND_i}+\\frac{\\sum_{i=1}^N(1-D_i)}{N}\\frac{\\sum_{i=1}^N(1-D_i)Y_{i,t}}{\\sum_{i=1}^N(1-D_i)} \\\\ &amp; = \\bar{D}\\bar{Y}^1_t+(1-\\bar{D})\\bar{Y}^0_t. \\end{align*}\\] We thus have: \\[\\begin{align*} X&#39;Y &amp; = N\\left(\\begin{array}{c} \\underbrace{\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^0_B+\\bar{Y}^1_A-\\bar{Y}^0_A)}_{\\mathbf{A}} \\\\ \\underbrace{\\bar{D}(\\bar{Y}^1_B+\\bar{Y}^1_A)}_{\\mathbf{B}}\\\\ \\underbrace{\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^0_A)}_{\\mathbf{C}} \\\\ \\underbrace{\\bar{D}\\bar{Y}^1_A}_{\\mathbf{D}} \\end{array}\\right) \\end{align*}\\] Using the fact that \\((X&#39;X)^{-1}=(Nx&#39;x)^{-1}=\\frac{1}{N}(x&#39;x)^{-1}=\\frac{1}{N}\\frac{\\tilde{x&#39;x}}{\\det(x&#39;x)}\\), we have: \\[\\begin{align*} \\hat{\\Theta}^{OLS} &amp; = (X&#39;X)^{-1}X&#39;Y \\\\ &amp; = \\frac{1}{\\bar{D}(1-\\bar{D})} \\left(\\begin{array}{c} \\bar{D}(\\mathbf{A}-\\mathbf{B}-\\mathbf{C}+\\mathbf{D}) \\\\ -\\bar{D}\\mathbf{A}+\\mathbf{B}+\\bar{D}\\mathbf{C}-\\mathbf{D} \\\\ \\bar{D}(-\\mathbf{A}+\\mathbf{B}+2\\mathbf{C}-2\\mathbf{D})\\\\ \\bar{D}\\mathbf{A}-\\mathbf{B}-2\\bar{D}\\mathbf{C}+2\\mathbf{D} \\end{array}\\right) \\end{align*}\\] Let’s take each term in turn: \\[\\begin{align*} \\hat{\\alpha}^{OLS} &amp; = \\frac{1}{1-\\bar{D}} \\left(\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^0_B+\\bar{Y}^1_A-\\bar{Y}^0_A) -\\bar{D}(\\bar{Y}^1_B+\\bar{Y}^1_A) -(\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^0_A)) +\\bar{D}\\bar{Y}^1_A\\right)\\\\ &amp; = \\frac{1}{1-\\bar{D}} \\left(\\bar{Y}^0_B(1-\\bar{D}) +\\bar{Y}^0_A(1-\\bar{D}-1+\\bar{D}) +\\bar{Y}^1_B(\\bar{D}-\\bar{D}) +\\bar{Y}^1_A(\\bar{D}-\\bar{D}-\\bar{D}+\\bar{D})\\right)\\\\ &amp; = \\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\mu}^{OLS} &amp; = \\frac{1}{\\bar{D}(1-\\bar{D})}\\left( -\\bar{D}(\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^0_B+\\bar{Y}^1_A-\\bar{Y}^0_A)) +\\bar{D}(\\bar{Y}^1_B+\\bar{Y}^1_A) +\\bar{D}(\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^0_A)) -\\bar{D}\\bar{Y}^1_A\\right)\\\\ &amp; = \\frac{1}{1-\\bar{D}}\\left( -\\bar{Y}^0_B(1-\\bar{D}) +\\bar{Y}^0_A(-1+\\bar{D}+1-\\bar{D}) +\\bar{Y}^1_B(1-\\bar{D}) +\\bar{Y}^1_A(-\\bar{D}+1+\\bar{D}-1)\\right) \\\\ &amp; = \\bar{Y}^1_B-\\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\delta}^{OLS} &amp; =\\frac{1}{1-\\bar{D}}\\left( -(\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^0_B+\\bar{Y}^1_A-\\bar{Y}^0_A)) +(\\bar{Y}^1_B+\\bar{Y}^1_A) +2(\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^0_A)) -2\\bar{D}\\bar{Y}^1_A\\right)\\\\ &amp; = \\frac{1}{1-\\bar{D}}\\left( -\\bar{Y}^0_B(1-\\bar{D}) +\\bar{Y}^0_A(2(1-\\bar{D})-(1-\\bar{D})) +\\bar{Y}^1_B(\\bar{D}-\\bar{D}) +\\bar{Y}^1_A(\\bar{D}-\\bar{D}+2\\bar{D}-2\\bar{D})\\right) \\\\ &amp; = \\bar{Y}^0_A-\\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\beta}^{OLS} &amp; =\\frac{1}{\\bar{D}(1-\\bar{D})}\\left( \\bar{D}(\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^0_B+\\bar{Y}^1_A-\\bar{Y}^0_A)) -\\bar{D}(\\bar{Y}^1_B+\\bar{Y}^1_A) -2 \\bar{D}(\\bar{Y}^0_A+\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^0_A)) +2\\bar{D}\\bar{Y}^1_A\\right)\\\\ &amp; = \\frac{1}{1-\\bar{D}}\\left( \\bar{Y}^0_B(1-\\bar{D}) +\\bar{Y}^0_A((1-\\bar{D})-2(1-\\bar{D})) +\\bar{Y}^1_B(\\bar{D}-1) +\\bar{Y}^1_A(\\bar{D}-1-2\\bar{D}+2)\\right) \\\\ &amp; = \\bar{Y}^1_A-\\bar{Y}^1_B-(\\bar{Y}^0_A-\\bar{Y}^0_B) \\end{align*}\\] This last results proves that \\(\\hat{\\beta}^{OLS}=\\hat{\\Delta}^Y_{DID}\\). For the within estimator, it can be written in matrix form as follows: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,B}-\\bar{Y}_1 \\\\ \\vdots \\\\ Y_{N,B}-\\bar{Y}_N \\\\Y_{1,A}-\\bar{Y}_1 \\\\ \\vdots \\\\ Y_{N,A}-\\bar{Y}_N \\end{array}\\right)}_{Y^W} &amp; = \\underbrace{\\left(\\begin{array}{ccc} 1 &amp; 0 &amp; -\\bar{D}_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; 0 &amp; -\\bar{D}_N \\\\ 1 &amp; 1 &amp; D_1-\\bar{D}_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; 1 &amp; D_N-\\bar{D}_N\\end{array}\\right)}_{X^W} \\underbrace{\\left(\\begin{array}{c} \\alpha^W \\\\ \\delta^W \\\\ \\beta^W \\end{array}\\right)}_{\\Theta^{W}} + \\underbrace{\\left(\\begin{array}{c} \\epsilon^W_{1,B} \\\\ \\vdots \\\\ \\epsilon^W_{N,B} \\\\ \\epsilon^W_{1,A} \\\\ \\vdots \\\\ \\epsilon^W_{N,A} \\end{array}\\right)}_{\\epsilon^W} \\end{align*}\\] We have: \\[\\begin{align*} {X^W}&#39;X^W &amp; = N\\underbrace{\\left(\\begin{array}{ccc} 2 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; \\frac{\\bar{D}}{2} \\\\ 0 &amp; \\frac{\\bar{D}}{2} &amp; \\frac{\\bar{D}}{2} \\end{array}\\right)}_{{x^W}&#39;x^W} \\end{align*}\\] This is because: \\[\\begin{align*} {X^W}&#39;X^W &amp; = \\left(\\begin{array}{ccc} 2N &amp; N &amp; -\\sum_{i=1}^N\\bar{D}_i+\\sum_{i=1}^N(D_i-\\bar{D}_i)\\\\ N &amp; N &amp; \\sum_{i=1}^N(D_i-\\bar{D}_i) \\\\ -\\sum_{i=1}^N\\bar{D}_i+\\sum_{i=1}^N(D_i-\\bar{D}_i) &amp; \\sum_{i=1}^N(D_i-\\bar{D}_i) &amp; \\sum_{i=1}^N\\bar{D}_i^2+\\sum_{i=1}^N(D_i-\\bar{D}_i)^2 \\end{array}\\right) \\end{align*}\\] and: \\[\\begin{align*} \\sum_{i=1}^N\\bar{D}_i &amp; = \\frac{1}{2}\\sum_{i=1}^N(D_{i,B}+D_{i,A}) \\\\ &amp; = \\frac{1}{2}\\sum_{i=1}^ND_{i} \\\\ &amp; = \\frac{1}{2}N\\bar{D}\\\\ \\sum_{i=1}^N(D_i-\\bar{D}_i) &amp; = N\\bar{D}-\\frac{1}{2}N\\bar{D} \\\\ &amp; = \\frac{1}{2}N\\bar{D}\\\\ \\sum_{i=1}^N\\bar{D}^2_i &amp; = \\frac{1}{4}\\sum_{i=1}^N(D_{i,B}+D_{i,A})^2\\\\ &amp; = \\frac{1}{4}\\sum_{i=1}^ND^2_{i} \\\\ &amp; = \\frac{1}{4}N\\bar{D} \\\\ \\sum_{i=1}^N(D_i-\\bar{D}_i)^2 &amp; = \\sum_{i=1}^N(D_{i}-\\frac{1}{2}D_{i})^2\\\\ &amp; = \\frac{1}{4}N\\bar{D} \\end{align*}\\] Now we can use the results here and here to compute the inverse of the \\({x^W}&#39;x^W\\) matrix. Let us first compute the determinant: \\[\\begin{align*} \\det({x^W}&#39;x^W) &amp; = 2(\\frac{\\bar{D}}{2}-\\frac{\\bar{D}^2}{4}) - \\frac{\\bar{D}}{2}\\\\ &amp; = \\frac{1}{2}\\bar{D}(1-\\bar{D}). \\end{align*}\\] And then the adjugate: \\[\\begin{align*} \\tilde{{x^W}&#39;x^W} &amp; = \\left(\\begin{array}{ccc} \\frac{\\bar{D}}{2}(1-\\frac{\\bar{D}}{2}) &amp; -\\frac{\\bar{D}}{2} &amp; \\frac{\\bar{D}}{2}\\\\ -\\frac{\\bar{D}}{2} &amp; \\bar{D} &amp; -\\bar{D}\\\\ \\frac{\\bar{D}}{2} &amp; -\\bar{D} &amp; 1 \\end{array}\\right) \\end{align*}\\] Let us now examine \\({X^W}&#39;Y^W\\): \\[\\begin{align*} {X^W}&#39;Y^W &amp; = \\left(\\begin{array}{c} \\sum_{i=1}^N(Y_{i,B}-\\bar{Y}_i)+\\sum_{i=1}^N(Y_{i,A}-\\bar{Y}_i)\\\\ \\sum_{i=1}^N(Y_{i,A}-\\bar{Y}_i) \\\\ -\\sum_{i=1}^N\\bar{D}_i(Y_{i,B}-\\bar{Y}_i)+\\sum_{i=1}^N(D_i-\\bar{D}_i)(Y_{i,A}-\\bar{Y}_i) \\end{array}\\right) \\end{align*}\\] We have: \\[\\begin{align*} \\sum_{i=1}^N(Y_{i,B}-\\bar{Y}_i) &amp; = N\\bar{Y}_B-\\frac{1}{2}N(\\bar{Y}_B+\\bar{Y}_A)\\\\ &amp; = \\frac{1}{2}N(\\bar{Y}_B-\\bar{Y}_A)\\\\ \\sum_{i=1}^N(Y_{i,A}-\\bar{Y}_i) &amp; = \\frac{1}{2}N(\\bar{Y}_A-\\bar{Y}_B)\\\\ \\sum_{i=1}^N\\bar{D}_i(Y_{i,B}-\\bar{Y}_i) &amp; = \\sum_{i=1}^N\\frac{1}{2}D_i(Y_{i,B}-\\frac{1}{2}\\sum_{i=1}^N(Y_{i,B}+Y_{i,A}))\\\\ &amp; = \\sum_{i=1}^N\\frac{1}{2}D_i\\frac{1}{2}(Y_{i,B}-Y_{i,A})\\\\ &amp; = \\frac{1}{4}\\sum_{i=1}^ND_i(Y_{i,B}-Y_{i,A})\\\\ &amp; = \\frac{1}{4}N\\bar{D}(\\bar{Y}^1_B-\\bar{Y}^1_A)\\\\ \\sum_{i=1}^N(D_i-\\bar{D}_i)(Y_{i,A}-\\bar{Y}_i) &amp; = \\sum_{i=1}^N(D_i-\\frac{1}{2}D_i)(Y_{i,A}-\\frac{1}{2}\\sum_{i=1}^N(Y_{i,B}+Y_{i,A}))\\\\ &amp; = \\frac{1}{4}\\sum_{i=1}^ND_i(Y_{i,A}-Y_{i,B})\\\\ &amp; = \\frac{1}{4}N\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^1_B). \\end{align*}\\] So, we have: \\[\\begin{align*} ({X^W}&#39;X^W)^{-1}{X^W}&#39;Y^W &amp; = \\frac{2}{N\\bar{D}(1-\\bar{D})} \\left(\\begin{array}{ccc} \\frac{\\bar{D}}{2}(1-\\frac{\\bar{D}}{2}) &amp; -\\frac{\\bar{D}}{2} &amp; \\frac{\\bar{D}}{2}\\\\ -\\frac{\\bar{D}}{2} &amp; \\bar{D} &amp; -\\bar{D}\\\\ \\frac{\\bar{D}}{2} &amp; -\\bar{D} &amp; 1 \\end{array}\\right) \\left(\\begin{array}{c} 0\\\\ \\frac{N}{2}(\\bar{Y}_A-\\bar{Y}_B)\\\\ \\frac{N}{2}\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^1_B) \\end{array}\\right) \\end{align*}\\] We thus have: \\[\\begin{align*} \\hat{\\beta}^W &amp; = \\frac{2}{N\\bar{D}(1-\\bar{D})}\\left(-\\bar{D}\\frac{N}{2}(\\bar{Y}_A-\\bar{Y}_B)+\\frac{N}{2}\\bar{D}(\\bar{Y}^1_A-\\bar{Y}^1_B)\\right)\\\\ &amp; = \\frac{1}{1-\\bar{D}}\\left(\\bar{Y}^1_A-\\bar{Y}^1_B-(\\bar{Y}_A-\\bar{Y}_B)\\right)\\\\ \\end{align*}\\] Using the fact that \\(\\bar{Y}_t=\\bar{D}\\bar{Y}_t^1+(1-\\bar{D})\\bar{Y}^0_t\\), we have \\(\\bar{Y}_A-\\bar{Y}_B=(1-\\bar{D})(\\bar{Y}^0_A-\\bar{Y}^0_B)+\\bar{D}(\\bar{Y}_A^1-\\bar{Y}_B^1)\\). As a consequence: \\[\\begin{align*} \\hat{\\beta}^W &amp; = \\frac{1-\\bar{D}}{1-\\bar{D}}\\left(\\bar{Y}^1_A-\\bar{Y}^1_B-(\\bar{Y}^0_A-\\bar{Y}^0_B)\\right)\\\\ &amp; = \\bar{Y}^1_A-\\bar{Y}^1_B-(\\bar{Y}^0_A-\\bar{Y}^0_B), \\end{align*}\\] which proves that \\(\\hat{\\beta}^{W}=\\hat{\\Delta}^Y_{DID}\\). Now for \\(\\hat{\\beta}^{LSDV}\\), the estimator can be written in matrix form as follows: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,B} \\\\ \\vdots \\\\ Y_{N,B} \\\\Y_{1,A} \\\\ \\vdots \\\\ Y_{N,A} \\end{array}\\right)}_{Y} &amp; = \\underbrace{\\left(\\begin{array}{ccccccc} 1 &amp; 0 &amp; \\dots &amp; 0 &amp; 1 &amp; 0 &amp; D_{1,B}\\\\ 0 &amp; 1 &amp; \\dots &amp; 0 &amp; 1 &amp; 0 &amp; D_{2,B}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\dots &amp; 1 &amp; 1 &amp; 0 &amp; D_{N,B}\\\\ 1 &amp; 0 &amp; \\dots &amp; 0 &amp; 0 &amp; 1 &amp; D_{1,A}\\\\ 0 &amp; 1 &amp; \\dots &amp; 0 &amp; 0 &amp; 1 &amp; D_{2,A}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\dots &amp; 1 &amp; 0 &amp; 1 &amp; D_{N,A}\\\\ \\end{array}\\right)}_{X^{LSDV}} \\underbrace{\\left(\\begin{array}{c} \\mu^{LSDV}_1\\\\ \\vdots \\\\ \\mu^{LSDV}_N \\\\ \\delta^{LSDV}_B \\\\ \\delta^{LSDV}_A \\\\ \\beta^{LSDV} \\end{array}\\right)}_{\\Theta^{LSDV}} + \\underbrace{\\left(\\begin{array}{c} \\epsilon^{LSDV}_{1,B} \\\\ \\vdots \\\\ \\epsilon^{LSDV}_{N,B} \\\\ \\epsilon^{LSDV}_{1,A} \\\\ \\vdots \\\\ \\epsilon^{LSDV}_{N,A} \\end{array}\\right).}_{\\epsilon^{LSDV}} \\end{align*}\\] In order to prove the result, it is going to be very convenient to use Frish-Waugh-Lovell Theorem. It can be stated as follows: Theorem A.1 (Frish-Waugh-Lovell) The coefficients on a set of variables \\(X_2\\) estimated by OLS in a linear regression with another set of control variables \\(X_1\\) is equal to the coefficients on the same set of variables estimated by OLS in a linear model where the outcome variable is the residual of regressing \\(Y\\) on \\(X_1\\) by OLS and the explanatory variables are the residuals of regressing \\(X_2\\) on \\(X_1\\). More formally: \\(\\hat{\\beta}_2^{OLS}=\\hat{\\beta}_2^{OLS(MX_1)}\\) where: \\[\\begin{align*} Y &amp; = X_1\\beta_1 + X_2\\beta_2 + \\epsilon \\\\ M_1Y &amp; = M_1X_2\\beta_2 + \\epsilon^* \\\\ M_1 &amp; = I - X_1(X_1&#39;X_1)^{-1}X_1&#39;. \\end{align*}\\] Proof. See Section 8.2.2 here. \\(M_1\\) is called the prediction or the residualizing matrix. In our case, let us call \\(X^{LSDV}_{\\mu}\\) the first \\(N\\) columns of \\(X^{LSDV}\\). \\(X^{LSDV}_{\\mu}\\) is going to play the role of \\(X_1\\) in Theorem A.1. Let us call \\(X^{LSDV}_{\\delta,D}\\) the matrix made of the last three columns of \\(X^{LSDV}\\). \\(X^{LSDV}_{\\delta,D}\\) is going to play the role of \\(X_2\\) in Theorem A.1. Let us first note that \\({X^{LSDV}_{\\mu}}&#39;X^{LSDV}_{\\mu}=2I_{N}\\), where \\(I_{N}\\) is the identity matrix of dimension \\(N\\). As a consequence, \\(({X^{LSDV}_{\\mu}}&#39;X^{LSDV}_{\\mu})^{-1}=\\frac{1}{2}I_N\\). Now, let us compute \\({X^{LSDV}_{\\mu}}&#39;Y\\): \\[\\begin{align*} {X^{LSDV}_{\\mu}}&#39;Y &amp; = \\left(\\begin{array}{c} Y_{1,B}+Y_{1,A} \\\\ \\vdots \\\\ Y_{N,B}+Y_{N,A} \\end{array}\\right). \\end{align*}\\] As a consequence, we have: \\[\\begin{align*} M^{LSDV}_{\\mu}Y &amp; = Y - X^{LSDV}_{\\mu}({X^{LSDV}_{\\mu}}&#39;X^{LSDV}_{\\mu})^{-1}{X^{LSDV}_{\\mu}}&#39;Y \\\\ &amp; = Y-\\frac{1}{2} X^{LSDV}_{\\mu}I_N \\left(\\begin{array}{c} Y_{1,B}+Y_{1,A} \\\\ \\vdots \\\\ Y_{N,B}+Y_{N,A} \\end{array}\\right) \\\\ &amp; = \\left(\\begin{array}{c} Y_{1,B} - \\frac{1}{2}(Y_{1,B}+Y_{1,A}) \\\\ \\vdots \\\\ Y_{N,B} - \\frac{1}{2}(Y_{N,B}+Y_{N,A})\\\\ Y_{1,A} - \\frac{1}{2}(Y_{1,B}+Y_{1,A}) \\\\ \\vdots \\\\ Y_{N,A} - \\frac{1}{2}(Y_{N,B}+Y_{N,A}) \\end{array}\\right). \\end{align*}\\] And finally: \\[\\begin{align*} M^{LSDV}_{\\mu}X^{LSDV}_{\\delta,D} &amp; = X^{LSDV}_{\\delta,D} - X^{LSDV}_{\\mu}({X^{LSDV}_{\\mu}}&#39;X^{LSDV}_{\\mu})^{-1}{X^{LSDV}_{\\mu}}&#39;X^{LSDV}_{\\delta,D} \\\\ &amp; = \\left(\\begin{array}{ccc} \\frac{1}{2} &amp; -\\frac{1}{2} &amp; D_{1,B}-\\frac{1}{2}(D_{1,B}+D_{1,A}) \\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ \\frac{1}{2} &amp; -\\frac{1}{2} &amp; D_{N,B}-\\frac{1}{2}(D_{1,B}+D_{1,A}) \\\\ -\\frac{1}{2} &amp; \\frac{1}{2} &amp; D_{1,A}-\\frac{1}{2}(D_{1,B}+D_{1,A}) \\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ -\\frac{1}{2} &amp; \\frac{1}{2} &amp; D_{N,A}-\\frac{1}{2}(D_{1,B}+D_{1,A}) \\\\ \\end{array}\\right). \\end{align*}\\] Using Theorem A.1, we can rewrite the LSDV version of the TWFE model as follows: \\[\\begin{align*} M^{LSDV}_{\\mu}Y &amp; = M^{LSDV}_{\\mu}X^{LSDV}_{\\delta,D} \\left(\\begin{array}{c} \\delta^{LSDV}_B \\\\ \\delta^{LSDV}_A \\\\ \\beta^{LSDV} \\end{array}\\right) + M^{LSDV}_{\\mu}\\epsilon^{LSDV} \\end{align*}\\] In a more compact notation, we have, \\(\\forall i\\in\\left[1,N\\right]\\) and \\(\\forall t\\in\\left\\{B,A\\right\\}\\): \\[\\begin{align*} Y_{i,t} - \\bar{Y}_i &amp; = \\frac{1}{2}(\\delta^{LSDV}_A-\\delta^{LSDV}_B)(\\uns{t=A}-\\uns{t=B}) + \\beta^{LSDV}(D_{i,t}-\\bar{D}_{i}) + \\epsilon^{LSDV}_{i,t}-\\bar{\\epsilon}^{LSDV}_{i}, \\end{align*}\\] which we can rewrite, for simplicity, as: \\[\\begin{align*} Y_{i,t} - \\bar{Y}_i &amp; = \\tilde{\\delta}^{LSDV}_t + \\beta^{LSDV}(D_{i,t}-\\bar{D}_{i}) + \\epsilon^{LSDV}_{i,t}-\\bar{\\epsilon}^{LSDV}_{i}, \\end{align*}\\] with \\(\\tilde{\\delta}^{LSDV}_A=-\\tilde{\\delta}_B^{LSDV}=\\bar{\\delta}^{LSDV}\\) and \\(\\bar{\\delta}^{LSDV}=\\frac{1}{2}(\\delta^{LSDV}_A-\\delta^{LSDV}_B)\\). In matrix form, we can thus rewrite the LSDV model transformed by the application of the Frich-Waugh theorem as follows: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,B}-\\bar{Y}_1 \\\\ \\vdots \\\\ Y_{N,B}-\\bar{Y}_N \\\\Y_{1,A}-\\bar{Y}_1 \\\\ \\vdots \\\\ Y_{N,A}-\\bar{Y}_N \\end{array}\\right)}_{Y^{LSDV}_r} &amp; = \\underbrace{\\left(\\begin{array}{ccc} 1 &amp; 0 &amp; -\\bar{D}_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; 0 &amp; -\\bar{D}_N \\\\ 0 &amp; 1 &amp; D_1-\\bar{D}_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 1 &amp; D_N-\\bar{D}_N \\end{array}\\right)}_{X^{LSDV}_r} \\underbrace{\\left(\\begin{array}{c} \\tilde{\\delta}^{LSDV}_B \\\\ \\tilde{\\delta}^{LSDV}_A \\\\ \\beta^{LSDV} \\end{array}\\right)}_{\\Theta^{LSDV}_r} + \\underbrace{\\left(\\begin{array}{c} \\epsilon^{LSDV}_{1,B}-\\bar{\\epsilon}^{LSDV}_{1} \\\\ \\vdots \\\\ \\epsilon^{LSDV}_{N,B}-\\bar{\\epsilon}^{LSDV}_{N} \\\\ \\epsilon^{LSDV}_{1,A}-\\bar{\\epsilon}^{LSDV}_{1} \\\\ \\vdots \\\\ \\epsilon^{LSDV}_{N,A}-\\bar{\\epsilon}^{LSDV}_{N} \\end{array}\\right)}_{\\epsilon^{LSDV}_r} \\end{align*}\\] This is very close to the formula for the Within estimator we have seen above. The only difference is that we have two time fixed effects instead of a constant and the After time fixed effect. We are going to solve for the estimator in a very similar way. First: \\[\\begin{align*} {X^{LSDV}_r}&#39;X^{LSDV}_r &amp; = N\\underbrace{\\left(\\begin{array}{ccc} 1 &amp; 0 &amp; -\\frac{\\bar{D}}{2}\\\\ 0 &amp; 1 &amp; \\frac{\\bar{D}}{2} \\\\ -\\frac{\\bar{D}}{2} &amp; \\frac{\\bar{D}}{2} &amp; \\frac{\\bar{D}}{2} \\end{array}\\right)}_{{x^{LSDV}_r}&#39;x^{LSDV}_r} \\end{align*}\\] The determinant of \\({x^{LSDV}_r}&#39;x^{LSDV}_r\\) is: \\[\\begin{align*} \\det({x^{LSDV}_r}&#39;x^{LSDV}_r) &amp; = \\frac{1}{2}\\bar{D}(1-\\bar{D}) \\end{align*}\\] and its adjoint matrix is: \\[\\begin{align*} \\tilde{{x^{LSDV}_r}&#39;x^{LSDV}_r} &amp; = \\left(\\begin{array}{ccc} \\frac{1}{2}\\bar{D}(1-\\frac{1}{2}\\bar{D}) &amp; - \\frac{1}{4}\\bar{D}^2 &amp; \\frac{1}{2}\\bar{D}\\\\ - \\frac{1}{4}\\bar{D}^2 &amp; \\frac{1}{2}\\bar{D}(1-\\frac{1}{2}\\bar{D}) &amp; -\\frac{1}{2}\\bar{D} \\\\ \\frac{1}{2}\\bar{D} &amp; -\\frac{1}{2}\\bar{D} &amp; 1 \\end{array}\\right). \\end{align*}\\] Finally, we have: \\[\\begin{align*} {X^{LSDV}_r}&#39;Y^{LSDV}_r &amp; = \\left(\\begin{array}{c} \\sum_{i=1}^N(Y_{i,B}-\\bar{Y}_i)\\\\ \\sum_{i=1}^N(Y_{i,A}-\\bar{Y}_i) \\\\ -\\sum_{i=1}^N\\bar{D}_i(Y_{i,B}-\\bar{Y}_i)+\\sum_{i=1}^N(D_i-\\bar{D}_i)(Y_{i,A}-\\bar{Y}_i) \\end{array}\\right) \\\\ &amp; = \\left(\\begin{array}{c} -\\frac{1}{2}N(\\bar{Y}_A-\\bar{Y}_B)\\\\ \\frac{1}{2}N(\\bar{Y}_A-\\bar{Y}_B)\\\\ \\frac{1}{2}N\\bar{D}(\\bar{Y}_A^1-\\bar{Y}_B^1) \\end{array}\\right) \\end{align*}\\] Using the fact that \\(\\hat{\\Theta}^{LSDV}_r=({X^{LSDV}_r}&#39;X^{LSDV}_r)^{-1}{X^{LSDV}_r}&#39;Y^{LSDV}_r\\), we have: \\[\\begin{align*} \\hat{\\beta}^{LSDV} &amp; = \\frac{2}{N\\bar{D}(1-\\bar{D})}\\left[-\\frac{\\bar{D}N}{2}(\\bar{Y}_A-\\bar{Y}_B)+\\frac{\\bar{D}N}{2}(\\bar{Y}_A^1-\\bar{Y}_B^1)\\right] \\\\ &amp; =\\frac{1}{1-\\bar{D}}\\left[\\bar{Y}_A^1-\\bar{Y}_B^1-(1-\\bar{D})(\\bar{Y}^0_A-\\bar{Y}^0_B)-\\bar{D}(\\bar{Y}_A^1-\\bar{Y}_B^1)\\right]\\\\ &amp; =\\frac{1}{1-\\bar{D}}\\left[(1-\\bar{D})(\\bar{Y}_A^1-\\bar{Y}_B^1)-(1-\\bar{D})(\\bar{Y}^0_A-\\bar{Y}^0_B)\\right]\\\\ &amp; =\\bar{Y}_A^1-\\bar{Y}_B^1-(\\bar{Y}^0_A-\\bar{Y}^0_B). \\end{align*}\\] The second equality uses the fact that \\(\\bar{Y}_A-\\bar{Y}_B=(1-\\bar{D})(\\bar{Y}^0_A-\\bar{Y}^0_B)+\\bar{D}(\\bar{Y}_A^1-\\bar{Y}_B^1)\\). This proves the result. To Do: the AP and LC estimators A.3.2 Proof of Theorem 4.12 The DID model in repeated cross sections can be written in the following matrix form: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,B} \\\\ \\vdots \\\\ Y_{N_B,B} \\\\Y_{1,A} \\\\ \\vdots \\\\ Y_{N_A,A} \\end{array}\\right)}_{Y} &amp; = \\underbrace{\\left(\\begin{array}{cccc} 1 &amp; D^B_{1} &amp; T_{1,B} &amp; D^B_{1}T_{1,B}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^B_{N_B} &amp; T_{N_B,B} &amp; D^B_{N_B}T_{N_B,B} \\\\ 1 &amp; D^A_{1} &amp; T_{1,A} &amp; D^A_{1}T_{1,A}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^A_{N_A} &amp; T_{N_A,A} &amp; D^A_{N_A}T_{N_A,A}\\end{array}\\right)}_{X} \\underbrace{\\left(\\begin{array}{c} \\alpha \\\\ \\mu \\\\ \\delta \\\\ \\beta \\end{array}\\right)}_{\\Theta} + \\underbrace{\\left(\\begin{array}{c} \\epsilon_{1,B} \\\\ \\vdots \\\\ \\epsilon_{N_B,B} \\\\ \\epsilon_{1,A} \\\\ \\vdots \\\\ \\epsilon_{N_A,A} \\end{array}\\right),}_{\\epsilon} \\end{align*}\\] where \\(D^B_{i}\\) and \\(D^A_{i}\\) denote the actual treatment status in period \\(A\\) of individuals observed in periods \\(B\\) and \\(A\\) respectively and \\(N_B\\) and \\(N_A\\) are the numbers of units observed in periods \\(B\\) and \\(A\\) respectively. Using the beginning of the proof of Lemma A.4, we know that: \\(\\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta)=N(X&#39;X)^{-1}\\frac{\\sqrt{N}}{N}X&#39;\\epsilon\\). Using Slutsky’s Theorem, we know that we can study both terms separately (see the same proof of Lemma A.4). Let’s start with \\(N(X&#39;X)^{-1}\\). Using the fact that \\(T_{i,B}=0\\) and \\(T_{i,A}=1\\), \\(\\forall i\\), we can write matrix \\(X\\) as follows: \\[\\begin{align*} X &amp; = \\left(\\begin{array}{cccc} 1 &amp; D^B_{1} &amp; 0 &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^B_{N_B} &amp; 0 &amp; 0 \\\\ 1 &amp; D^A_{1} &amp; 1 &amp; D^A_{1}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^A_{N_A} &amp; 1 &amp; D^A_{N_A}\\end{array}\\right) \\end{align*}\\] Doing some matrix multiplication, we have: \\[\\begin{align*} X&#39;X &amp; = N_A\\underbrace{\\left(\\begin{array}{cccc} k+1 &amp; k\\bar{D}_B+\\bar{D}_A &amp; 1 &amp; \\bar{D}_A\\\\ k\\bar{D}_B+\\bar{D}_A &amp; k\\bar{D}_B+\\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A \\\\ 1 &amp; \\bar{D}_A &amp; 1 &amp; \\bar{D}_A\\\\ \\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A \\end{array}\\right)}_{x&#39;x} \\end{align*}\\] with \\(\\bar{D}_t=\\frac{1}{N_t}\\sum_{i=1}^{N_t}D^t_i\\), \\(k=\\frac{N_B}{N_A}\\), and using the fact that \\((D^t_i)^2=D^t_i\\) since \\(D^t_i\\in\\left\\{0,1\\right\\}\\). Using results on the inverse of a 4 by 4 matrix presented here and collecting terms patiently, we find that the determinant of \\(x&#39;x\\) is equal to: \\[\\begin{align*} \\det(x&#39;x) &amp; = k^2\\pi\\bar{D}_A^2(1-\\bar{D}_A)(1-\\pi\\bar{D}_A), \\end{align*}\\] with \\(\\pi=\\frac{\\bar{D}_B}{\\bar{D}_A}\\), and its adjugate is equal to: \\[\\begin{align*} \\tilde{x&#39;x} &amp; = k\\pi\\bar{D}_A(1-\\bar{D}_A) \\left(\\begin{array}{cccc} \\bar{D}_A &amp; -\\bar{D}_A &amp; -\\bar{D}_A &amp; \\bar{D}_A\\\\ -\\bar{D}_A &amp; \\frac{1}{\\pi} &amp; \\bar{D}_A &amp; -\\frac{1}{\\pi} \\\\ -\\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A} &amp; -\\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\\\ \\bar{D}_A &amp; -\\frac{1}{\\pi} &amp; -\\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A} &amp; k\\frac{1-\\pi\\bar{D}_A}{1-\\bar{D}_A}+\\frac{1}{\\pi} \\end{array}\\right) \\end{align*}\\] We finally have that \\(N_A(X&#39;X)^{-1}=\\frac{1}{\\det(x&#39;x)}\\tilde{x&#39;x}\\). Taking the \\(\\text{plim}\\) with respect to \\(N_A\\), we have that: \\[\\begin{align*} \\text{plim}N_A(X&#39;X)^{-1} &amp; = \\frac{1}{kp(1-p)} \\left(\\begin{array}{cccc} p &amp; -p &amp; -p &amp; p\\\\ -p &amp; 1 &amp; p &amp; -1 \\\\ -p &amp; p &amp; p(k+1) &amp; -p(k+1)\\\\ p &amp; -1 &amp; -p(k+1) &amp; k+1 \\end{array}\\right) \\end{align*}\\] The result comes from \\(\\text{plim}\\bar{D}_B=\\text{plim}\\bar{D}_A=\\Pr(D_i=1)=p\\), according to the Law of Large Numbers, and thus, using Slutsky’s Theorem, \\(\\text{plim}\\pi=1\\). Let us now derive the asymptotic distribution of \\(\\frac{\\sqrt{N}}{N}X&#39;\\epsilon\\). In order to do that, we need to know the coefficients of the OLS DID model in repeated cross sections of different sizes. They probably are the same that with a panel, but we still need to check. We have that: \\[\\begin{align*} X&#39;Y &amp; = N_A\\left(\\begin{array}{c} k\\bar{Y}_B+\\bar{Y}_A \\\\ \\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)\\\\ \\bar{Y}_A \\\\ \\bar{D}_A\\bar{Y}^1_A \\end{array}\\right) \\end{align*}\\] Using the fact that \\(\\bar{Y}_t = \\bar{D}_t\\bar{Y}^1_t+(1-\\bar{D}_t)\\bar{Y}^0_t\\), we have that: \\[\\begin{align*} X&#39;Y &amp; = N_A\\left(\\begin{array}{c} \\underbrace{k\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}_A(k\\pi(\\bar{Y}^1_B-\\bar{Y}^0_B)+\\bar{Y}^1_A-\\bar{Y}^0_A)}_{\\mathbf{A}} \\\\ \\underbrace{\\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)}_{\\mathbf{B}}\\\\ \\underbrace{\\bar{Y}^0_A+\\bar{D}_A(\\bar{Y}^1_A-\\bar{Y}^0_A)}_{\\mathbf{C}} \\\\ \\underbrace{\\bar{D}_A\\bar{Y}^1_A}_{\\mathbf{D}} \\end{array}\\right) \\end{align*}\\] Using the fact that \\((X&#39;X)^{-1}=\\frac{1}{N_A}\\frac{\\tilde{x&#39;x}}{\\det(x&#39;x)}\\), we have: \\[\\begin{align*} \\hat{\\Theta}^{OLS} &amp; = (X&#39;X)^{-1}X&#39;Y \\\\ &amp; = \\frac{1}{\\bar{D}_Ak(1-\\pi\\bar{D}_A)} \\left(\\begin{array}{c} \\bar{D}_A(\\mathbf{A}-\\mathbf{B}-\\mathbf{C}+\\mathbf{D}) \\\\ -\\bar{D}_A\\mathbf{A}+\\frac{\\mathbf{B}}{\\pi}+\\bar{D}_A\\mathbf{C}-\\frac{\\mathbf{D}}{\\pi} \\\\ \\bar{D}_A(-\\mathbf{A}+\\mathbf{B}+\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\mathbf{C}-\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\mathbf{D})\\\\ \\bar{D}_A\\mathbf{A}-\\frac{\\mathbf{B}}{\\pi}-\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\bar{D}_A\\mathbf{C}+(k\\frac{1-\\pi\\bar{D}_A}{1-\\bar{D}_A}+\\frac{1}{\\pi})\\mathbf{D} \\end{array}\\right) \\end{align*}\\] Let’s take each term in turn: \\[\\begin{align*} \\hat{\\alpha}^{OLS} &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)} \\left(k\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}_A(k\\pi(\\bar{Y}^1_B-\\bar{Y}^0_B)+\\bar{Y}^1_A-\\bar{Y}^0_A) - \\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)\\right.\\\\ &amp; \\phantom{\\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(\\right.} \\left. - \\bar{Y}^0_A-\\bar{D}_A(\\bar{Y}^1_A-\\bar{Y}^0_A)+\\bar{D}_A\\bar{Y}^1_A\\right)\\\\ &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)} \\left(\\bar{Y}^0_B(k-k\\pi\\bar{D}_A)+ \\bar{Y}^0_A(1-\\bar{D}_A-1+\\bar{D}_A)+ \\bar{Y}^1_B(k\\pi\\bar{D}_A-k\\pi\\bar{D}_A)+ \\right.\\\\ &amp; \\phantom{\\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(\\right.}\\left. \\bar{Y}^1_A(\\bar{D}_A-\\bar{D}_A-\\bar{D}_A+\\bar{D}_A)\\right) \\\\ &amp; = \\bar{Y}^0_Bk\\frac{1-\\pi\\bar{D}_A}{k(1-\\pi\\bar{D}_A)}\\\\ &amp; = \\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\mu}^{OLS} &amp; = \\frac{1}{k\\bar{D}_A(1-\\pi\\bar{D}_A)} \\left(-\\bar{D}_A(k\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}_A(k\\pi(\\bar{Y}^1_B-\\bar{Y}^0_B)+\\bar{Y}^1_A-\\bar{Y}^0_A))\\right.\\\\ &amp; \\phantom{= \\frac{1}{k\\bar{D}_A(1-\\pi\\bar{D}_A)}} \\left.+\\frac{\\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)}{\\pi}+\\bar{D}_A(\\bar{Y}^0_A+\\bar{D}_A(\\bar{Y}^1_A-\\bar{Y}^0_A))-\\frac{\\bar{D}_A\\bar{Y}^1_A}{\\pi}\\right)\\\\ &amp; = \\frac{1}{k\\bar{D}_A(1-\\pi\\bar{D}_A)} \\left(-\\bar{D}_Ak\\bar{Y}^0_B(1-\\pi\\bar{D}_A)-\\bar{Y}^0_A\\bar{D}_A(1-\\bar{D}_A-1+\\bar{D}_A)\\right.\\\\ &amp; \\phantom{= \\frac{1}{k\\bar{D}_A(1-\\pi\\bar{D}_A)}} \\left.+\\bar{D}_Ak\\bar{Y}^1_B(1-\\pi\\bar{D}_A)+\\bar{Y}^1_A(-\\bar{D}_A^2+\\frac{\\bar{D}_A}{\\pi}+\\bar{D}_A^2-\\frac{\\bar{D}_A}{\\pi})\\right) \\\\ &amp; = \\frac{k\\bar{D}_A(1-\\pi\\bar{D}_A)}{k\\bar{D}_A(1-\\pi\\bar{D}_A)}(\\bar{Y}^1_B-\\bar{Y}^0_B)\\\\ &amp; = \\bar{Y}^1_B-\\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\delta}^{OLS} &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(-(k\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}_A(k\\pi(\\bar{Y}^1_B-\\bar{Y}^0_B)+\\bar{Y}^1_A-\\bar{Y}^0_A))\\right. \\\\ &amp; \\phantom{=\\frac{1}{k(1-\\pi\\bar{D}_A)}}+\\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)+\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}(\\bar{Y}^0_A+\\bar{D}_A(\\bar{Y}^1_A-\\bar{Y}^0_A))\\\\ &amp; \\phantom{=\\frac{1}{k(1-\\pi\\bar{D}_A)}}\\left.-\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\bar{D}_A\\bar{Y}^1_A\\right) \\\\ &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(-\\bar{Y}^0_Bk(1-\\pi\\bar{D}_A)-\\bar{Y}^0_A(1-\\bar{D}_A-(k+1-\\bar{D}_A(k\\pi+1)))\\right.\\\\ &amp; \\phantom{=\\frac{1}{k(1-\\pi\\bar{D}_A)}}\\left.+\\bar{Y}^1_B(-k\\pi\\bar{D}_A+k\\pi\\bar{D}_A)+\\bar{Y}^1_A(-\\bar{D}_A+\\bar{D}_A+\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}(\\bar{D}_A-\\bar{D}_A))\\right)\\\\ &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(-\\bar{Y}^0_Bk(1-\\pi\\bar{D}_A)+\\bar{Y}^0_Ak(1-\\pi\\bar{D}_A)\\right)\\\\ &amp; = \\bar{Y}^0_A-\\bar{Y}^0_B \\end{align*}\\] \\[\\begin{align*} \\hat{\\beta}^{OLS} &amp; =\\frac{1}{\\bar{D}_Ak(1-\\pi\\bar{D}_A)}\\left(\\bar{D}_A(k\\bar{Y}^0_B+\\bar{Y}^0_A+\\bar{D}_A(k\\pi(\\bar{Y}^1_B-\\bar{Y}^0_B)+\\bar{Y}^1_A-\\bar{Y}^0_A))-\\frac{\\bar{D}_A(k\\pi\\bar{Y}^1_B+\\bar{Y}^1_A)}{\\pi}\\right.\\\\ &amp; \\phantom{ =\\frac{1}{\\bar{D}_Ak(1-\\pi\\bar{D}_A)}}\\left.-\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\bar{D}_A(\\bar{Y}^0_A+\\bar{D}_A(\\bar{Y}^1_A-\\bar{Y}^0_A))+(k\\frac{1-\\pi\\bar{D}_A}{1-\\bar{D}_A}+\\frac{1}{\\pi})\\bar{D}_A\\bar{Y}^1_A\\right) \\\\ &amp; = \\frac{1}{\\bar{D}_Ak(1-\\pi\\bar{D}_A)}\\left(\\bar{Y}^0_B\\bar{D}_Ak(1-\\pi\\bar{D}_A)+\\bar{Y}^0_A\\bar{D}_A(1-\\bar{D}_A-(k+1-\\bar{D}_A(k\\pi+1)))-\\bar{Y}^1_B\\bar{D}_Ak(1-\\pi\\bar{D}_A)\\right.\\\\ &amp; \\phantom{= \\frac{1}{\\bar{D}_Ak(1-\\pi\\bar{D}_A)}}\\left.+\\bar{Y}^1_A\\bar{D}_A(\\bar{D}_A-\\frac{1}{\\pi}-\\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}+k\\frac{1-\\pi\\bar{D}_A}{1-\\bar{D}_A}+\\frac{1}{\\pi})\\right)\\\\ &amp; = \\frac{1}{k(1-\\pi\\bar{D}_A)}\\left(-k(1-\\pi\\bar{D}_A)(\\bar{Y}^1_B-\\bar{Y}^0_B)-k(1-\\pi\\bar{D}_A)\\bar{Y}^0_A+ k(1-\\pi\\bar{D}_A)\\bar{Y}^1_A\\right)\\\\ &amp; = \\bar{Y}^1_A-\\bar{Y}^0_A-(\\bar{Y}^1_B-\\bar{Y}^0_B). \\end{align*}\\] So it is confirmed that OLS estimation of the DID model in repeated cross sections of different sizes estimates the same parameters than in panel data. Thanks to the Law of Large Numbers, we know that: \\[\\begin{align*} \\text{plim}\\hat\\Theta^{OLS} &amp; =\\left(\\begin{array}{c} \\esp{Y^0_{i,B}|D_i=0}\\\\ \\esp{Y^0_{i,B}|D_i=1}-\\esp{Y^0_{i,B}|D_i=1}\\\\ \\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0}\\\\ \\esp{Y^1_{i,A}-Y^0_{i,B}|D_i=1}-\\esp{Y^0_{i,A}-Y^0_{i,B}|D_i=0} \\end{array}\\right), \\end{align*}\\] where the \\(\\text{plim}\\) is taken over \\(N=N_A+N_B\\). In order to study more easily the DID model as estimated by OLS, we are going to rewrite it as a pure cross sectional model: \\[\\begin{align*} Y_j &amp; = \\alpha + \\mu D_j + \\delta T_j + \\beta D_jT_j + \\epsilon_j, \\end{align*}\\] where \\(j=i\\) when \\(t=B\\) and \\(j=N_B+i\\) when \\(t=A\\), \\(D_j=D_i^t\\), \\(T_j=T_{i,t}\\) and \\(Y_j=Y_{i,t}\\). In that case, we are assuming that \\(T_i\\) is a random variable, whereas in real life, the sample is stratified with respect to \\(T_i\\). We will treat this case in the stratification section. For now, assuming that time is sampled as a usual random variable is a useful simplification. From what we have proven above, we know that: \\[\\begin{align*} \\epsilon_{j} &amp; = Y_{j}-\\left(\\esp{Y^0_{j}|D_j=0,T_j=0}+D_j(\\esp{Y^0_{j}|D_j=1,T_j=0}-\\esp{Y^0_{j}|D_j=0,T_j=0})\\right.\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.}+T_j(\\esp{Y^0_{j}|D_j=0,T_j=1}-\\esp{Y^0_{j}|D_j=0,T_j=0})\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.}+D_jT_j(\\esp{Y^1_{j}|D_j=1,T_j=1}-\\esp{Y^0_{j}|D_j=1,T_j=0}\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.+D_jT_j}\\left.-(\\esp{Y^0_{j}|D_j=0,T_j=1}-\\esp{Y^0_{j}|D_j=0,T_j=0}))\\right) \\end{align*}\\] With this notation, and \\(N=N_A+N_B\\), we have: \\[\\begin{align*} \\frac{\\sqrt{N}}{N}X&#39;\\epsilon &amp; =\\sqrt{N}\\left(\\begin{array}{c} \\frac{1}{N}\\sum_{i=1}^N\\epsilon_{j} \\\\ \\frac{1}{N}\\sum_{i=1}^ND_j\\epsilon_{j} \\\\ \\frac{1}{N}\\sum_{i=1}^NT_j\\epsilon_{j} \\\\ \\frac{1}{N}\\sum_{i=1}^ND_jT_j\\epsilon_{j} \\end{array}\\right). \\end{align*}\\] In order to be able to use the vector CLT in order to study the distribution of these quantities, we need first to compute the expectation of these variables. Let us first start with \\(\\esp{D_jT_j\\epsilon_{j}}\\): \\[\\begin{align*} \\esp{D_jT_j\\epsilon_{j}} &amp; =\\esp{\\epsilon_{j}|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1)\\\\ &amp; = 0, \\end{align*}\\] where the first equality follows from Bayes’ Law and the second equality from the definition of \\(\\epsilon_{j}\\). Using the same reasoning, we have: \\[\\begin{align*} \\esp{D_j\\epsilon_{j}} &amp; =\\esp{\\epsilon_{j}|D_j=1,T_j=1}\\Pr(T_j=1|D_j=1)+\\esp{\\epsilon_{j}|D_j=1,T_j=0}\\Pr(T_j=0|D_j=1)\\\\ &amp; = 0\\\\ \\esp{T_j\\epsilon_{j}} &amp; =\\esp{\\epsilon_{j}|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)+\\esp{\\epsilon_{j}|D_j=0,T_j=1}\\Pr(D_j=0|T_j=1)\\\\ &amp; = 0\\\\ \\esp{\\epsilon_{j}} &amp; =\\esp{\\epsilon_{j}|T_j=1}\\Pr(T_j=1)+\\esp{\\epsilon_{j}|T_j=0}\\Pr(T_j=0)\\\\ &amp; = (\\esp{\\epsilon_{j}|T_j=0,D_j=1}\\Pr(D_j=1|T_j=0)+\\esp{\\epsilon_{j}|T_j=0,D_j=0}\\Pr(D_j=0|T_j=0))\\Pr(T_j=0)\\\\ &amp; = 0. \\end{align*}\\] Using the vector version of the CLT that we have already invoked in the proof of Lemma A.4, we have that \\(\\sqrt{N}\\frac{X&#39;\\epsilon}{N}\\sim\\mathcal{N}((0,0,0,0),\\mathbf{V_{x\\epsilon}})\\) with: \\[\\begin{align*} \\mathbf{V_{x\\epsilon}} &amp; = \\esp{\\left(\\begin{array}{c} \\epsilon_i \\\\ \\epsilon_iD_i \\\\ \\epsilon_iT_i \\\\ \\epsilon_iD_iT_i \\end{array}\\right) \\left(\\begin{array}{cccc} \\epsilon_i &amp; \\epsilon_iD_i &amp; \\epsilon_iT_i &amp; \\epsilon_iD_iT_i \\end{array}\\right)} - \\esp{\\left(\\begin{array}{c} \\epsilon_i \\\\ \\epsilon_iD_i \\\\ \\epsilon_iT_i \\\\ \\epsilon_iD_iT_i \\end{array}\\right)} \\esp{\\left(\\begin{array}{cccc} \\epsilon_i &amp; \\epsilon_iD_i &amp; \\epsilon_iT_i &amp; \\epsilon_iD_iT_i \\end{array}\\right)}\\\\ &amp; = \\esp{\\epsilon_i^2\\left(\\begin{array}{cccc} 1 &amp; D_i &amp; T_i &amp; D_iT_i \\\\ D_i &amp; D_i &amp; D_iT_i &amp; D_iT_i \\\\ T_i &amp; D_iT_i &amp; T_i &amp; D_iT_i \\\\ D_iT_i &amp; D_iT_i &amp; D_iT_i &amp; D_iT_i \\end{array}\\right)}, \\end{align*}\\] where we made use of the fact that \\(T_i^2=T_i\\) and \\(D_i^2=D_i\\). Before we can use the Delta Method to derive the distribution of the OLS DID estimator, we need to compute \\(\\text{plim}N(X&#39;X)-1\\) as a function of \\(N\\) and not \\(N_A\\), as we did before. In order to obtain that without redoing the matrix inversion all over again (which is pretty awful without the trick of factoring \\(N_A\\)), we are going to use the fact that the proportion of observations belonging to period \\(A\\) is equal to \\(\\bar{T}_A=\\frac{N_A}{N}=\\sum_{j=1}^NT_j\\), and the proportion of observations belonging to period \\(B\\) is equal to \\(1-\\bar{T}_A\\). We also have that \\(k=\\frac{N_B}{N_A}=\\frac{(1-\\bar{T}_A)N}{\\bar{T}_AN}=\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\). Finally, note that \\(\\pi=\\frac{\\bar{D}_B}{\\bar{D}_A}\\). As a consequence of that and of our previous computations, we have that: \\[\\begin{align*} (X&#39;X)^{-1} &amp; = \\frac{1}{N_A}\\frac{1}{k\\bar{D}_A(1-\\pi\\bar{D}_A)} \\left(\\begin{array}{cccc} \\bar{D}_A &amp; -\\bar{D}_A &amp; -\\bar{D}_A &amp; \\bar{D}_A\\\\ -\\bar{D}_A &amp; \\frac{1}{\\pi} &amp; \\bar{D}_A &amp; -\\frac{1}{\\pi} \\\\ -\\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A} &amp; -\\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A}\\\\ \\bar{D}_A &amp; -\\frac{1}{\\pi} &amp; -\\bar{D}_A\\frac{k+1-\\bar{D}_A(k\\pi+1)}{1-\\bar{D}_A} &amp; k\\frac{1-\\pi\\bar{D}_A}{1-\\bar{D}_A}+\\frac{1}{\\pi} \\end{array}\\right) \\\\ &amp; = \\frac{1}{N\\bar{T}_A}\\frac{1}{\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\bar{D}_A(1-\\frac{\\bar{D}_B}{\\bar{D}_A}\\bar{D}_A)}\\\\ &amp; \\phantom{=} \\left(\\begin{array}{cccc} \\bar{D}_A &amp; -\\bar{D}_A &amp; -\\bar{D}_A &amp; \\bar{D}_A\\\\ -\\bar{D}_A &amp; \\frac{\\bar{D}_A}{\\bar{D}_B} &amp; \\bar{D}_A &amp; -\\frac{\\bar{D}_A}{\\bar{D}_B} \\\\ -\\bar{D}_A &amp; \\bar{D}_A &amp; \\bar{D}_A\\frac{\\frac{1-\\bar{T}_A}{\\bar{T}_A}+1-\\bar{D}_A(\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{\\bar{D}_B}{\\bar{D}_A}+1)}{1-\\bar{D}_A} &amp; -\\bar{D}_A\\frac{\\frac{1-\\bar{T}_A}{\\bar{T}_A}+1-\\bar{D}_A(\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{\\bar{D}_B}{\\bar{D}_A}+1)}{1-\\bar{D}_A}\\\\ \\bar{D}_A &amp; -\\frac{\\bar{D}_A}{\\bar{D}_B} &amp; -\\bar{D}_A\\frac{\\frac{1-\\bar{T}_A}{\\bar{T}_A}+1-\\bar{D}_A(\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{\\bar{D}_B}{\\bar{D}_A}+1)}{1-\\bar{D}_A} &amp; \\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{1-\\frac{\\bar{D}_B}{\\bar{D}_A}\\bar{D}_A}{1-\\bar{D}_A}+\\frac{\\bar{D}_A}{\\bar{D}_B} \\end{array}\\right) \\\\ &amp; = \\frac{1}{N}\\frac{1}{(1-\\bar{T}_A)(1-\\bar{D}_B)}\\\\ &amp; \\phantom{=} \\left(\\begin{array}{cccc} 1 &amp; -1 &amp; -1 &amp; 1\\\\ -1 &amp; \\frac{1}{\\bar{D}_B} &amp; 1 &amp; -\\frac{1}{\\bar{D}_B} \\\\ -1 &amp; 1 &amp; \\frac{1-\\bar{D}_B+\\bar{T}_A(\\bar{D}_B-\\bar{D}_A)}{\\bar{T}_A(1-\\bar{D}_A)} &amp; -\\frac{1-\\bar{D}_B+\\bar{T}_A(\\bar{D}_B-\\bar{D}_A)}{\\bar{T}_A(1-\\bar{D}_A)}\\\\ 1 &amp; -\\frac{1}{\\bar{D}_B} &amp; -\\frac{1-\\bar{D}_B+\\bar{T}_A(\\bar{D}_B-\\bar{D}_A)}{\\bar{T}_A(1-\\bar{D}_A)} &amp; \\frac{1}{\\bar{D}_A}\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{1-\\bar{D}_B}{1-\\bar{D}_A}+\\frac{1}{\\bar{D}_B} \\end{array}\\right), \\end{align*}\\] because: \\[\\begin{align*} \\frac{\\frac{1-\\bar{T}_A}{\\bar{T}_A}+1-\\bar{D}_A(\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\frac{\\bar{D}_B}{\\bar{D}_A}+1)}{1-\\bar{D}_A} &amp; = \\frac{1+\\frac{1-\\bar{T}_A}{\\bar{T}_A}-\\frac{1-\\bar{T}_A}{\\bar{T}_A}\\bar{D}_B+ \\bar{D}_A}{1-\\bar{D}_A} \\\\ = &amp; \\frac{\\bar{T}_A+1-\\bar{T}_A-\\bar{D}_B+\\bar{T}_A\\bar{D}_B+ \\bar{D}_A\\bar{T}_A}{\\bar{T}_A(1-\\bar{D}_A)}\\\\ = &amp; \\frac{1-\\bar{D}_B+\\bar{T}_A(\\bar{D}_B-\\bar{D}_A)}{\\bar{T}_A(1-\\bar{D}_A)}. \\end{align*}\\] As a consequence, we have: \\[\\begin{align*} \\text{plim}N(X&#39;X)^{-1} &amp; = \\frac{1}{(1-p_A)(1-p)} \\left(\\begin{array}{cccc} 1 &amp; -1 &amp; -1 &amp; 1\\\\ -1 &amp; \\frac{1}{p} &amp; 1 &amp; -\\frac{1}{p} \\\\ -1 &amp; 1 &amp; \\frac{1}{p_A} &amp; -\\frac{1}{p_A} \\\\ 1 &amp; -\\frac{1}{p} &amp; -\\frac{1}{p_A} &amp; \\frac{1}{pp_A} \\end{array}\\right), \\end{align*}\\] using the Law of Large Numbers, Slutsky’s Theorem and the fact that \\(\\text{plim}\\bar{T}_A=p_A\\), the proportion of observations stemming from the After period, \\(\\text{plim}\\bar{D}_A=\\text{plim}\\bar{D}_B=p\\) and the fact that \\(\\frac{1}{p}\\frac{1-p_A}{p_A}+\\frac{1}{p}=\\frac{1}{pp_A}\\). Now, we can derive the asymptotic distribution of \\(\\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta)=N(X&#39;X)^{-1}\\frac{\\sqrt{N}}{N}X&#39;\\epsilon\\). Using the Delta Method, we have that \\(\\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta)\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left((0,0,0,0),\\sigma_{XX}^{-1}\\mathbf{V_{x\\epsilon}}\\sigma_{XX}^{-1}\\right)\\). So we’re in for a treat: deriving the lower diagonal term in the quadratic form \\(\\sigma_{XX}^{-1}\\mathbf{V_{x\\epsilon}}\\sigma_{XX}^{-1}\\). Let us start. We first need the four terms on the last line of \\((1-p_A)^2(1-p)^2\\sigma_{XX}^{-1}\\mathbf{V_{x\\epsilon}}=(\\mathbf{A},\\mathbf{B},\\mathbf{C},\\mathbf{D})\\) (the squared terms in the beginning are accounting for the constant terms in the matrix multiplication): \\[\\begin{align*} \\mathbf{A}&amp; = \\esp{\\epsilon_j^2} -\\frac{1}{p}\\esp{\\epsilon_j^2D_j} -\\frac{1}{p_A}\\esp{\\epsilon_j^2T_j} + \\frac{1}{pp_A}\\esp{\\epsilon_j^2D_jT_j}\\\\ &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=0}\\Pr(D_j=0|T_j=0)\\Pr(T_j=0)+\\esp{\\epsilon_j^2|D_j=1,T_j=0}\\Pr(D_j=1|T_j=0)\\Pr(T_j=0)\\\\ &amp; \\phantom{=}+\\esp{\\epsilon_j^2|D_j=0,T_j=1}\\Pr(D_j=0|T_j=1)\\Pr(T_j=1)+\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1) \\\\ &amp; \\phantom{=}-\\frac{1}{p}\\esp{\\epsilon_j^2|D_j=1}\\Pr(D_j=1) -\\frac{1}{p_A}\\esp{\\epsilon_j^2|T_j=1}\\Pr(T_j=1) \\\\ &amp; \\phantom{=}+ \\frac{1}{pp_A}\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1)\\\\ &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=0}(1-p)(1-p_A)+\\esp{\\epsilon_j^2|D_j=1,T_j=0}p(1-p_A)\\\\ &amp; \\phantom{=}+\\esp{\\epsilon_j^2|D_j=0,T_j=1}(1-p)p_A+\\esp{\\epsilon_j^2|D_j=1,T_j=1}pp_A \\\\ &amp; \\phantom{=}-\\esp{\\epsilon_j^2|D_j=1} -\\esp{\\epsilon_j^2|T_j=1} \\\\ &amp; \\phantom{=}+ \\esp{\\epsilon_j^2|D_j=1,T_j=1}\\\\ &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=0}(1-p)(1-p_A)+\\esp{\\epsilon_j^2|D_j=1,T_j=0}p(1-p_A)\\\\ &amp; \\phantom{=}+\\esp{\\epsilon_j^2|D_j=0,T_j=1}(1-p)p_A+\\esp{\\epsilon_j^2|D_j=1,T_j=1}pp_A \\\\ &amp; \\phantom{=}-\\esp{\\epsilon_j^2|D_j=1,T_j=0}(1-p_A)-\\esp{\\epsilon_j^2|D_j=1,T_j=1}p_A\\\\ &amp; \\phantom{=}-\\esp{\\epsilon_j^2|D_j=0,T_j=1}(1-p)-\\esp{\\epsilon_j^2|D_j=1,T_j=1}p \\\\ &amp; \\phantom{=}+ \\esp{\\epsilon_j^2|D_j=1,T_j=1}\\\\ &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=0}(1-p)(1-p_A)\\\\ &amp; \\phantom{=}-\\esp{\\epsilon_j^2|D_j=1,T_j=0}(1-p)(1-p_A)\\\\ &amp; \\phantom{=}-\\esp{\\epsilon_j^2|D_j=0,T_j=1}(1-p)(1-p_A)\\\\ &amp; \\phantom{=}+\\esp{\\epsilon_j^2|D_j=1,T_j=1}(1-p)(1-p_A)\\\\ &amp; = (1-p)(1-p_A)(\\sigma_{\\epsilon_{0,0}}^2-\\sigma_{\\epsilon_{1,0}}^2-\\sigma_{\\epsilon_{0,1}}^2+\\sigma_{\\epsilon_{1,1}}^2)\\\\ \\mathbf{B}&amp; = \\esp{\\epsilon_j^2D_j} -\\frac{1}{p}\\esp{\\epsilon_j^2D_j} -\\frac{1}{p_A}\\esp{\\epsilon_j^2D_jT_j} + \\frac{1}{pp_A}\\esp{\\epsilon_j^2D_jT_j}\\\\ &amp; = \\esp{\\epsilon_j^2D_j}(1-\\frac{1}{p})+\\esp{\\epsilon_j^2D_jT_j}\\frac{1}{p_A}(\\frac{1}{p}-1) \\\\ &amp; = (1-\\frac{1}{p})\\esp{\\epsilon_j^2|D_j=1}\\Pr(D_j=1)+\\frac{1}{p_A}(\\frac{1}{p}-1)\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1) \\\\ &amp; = p(1-\\frac{1}{p})\\left(\\esp{\\epsilon_j^2|D_j=1,T_j=0}\\Pr(T_j=0|D_j=1)+\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(T_j=1|D_j=1)\\right)\\\\ &amp; \\phantom{=}+\\frac{1}{p_A}(\\frac{1}{p}-1)\\sigma_{\\epsilon_{1,1}}^2pp_A\\\\ &amp; = p(1-\\frac{1}{p})\\left(\\sigma_{\\epsilon_{1,0}}^2(1-p_A)+\\sigma_{\\epsilon_{1,1}}^2p_A\\right)+\\frac{1}{p_A}(\\frac{1}{p}-1)\\sigma_{\\epsilon_{1,1}}^2pp_A\\\\ &amp; = -(1-p)\\left(\\sigma_{\\epsilon_{1,0}}^2(1-p_A)+\\sigma_{\\epsilon_{1,1}}^2p_A\\right)+(1-p)\\sigma_{\\epsilon_{1,1}}^2\\\\ &amp; = (1-p)\\left(\\sigma_{\\epsilon_{1,1}}^2-\\sigma_{\\epsilon_{1,0}}^2(1-p_A)-\\sigma_{\\epsilon_{1,1}}^2p_A\\right)\\\\ &amp; = (1-p)(1-p_A)\\left(\\sigma_{\\epsilon_{1,1}}^2-\\sigma_{\\epsilon_{1,0}}^2\\right) \\\\ \\mathbf{C}&amp; = \\esp{\\epsilon_j^2T_j} -\\frac{1}{p}\\esp{\\epsilon_j^2D_jT_j} -\\frac{1}{p_A}\\esp{\\epsilon_j^2T_j} + \\frac{1}{pp_A}\\esp{\\epsilon_j^2D_jT_j}\\\\ &amp; = \\esp{\\epsilon_j^2|T_j=1}\\Pr(T_j=1)-\\frac{1}{p}\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1)\\\\ &amp; \\phantom{=}-\\frac{1}{p_A}\\esp{\\epsilon_j^2|T_j=1}\\Pr(T_j=1)+\\frac{1}{pp_A}\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1)\\\\ &amp; = -(1-p_A)(\\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)+\\esp{\\epsilon_j^2|D_j=0,T_j=1}\\Pr(D_j=0|T_j=1))\\\\ &amp; \\phantom{=}+\\esp{\\epsilon_j^2|D_j=1,T_j=1}(1-p_A)\\\\ &amp; = (1-p_A)(\\sigma_{\\epsilon_{1,1}}^2(1-p)-(1-p)\\sigma_{\\epsilon_{0,1}}^2)\\\\ &amp; = (1-p)(1-p_A)(\\sigma_{\\epsilon_{1,1}}^2-\\sigma_{\\epsilon_{0,1}}^2)\\\\ \\mathbf{D}&amp; = \\esp{\\epsilon_j^2D_jT_j} -\\frac{1}{p}\\esp{\\epsilon_j^2D_jT_j} -\\frac{1}{p_A}\\esp{\\epsilon_j^2D_jT_j} + \\frac{1}{pp_A}\\esp{\\epsilon_j^2D_jT_j}\\\\ &amp; = \\esp{\\epsilon_j^2|D_j=1,T_j=1}\\Pr(D_j=1|T_j=1)\\Pr(T_j=1)(1-\\frac{1}{p}-\\frac{1}{p_A}+\\frac{1}{pp_A})\\\\ &amp; = \\sigma_{\\epsilon_{1,1}}^2(pp_A-p_A-p+1)\\\\ &amp; = (1-p)(1-p_A)\\sigma_{\\epsilon_{1,1}}^2 \\end{align*}\\] since \\(1-p-p_A+pp_A=(1-p)(1-p_A)\\), and where \\(\\sigma_{\\epsilon_{d,t}}^2=\\esp{\\epsilon_j^2|D_j=d,T_j=t}\\). We also make use of the fact that \\(\\Pr(D_j=d|T_j=t)=\\Pr(D_j=d)\\) and \\(\\Pr(T_j=t|D_j=d)=\\Pr(T_j=t)\\), that is that the participants and non participants are sampled exactly in the same proportion in both periods. Let us now obtain \\(\\var{\\hat{\\beta}^{OLS}}\\), the variance of the \\(\\hat{\\beta}^{OLS}\\) parameter. It is the last diagonal term of the matrix \\(\\sigma_{XX}^{-1}\\mathbf{V_{x\\epsilon}}\\sigma_{XX}^{-1}\\). We know that: \\[\\begin{align*} \\var{\\hat{\\beta}^{OLS}} &amp; = \\frac{1}{(1-p)^2(1-p_A)^2}\\left(\\mathbf{A}-\\frac{1}{p}\\mathbf{B}-\\frac{1}{p_A}\\mathbf{C}+\\frac{1}{pp_A}\\mathbf{D}\\right)\\\\ &amp; = \\frac{1}{(1-p)(1-p_A)}\\left(\\sigma_{\\epsilon_{0,0}}^2-\\sigma_{\\epsilon_{1,0}}^2-\\sigma_{\\epsilon_{0,1}}^2+\\sigma_{\\epsilon_{1,1}}^2 -\\frac{1}{p}(\\sigma_{\\epsilon_{1,1}}^2-\\sigma_{\\epsilon_{1,0}}^2) \\right.\\\\ &amp; \\phantom{= \\frac{1}{(1-p)(1-p_A)}\\left(\\right.}\\left. -\\frac{1}{p_A}(\\sigma_{\\epsilon_{1,1}}^2-\\sigma_{\\epsilon_{0,1}}^2)+ \\frac{1}{pp_A}\\sigma_{\\epsilon_{1,1}}^2\\right)\\\\ &amp; = \\frac{1}{(1-p)(1-p_A)}\\left(\\sigma_{\\epsilon_{0,0}}^2+\\sigma_{\\epsilon_{1,0}}^2(-1+\\frac{1}{p})+\\sigma_{\\epsilon_{0,1}}^2(-1+\\frac{1}{p_A})+\\sigma_{\\epsilon_{1,1}}^2(1-\\frac{1}{p}-\\frac{1}{p_A}+\\frac{1}{pp_A})\\right)\\\\ &amp; = \\frac{1}{(1-p)(1-p_A)}\\left(\\sigma_{\\epsilon_{0,0}}^2+\\sigma_{\\epsilon_{1,0}}^2\\frac{1-p}{p}+\\sigma_{\\epsilon_{0,1}}^2(\\frac{1-p_A}{p_A}+\\sigma_{\\epsilon_{1,1}}^2\\frac{pp_A-p_A-p+1}{pp_A}\\right)\\\\ &amp; = \\frac{\\sigma_{\\epsilon_{0,0}}^2}{(1-p)(1-p_A)}+\\frac{\\sigma_{\\epsilon_{1,0}}^2}{p(1-p_A)}+\\frac{\\sigma_{\\epsilon_{0,1}}^2}{(1-p)p_A}+\\frac{\\sigma_{\\epsilon_{1,1}}^2}{pp_A}, \\end{align*}\\] using again the fact that \\(1-p-p_A+pp_A=(1-p)(1-p_A)\\). Finally, using the formula for \\(\\epsilon_j\\), we have: \\[\\begin{align*} \\sigma_{\\epsilon_{0,0}}^2 &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=0} \\\\ &amp; = \\esp{(Y_j-\\esp{Y^0_j|D_j=0,T_j=0})^2|D_j=0,T_j=0}\\\\ &amp; = \\esp{(Y^0_{i,B}-\\esp{Y^0_{i,B}|D_i=0)^2}|D_i=0}\\\\ &amp; = \\var{Y^0_{i,B}|D_i=0}\\\\ \\sigma_{\\epsilon_{1,0}}^2 &amp; = \\esp{\\epsilon_j^2|D_j=1,T_j=0} \\\\ &amp; = \\esp{(Y_j-\\esp{Y^0_j|D_j=1,T_j=0})^2|D_j=1,T_j=0}\\\\ &amp; = \\esp{(Y^0_{i,B}-\\esp{Y^0_{i,B}|D_i=1)^2}|D_i=1}\\\\ &amp; = \\var{Y^0_{i,B}|D_i=1}\\\\ \\sigma_{\\epsilon_{0,1}}^2 &amp; = \\esp{\\epsilon_j^2|D_j=0,T_j=1} \\\\ &amp; = \\esp{(Y_j-\\esp{Y^0_j|D_j=0,T_j=1})^2|D_j=0,T_j=1}\\\\ &amp; = \\esp{(Y^0_{i,A}-\\esp{Y^0_{i,A}|D_i=0)^2}|D_i=0}\\\\ &amp; = \\var{Y^0_{i,A}|D_i=0}\\\\ \\sigma_{\\epsilon_{1,1}}^2 &amp; = \\esp{\\epsilon_j^2|D_j=1,T_j=1} \\\\ &amp; = \\esp{(Y_j-\\esp{Y^1_j|D_j=1,T_j=1})^2|D_j=1,T_j=1}\\\\ &amp; = \\esp{(Y^1_{i,A}-\\esp{Y^1_{i,A}|D_i=1)^2}|D_i=1}\\\\ &amp; = \\var{Y^1_{i,A}|D_i=1} \\end{align*}\\] This proves the result. A.3.3 Proof of Theorem 4.19 The proof uses saturated models as Angrist and Pischke(2009). A saturated model is a model involving only categorical variables where the model has a separate parameter for each various sets of parameter values that the covariates can take. We can check that Sun and Abraham’s model is a saturated model. Let’s start with the model in repeated cross sections (with group fixed effects). In the population, excluding the group of individuals that are always treated (adding this group would entail adding a separate dummy for each date at which they are observed, I leave that as an exercise), with \\(T=4\\) (larger time series do not change the basic result): \\[\\begin{align*} \\esp{Y_{i,1}|D_i=\\infty} &amp; = \\alpha \\\\ \\esp{Y_{i,2}|D_i=\\infty} &amp;= \\alpha+\\delta_2 \\\\ \\esp{Y_{i,3}|D_i=\\infty} &amp; = \\alpha+\\delta_3 \\\\ \\esp{Y_{i,4}|D_i=\\infty} &amp; = \\alpha+\\delta_4 \\\\ \\esp{Y_{i,1}|D_i=2} &amp; = \\alpha +\\mu_2 \\\\ \\esp{Y_{i,2}|D_i=2} &amp; = \\alpha +\\mu_2 +\\delta_2 + \\beta_{2,0}^{SA}\\\\ \\esp{Y_{i,3}|D_i=2} &amp; = \\alpha +\\mu_2 +\\delta_3 + \\beta_{2,1}^{SA} \\\\ \\esp{Y_{i,4}|D_i=2} &amp; = \\alpha +\\mu_2 +\\delta_4 + \\beta_{2,2}^{SA} \\\\ \\esp{Y_{i,1}|D_i=3} &amp; = \\alpha +\\mu_3 + \\beta_{3,-2}^{SA} \\\\ \\esp{Y_{i,2}|D_i=3} &amp; = \\alpha +\\mu_3 + \\delta_2 \\\\ \\esp{Y_{i,3}|D_i=3} &amp; = \\alpha +\\mu_3 + \\delta_3 + \\beta_{3,0}^{SA} \\\\ \\esp{Y_{i,4}|D_i=3} &amp; = \\alpha+\\mu_3 + \\delta_4 + \\beta_{3,1}^{SA} \\\\ \\esp{Y_{i,1}|D_i=4} &amp; = \\alpha +\\mu_4 +\\beta_{4,-3}^{SA} \\\\ \\esp{Y_{i,2}|D_i=4} &amp; = \\alpha +\\mu_4 + \\delta_2+\\beta_{4,-2}^{SA} \\\\ \\esp{Y_{i,3}|D_i=4} &amp; = \\alpha +\\mu_4 + \\delta_3 \\\\ \\esp{Y_{i,4}|D_i=4} &amp; = \\alpha +\\mu_4 + \\delta_4 + \\beta_{4,0}^{SA} \\end{align*}\\] The model has 16 parameters to model the 16 different combinations of the regressors. It is thus a saturated model. Let us now state the Linear Conditional Expectation Function Theorem: Theorem A.2 (Linear Conditional Expectation Function) Let \\(\\esp{Y_i|X_i}=X_i&#39;\\Theta^*\\) for a \\(K\\times 1\\) vector of coefficients \\(\\Theta^*\\). Then \\(\\Theta^*=\\esp{X_i&#39;X_i}^{-1}\\esp{X_i&#39;Y_i}=\\Theta^{OLS}\\). Theorem A.2 states that the coefficients of a model with a linear conditional expectation function can be obtained by using OLS. Applying Theorem A.2 to Sun and Abraham’s saturated model, we have that: \\[\\begin{align*} \\alpha &amp; = \\esp{Y_{i,1}|D_i=\\infty}=\\alpha^{OLS} \\\\ \\delta_2 &amp; =\\esp{Y_{i,2}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty}=\\delta_2^{OLS} \\\\ \\delta_3 &amp;= \\esp{Y_{i,3}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty}=\\delta_3^{OLS} \\\\ \\delta_4 &amp; = \\esp{Y_{i,4}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty}=\\delta_4^{OLS} \\\\ \\mu_2 &amp; = \\esp{Y_{i,1}|D_i=2}-\\esp{Y_{i,1}|D_i=\\infty} =\\mu_2^{OLS} \\\\ \\mu_3 &amp; = \\esp{Y_{i,2}|D_i=3}-\\esp{Y_{i,2}|D_i=\\infty} =\\mu_3^{OLS} \\\\ \\mu_4 &amp; = \\esp{Y_{i,3}|D_i=4}-\\esp{Y_{i,3}|D_i=\\infty} =\\mu_4^{OLS} \\\\ \\beta_{2,0}^{SA} &amp; = \\esp{Y_{i,2}|D_i=2}-\\esp{Y_{i,1}|D_i=2}-(\\esp{Y_{i,2}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty}) =\\beta_{2,0}^{OLS} \\\\ \\beta_{2,1}^{SA} &amp; = \\esp{Y_{i,3}|D_i=2}-\\esp{Y_{i,1}|D_i=2}-(\\esp{Y_{i,3}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty})=\\beta_{2,1}^{OLS} \\\\ \\beta_{2,2}^{SA} &amp; = \\esp{Y_{i,4}|D_i=2}-\\esp{Y_{i,1}|D_i=2}-(\\esp{Y_{i,4}|D_i=\\infty}-\\esp{Y_{i,1}|D_i=\\infty})=\\beta_{2,2}^{OLS} \\\\ \\beta_{3,-2}^{SA} &amp; =\\esp{Y_{i,1}|D_i=3}-\\esp{Y_{i,2}|D_i=3}-(\\esp{Y_{i,1}|D_i=\\infty}-\\esp{Y_{i,2}|D_i=\\infty})=\\beta_{3,-2}^{OLS}\\\\ \\beta_{3,0}^{SA} &amp; =\\esp{Y_{i,3}|D_i=3}-\\esp{Y_{i,2}|D_i=3}-(\\esp{Y_{i,3}|D_i=\\infty}-\\esp{Y_{i,2}|D_i=\\infty})=\\beta_{3,0}^{OLS}\\\\ \\beta_{3,1}^{SA} &amp; =\\esp{Y_{i,4}|D_i=3}-\\esp{Y_{i,2}|D_i=3}-(\\esp{Y_{i,4}|D_i=\\infty}-\\esp{Y_{i,2}|D_i=\\infty})=\\beta_{3,1}^{OLS}\\\\ \\beta_{4,-3}^{SA} &amp; =\\esp{Y_{i,1}|D_i=4}-\\esp{Y_{i,3}|D_i=4}-(\\esp{Y_{i,1}|D_i=\\infty}-\\esp{Y_{i,3}|D_i=\\infty})=\\beta_{4,-3}^{OLS}\\\\ \\beta_{4,-2}^{SA} &amp; =\\esp{Y_{i,2}|D_i=4}-\\esp{Y_{i,3}|D_i=4}-(\\esp{Y_{i,2}|D_i=\\infty}-\\esp{Y_{i,3}|D_i=\\infty})=\\beta_{4,-2}^{OLS}\\\\ \\beta_{4,0}^{SA} &amp; =\\esp{Y_{i,4}|D_i=4}-\\esp{Y_{i,3}|D_i=4}-(\\esp{Y_{i,4}|D_i=\\infty}-\\esp{Y_{i,3}|D_i=\\infty})=\\beta_{4,0}^{OLS} \\end{align*}\\] This proves that Sun and Abraham’s estimator is actually equal to the individual DID estimators \\(\\beta_{d,\\tau}^{SA}=\\Delta^{Y}_{DID}(d,\\infty,\\tau,d-1)\\) in the population, which completes the proof for the model with group fixed effects and \\(T=4\\). I leave generalizing this result to any \\(T\\) and to the panel data model with individual fixed effects as an exercise. A.3.4 Proof of Theorem 4.20 Let us start with Sun and Abraham’s model in repeated cross sections, with group fixed effects. Here is how we can write this model with four time periods: \\[\\begin{align*} Y &amp; = X\\Theta + \\epsilon \\end{align*}\\] with \\[\\begin{align*} Y &amp; =\\left(\\begin{array}{c} Y_{1,1} \\\\ \\vdots \\\\ Y_{N_1,1}\\\\ Y_{1,2} \\\\ \\vdots \\\\Y_{N_2,2}\\\\ Y_{1,3} \\\\ \\vdots \\\\ Y_{N_3,3}\\\\ Y_{1,4} \\\\ \\vdots \\\\ Y_{N_4,4} \\end{array}\\right) \\\\ X &amp; = \\left(\\begin{array}{cccccccccccccccc} 1 &amp; D^2_1 &amp; D^3_1 &amp; D^4_1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; D^3_1 &amp; 0 &amp; 0 &amp; D^4_1 &amp; 0 &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp;\\vdots &amp; \\vdots&amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; D^2_{N_1} &amp; D^3_{N_1} &amp; D^4_{N_1} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; D^3_{N_1} &amp; 0 &amp; 0 &amp; D^4_{N_1} &amp; 0 &amp; 0\\\\ 1 &amp; D^2_1 &amp; D^3_1 &amp; D^4_1 &amp; 1 &amp; 0 &amp; 0 &amp; D^2_1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; D^4_1 &amp;0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp;\\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots&amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; D^2_{N_2} &amp; D^3_{N_2} &amp; D^4_{N_2} &amp; 1 &amp; 0 &amp; 0 &amp; D^2_{N_2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;0 &amp; D^4_{N_2} &amp; 0\\\\ 1 &amp; D^2_1 &amp; D^3_1 &amp; D^4_1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; D^2_1 &amp; 0 &amp; 0 &amp; D^3_1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots&amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; D^2_{N_3} &amp; D^3_{N_3} &amp; D^4_{N_3} &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; D^2_{N_3} &amp; 0 &amp; 0 &amp; D^3_{N_3} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; D^2_1 &amp; D^3_1 &amp; D^4_1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; D^2_1 &amp; 0 &amp; 0 &amp; D^3_1 &amp; 0 &amp; 0 &amp; D^4_1\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots&amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; D^2_{N_4} &amp; D^3_{N_4} &amp; D^4_{N_4} &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; D^2_{N_4} &amp; 0 &amp; 0 &amp; D^3_{N_4} &amp; 0 &amp; 0 &amp; D^4_{N_4} \\end{array}\\right)\\\\ \\Theta &amp; =\\left(\\begin{array}{c} \\alpha \\\\ \\mu_2\\\\ \\mu_3\\\\ \\mu_4 \\\\ \\delta_2\\\\ \\delta_3\\\\ \\delta_4 \\\\ \\beta^{SA}_{2,0}\\\\ \\beta^{SA}_{2,1}\\\\ \\beta^{SA}_{2,2}\\\\ \\beta^{SA}_{3,-2}\\\\ \\beta^{SA}_{3,0}\\\\ \\beta^{SA}_{3,1}\\\\ \\beta^{SA}_{4,-3}\\\\ \\beta^{SA}_{4,-2}\\\\ \\beta^{SA}_{4,0} \\end{array}\\right)\\\\ \\epsilon &amp; =\\left(\\begin{array}{c} \\epsilon_{1,1} \\\\ \\vdots \\\\\\epsilon_{N_1,1}\\\\ \\epsilon_{1,2} \\\\ \\vdots \\\\ \\epsilon_{N_2,2}\\\\ \\epsilon_{1,3} \\\\ \\vdots \\\\ \\epsilon_{N_3,3}\\\\ \\epsilon_{1,4} \\\\ \\vdots \\\\ \\epsilon_{N_4,4} \\end{array}\\right), \\end{align*}\\] with \\(D^d_i=\\uns{D_i=d}\\) and \\(N_t\\) the number of observations at time \\(t\\). If we are in a panel, each \\(i\\) is the same across time periods. If we are in a repeated cross section, the \\(i\\) index refers to different individuals. This model is very difficult to solve by brute force, since its \\(X&#39;X\\) matrix is \\(16 \\times 16\\) and has no easy simplification on sight. Here is the \\(X&#39;X\\) for panel data (which is slightly simpler), with \\(\\bar{D^d}=\\frac{1}{N}\\sum_{i=1}^N\\uns{D_i=d}\\), and \\(N\\) the number of individuals in the panel: \\[\\begin{align*} X&#39;X &amp; = N\\left(\\begin{array}{cccccccccccccccc} T &amp; T\\bar{D^2} &amp; T\\bar{D^3} &amp; T\\bar{D^4} &amp; 1 &amp; 1 &amp; 1 &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; \\bar{D^4} &amp; \\bar{D^4} &amp; \\bar{D^4}\\\\ T\\bar{D^2} &amp; T\\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ T\\bar{D^3} &amp; 0 &amp; T\\bar{D^3} &amp; 0 &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0\\\\ T\\bar{D^4} &amp; 0 &amp; 0 &amp; T\\bar{D^4} &amp; \\bar{D^4} &amp; \\bar{D^4} &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; \\bar{D^4} &amp; \\bar{D^4}\\\\ 1 &amp; \\bar{D^2} &amp; \\bar{D^3} &amp; \\bar{D^4} &amp; 1 &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 \\\\ 1 &amp; \\bar{D^2} &amp; \\bar{D^3} &amp; \\bar{D^4} &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; \\bar{D^2} &amp; \\bar{D^3} &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; \\bar{D^4}\\\\ \\bar{D^2} &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\bar{D^2} &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ \\bar{D^2} &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; \\bar{D^2} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\bar{D^3} &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\bar{D^3} &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\bar{D^3} &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^3} &amp; 0 &amp; 0 &amp; 0 \\\\ \\bar{D^4} &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 &amp; 0 \\\\ \\bar{D^4} &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 \\\\ \\bar{D^4} &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; \\bar{D^4} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\bar{D^4} \\end{array}\\right) \\end{align*}\\] The epiphany comes when you are able to write this model with a separate constant, time and group dummies for each separate treated group for which we want to estimate the DID model for. We have 9 separate interaction parameters \\(\\beta^{SA}_{d,\\tau}\\) to estimate. We are thus going to estimate \\(9 \\times 4\\) parameters total (i.e. run 9 separate regressions with four parameters, but all at once). We thus have to write a \\(36 \\times 36\\) \\(X&#39;X\\) matrix. The key is that this matrix is going to be block diagonal, with \\(4 \\times 4\\) blocks that are identical to the blocks of the \\(X&#39;X\\) matrix in the case of a simple OLS DID estimator with two time periods. Also, the parameters that are redundant in this model (i.e. that appear several times at different places) will be estimated in exactly the same way, which shows that the two formulations of the model (\\(16 \\times 16\\) and \\(36 \\times 36\\)) are equivalent and estimate the exact same set of 16 parameters. In order to see how this works (and to prove the result), let’s write the model for \\(\\beta^{SA}_{2,0}\\). To be able to do that, we are going to order all the observations in each time period by the opposite of the treatment group to which they belong. We also denote \\(N_t^{d}\\) the number of observations of group \\(D_i=d\\) in period \\(t\\), \\(D^d_{i,t}=\\uns{D_i=d}\\) and \\(T^{d+\\tau}_{i,t}=\\uns{d+\\tau=t}\\). With these notations, we have: \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,1} \\\\ \\vdots \\\\ Y_{N_1^{\\infty},1} \\\\Y_{N_1^{\\infty}+1,1} \\\\ \\vdots \\\\ Y_{N_1^{\\infty}+N_1^{2},1} \\\\ Y_{1,2} \\\\ \\vdots \\\\ Y_{N_2^{\\infty},2} \\\\Y_{N_2^{\\infty}+1,2} \\\\ \\vdots \\\\ Y_{N_2^{\\infty}+N_2^{2},2} \\end{array}\\right)}_{Y_{2,0}} &amp; = \\underbrace{\\left(\\begin{array}{cccc} 1 &amp; D^2_{1,1} &amp; T^2_{1,1} &amp; D^2_{1,1}T^2_{1,1}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^2_{N_1^{\\infty},1} &amp; T^2_{N_1^{\\infty},1} &amp; D^2_{N_1^{\\infty},1}T^2_{N_1^{\\infty},1} \\\\ 1 &amp; D^2_{N_1^{\\infty}+1,1} &amp; T^2_{N_1^{\\infty}+1,1} &amp; D^2_{N_1^{\\infty}+1,1}T^2_{N_1^{\\infty}+1,1} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^2_{N_1^{\\infty}+N_1^{2},1} &amp; T^2_{N_1^{\\infty}+N_1^{2},1} &amp; D^2_{N_1^{\\infty}+N_1^{2},1}T^2_{N_1^{\\infty}+N_1^{2},1} \\\\ 1 &amp; D^2_{1,2} &amp; T^2_{1,2} &amp; D^2_{1,2}T^2_{1,2}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^2_{N_1^{\\infty},2} &amp; T^2_{N_1^{\\infty},2} &amp; D^2_{N_1^{\\infty},2}T^2_{N_1^{\\infty},2} \\\\ 1 &amp; D^2_{N_1^{\\infty}+1,2} &amp; T^2_{N_1^{\\infty}+1,2} &amp; D^2_{N_1^{\\infty}+1,2}T^2_{N_1^{\\infty}+1,2} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ 1 &amp; D^2_{N_1^{\\infty}+N_1^{2},2} &amp; T^2_{N_1^{\\infty}+N_1^{2},2} &amp; D^2_{N_1^{\\infty}+N_1^{2},2}T^2_{N_1^{\\infty}+N_1^{2},2} \\end{array}\\right)}_{X_{2,0}} \\underbrace{\\left(\\begin{array}{c} \\tilde\\alpha_{2,0} \\\\ \\tilde\\mu_{2,0} \\\\ \\tilde\\delta_{2,0} \\\\ \\beta^{SA}_{2,0} \\end{array}\\right)}_{\\Theta_{2,0}} + \\underbrace{\\left(\\begin{array}{c} \\epsilon_{1,1} \\\\ \\vdots \\\\ \\epsilon_{N_1^{\\infty},1} \\\\\\epsilon_{N_1^{\\infty}+1,1} \\\\ \\vdots \\\\ \\epsilon_{N_1^{\\infty}+N_1^{2},1} \\\\ \\epsilon_{1,2} \\\\ \\vdots \\\\ \\epsilon_{N_2^{\\infty},2} \\\\\\epsilon_{N_2^{\\infty}+1,2} \\\\ \\vdots \\\\ \\epsilon_{N_2^{\\infty}+N_2^{2},2} \\end{array}\\right)}_{\\epsilon_{2,0}} \\end{align*}\\] Now, we can write 9 such models, one for each \\(\\beta^{SA}_{d,\\tau}\\). If we stack the \\(Y_{d,\\tau}\\) on top of each other, starting with \\(d=2\\) and \\(\\tau=0\\), and we stack in the same way the \\(\\Theta_{d,\\tau}\\) vectors, and, finally, we regroup all the \\(X_{d,\\tau}\\) matrices in a block diagonal matrix, we have a new model \\(\\tilde{Y} = \\tilde{X}\\tilde{\\Theta} + \\tilde{\\epsilon}\\). The stacked model has \\(4 \\times 9=36\\) parameters while the original model has 16 parameters. For the two models to be identical, it has to be that there exists \\(36-16=20\\) direct restrictions on the parameters of the stacked model. Using the fact that some parts of the data set are duplicated in teh stack model, we can determine the link between the parameters in the stacked model and the ones in the original model. For example, we know that \\(Y_{1,1}=\\tilde{\\alpha}_{2,0}+\\epsilon_{1,1}=\\tilde{\\alpha}_{2,1}+\\epsilon_{1,1}=\\tilde{\\alpha}_{2,2}+\\epsilon_{1,1}=\\alpha+\\epsilon_{1,1}\\). As a consequence, we have \\(\\tilde{\\alpha}_{2,0}=\\tilde{\\alpha}_{2,1}=\\tilde{\\alpha}_{2,2}=\\alpha\\). Using similar sets of restrictions, we can also show that: \\(\\tilde\\delta_{2,0}=\\delta_2\\), \\(\\tilde\\delta_{2,1}=\\delta_3\\) and \\(\\tilde\\delta_{2,2}=\\delta_4\\); \\(\\tilde{\\mu}_{d,\\tau}=\\mu_d\\), \\(\\forall d,\\tau\\); \\(\\tilde{\\alpha}_{3,-2}=\\tilde{\\alpha}_{3,0}=\\tilde{\\alpha}_{3,1}=\\alpha+\\delta_2\\); \\(\\tilde{\\alpha}_{4,-3}=\\tilde{\\alpha}_{4,-2}=\\tilde{\\alpha}_{4,0}=\\alpha+\\delta_3\\); \\(\\tilde\\delta_{3,-2}=-\\delta_2\\); \\(\\tilde\\delta_{3,0}=\\delta_3-\\delta_2\\); \\(\\tilde\\delta_{3,1}=\\delta_4-\\delta_2\\); \\(\\tilde\\delta_{4,-3}=-\\delta_3\\); \\(\\tilde\\delta_{4,-2}=\\delta_2-\\delta_3\\); \\(\\tilde\\delta_{4,0}=\\delta_4-\\delta_3\\). We have thus shown that every single parameter in the stacked model can be derived from the parameters in the original model. What is left to check now is that the estimation of the stacked model by OLS abides by the constraints implied by these equalities. In order to complete the proof, we make use of the fact that the inverse of a block diagonal matrix is the blog diagonal matrix of the inverses of each block. Using the proof of Theorem 4.12 (especially the beginning of the proof, which derives the OLS DID estimator in repeated cross sections of different sizes), we can now show that: \\[\\begin{align*} \\hat{\\tilde{\\alpha}}^{OLS}_{d,\\tau} &amp; = \\bar{Y}^{\\infty}_{d-1}\\\\ \\hat{\\tilde{\\mu}}^{OLS}_{d,\\tau} &amp; = \\bar{Y}^{d}_{d-1}-\\bar{Y}^{\\infty}_{d-1}\\\\ \\hat{\\tilde{\\delta}}^{OLS}_{d,\\tau} &amp; = \\bar{Y}^{\\infty}_{d+\\tau}-\\bar{Y}^{\\infty}_{d-1}\\\\ \\hat{\\beta}^{SA}_{d,\\tau} &amp; = \\bar{Y}^{d}_{d+\\tau}-\\bar{Y}^{d}_{d-1}-(\\bar{Y}^{\\infty}_{d+\\tau}-\\bar{Y}^{\\infty}_{d-1}). \\end{align*}\\] These results show that all the constraints on the parameters of the stacked model are verified (I leave this as an exercise). The last equality proves the result for the OLS DID model in repeated cross sections. The proof for panel data follows exactly the same lines. Let us now turn to the First Difference estimator in panel data. The First Difference transformation of Sun and Abraham model which uses \\(d-1\\) as the benchmark period can be written as follows (for \\(\\tau\\neq-1\\)): \\[\\begin{align*} Y_{i,d+\\tau} - Y_{i,d-1} &amp; = \\alpha_{d,\\tau}^{FD} + \\beta_{d,\\tau}^{FD}\\uns{D_i=d} + \\epsilon^{FD}_{i,d+\\tau}, \\end{align*}\\] with: \\[\\begin{align*} \\alpha_{d,\\tau}^{FD} &amp; = \\delta_{d+\\tau} - \\delta_{d-1}\\\\ \\beta_{d,\\tau}^{FD} &amp; = \\beta_{d,\\tau}^{SA}\\\\ \\epsilon^{FD}_{i,d+\\tau} &amp; = \\epsilon^{SA}_{i,d+\\tau}-\\epsilon^{FD}_{i,d-1}. \\end{align*}\\] Using the same trick as for the model in repeated cross sections, we can rewrite this model as stacked model with a block diagonal matrix of covariates. Here is the block corresponding to the estimation of \\(\\beta^{SA}_{2,0}\\): \\[\\begin{align*} \\underbrace{\\left(\\begin{array}{c} Y_{1,2}-Y_{1,1} \\\\ \\vdots \\\\ Y_{N^{\\infty},2}- Y_{N^{\\infty},1} \\\\Y_{N^{\\infty}+1,2}-Y_{N^{\\infty}+1,1} \\\\ \\vdots \\\\ Y_{N^{\\infty}+N^{2},2} -Y_{N^{\\infty}+N^{2},1} \\end{array}\\right)}_{\\Delta Y_{2,0}} &amp; = \\underbrace{\\left(\\begin{array}{cccc} 1 &amp; 0 \\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; 0 \\\\ 1 &amp; 1 \\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; 1 \\end{array}\\right)}_{\\Delta X_{2,0}} \\underbrace{\\left(\\begin{array}{c} \\alpha^{FD}_{2,0} \\\\ \\beta^{FD}_{2,0} \\end{array}\\right)}_{\\Theta^{FD}_{2,0}} + \\underbrace{\\left(\\begin{array}{c} \\epsilon^{FD}_{1,2} \\\\ \\vdots \\\\ \\epsilon^{FD}_{N^{\\infty},2} \\\\\\epsilon^{FD}_{N^{\\infty}+1,2} \\\\ \\vdots \\\\ \\epsilon^{FD}_{N^{\\infty}+N^{2},2} \\end{array}\\right)}_{\\epsilon^{FD}_{2,0}} \\end{align*}\\] Stacking all the vectors of outcomes, the vector of coefficients and the vector of residuals on top of each other, and organizing the matrices of covariates in a block diagonal matrix, we obtain the stacked Sun and Abraham model in first differences: \\(\\Delta Y = \\Delta X\\Theta^{FD} + \\epsilon^{FD}\\). Using the fact that the inverse of a block diagonal matrix is the blog diagonal matrix of the inverses of each block and the proof of Lemma A.3, we can show that \\(\\hat\\beta^{FD}_{d,\\tau}\\) is the with/without estimator applied to \\(Y_{i,d+\\tau} - Y_{i,d-1}\\). The result follows. Let us now study the Within estimator of Sun and Abraham model in panel data. The within mean of Sun and Abraham model depends on the group the observation belongs to. For \\(i\\) such that \\(D_i=d\\), we have: \\[\\begin{align*} \\underbrace{\\frac{1}{T}\\sum_{t=1}^TY_{i,t}}_{\\bar{Y}_{i,.}} = \\underbrace{\\frac{1}{T}\\sum_{t=1}^T\\delta_{t}}_{\\bar{\\delta}}+ \\underbrace{\\frac{1}{T}\\sum_{\\tau\\neq-1}^T\\beta_{d,\\tau}^{SA}}_{\\bar{\\beta}_d} \\uns{D_i=d}+\\underbrace{\\frac{1}{T}\\sum_{t=1}^T\\epsilon_{i,t}}_{\\bar{\\epsilon}_{i,.}}. \\end{align*}\\] As a consequence, for \\(i\\) such that \\(D_i=d\\) or \\(D_i=\\infty\\), we can write the within transformation of Sun and Abraham model as follows: \\[\\begin{align*} Y_{i,d+\\tau}-\\bar{Y}_{i,.} &amp; = \\underbrace{\\delta_{d-1}-\\bar{\\delta}}_{\\alpha_d^{FE}}+\\underbrace{(\\delta_{d+\\tau}-\\delta_{d-1})}_{\\delta_{d+\\tau}^{FE}}\\uns{T_i=d+\\tau}\\underbrace{-\\bar{\\beta}_d}_{\\mu_d^{FE}}\\uns{D_i=d} +\\beta_{d,\\tau}^{SA}\\uns{D_i=d}\\uns{T_i=d+\\tau}+\\epsilon_{i,t}-\\bar{\\epsilon}_{i,.}. \\end{align*}\\] The within transformation of Sun and Abraham model is thus equivalent to the OLS DID model applied to the within-transformed outcomes \\(Y_{i,d+\\tau}-\\bar{Y}_{i,.}\\). Building a stacked model of the within transformed Sun and Abraham model and using the fact that the inverse of a block diagonal matrix is the blog diagonal matrix of the inverses of each block along with Theorem 4.10 proves that: \\[\\begin{align*} \\hat\\beta_{d,\\tau}^{SA} &amp; = \\frac{\\sum_{i=1}^{N}(Y_{i,d+\\tau}-\\bar{Y}_{i,.}-(Y_{i,d-1}-\\bar{Y}_{i,.}))\\uns{D_i=d}}{\\sum_{i=1}^{N}\\uns{D_i=d}} \\\\ &amp; \\phantom{=} - \\frac{\\sum_{i=1}^{N}(Y_{i,d+\\tau}-\\bar{Y}_{i,.}-(Y_{i,d-1}-\\bar{Y}_{i,.}))\\uns{D_i=\\infty}}{\\sum_{i=1}^{N}\\uns{D_i=\\infty}}\\\\ &amp; = \\frac{\\sum_{i=1}^{N}(Y_{i,d+\\tau}-Y_{i,d-1})\\uns{D_i=d}}{\\sum_{i=1}^{N}\\uns{D_i=d}} \\\\ &amp; \\phantom{=} - \\frac{\\sum_{i=1}^{N}(Y_{i,d+\\tau}-Y_{i,d-1})\\uns{D_i=\\infty}}{\\sum_{i=1}^{N}\\uns{D_i=\\infty}}, \\end{align*}\\] which proves the result. Let us finally look at the Least Squares Dummy Variables estimator. Let’s denote \\(X_{\\mu}\\) the matrix of individual dummies in the LSDV estimator. We are going to apply Theorem A.1, i.e. Frish-Waugh-Lovell Theorem, partialling out these individual dummies from the list of regressors. First, we have \\((X&#39;_{\\mu}X_{\\mu})^{-1}=\\frac{1}{T}I_N\\) where \\(I_N\\) is the identity matrix of dimension \\(N\\) and \\(T\\) is the total number of time periods in the panel. Second, we have that \\(M_{\\mu}Y=X_{\\mu}(X&#39;_{\\mu}X_{\\mu})^{-1}X&#39;_{\\mu}Y=\\left(\\dots,Y_{i,t}-\\bar{Y}_{i,.},\\dots\\right)\\). For the time fixed effects, we have \\(M_{\\mu}X_{-\\mu,T}\\) a matrix with \\(1-\\frac{1}{T}\\) where \\(T_{i,t}=1\\) and \\(-\\frac{1}{T}\\) otherwise. For the interactive treatment dummies, we have \\(M_{\\mu}X_{-\\mu,DT}\\) a matrix with \\(D^d_i(1-\\frac{1}{T})\\) where \\(D^d_i\\) appeared in the original \\(X_{-\\mu,DT}\\) matrix (the last 9 columns of the \\(X\\) matrix) and \\(-\\frac{D^d_i}{T}\\) otherwise. As a consequence of Theorem A.1, we can rewrite the LSDV model as follows: \\[\\begin{align*} Y_{i,t} - \\bar{Y}_{i,.} &amp; = \\delta_t-\\bar\\delta-\\sum_d\\bar\\beta^{SA}_d\\uns{D_i=d}+\\sum_d\\sum_{\\tau\\neq-1}\\beta^{SA}_{d,\\tau}\\uns{D_i=d}\\uns{t=d+\\tau}+\\epsilon^{LSDV}_{i,t} - \\bar{\\epsilon}^{LSDV}_{i,.}. \\end{align*}\\] This is the same formula as the one we have uncovered in the within transformation we have studied just above. Using the same approach proves the result. A.3.5 Proof of Theorem 4.24 Using the beginning of the proof of Lemma A.4, we know that: \\(\\sqrt{N}(\\hat{\\tilde\\Theta}_{OLS}-\\tilde\\Theta)=N(\\tilde{X}&#39;\\tilde{X})^{-1}\\frac{\\sqrt{N}}{N}\\tilde{X}&#39;\\tilde{\\epsilon}\\). Using Slutsky’s Theorem, we know that we can study both terms separately (see the same proof of Lemma A.4). \\(N(\\tilde{X}&#39;\\tilde{X})^{-1}\\) can be derived rather directly from the fact that Sun and Abraham model can be written as a block diagonal matrix, as shown in the proof of Theorem 4.20. The most difficult part is going to be to derive the distribution of \\(\\frac{\\sqrt{N}}{N}\\tilde{X}&#39;\\tilde{\\epsilon}\\). Let us start with \\(N(\\tilde{X}&#39;\\tilde{X})^{-1}\\). Let us define \\(N_{t,d}\\) the number of observations observed in group \\(d\\) at period \\(t\\). We also define \\(N^B_{d,\\tau}=N_{d-1,\\infty}+N_{d-1,d}\\) the number of observations used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\) that are observed in the reference (or before) period and \\(N^A_{d,\\tau}=N_{d+\\tau,\\infty}+N_{d+\\tau,d}\\) the number of observations used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\) that are observed in the after period. We also define \\(N^{SA}_{d,\\tau}=N^A_{d,\\tau}+N^B_{d,\\tau}\\), the number of observations used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\). We also define \\(\\bar{T}_A^{d,\\tau}=\\frac{N^A_{d,\\tau}}{N^{SA}_{d,\\tau}}\\), \\(k^{d,\\tau}=\\frac{N^B_{d,\\tau}}{N^{A}_{d,\\tau}}=\\frac{1-\\bar{T}_A^{d,\\tau}}{\\bar{T}_A^{d,\\tau}}\\). We let \\(\\bar{D}_A^{d,\\tau}\\) and \\(\\bar{D}_B^{d,\\tau}\\) denote the proportion of treated observations in the after and before periods used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\). We also define \\(\\bar{P}^{d,\\tau}=\\frac{N^{SA}_{d,\\tau}}{N}\\) the proportion of observations used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\). We also have: \\(\\text{plim}\\bar{P}^{d,\\tau}=p^{d,\\tau}\\), \\(\\text{plim}\\bar{D}_A^{d,\\tau}=\\text{plim}\\bar{D}_B^{d,\\tau}=p^{d,\\tau}_D\\) and \\(\\text{plim}\\bar{T}_A^{d,\\tau}=p^{d,\\tau}_A\\). \\(p^{d,\\tau}=\\Pr(D^{d,\\tau}_i=1)\\), with \\(D^{d,\\tau}_i=\\uns{(D_i=d\\lor D_i=\\infty)\\land(T_i=d-1\\lor T_i=d+\\tau)}\\) a dummy indicating that a unit in the population belongs to the set of units used to identify \\(\\beta^{SA}_{d,\\tau}\\). \\(p^{d,\\tau}_D=\\Pr(D_i=d|D^{d,\\tau}_i=1)\\) is the proportion of treated units among the set of units used to identify \\(\\beta^{SA}_{d,\\tau}\\). \\(p^{d,\\tau}_A=\\Pr(T_i=d+\\tau|D^{d,\\tau}_i=1)\\) is the proportion of units belonging to the after period among the set of units used to identify \\(\\beta^{SA}_{d,\\tau}\\). Finally, let \\((X&#39;X)^{-1}_{d,\\tau}\\) denote the block of the matrix \\((\\tilde{X}&#39;\\tilde{X})^{-1}\\) which is used to estimate \\(\\hat{\\beta}^{SA}_{d,\\tau}\\). With all these definitions, we can now follow the proof of Theorem 4.12 in order to derive the following result: \\[\\begin{align*} \\sigma_{\\tilde{X}\\tilde{X}^{-1}}^{d,\\tau} &amp;= \\text{plim}N(X&#39;X)^{-1}_{d,\\tau} = \\frac{1}{p^{d,\\tau}(1-p^{d,\\tau}_A)(1-p^{d,\\tau}_D)} \\left(\\begin{array}{cccc} 1 &amp; -1 &amp; -1 &amp; 1\\\\ -1 &amp; \\frac{1}{p^{d,\\tau}_D} &amp; 1 &amp; -\\frac{1}{p^{d,\\tau}_D} \\\\ -1 &amp; 1 &amp; \\frac{1}{p^{d,\\tau}_A} &amp; -\\frac{1}{p^{d,\\tau}_A} \\\\ 1 &amp; -\\frac{1}{p^{d,\\tau}_D} &amp; -\\frac{1}{p^{d,\\tau}_A} &amp; \\frac{1}{p^{d,\\tau}_Dp^{d,\\tau}_A} \\end{array}\\right) \\end{align*}\\] Using the fact that the inverse of a block diagonal matrix is the blog diagonal matrix of the inverses of each block, we now know \\(\\text{plim}N(\\tilde{X}&#39;\\tilde{X})^{-1}=\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\) is block diagonal matrix with blocks equal to \\(\\sigma_{\\tilde{X}\\tilde{X}^{-1}}^{d,\\tau}\\). Let us now turn to \\(\\frac{\\sqrt{N}}{N}\\tilde{X}&#39;\\tilde{\\epsilon}\\). In order to derive its distribution, we have to write Sun and Abraham model in a repeated cross section with the observations grouped by blocks corresponding to the parameters they help to estimate. This model can be written as: \\[\\begin{align*} Y_{j}D^{d,\\tau}_j &amp; = \\tilde\\alpha^{d,\\tau}D^{d,\\tau}_j + \\tilde\\mu_{d,\\tau}\\uns{D_{j}=d}D^{d,\\tau}_j + \\tilde\\delta_{d,\\tau}\\uns{T_j=d+\\tau}D^{d,\\tau}_j \\\\ &amp; \\phantom{=} + \\beta_{d,\\tau}^{SA}\\uns{D_{i}=d}\\uns{T_j=d+\\tau}D^{d,\\tau}_j + \\tilde\\epsilon_{j}D^{d,\\tau}_j, \\end{align*}\\] with: \\[\\begin{align*} \\tilde\\epsilon_{j} &amp; = Y_{j}-\\left(\\esp{Y^0_{j}|D_j=\\infty,T_j=d-1}\\right.\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.}+\\uns{D_j=d}(\\esp{Y^0_{j}|D_j=d,T_j=d-1}-\\esp{Y^0_{j}|D_j=\\infty,T_j=d-1}) &amp; \\phantom{=Y_{j}-\\left(\\right.}+\\uns{T_j=d+\\tau}(\\esp{Y^0_{j}|D_j=\\infty,T_j=d+\\tau}-\\esp{Y^0_{j}|D_j=\\infty,T_j=d-1})\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.}+\\uns{D_{j}=d}\\uns{T_j=d+\\tau}(\\esp{Y^1_{j}|D_j=d,T_j=d+\\tau}-\\esp{Y^0_{j}|D_j=d,T_j=d-1}\\\\ &amp; \\phantom{=Y_{j}-\\left(\\right.+\\uns{D_{j}=d}\\uns{T_j=d+\\tau}}\\left.-(\\esp{Y^0_{j}|D_j=\\infty,T_j=d+\\tau}-\\esp{Y^0_{j}|D_j=\\infty,T_j=d-1}))\\right). \\end{align*}\\] It is pretty straightforward to prove that \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_j}=0\\). For that, note that \\(D^{d,\\tau}_j=f(D_j,T_j)\\) so that conditioning on \\(D^{d,\\tau}_j\\) is irrelevant when also conditioning on \\((D_j,T_j)\\). Then, check that \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_j\\uns{D_{j}=d}\\uns{T_j=d+\\tau}}=0\\). The same thing holds for \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_j\\uns{T_j=d+\\tau}}=0\\) and for \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_j\\uns{D_{j}=d}}=0\\), which proves the result. It can also be shown that \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j}=0\\), with either \\(j\\neq j&#39;\\) or \\(\\tau\\neq \\tau&#39;\\) or both. If it is the case that \\(D^{d,\\tau}_j\\Ind D^{d&#39;,\\tau&#39;}_j\\), then the term is zero. If \\(D^{d,\\tau}_j\\) and \\(D^{d&#39;,\\tau&#39;}_j\\) are not independent, by definition of \\(D^{d,\\tau}_j\\), \\(\\esp{\\tilde\\epsilon_{j}D^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j}\\) can only involve the following terms: \\(\\esp{\\tilde\\epsilon_{j}|D_j=d,T_j=d+\\tau}\\), \\(\\esp{\\tilde\\epsilon_{j}|D_j=d,T_j=d-1}\\), \\(\\esp{\\tilde\\epsilon_{j}|D_j=\\infty,T_j=d+\\tau}\\) and \\(\\esp{\\tilde\\epsilon_{j}|D_j=\\infty,T_j=d-1}\\), and all of these terms are equal to zero. Using the vector version of the Central Limit Theorem that we have already used in the proof of Theorem 4.12, we thus have that \\(\\frac{\\sqrt{N}}{N}\\tilde{X}&#39;\\tilde{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}})\\). Using the Delta Method, we have that \\(\\sqrt{N}(\\hat{\\Theta}_{OLS}-\\Theta)\\stackrel{d}{\\rightarrow}\\mathcal{N}\\left(\\mathbf{0},\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\right)\\). In order to prove the result, we simply need to derive the fourth term on the diagonal of each \\(4\\times 4\\) block of \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\). Since \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\) is block diagonal, the \\(4\\times 4\\) blocks of \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\) are equal to \\(\\sigma_{\\tilde{X}\\tilde{X}^{-1}}^{d,\\tau}\\mathbf{V}^{d,\\tau}_{\\mathbf{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}^{-1}}^{d,\\tau}\\), with (following the proof of Theorem 4.12): \\[\\begin{align*} \\mathbf{V}^{d,\\tau}_{\\mathbf{\\tilde{x}\\tilde{\\epsilon}}} &amp; = \\esp{\\epsilon_j^2D^{d,\\tau}_j\\left(\\begin{array}{cccc} 1 &amp; D^d_j &amp; T^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j \\\\ D^d_j &amp; D^d_j &amp; D^d_jT^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j \\\\ T^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j &amp; T^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j \\\\ D^d_jT^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j &amp; D^d_jT^{d,\\tau}_j \\end{array}\\right)}, \\end{align*}\\] with \\(D^d_j=\\uns{D_{j}=d}\\) and \\(T_j^{d,\\tau}=\\uns{T_j=d+\\tau}D^{d,\\tau}_j\\). Following the proof of Theorem 4.12 proves the result. A.3.6 Proof of Theorem 4.26 The key to the proof relies on the covariance terms. The covariance terms come from the off-\\(4\\times 4\\)-block-diagonal elements of the \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\) matrix. They are due to the fact that the same data are used repeatedly to estimate the \\(\\beta^{SA}_{d,\\tau}\\) parameters. For example, the observations from the never treated group are used as benchmarks for the estimation of \\(\\beta^{SA}_{2,0}\\), \\(\\beta^{SA}_{2,1}\\) and \\(\\beta^{SA}_{2,2}\\). The same observations are used as post-treatment observations for the estimation of \\(\\beta^{SA}_{2,0}\\), \\(\\beta^{SA}_{3,-2}\\) and \\(\\beta^{SA}_{4,-3}\\). In order to rigorously derive these covariance terms, we need to derive the off-\\(4\\times 4\\)-block-diagonal elements of the \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\) matrix in the proof of Theorem 4.24. For two sets of observations used to estimate \\(\\beta^{SA}_{d,\\tau}\\) and \\(\\beta^{SA}_{d&#39;,\\tau&#39;}\\), \\(d\\neq d&#39;\\) or \\(\\tau\\neq\\tau&#39;\\), we only need the last line of the off-\\(4\\times 4\\)-block-diagonal covariance matrix of \\(\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\mathbf{V_{\\tilde{x}\\tilde{\\epsilon}}}\\sigma_{\\tilde{X}\\tilde{X}}^{-1}\\). Indeed, using results in the proof of Theorem 4.24, we can show that: \\[\\begin{align*} \\text{Cov}(\\hat{\\beta}^{SA}_{d,\\tau},\\hat{\\beta}^{SA}_{d&#39;,\\tau&#39;}) &amp; = \\frac{1}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}(1-p_A^{d,\\tau})(1-p_A^{d&#39;,\\tau&#39;})(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\\\ &amp; \\phantom{=} \\left(\\mathbf{A}_4-\\frac{1}{p_D^{d,\\tau}}\\mathbf{B}_4-\\frac{1}{p_A^{d,\\tau}}\\mathbf{C}_4+\\frac{1}{p_A^{d,\\tau}p_D^{d,\\tau}}\\mathbf{D}_4\\right), \\end{align*}\\] with: \\[\\begin{align*} \\mathbf{A}_4 &amp; = \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} -\\frac{1}{p_D^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} -\\frac{1}{p^{d&#39;,\\tau&#39;}_A}\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} \\\\ &amp; \\phantom{=} + \\frac{1}{p_D^{d&#39;,\\tau&#39;}p_A^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jT^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}}\\\\ \\mathbf{B}_4 &amp; = \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}} -\\frac{1}{p_D^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}} -\\frac{1}{p^{d&#39;,\\tau&#39;}_A}\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}} \\\\ &amp; \\phantom{=} + \\frac{1}{p_D^{d&#39;,\\tau&#39;}p_A^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jT^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}}\\\\ \\mathbf{C}_4 &amp; = \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}} -\\frac{1}{p_D^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}} -\\frac{1}{p^{d&#39;,\\tau&#39;}_A}\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}} \\\\ &amp; \\phantom{=} + \\frac{1}{p_D^{d&#39;,\\tau&#39;}p_A^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jT^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}}\\\\ \\mathbf{D}_4 &amp; = \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D^{d}_jT^{d,\\tau}_jD_j^{d,\\tau}} -\\frac{1}{p_D^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jT^{d,\\tau}_jD_j^{d,\\tau}} -\\frac{1}{p^{d&#39;,\\tau&#39;}_A}\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jT^{d,\\tau}_jD_j^{d,\\tau}} \\\\ &amp; \\phantom{=} + \\frac{1}{p_D^{d&#39;,\\tau&#39;}p_A^{d&#39;,\\tau&#39;}}\\esp{\\epsilon_j^2D^{d&#39;}_jT^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jT^{d,\\tau}_jD_j^{d,\\tau}} \\end{align*}\\] Let us start with \\(\\mathbf{A}_4\\)’s first term, \\(\\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}}\\). Note first that if \\(d=d&#39;\\), we have to have \\(\\tau\\neq\\tau&#39;\\), otherwise the term would be on the diagonal. As a consequence, with \\(d=d&#39;\\), we can have only two configurations for which \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\), and they both correspond to a baseline observation (\\(T_j=d-1\\)) either for the control group (\\(D_j=\\infty\\)) or for the treated group (\\(D_j=d\\)). In that case, we thus have: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\left(\\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})\\right.\\\\ &amp; \\phantom{=}\\left.+\\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}\\right)p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}, \\end{align*}\\] with \\(p_D^{d,\\tau,d&#39;,\\tau&#39;}\\) the proportion of treated individuals in the group such as \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\) and \\(p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}\\) is the proportion of observations observed in period \\(d-1\\) among the observations such as \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\) and \\(p^{d,\\tau,d&#39;,\\tau&#39;}\\) the proportion of observations such as \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\). When \\(d\\neq d&#39;\\), we have three possible cases: \\(d-1=d&#39;+\\tau&#39;\\), \\(d&#39;-1=d+\\tau\\) or \\(d&#39;+\\tau&#39;=d+\\tau\\). Because the treated groups are different in that case, the only possible correspondence in these cases is due to the control group, with the After period for one treated group being the Before period for another treated group or the After periods being the same for both groups. If \\(d-1=d&#39;+\\tau&#39;\\), we have: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}, \\end{align*}\\] where \\(p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}\\) is the proportion of observations observed in period \\(d-1\\) among the observations such as \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\). If \\(d&#39;-1=d+\\tau\\), we have: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d&#39;-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] Finally, if \\(d&#39;+\\tau&#39;=d+\\tau\\), we have: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] Let us now look at the next term: \\(\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}}\\). Here, there is only one case that yields a non zero term, when \\(d=d&#39;\\) (all the other configurations involve only the untreated group and thus have \\(D^{d&#39;}_j=0\\)). In that case, we have: \\[\\begin{align*} \\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d&#39;-1}|D_i=d&#39;}p_D^{d,\\tau,d&#39;,\\tau&#39;}p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] Let us now look at the next term: \\(\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}}\\). Here, there are two cases that yield a non zero term, when \\(d-1=d&#39;+\\tau&#39;\\) and when \\(d&#39;+\\tau&#39;=d+\\tau\\) (all the other configurations involve only the Before period and thus have \\(T^{d&#39;,\\tau&#39;}_j=0\\)). In both case, we have: \\[\\begin{align*} \\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d&#39;+\\tau&#39;}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d&#39;+\\tau&#39;}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] Let us now look at the next term: \\(\\esp{\\epsilon_j^2D^{d&#39;}_jT^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}}\\). This term is equal to zero since there is no treated observation observed in a post-treatment period such that \\(D_j^{d&#39;,\\tau&#39;}D_j^{d,\\tau}=1\\). Let us now move on to \\(\\mathbf{B}_4\\). For \\(\\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}}\\) to be non zero, we have to have that \\(d=d&#39;\\) (otherwise, \\(D_j^d=0\\)). The only corresponding nonzero case corresponds to a baseline observation for the treated group: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] The next term (\\(\\esp{\\epsilon_j^2D^{d&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}}\\)) is the same since, with \\(d=d&#39;\\), \\(D_j^d=D_j^{d&#39;}\\). The last two terms of \\(\\mathbf{B}_4\\) are null everywhere. This is because it can only be that \\(d=d&#39;\\) (since \\(D_j^d=1\\)) and it cannot be a baseline observation (since \\(T^{d,\\tau&#39;}_j=1\\)). Since treated observations appear only once for each \\(d\\), \\(\\tau\\neq\\tau&#39;\\Rightarrow\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}D^{d}_jD_j^{d,\\tau}}=0\\). Let us now move on to \\(\\mathbf{C}_4\\). For the first term \\(\\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}}\\), we cannot have nonzero terms when \\(d=d&#39;\\), since this case involves only baseline period variances and this contradicts \\(T^{d,\\tau}_j=1\\), and thus the term is null in that case. The only possible nonzero cases involve \\(d&#39;-1=d+\\tau\\) or \\(d&#39;+\\tau&#39;=d+\\tau\\). In that case, we have: \\[\\begin{align*} \\esp{\\epsilon_j^2D_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] The next term in \\(\\mathbf{C}_4\\) is zero everywhere since it involves the same term as above plus the additional requirement that \\(D^{d&#39;}_j=1\\). Since this entails that observations have to belong to a treatment group, and the previous term only includes terms from the control group, this term has to be zero everywhere. The term \\(\\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}}\\) is non zero only when \\(d&#39;+\\tau&#39;=d+\\tau\\) (it is the same as the first term in \\(\\mathbf{C}_4\\) with the added constraint that \\(T^{d&#39;,\\tau&#39;}_j=1\\)). We thus have: \\[\\begin{align*} \\esp{\\epsilon_j^2T^{d&#39;,\\tau&#39;}_jD_j^{d&#39;,\\tau&#39;}T^{d,\\tau}_jD_j^{d,\\tau}} &amp; = \\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}. \\end{align*}\\] The last term in \\(\\mathbf{C}_4\\) everywhere since it is a subset of the second term, which is already zero. Finally, all the terms in \\(\\mathbf{D}_4\\) are equal to zero. This is because \\(T^{d,\\tau}_jD^{d}_j=1\\) implies that we cannot have \\(d=d&#39;\\) (because the only nonzero terms would then be the ones in the baseline period, which contradicts the fact that \\(T^{d,\\tau}_j=1\\)). The remaining potential nonzero configurations only concern the control group, which runs counter \\(D^{d}_j=1\\). Hence the result. Collecting terms, we now have, when \\(d=d&#39;\\): \\[\\begin{align*} \\mathbf{A}_4 &amp; = \\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}\\\\ &amp; \\phantom{=}+\\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}(1-\\frac{1}{p_D^{d&#39;,\\tau&#39;}})\\\\ \\mathbf{B}_4 &amp; = \\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}(1-\\frac{1}{p_D^{d&#39;,\\tau&#39;}})\\\\ \\mathbf{C}_4 &amp; = 0 \\\\ \\mathbf{D}_4 &amp; = 0, \\end{align*}\\] and thus: \\[\\begin{align*} \\text{Cov}(\\hat{\\beta}^{SA}_{d,\\tau},\\hat{\\beta}^{SA}_{d&#39;,\\tau&#39;}) &amp; = \\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}} \\left(\\frac{\\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{(1-p_A^{d,\\tau})(1-p_A^{d&#39;,\\tau&#39;})(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\right.\\\\ &amp; \\phantom{=}\\left.+\\frac{\\var{Y^0_{i,d-1}|D_i=d}p_D^{d,\\tau,d&#39;,\\tau&#39;}}{(1-p_A^{d,\\tau})(1-p_A^{d&#39;,\\tau&#39;})p_D^{d,\\tau}p_D^{d&#39;,\\tau&#39;}}\\right). \\end{align*}\\] Alternatively, when \\(d+\\tau=d&#39;+\\tau&#39;\\), we have: \\[\\begin{align*} \\mathbf{A}_4 &amp; = \\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}(1-\\frac{1}{p^{d&#39;,\\tau&#39;}_A}) \\\\ \\mathbf{B}_4 &amp; = 0\\\\ \\mathbf{C}_4 &amp; = \\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}(1-\\frac{1}{p^{d&#39;,\\tau&#39;}_A})\\\\ \\mathbf{D}_4 &amp; = 0 \\end{align*}\\] and thus: \\[\\begin{align*} \\text{Cov}(\\hat{\\beta}^{SA}_{d,\\tau},\\hat{\\beta}^{SA}_{d&#39;,\\tau&#39;}) &amp; = \\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d+\\tau}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d+\\tau}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}p_A^{d,\\tau}p_A^{d&#39;,\\tau&#39;}(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\end{align*}\\] Finally, when \\(d-1=d&#39;+\\tau&#39;\\), we have: \\[\\begin{align*} \\mathbf{A}_4 &amp; = \\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;}(1-\\frac{1}{p^{d&#39;,\\tau&#39;}_A})\\\\ \\mathbf{B}_4 &amp; = 0\\\\ \\mathbf{C}_4 &amp; = 0\\\\ \\mathbf{D}_4 &amp; = 0 \\end{align*}\\] and thus: \\[\\begin{align*} \\text{Cov}(\\hat{\\beta}^{SA}_{d,\\tau},\\hat{\\beta}^{SA}_{d&#39;,\\tau&#39;}) &amp; = -\\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d-1}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}(1-p_A^{d,\\tau})p_A^{d&#39;,\\tau&#39;}(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})}. \\end{align*}\\] And when \\(d&#39;-1=d+\\tau\\), we have: \\[\\begin{align*} \\mathbf{A}_4 &amp; = \\var{Y^0_{i,d&#39;-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;} \\\\ \\mathbf{B}_4 &amp; = 0\\\\ \\mathbf{C}_4 &amp; = \\var{Y^0_{i,d&#39;-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}p^{d,\\tau,d&#39;,\\tau&#39;} \\\\ \\mathbf{D}_4 &amp; = 0 \\end{align*}\\] and thus: \\[\\begin{align*} \\text{Cov}(\\hat{\\beta}^{SA}_{d,\\tau},\\hat{\\beta}^{SA}_{d&#39;,\\tau&#39;}) &amp; = -\\frac{p^{d,\\tau,d&#39;,\\tau&#39;}p_{d&#39;-1}^{d,\\tau,d&#39;,\\tau&#39;}\\var{Y^0_{i,d&#39;-1}|D_i=\\infty}(1-p_D^{d,\\tau,d&#39;,\\tau&#39;})}{p^{d,\\tau}p^{d&#39;,\\tau&#39;}p_A^{d,\\tau}(1-p_A^{d&#39;,\\tau&#39;})(1-p_D^{d,\\tau})(1-p_D^{d&#39;,\\tau&#39;})} \\end{align*}\\] This proves the result. A.3.7 Proof of Theorem 4.25 The proof follows closely that of Theorem 4.24, except that our stacked model is \\(\\Delta Y = \\Delta X\\Theta^{FD} + \\epsilon^{FD}\\), as introduced in the proof of 4.20. Using the beginning of the proof of Lemma A.4, we know that: \\(\\sqrt{N}(\\hat{\\Theta}^{FD}-\\Theta^{FD})=N(\\Delta X&#39;\\Delta X)^{-1}\\frac{\\sqrt{N}}{N}\\Delta X&#39;\\epsilon^{FD}\\). Using Slutsky’s Theorem, we know that we can study both terms separately (see the same proof of Lemma A.4). Let us start with \\(N(\\Delta X&#39;\\Delta X)^{-1}\\). Let’s denote \\(N_{d,\\infty}\\) the number of observations that are such that \\(D_i=d\\) or \\(D_i=\\infty\\) and \\(p^{d,\\infty}=\\text{plim}\\frac{N_{d,\\infty}}{N}\\). Let’s also denote \\(p^{d,\\infty}_D=\\Pr(D_i=d|D_i=d\\cup D_i=\\infty)\\). Using the same reasoning as in the proof of Theorem 4.24, and using the proof of Theorem 2.5, we can show that: \\[\\begin{align*} \\sigma_{\\Delta X \\Delta X^{-1}}^{d,\\tau} &amp;= \\text{plim}N(\\Delta X&#39;\\Delta X)^{-1}_{d,\\tau} = \\frac{1}{p^{d,\\infty}p^{d,\\infty}_D(1-p^{d,\\infty}_D)} \\left(\\begin{array}{cc} p^{d,\\infty}_D &amp; -p^{d,\\infty}_D\\\\ -p^{d,\\infty}_D &amp; 1 \\end{array}\\right) \\end{align*}\\] with \\(N(\\Delta X&#39;\\Delta X)^{-1}_{d,\\tau}\\) the block of the \\(N(\\Delta X&#39;\\Delta X)^{-1}\\) matrix that is related to the estimation of \\(\\hat{\\beta}^{SA}_{d,\\tau}\\) and using the fact that the inverse of a block diagonal matrix is the blog diagonal matrix of the inverses of each block. The proof then follows the line of the proof of Theorem 2.5, replacing \\(Y_{i}\\) by \\(Y_{i,d+\\tau}-Y_{i,d-1}\\). This proves the result. A.3.8 Proof of Theorem 4.27 The key to the proof lies in the covariance terms. They in turn depend on the product of the following matrix: \\(\\sigma_{\\Delta{X}\\Delta{X}^{-1}}^{d,\\tau,d&#39;,\\tau&#39;}\\mathbf{V}^{d,\\tau,d&#39;,\\tau&#39;}_{\\mathbf{\\Delta{x}\\Delta{\\epsilon}}}\\sigma_{\\Delta{X}\\Delta{X}^{-1}}^{d,\\tau,d&#39;,\\tau&#39;}\\), where: \\[\\begin{align*} \\mathbf{V}^{d,\\tau,d&#39;,\\tau&#39;}_{\\mathbf{\\Delta{x}\\Delta{\\epsilon}}} &amp; = \\esp{\\Delta\\epsilon_j^2\\left(\\begin{array}{cccc} D^{d,\\tau}_j &amp; D^d_jD^{d,\\tau}_j &amp; D^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j \\\\ D^d_jD^{d,\\tau}_j &amp; D^d_jD^{d,\\tau}_j &amp; D^d_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^d_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j \\\\ D^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^d_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^{d&#39;,\\tau&#39;}_j \\\\ D^{d&#39;}_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^d_jD^{d,\\tau}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^{d&#39;,\\tau&#39;}_j &amp; D^{d&#39;}_jD^{d&#39;,\\tau&#39;}_j \\end{array}\\right)}, \\end{align*}\\] and \\(\\mathbf{V}^{d,\\tau,d&#39;,\\tau&#39;}_{\\mathbf{\\Delta{x}\\Delta{\\epsilon}}}\\) is the part of the \\(\\mathbf{V}_{\\mathbf{\\Delta{x}\\Delta{\\epsilon}}}\\) matrix that relates to the estimators of \\(\\beta^{SA}_{d,\\tau}\\) and \\(\\beta^{SA}_{d&#39;,\\tau&#39;}\\). We also have that \\(\\sigma_{\\Delta{X}\\Delta{X}^{-1}}^{d,\\tau,d&#39;,\\tau&#39;}\\) is the blocks of the matrix \\(\\sigma_{\\Delta{X}\\Delta{X}^{-1}}\\) corresponding to the same estimation, with blocks formed by \\(\\sigma_{\\Delta X \\Delta X^{-1}}^{d,\\tau}\\) and \\(\\sigma_{\\Delta X \\Delta X^{-1}}^{d&#39;,\\tau&#39;}\\). A.4 Proofs of results in Chapter 5 A.4.1 Proof of Theorem 5.4 One way to obtain the result is to apply Theorem 7.2 in Imbens and Rubin (2015). A more constructive proof follows similar lines, but differs somehow at critical points. We know that \\(\\hat\\Delta^Y_{WWOLSX}=\\hat\\delta^{OLS}\\), where: \\[\\begin{align*} (\\hat\\alpha_1,\\hat\\alpha_0,\\hat\\beta_1,\\hat\\beta_0,\\hat\\delta^{OLS}) &amp; = \\arg\\min_{\\alpha_1,\\alpha_0,\\beta_1,\\beta_0,\\delta} \\frac{1}{N}\\sum_{i=1}^N\\left(Y_i-\\alpha_0 - \\beta_0&#39;X_i - (\\beta_1-\\beta_0)&#39;\\left(X_i-\\esp{X_i|D_i=1}\\right)D_i - \\delta D_i\\right)^2 \\end{align*}\\] Replacing \\(\\delta\\) by its value in the population (\\(\\Delta^Y_{TT}=\\alpha_1-\\alpha_0+(\\beta_1-\\beta_0)&#39;\\esp{X_i|D_i=1}\\)), using Theorem 5.2, we can easily show that the remaining parameters can be obtained by two separate optimizations: \\[\\begin{align*} (\\hat\\alpha_0,\\hat\\beta_0) &amp; = \\arg\\min_{\\alpha_0,\\beta_0} \\frac{1}{N}\\sum_{i=1}^N(1-D_i)\\left(Y_i-\\alpha_0 - \\beta_0&#39;X_i \\right)^2\\\\ (\\hat\\alpha_1,\\hat\\beta_1) &amp; = \\arg\\min_{\\alpha_1,\\beta_1} \\frac{1}{N}\\sum_{i=1}^ND_i\\left(Y_i-\\alpha_1 - \\beta_1&#39;X_i \\right)^2 \\end{align*}\\] By Theorem A.2, these parameters are also identified in the population by the OLS estimator. We now write \\(\\tilde{Y}_i=(1-D_i)\\tilde{Y}_i^0+D_i\\tilde{Y}_i^1\\), with: \\[\\begin{align*} \\tilde{Y}_i^0 &amp; = Y_i-\\beta_0&#39;(X_i-\\bar{X}_1) = \\alpha_0+\\beta_0&#39;\\bar{X}_1 +U_i^0 \\\\ \\tilde{Y}_i^1 &amp; = Y_i-\\beta_1&#39;(X_i-\\bar{X}_1) = \\alpha_1+\\beta_1&#39;\\bar{X}_1 +U_i^1, \\end{align*}\\] with \\(\\bar{X}_1=\\frac{\\sum_{i=1}^ND_iX_i}{\\sum_{i=1}^ND_i}\\) in the sample and \\(\\bar{X}_1=\\esp{X_i|D_i=1}\\) in the population. \\(U_i^1\\) and \\(U_i^0\\) are mean-zero noise terms independent from \\(X_i\\) and \\(D_i\\) by Assumptions 5.2, 5.3 and 5.4. Now, let’s estimate the following regression by OLS: \\[\\begin{align*} \\tilde{Y}_i &amp; = \\alpha + \\delta D_i + U_i \\\\ &amp; = \\alpha_0+\\beta_0&#39;\\bar{X}_1 +(\\alpha_1-\\alpha_0+(\\beta_1-\\beta_0)&#39;\\bar{X}_1)D_i + (1-D_i)U_i^0+D_iU_i^1 \\end{align*}\\] \\(\\delta^{OLS}\\) estimates the treatment effect on the treated. It is also equal to the \\(\\Delta^Y_{WWOLSX}\\) estimator (since it is a combination of the same OLS parameters). Using Lemma A.3, we know that \\(\\delta^{OLS}\\) is the With/Without estimator applied to \\(\\tilde{Y}_i\\). Using Assumptions 2.1, 5.5 and 5.6, Lemma A.5 implies that: \\[\\begin{align*} \\sqrt{N}(\\hat{\\delta}^{OLS}-\\Delta^Y_{TT}) &amp; \\stackrel{d}{\\rightarrow} \\mathcal{N}\\left(0,\\frac{\\var{\\tilde{Y}_i^1|D_i=1}}{\\Pr(D_i=1)}+\\frac{\\var{\\tilde{Y}_i^0|D_i=0}}{1-\\Pr(D_i=1)}\\right). \\end{align*}\\] By construction, and using Assumptions 5.3 and 5.4, \\(\\var{\\tilde{Y}_i^d|D_i=d}=\\var{Y_i^d|X_i,D_i=d}\\). Clarify what \\(\\var{Y_i^d|X_i,D_i=d}\\) is exactly and what happens when it depends on \\(X_i\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
