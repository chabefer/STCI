<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference</title>
  <meta name="description" content="This is an open source collaborative book." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source collaborative book." />
  <meta name="github-repo" content="chabefer/STCI" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference" />
  
  <meta name="twitter:description" content="This is an open source collaborative book." />
  

<meta name="author" content="Sylvain Chabé-Ferret" />


<meta name="date" content="2022-03-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Distribution.html"/>
<link rel="next" href="Bounds.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
$$
\newcommand{\uns}[1]{\mathbf{1}[#1]}
\newcommand{\esp}[1]{\mathbf{E}[#1]}
\newcommand{\hatesp}[1]{\hat{\mathbf{E}}[ #1 ]}
\newcommand{\Ind}{\perp\kern-5pt\perp}
\newcommand{\var}[1]{\mathbf{V}[ #1 ]}
\newcommand{\cov}[1]{\mathbf{C}[ #1 ]}
\newcommand{\plim}[1]{\text{plim}_{ #1 \rightarrow \infty}}
\newcommand{\plims}{\text{plim}}
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\partdersq}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\DeclareMathOperator{\diag}{diag}
$$


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Tools for Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Fundamental Problems of Inference</b></span></li>
<li class="chapter" data-level="" data-path="introduction-the-two-fundamental-problems-of-inference.html"><a href="introduction-the-two-fundamental-problems-of-inference.html"><i class="fa fa-check"></i>Introduction: the Two Fundamental Problems of Inference</a></li>
<li class="chapter" data-level="1" data-path="FPCI.html"><a href="FPCI.html"><i class="fa fa-check"></i><b>1</b> Fundamental Problem of Causal Inference</a>
<ul>
<li class="chapter" data-level="1.1" data-path="FPCI.html"><a href="FPCI.html#rubin-causal-model"><i class="fa fa-check"></i><b>1.1</b> Rubin Causal Model</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="FPCI.html"><a href="FPCI.html#treatment-allocation-rule"><i class="fa fa-check"></i><b>1.1.1</b> Treatment allocation rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="FPCI.html"><a href="FPCI.html#potential-outcomes"><i class="fa fa-check"></i><b>1.1.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="1.1.3" data-path="FPCI.html"><a href="FPCI.html#switching-equation"><i class="fa fa-check"></i><b>1.1.3</b> Switching equation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="FPCI.html"><a href="FPCI.html#treatment-effects"><i class="fa fa-check"></i><b>1.2</b> Treatment effects</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="FPCI.html"><a href="FPCI.html#individual-level-treatment-effects"><i class="fa fa-check"></i><b>1.2.1</b> Individual level treatment effects</a></li>
<li class="chapter" data-level="1.2.2" data-path="FPCI.html"><a href="FPCI.html#average-treatment-effect-on-the-treated"><i class="fa fa-check"></i><b>1.2.2</b> Average treatment effect on the treated</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="FPCI.html"><a href="FPCI.html#fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Fundamental problem of causal inference</a></li>
<li class="chapter" data-level="1.4" data-path="FPCI.html"><a href="FPCI.html#intuitive-estimators-confounding-factors-and-selection-bias"><i class="fa fa-check"></i><b>1.4</b> Intuitive estimators, confounding factors and selection bias</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="FPCI.html"><a href="FPCI.html#withwithout-comparison-selection-bias-and-cross-sectional-confounders"><i class="fa fa-check"></i><b>1.4.1</b> With/Without comparison, selection bias and cross-sectional confounders</a></li>
<li class="chapter" data-level="1.4.2" data-path="FPCI.html"><a href="FPCI.html#the-beforeafter-comparison-temporal-confounders-and-time-trend-bias"><i class="fa fa-check"></i><b>1.4.2</b> The before/after comparison, temporal confounders and time trend bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FPSI.html"><a href="FPSI.html"><i class="fa fa-check"></i><b>2</b> Fundamental Problem of Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="FPSI.html"><a href="FPSI.html#sec:sampnoise"><i class="fa fa-check"></i><b>2.1</b> What is sampling noise? Definition and illustration</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="FPSI.html"><a href="FPSI.html#sec:definitionnoise"><i class="fa fa-check"></i><b>2.1.1</b> Sampling noise, a definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisepop"><i class="fa fa-check"></i><b>2.1.2</b> Sampling noise for the population treatment effect</a></li>
<li class="chapter" data-level="2.1.3" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisesamp"><i class="fa fa-check"></i><b>2.1.3</b> Sampling noise for the sample treatment effect</a></li>
<li class="chapter" data-level="2.1.4" data-path="FPSI.html"><a href="FPSI.html#sec:confinterv"><i class="fa fa-check"></i><b>2.1.4</b> Building confidence intervals from estimates of sampling noise</a></li>
<li class="chapter" data-level="2.1.5" data-path="FPSI.html"><a href="FPSI.html#reporting-sampling-noise-a-proposal"><i class="fa fa-check"></i><b>2.1.5</b> Reporting sampling noise: a proposal</a></li>
<li class="chapter" data-level="2.1.6" data-path="FPSI.html"><a href="FPSI.html#sec:effectsize"><i class="fa fa-check"></i><b>2.1.6</b> Using effect sizes to normalize the reporting of treatment effects and their precision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FPSI.html"><a href="FPSI.html#sec:estimsampnoise"><i class="fa fa-check"></i><b>2.2</b> Estimating sampling noise</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="FPSI.html"><a href="FPSI.html#sec:assumptions"><i class="fa fa-check"></i><b>2.2.1</b> Assumptions</a></li>
<li class="chapter" data-level="2.2.2" data-path="FPSI.html"><a href="FPSI.html#sec:cheb"><i class="fa fa-check"></i><b>2.2.2</b> Using Chebyshev’s inequality</a></li>
<li class="chapter" data-level="2.2.3" data-path="FPSI.html"><a href="FPSI.html#sec:CLT"><i class="fa fa-check"></i><b>2.2.3</b> Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.4" data-path="FPSI.html"><a href="FPSI.html#sec:resamp"><i class="fa fa-check"></i><b>2.2.4</b> Using resampling methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Methods of Causal Inference</b></span></li>
<li class="chapter" data-level="3" data-path="RCT.html"><a href="RCT.html"><i class="fa fa-check"></i><b>3</b> Randomized Controlled Trials</a>
<ul>
<li class="chapter" data-level="3.1" data-path="RCT.html"><a href="RCT.html#sec:design1"><i class="fa fa-check"></i><b>3.1</b> Brute Force Design</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="RCT.html"><a href="RCT.html#identification"><i class="fa fa-check"></i><b>3.1.1</b> Identification</a></li>
<li class="chapter" data-level="3.1.2" data-path="RCT.html"><a href="RCT.html#estimating-ate"><i class="fa fa-check"></i><b>3.1.2</b> Estimating ATE</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="RCT.html"><a href="RCT.html#sec:design2"><i class="fa fa-check"></i><b>3.2</b> Self-Selection design</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="RCT.html"><a href="RCT.html#identification-1"><i class="fa fa-check"></i><b>3.2.1</b> Identification</a></li>
<li class="chapter" data-level="3.2.2" data-path="RCT.html"><a href="RCT.html#estimating-tt"><i class="fa fa-check"></i><b>3.2.2</b> Estimating TT</a></li>
<li class="chapter" data-level="3.2.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="RCT.html"><a href="RCT.html#sec:design3"><i class="fa fa-check"></i><b>3.3</b> Eligibility design</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="RCT.html"><a href="RCT.html#identification-2"><i class="fa fa-check"></i><b>3.3.1</b> Identification</a></li>
<li class="chapter" data-level="3.3.2" data-path="RCT.html"><a href="RCT.html#estimating-the-ite-and-the-tt"><i class="fa fa-check"></i><b>3.3.2</b> Estimating the ITE and the TT</a></li>
<li class="chapter" data-level="3.3.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-2"><i class="fa fa-check"></i><b>3.3.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="RCT.html"><a href="RCT.html#sec:design4"><i class="fa fa-check"></i><b>3.4</b> Encouragement Design</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="RCT.html"><a href="RCT.html#identification-3"><i class="fa fa-check"></i><b>3.4.1</b> Identification</a></li>
<li class="chapter" data-level="3.4.2" data-path="RCT.html"><a href="RCT.html#IVRCT"><i class="fa fa-check"></i><b>3.4.2</b> Estimating the Local Average Treatment Effect and the Intention to Treat Effect</a></li>
<li class="chapter" data-level="3.4.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-3"><i class="fa fa-check"></i><b>3.4.3</b> Estimating sampling noise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="NE.html"><a href="NE.html"><i class="fa fa-check"></i><b>4</b> Natural Experiments</a>
<ul>
<li class="chapter" data-level="4.1" data-path="NE.html"><a href="NE.html#instrumental-variables"><i class="fa fa-check"></i><b>4.1</b> Instrumental Variables</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="NE.html"><a href="NE.html#an-example-where-monotonicity-does-not-hold"><i class="fa fa-check"></i><b>4.1.1</b> An example where Monotonicity does not hold</a></li>
<li class="chapter" data-level="4.1.2" data-path="NE.html"><a href="NE.html#identification-4"><i class="fa fa-check"></i><b>4.1.2</b> Identification</a></li>
<li class="chapter" data-level="4.1.3" data-path="NE.html"><a href="NE.html#estimation"><i class="fa fa-check"></i><b>4.1.3</b> Estimation</a></li>
<li class="chapter" data-level="4.1.4" data-path="NE.html"><a href="NE.html#estimation-of-sampling-noise"><i class="fa fa-check"></i><b>4.1.4</b> Estimation of sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="NE.html"><a href="NE.html#regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2</b> Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="4.3" data-path="NE.html"><a href="NE.html#difference-in-differences"><i class="fa fa-check"></i><b>4.3</b> Difference In Differences</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="NE.html"><a href="NE.html#sec:DIDbasic"><i class="fa fa-check"></i><b>4.3.1</b> Difference In Differences with two time periods</a></li>
<li class="chapter" data-level="4.3.2" data-path="NE.html"><a href="NE.html#sec:DIDr"><i class="fa fa-check"></i><b>4.3.2</b> Reverse Difference In Differences designs with two time periods</a></li>
<li class="chapter" data-level="4.3.3" data-path="NE.html"><a href="NE.html#difference-in-differences-with-multiple-time-periods"><i class="fa fa-check"></i><b>4.3.3</b> Difference In Differences with multiple time periods</a></li>
<li class="chapter" data-level="4.3.4" data-path="NE.html"><a href="NE.html#difference-in-differences-with-instrumental-variables"><i class="fa fa-check"></i><b>4.3.4</b> Difference In Differences with Instrumental Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sec:OM.html"><a href="sec:OM.html"><i class="fa fa-check"></i><b>5</b> Observational Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="sec:OM.html"><a href="sec:OM.html#imputation-methods"><i class="fa fa-check"></i><b>5.1</b> Imputation methods</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="threats.html"><a href="threats.html"><i class="fa fa-check"></i><b>6</b> Threats to the validity of Causal Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="threats.html"><a href="threats.html#threats-to-internal-validity"><i class="fa fa-check"></i><b>6.1</b> Threats to internal validity</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="threats.html"><a href="threats.html#survey-bias"><i class="fa fa-check"></i><b>6.1.1</b> Survey bias</a></li>
<li class="chapter" data-level="6.1.2" data-path="threats.html"><a href="threats.html#experimenter-bias"><i class="fa fa-check"></i><b>6.1.2</b> Experimenter bias</a></li>
<li class="chapter" data-level="6.1.3" data-path="threats.html"><a href="threats.html#substitution-bias"><i class="fa fa-check"></i><b>6.1.3</b> Substitution bias</a></li>
<li class="chapter" data-level="6.1.4" data-path="threats.html"><a href="threats.html#diffusion-bias"><i class="fa fa-check"></i><b>6.1.4</b> Diffusion bias</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="threats.html"><a href="threats.html#threats-to-the-measurement-of-precision"><i class="fa fa-check"></i><b>6.2</b> Threats to the measurement of precision</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="threats.html"><a href="threats.html#insufficient-precision"><i class="fa fa-check"></i><b>6.2.1</b> Insufficient precision</a></li>
<li class="chapter" data-level="6.2.2" data-path="threats.html"><a href="threats.html#clustering"><i class="fa fa-check"></i><b>6.2.2</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="threats.html"><a href="threats.html#threats-to-external-validity"><i class="fa fa-check"></i><b>6.3</b> Threats to external validity</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="threats.html"><a href="threats.html#randomization-bias"><i class="fa fa-check"></i><b>6.3.1</b> Randomization bias</a></li>
<li class="chapter" data-level="6.3.2" data-path="threats.html"><a href="threats.html#equilibrium-effects"><i class="fa fa-check"></i><b>6.3.2</b> Equilibrium effects</a></li>
<li class="chapter" data-level="6.3.3" data-path="threats.html"><a href="threats.html#context-effects"><i class="fa fa-check"></i><b>6.3.3</b> Context effects</a></li>
<li class="chapter" data-level="6.3.4" data-path="threats.html"><a href="threats.html#site-selection-bias"><i class="fa fa-check"></i><b>6.3.4</b> Site selection bias</a></li>
<li class="chapter" data-level="6.3.5" data-path="threats.html"><a href="threats.html#publication-bias"><i class="fa fa-check"></i><b>6.3.5</b> Publication bias</a></li>
<li class="chapter" data-level="6.3.6" data-path="threats.html"><a href="threats.html#ethical-and-political-issues"><i class="fa fa-check"></i><b>6.3.6</b> Ethical and political issues</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Additional Topics</b></span></li>
<li class="chapter" data-level="7" data-path="Power.html"><a href="Power.html"><i class="fa fa-check"></i><b>7</b> Power Analysis</a></li>
<li class="chapter" data-level="8" data-path="sec:placebo.html"><a href="sec:placebo.html"><i class="fa fa-check"></i><b>8</b> Placebo Tests</a></li>
<li class="chapter" data-level="9" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>9</b> Clustering</a></li>
<li class="chapter" data-level="10" data-path="LaLonde.html"><a href="LaLonde.html"><i class="fa fa-check"></i><b>10</b> LaLonde Tests</a></li>
<li class="chapter" data-level="11" data-path="Diffusion.html"><a href="Diffusion.html"><i class="fa fa-check"></i><b>11</b> Diffusion effects</a></li>
<li class="chapter" data-level="12" data-path="Distribution.html"><a href="Distribution.html"><i class="fa fa-check"></i><b>12</b> Distributional effects</a></li>
<li class="chapter" data-level="13" data-path="meta.html"><a href="meta.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and Publication Bias</a>
<ul>
<li class="chapter" data-level="13.1" data-path="meta.html"><a href="meta.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="meta.html"><a href="meta.html#basic-setting"><i class="fa fa-check"></i><b>13.1.1</b> Basic setting</a></li>
<li class="chapter" data-level="13.1.2" data-path="meta.html"><a href="meta.html#why-vote-counting-does-not-work"><i class="fa fa-check"></i><b>13.1.2</b> Why vote-counting does not work</a></li>
<li class="chapter" data-level="13.1.3" data-path="meta.html"><a href="meta.html#MetaWA"><i class="fa fa-check"></i><b>13.1.3</b> Meta-analysis when treatment effects are homogeneous: the fixed effects approach</a></li>
<li class="chapter" data-level="13.1.4" data-path="meta.html"><a href="meta.html#meta-analysis-when-treatment-effects-are-heterogeneous-the-random-effects-approach"><i class="fa fa-check"></i><b>13.1.4</b> Meta-analysis when treatment effects are heterogeneous: the random effects approach</a></li>
<li class="chapter" data-level="13.1.5" data-path="meta.html"><a href="meta.html#meta-regression"><i class="fa fa-check"></i><b>13.1.5</b> Meta-regression</a></li>
<li class="chapter" data-level="13.1.6" data-path="meta.html"><a href="meta.html#constantly-updated-meta-analysis"><i class="fa fa-check"></i><b>13.1.6</b> Constantly updated meta-analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="meta.html"><a href="meta.html#publication-bias-and-site-selection-bias"><i class="fa fa-check"></i><b>13.2</b> Publication bias and site selection bias</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="meta.html"><a href="meta.html#sources-of-publication-bias-and-of-site-selection-bias-and-questionable-research-practices"><i class="fa fa-check"></i><b>13.2.1</b> Sources of publication bias and of site selection bias and Questionable Research Practices</a></li>
<li class="chapter" data-level="13.2.2" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-publication-bias"><i class="fa fa-check"></i><b>13.2.2</b> Detection of and correction for publication bias</a></li>
<li class="chapter" data-level="13.2.3" data-path="meta.html"><a href="meta.html#getting-rid-of-publication-bias-registered-reports-and-pre-analysis-plans"><i class="fa fa-check"></i><b>13.2.3</b> Getting rid of publication bias: registered reports and pre-analysis plans</a></li>
<li class="chapter" data-level="13.2.4" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-site-selection-bias"><i class="fa fa-check"></i><b>13.2.4</b> Detection of and correction for site selection bias</a></li>
<li class="chapter" data-level="13.2.5" data-path="meta.html"><a href="meta.html#vote-counting-and-publication-bias"><i class="fa fa-check"></i><b>13.2.5</b> Vote counting and publication bias</a></li>
<li class="chapter" data-level="13.2.6" data-path="meta.html"><a href="meta.html#the-value-of-a-statistically-significant-result"><i class="fa fa-check"></i><b>13.2.6</b> The value of a statistically significant result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Bounds.html"><a href="Bounds.html"><i class="fa fa-check"></i><b>14</b> Bounds</a></li>
<li class="chapter" data-level="15" data-path="mediation-analysis.html"><a href="mediation-analysis.html"><i class="fa fa-check"></i><b>15</b> Mediation Analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-a-framework"><i class="fa fa-check"></i><b>15.1</b> Mediation analysis: a framework</a></li>
<li class="chapter" data-level="15.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#the-fundamental-problem-of-mediation-analysis"><i class="fa fa-check"></i><b>15.2</b> The Fundamental Problem of Mediation Analysis</a></li>
<li class="chapter" data-level="15.3" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-under-unconfoundedness"><i class="fa fa-check"></i><b>15.3</b> Mediation analysis under unconfoundedness</a></li>
<li class="chapter" data-level="15.4" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-panel-data"><i class="fa fa-check"></i><b>15.4</b> Mediation analysis with panel data</a></li>
<li class="chapter" data-level="15.5" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-instruments"><i class="fa fa-check"></i><b>15.5</b> Mediation analysis with instruments</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="proofs.html"><a href="proofs.html"><i class="fa fa-check"></i><b>A</b> Proofs</a>
<ul>
<li class="chapter" data-level="A.1" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-reffpsi"><i class="fa fa-check"></i><b>A.1</b> Proofs of results in Chapter @ref(FPSI)</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="proofs.html"><a href="proofs.html#proofcheb"><i class="fa fa-check"></i><b>A.1.1</b> Proof of Theorem @ref(thm:uppsampnoise)</a></li>
<li class="chapter" data-level="A.1.2" data-path="proofs.html"><a href="proofs.html#proofCLT"><i class="fa fa-check"></i><b>A.1.2</b> Proof of Theorem @ref(thm:asympnoiseWW)</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refrct"><i class="fa fa-check"></i><b>A.2</b> Proofs of results in Chapter @ref(RCT)</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="proofs.html"><a href="proofs.html#proofIdentLATE"><i class="fa fa-check"></i><b>A.2.1</b> Proof of Theorem @ref(thm:IdentLATE)</a></li>
<li class="chapter" data-level="A.2.2" data-path="proofs.html"><a href="proofs.html#proofWaldIV"><i class="fa fa-check"></i><b>A.2.2</b> Proof of Theorem @ref(thm:WaldIV)</a></li>
<li class="chapter" data-level="A.2.3" data-path="proofs.html"><a href="proofs.html#ProofAsymWald"><i class="fa fa-check"></i><b>A.2.3</b> Proof of Theorem @ref(thm:asymWald)</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refne"><i class="fa fa-check"></i><b>A.3</b> Proofs of results in Chapter @ref(NE)</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="proofs.html"><a href="proofs.html#proofEstimDID"><i class="fa fa-check"></i><b>A.3.1</b> Proof of Theorem @ref(thm:EstimDID)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Tools for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="meta" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> Meta-analysis and Publication Bias</h1>
<p>When several research teams work on a similar topic, they obtain and publish several estimates for the same program of for similar programs.
For example, teams of doctors regularly test the same treatment on different samples or populations in order to refine the estimated effect.
Similarly, economists report on the effects of similar types of programs (Conditional and Unconditional Cash Transfers, Job Training Programs, microcredit, etc) implemented in different countries.</p>
<p>Meta-analysis aims at summarizing and synthetizing the available evidence with two main goals in mind:</p>
<ol style="list-style-type: decimal">
<li>Increasing precision by providing an average estimated effect combining several estimates</li>
<li>Explaining variations in treatment effectiveness by relating changes in effect size to changes in sample characteristics.</li>
</ol>
<p>One key issue that meta-analysis has to face – actually, we all have to face it, meta-analysis simply makes it more apparent – is that of publication bias.
Publication bias is due to the fact that referees and editors have a marked preference for publishing statistically significant results.
The problem with this approach is that the distribution of published results is going to be censored on the left: we will have more statistically significant results in the published record, and as a consequence, the average published result will be an upward biased estimate of the true treatment effect in the population.
This is potentially a very severe problem if the amount of censoring due to publication bias is large.
Eventually, this hinges on the true distribution of treatment effects: if it is centered on zero or close to zero, we run the risk of having very large publication bias.</p>
<p>In this chapter, I present first the tools for meta-analysis, and I then move on to testing and correcting for publication bias.
Most of the material presented here stems from the reference book by <a href="https://www.sciencedirect.com/book/9780080570655/statistical-methods-for-meta-analysis">Hedges and Olkin</a>.
When needed, I update this book with new references that I then cite.
the R code comes mainly from a <a href="http://www.edii.uclm.es/~useR-2013/Tutorials/kovalchik/kovalchik_meta_tutorial.pdf">wonderful set of slides</a> explaining of the <code>metafor</code> package works.</p>
<div id="meta-analysis" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Meta-analysis</h2>
<p>There are several approaches and refinements to meta-analysis.
In this section, I am going to present only the most important ones.
I’ll defer the reader to other more specialized publications if needed.</p>
<p>I first present the basics of meta-analysis: the constitution and structure of the sample.
Second, I present the problems of the intuitive “vote-counting” method.
Third, I present the methods used when treatment effects are homogeneous across studies, called fixed effects models.
Fourth, I move to the methods used when effects are heterogeneous across studies, or random effects models, and the tests used to decide whether we are in a fixed or random effects framework.
Fifth, I present meta-regression, that tries to capture treatment effect heterogeneity by including covariates.
Finally, I present constantly updated meta-analysis, a way to aggregate results of individual studies as they come.</p>
<div id="basic-setting" class="section level3" number="13.1.1">
<h3><span class="header-section-number">13.1.1</span> Basic setting</h3>
<p>The basic setting for a meta-analysis is that you have access to a list of estimates for the effect of a given program and for their precision.
These estimates come from the literature, searching published and unpublished sources alike.
This data is usually collected after an extensive search of bibliographic databases.
Then, one has to select among all the studies selected by the search the ones that are actualy relevant.
This is the most excruciating part of a meta-analysis, since a lot of the studies selected by hte search algorithm are actually irrelevant.
Finally, one has to extract from each relevant paper an estimate of the effect of the treatment and of its precision.
In general, one tries to choose standardized estimates such as the effect size (see Section <a href="FPSI.html#sec:effectsize">2.1.6</a> for a definition) and its standard error.
After all this process, we should end up with a dataset like: <span class="math inline">\(\left\{(\hat{\theta}_k,\hat{\sigma}_k)\right\}_{k=1}^N\)</span>, with <span class="math inline">\(\hat{\theta}_k\)</span> the estimated effect size, <span class="math inline">\(\hat{\sigma}_k\)</span> its estimated standard error, and <span class="math inline">\(N\)</span> the number of included studies.</p>

<div class="example">
<span id="exm:unnamed-chunk-228" class="example"><strong>Example 13.1  </strong></span>Let’s see how such a dataset would look like?
Let’s build one from our simulations.
</div>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="meta.html#cb214-1" aria-hidden="true" tabindex="-1"></a>N.sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>,<span class="dv">10000</span>,<span class="dv">100000</span>)</span>
<span id="cb214-2"><a href="meta.html#cb214-2" aria-hidden="true" tabindex="-1"></a>N.plot.ES.CLT <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">7</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb214-3"><a href="meta.html#cb214-3" aria-hidden="true" tabindex="-1"></a>data.meta <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">ES=</span><span class="fu">numeric</span>(),</span>
<span id="cb214-4"><a href="meta.html#cb214-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">se=</span><span class="fu">numeric</span>())</span>
<span id="cb214-5"><a href="meta.html#cb214-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb214-6"><a href="meta.html#cb214-6" aria-hidden="true" tabindex="-1"></a>se.ww.CLT.ES <span class="ot">&lt;-</span> <span class="cf">function</span>(N,v1,v0,p){</span>
<span id="cb214-7"><a href="meta.html#cb214-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">sqrt</span>((v1<span class="sc">/</span>p<span class="sc">+</span>v0<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">/</span>N)<span class="sc">/</span>v0)</span>
<span id="cb214-8"><a href="meta.html#cb214-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb214-9"><a href="meta.html#cb214-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb214-10"><a href="meta.html#cb214-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(N.sample)){</span>
<span id="cb214-11"><a href="meta.html#cb214-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb214-12"><a href="meta.html#cb214-12" aria-hidden="true" tabindex="-1"></a>  simuls.ww[[k]]<span class="sc">$</span>se.ES <span class="ot">&lt;-</span> <span class="fu">se.ww.CLT.ES</span>(N.sample[[k]],simuls.ww[[k]][,<span class="st">&#39;V1&#39;</span>],simuls.ww[[k]][,<span class="st">&#39;V0&#39;</span>],simuls.ww[[k]][,<span class="st">&#39;p&#39;</span>])</span>
<span id="cb214-13"><a href="meta.html#cb214-13" aria-hidden="true" tabindex="-1"></a>  test.ES <span class="ot">&lt;-</span> simuls.ww[[k]][<span class="fu">sample</span>(N.plot.ES.CLT[[k]]),<span class="fu">c</span>(<span class="st">&#39;ES&#39;</span>,<span class="st">&#39;se.ES&#39;</span>)]</span>
<span id="cb214-14"><a href="meta.html#cb214-14" aria-hidden="true" tabindex="-1"></a>  test.ES<span class="sc">$</span>N <span class="ot">&lt;-</span> <span class="fu">rep</span>(N.sample[[k]],N.plot.ES.CLT[[k]])</span>
<span id="cb214-15"><a href="meta.html#cb214-15" aria-hidden="true" tabindex="-1"></a>  data.meta <span class="ot">&lt;-</span> <span class="fu">rbind</span>(data.meta,test.ES)</span>
<span id="cb214-16"><a href="meta.html#cb214-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb214-17"><a href="meta.html#cb214-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb214-18"><a href="meta.html#cb214-18" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>id <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data.meta)</span>
<span id="cb214-19"><a href="meta.html#cb214-19" aria-hidden="true" tabindex="-1"></a><span class="co">#data.meta$N &lt;- factor(data.meta$N,levels(N.sample))</span></span>
<span id="cb214-20"><a href="meta.html#cb214-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb214-21"><a href="meta.html#cb214-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb214-22"><a href="meta.html#cb214-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb214-23"><a href="meta.html#cb214-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb214-24"><a href="meta.html#cb214-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb214-25"><a href="meta.html#cb214-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="sc">+</span></span>
<span id="cb214-26"><a href="meta.html#cb214-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb214-27"><a href="meta.html#cb214-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:confintervalESCLT"></span>
<img src="STCI_files/figure-html/confintervalESCLT-1.png" alt="Example data set: effect sizes and confidence intervals with $\delta=$ 0.95" width="60%" />
<p class="caption">
Figure 13.1: Example data set: effect sizes and confidence intervals with <span class="math inline">\(\delta=\)</span> 0.95
</p>
</div>
<p>Figure <a href="meta.html#fig:confintervalESCLT">13.1</a> shows the resulting sample.
I’ve selected 10 studies with <span class="math inline">\(N=\)</span> 100, 7 studies with <span class="math inline">\(N=\)</span> 1000, 2 studies with <span class="math inline">\(N=\)</span> 10^{4}, and 1 study with <span class="math inline">\(N=\)</span> 10^{5}.
The studies are represented in that order, mimicking the increasing sample size of studies that accumulate evidence on a treatment, probably with studies with a small sample size at first, and only large studies at the end for the most promising treatments.</p>
</div>
<div id="why-vote-counting-does-not-work" class="section level3" number="13.1.2">
<h3><span class="header-section-number">13.1.2</span> Why vote-counting does not work</h3>
<p>Vote-counting is an alternative to weighted average or meta-regression.
The term, coined by Light and Smith (1971), refers to the practice of counting the number of studies that fall under one of three categories:</p>
<ul>
<li>Significant and positive,</li>
<li>Insignificant,</li>
<li>Significant and negative.</li>
</ul>
<p>A vote-counting approach concludes that there is evidence in favor of the treatment when the majority of effects fall in the first category, that there is no evidence that the treatment has an impact whenthe majority of studies fall in the second category, and that there is evidence that the treatment is defavorable when the majority of studies fall in the third category.
In general, majority is evaluated at 33%.</p>
<p>The main problem with the vote counting approach is that it does not give more weight to more precise studies.
As a consequence, there is a very realistic possibility that the probability of finding the truth decrease as we add more studies to the meta-analysis.</p>
<p>Let’s see how this could happen with a simulation taken from HEdges and Olkin’s book.
Let <span class="math inline">\(p\)</span> be the probaility that a given result is significant and positive.
<span class="math inline">\(p\)</span> depends on the sample size <span class="math inline">\(n\)</span> of the study, and on the true treatment effect, <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  p &amp; = \int_{C_{\alpha}}^{\infty}f(t;\theta,n),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(f\)</span> is the density of the test statistic <span class="math inline">\(T\)</span> used to evaluate whether the effect is significant or not, and <span class="math inline">\(C_{\alpha}\)</span> is the critical value of the test <span class="math inline">\(T\)</span>.
If <span class="math inline">\(n\)</span> and <span class="math inline">\(\theta\)</span> are constant over studies (for simplicity), the process of accumulating significant results can be modelled as a binomial with parameter <span class="math inline">\(p\)</span>.
The probability that over <span class="math inline">\(K\)</span> studies, we have a proportion of significant results larger than a pre-specified threshold (let’s say <span class="math inline">\(C_0\)</span>) is equal to:</p>
<p><span class="math display">\[\begin{align*}
  \Pr(\frac{X}{K}&gt;C_0) &amp; = \sum_{k=\text{int}(C_{0}k)+1}^{K}\left(\begin{array}{c}K\\k\end{array}\right)p^k(1-p)^{K-k},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\text{int}(a)\)</span> is the greatest integer larger or equal to <span class="math inline">\(a\)</span> and <span class="math inline">\(0\leq C_0\leq 1\)</span>.
In order to use this formula, we simply have to choose a test.
Let’s choose the two-sided t-test of a zero treatment effect in an RCT with equal tozes for treated and control groups.
In that case, <span class="math inline">\(p\)</span> is simply the power of the test.
In Chapter <a href="Power.html#Power">7</a>, we have derived a formula for the power of this test when <span class="math inline">\(N\)</span> is large:</p>
<p><span class="math display">\[\begin{align*}
  \kappa &amp; = \Phi\left(\frac{\beta_A}{\sqrt{\var{\hat{E}}}}-\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right),
\end{align*}\]</span></p>
<p>with <span class="math inline">\(\var{\hat{E}}=\frac{C(\hat{E})}{N}\)</span> and <span class="math inline">\(C(\hat{E})\)</span> the variance of the estimator across sampling replications.
Let’s make the simplifying assumption that the treatment effect is constant, so that the variance of the estimator is basically the variance of the outcomes.
Let’s also assume that we are working with effect sizes, so that our outcomes are normalized to have mean zero and variance one.
Under these assumptions, <span class="math inline">\(C(\hat{E})=1\)</span> and we can implement the power formula:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="meta.html#cb215-1" aria-hidden="true" tabindex="-1"></a>PowerTwoside <span class="ot">&lt;-</span> <span class="cf">function</span>(betaA,alpha,N,<span class="at">CE=</span><span class="dv">1</span>){</span>
<span id="cb215-2"><a href="meta.html#cb215-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">pnorm</span>(<span class="sc">-</span>betaA<span class="sc">/</span><span class="fu">sqrt</span>(CE<span class="sc">/</span>N)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))<span class="sc">+</span><span class="fu">pnorm</span>(betaA<span class="sc">/</span><span class="fu">sqrt</span>(CE<span class="sc">/</span>N)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>)))</span>
<span id="cb215-3"><a href="meta.html#cb215-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb215-4"><a href="meta.html#cb215-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-5"><a href="meta.html#cb215-5" aria-hidden="true" tabindex="-1"></a>PowerTwosideStudent <span class="ot">&lt;-</span> <span class="cf">function</span>(betaA,alpha,N,<span class="at">CE=</span><span class="dv">1</span>){</span>
<span id="cb215-6"><a href="meta.html#cb215-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">pt</span>(<span class="sc">-</span>betaA<span class="sc">/</span><span class="fu">sqrt</span>(CE<span class="sc">/</span>N)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>),<span class="at">df=</span>N<span class="dv">-1</span>)<span class="sc">+</span><span class="fu">pt</span>(betaA<span class="sc">/</span><span class="fu">sqrt</span>(CE<span class="sc">/</span>N)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>),<span class="at">df=</span>N<span class="dv">-1</span>))</span>
<span id="cb215-7"><a href="meta.html#cb215-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb215-8"><a href="meta.html#cb215-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-9"><a href="meta.html#cb215-9" aria-hidden="true" tabindex="-1"></a>VoteCounting <span class="ot">&lt;-</span> <span class="cf">function</span>(betaA,C0,K,...){</span>
<span id="cb215-10"><a href="meta.html#cb215-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">pbinom</span>(<span class="at">q=</span>C0<span class="sc">*</span>K,<span class="at">size=</span>K,<span class="at">prob=</span><span class="fu">PowerTwosideStudent</span>(<span class="at">betaA=</span>betaA,...),<span class="at">lower.tail =</span> <span class="cn">FALSE</span>))</span>
<span id="cb215-11"><a href="meta.html#cb215-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb215-12"><a href="meta.html#cb215-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-13"><a href="meta.html#cb215-13" aria-hidden="true" tabindex="-1"></a><span class="fu">PowerTwosideStudent</span>(<span class="at">betaA=</span><span class="fl">0.1</span>,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">N=</span><span class="dv">300</span>)</span>
<span id="cb215-14"><a href="meta.html#cb215-14" aria-hidden="true" tabindex="-1"></a><span class="fu">VoteCounting</span>(<span class="at">C0=</span>.<span class="dv">33</span>,<span class="at">K=</span><span class="dv">3000</span>,<span class="at">betaA=</span><span class="fl">0.1</span>,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">N=</span><span class="dv">300</span>)</span>
<span id="cb215-15"><a href="meta.html#cb215-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-16"><a href="meta.html#cb215-16" aria-hidden="true" tabindex="-1"></a>Sample.size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">200</span>,<span class="dv">300</span>)</span>
<span id="cb215-17"><a href="meta.html#cb215-17" aria-hidden="true" tabindex="-1"></a>BetaA <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.1</span>,<span class="fl">1.5</span>,<span class="at">by=</span><span class="fl">0.1</span>)</span>
<span id="cb215-18"><a href="meta.html#cb215-18" aria-hidden="true" tabindex="-1"></a>K.list <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">1000</span>)</span>
<span id="cb215-19"><a href="meta.html#cb215-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-20"><a href="meta.html#cb215-20" aria-hidden="true" tabindex="-1"></a>power.vote <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">&quot;Power&quot;</span><span class="ot">=</span> <span class="dv">0</span>,<span class="st">&#39;BetaA&#39;</span><span class="ot">=</span> <span class="dv">0</span>,<span class="st">&#39;N&#39;</span><span class="ot">=</span> <span class="dv">0</span>,<span class="st">&#39;K&#39;</span><span class="ot">=</span> <span class="dv">0</span>)</span>
<span id="cb215-21"><a href="meta.html#cb215-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb215-22"><a href="meta.html#cb215-22" aria-hidden="true" tabindex="-1"></a><span class="co">#power.vote &lt;- sapply(BetaA,VoteCounting,C0=.33,K=K.list[[1]],alpha=0.05,N=Sample.size[[1]])</span></span>
<span id="cb215-23"><a href="meta.html#cb215-23" aria-hidden="true" tabindex="-1"></a><span class="co">#power.vote &lt;- cbind(power.vote,BetaA,Sample.size[[1]],K.list[[1]])</span></span>
<span id="cb215-24"><a href="meta.html#cb215-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-25"><a href="meta.html#cb215-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(K.list))){</span>
<span id="cb215-26"><a href="meta.html#cb215-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(Sample.size))){</span>
<span id="cb215-27"><a href="meta.html#cb215-27" aria-hidden="true" tabindex="-1"></a>    power.vote.int <span class="ot">&lt;-</span> <span class="fu">sapply</span>(BetaA,VoteCounting,<span class="at">C0=</span>.<span class="dv">33</span>,<span class="at">K=</span>K.list[[j]],<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">N=</span>Sample.size[[k]])</span>
<span id="cb215-28"><a href="meta.html#cb215-28" aria-hidden="true" tabindex="-1"></a>    power.vote.int <span class="ot">&lt;-</span> <span class="fu">cbind</span>(power.vote.int,BetaA,Sample.size[[k]],K.list[[j]])</span>
<span id="cb215-29"><a href="meta.html#cb215-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">colnames</span>(power.vote.int) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Power&#39;</span>,<span class="st">&#39;BetaA&#39;</span>,<span class="st">&#39;N&#39;</span>,<span class="st">&#39;K&#39;</span>)</span>
<span id="cb215-30"><a href="meta.html#cb215-30" aria-hidden="true" tabindex="-1"></a>    power.vote <span class="ot">&lt;-</span> <span class="fu">rbind</span>(power.vote,power.vote.int)  </span>
<span id="cb215-31"><a href="meta.html#cb215-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb215-32"><a href="meta.html#cb215-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb215-33"><a href="meta.html#cb215-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-34"><a href="meta.html#cb215-34" aria-hidden="true" tabindex="-1"></a>power.vote <span class="ot">&lt;-</span> power.vote[<span class="sc">-</span><span class="dv">1</span>,]</span>
<span id="cb215-35"><a href="meta.html#cb215-35" aria-hidden="true" tabindex="-1"></a>power.vote<span class="sc">$</span>K.int <span class="ot">&lt;-</span> power.vote<span class="sc">$</span>K</span>
<span id="cb215-36"><a href="meta.html#cb215-36" aria-hidden="true" tabindex="-1"></a>power.vote<span class="sc">$</span>K <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(power.vote<span class="sc">$</span>K)</span>
<span id="cb215-37"><a href="meta.html#cb215-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-38"><a href="meta.html#cb215-38" aria-hidden="true" tabindex="-1"></a><span class="co">#ggplot(data=filter(power.vote,K==10),aes(x=N,y=Power,group=as.factor(BetaA),shape=as.factor(BetaA),color=as.factor(BetaA)))+</span></span>
<span id="cb215-39"><a href="meta.html#cb215-39" aria-hidden="true" tabindex="-1"></a><span class="co">#  geom_line()+</span></span>
<span id="cb215-40"><a href="meta.html#cb215-40" aria-hidden="true" tabindex="-1"></a><span class="co">#  geom_point()</span></span>
<span id="cb215-41"><a href="meta.html#cb215-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-42"><a href="meta.html#cb215-42" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span><span class="fu">filter</span>(power.vote,BetaA<span class="sc">==</span><span class="fl">0.1</span>),<span class="fu">aes</span>(<span class="at">x=</span>N,<span class="at">y=</span>Power,<span class="at">group=</span>K,<span class="at">shape=</span>K,<span class="at">color=</span>K))<span class="sc">+</span></span>
<span id="cb215-43"><a href="meta.html#cb215-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb215-44"><a href="meta.html#cb215-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb215-45"><a href="meta.html#cb215-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;N (BetaA=0.1)&quot;</span>)<span class="sc">+</span></span>
<span id="cb215-46"><a href="meta.html#cb215-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Detection probability of the vote counting rule&quot;</span>)<span class="sc">+</span></span>
<span id="cb215-47"><a href="meta.html#cb215-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb215-48"><a href="meta.html#cb215-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">name=</span><span class="st">&quot;K&quot;</span>)</span>
<span id="cb215-49"><a href="meta.html#cb215-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-50"><a href="meta.html#cb215-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb215-51"><a href="meta.html#cb215-51" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span><span class="fu">filter</span>(power.vote,BetaA<span class="sc">==</span><span class="fl">0.2</span>),<span class="fu">aes</span>(<span class="at">x=</span>N,<span class="at">y=</span>Power,<span class="at">group=</span>K,<span class="at">shape=</span>K,<span class="at">color=</span>K))<span class="sc">+</span></span>
<span id="cb215-52"><a href="meta.html#cb215-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb215-53"><a href="meta.html#cb215-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb215-54"><a href="meta.html#cb215-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;N (BetaA=0.2)&quot;</span>)<span class="sc">+</span></span>
<span id="cb215-55"><a href="meta.html#cb215-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Detection probability of the vote counting rule&quot;</span>)<span class="sc">+</span></span>
<span id="cb215-56"><a href="meta.html#cb215-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:VoteCounting"></span>
<img src="STCI_files/figure-html/VoteCounting-1.png" alt="Detection probability of the vote counting rule" width="50%" /><img src="STCI_files/figure-html/VoteCounting-2.png" alt="Detection probability of the vote counting rule" width="50%" />
<p class="caption">
Figure 13.2: Detection probability of the vote counting rule
</p>
</div>
<p>Figure <a href="meta.html#fig:VoteCounting">13.2</a> shows that the vote counting rule has a very inconvenient property: when the power of the test is lower than 33%, the probability that the vote counting rule detects a true effect decreases with the number of studies included in the meta-analysis, and converges to zero when the number of studies gets large.<br />
For example, when <span class="math inline">\(N=100\)</span> and <span class="math inline">\(\beta_A=0.1\)</span>, the probability of detecting the effect using the vote counting method is equal to 0.076 with <span class="math inline">\(K=10\)</span> studies and decreases to 0.043 when <span class="math inline">\(K=20\)</span>, and 0 when <span class="math inline">\(K=100\)</span>.
The pattern is reverse for more powerful studies, such as when <span class="math inline">\(N=300\)</span> and <span class="math inline">\(\beta_A=0.1\)</span> or when <span class="math inline">\(N=100\)</span> and <span class="math inline">\(\beta_A=0.2\)</span>.
The intuition for this result is that the vote counting method does not average out the sampling noise in each individual study.</p>
</div>
<div id="MetaWA" class="section level3" number="13.1.3">
<h3><span class="header-section-number">13.1.3</span> Meta-analysis when treatment effects are homogeneous: the fixed effects approach</h3>
<p>The key idea of meta-analysis with fixed effects is to combine the effect size estimates stemming from different studies, weighing them by their relative precision.</p>

<div class="definition">
<span id="def:metaweights" class="definition"><strong>Definition 13.1  (Weighted Meta-Analytic Estimator)  </strong></span>The weighted meta-analytic estimator is
<span class="math display">\[
\bar{\theta} = \sum_{k=1}^Nw_k\hat{\theta}_k \text{ with } w_k=\frac{\frac{1}{\hat{\sigma}^2_k}}{\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k}}.
\]</span>
</div>
<p>Under some assumptions, the estimator <span class="math inline">\(\bar{\theta}\)</span> converges to the true effect of the treatment.
Let’s delineate these assumptions.</p>

<div class="definition">
<span id="def:metahomo" class="definition"><strong>Definition 13.2  (Homogeneous Treatment Effect)  </strong></span>Each <span class="math inline">\(\hat{\theta}_k\)</span> converges to the same treatment effect <span class="math inline">\(\theta\)</span>.
</div>
<p>Assumption <a href="meta.html#def:metahomo">13.2</a> imposes that all the studies have been drawn from the same population, where the treatment effect is a constant.</p>

<div class="definition">
<span id="def:metaind" class="definition"><strong>Definition 13.3  (Independence of Estimates)  </strong></span>The <span class="math inline">\(\hat{\theta}_k\)</span> are independent from each other.
</div>
<p>Assumption <a href="meta.html#def:metaind">13.3</a> imposes that all the studies estimates are independent from each other.
That means that they do not share sampling units and that they are not affected by common shocks.</p>
<p>Under these assumptions, we can show two important results.</p>

<div class="theorem">
<span id="thm:metafixedcons" class="theorem"><strong>Theorem 13.1  (Consistency of the Weighted Meta-Analytic Estimator)  </strong></span>Under Assumptions <a href="meta.html#def:metahomo">13.2</a> and <a href="meta.html#def:metaind">13.3</a>, when the sample size of each study goes to infinity, <span class="math inline">\(\bar{\theta}\approx\theta\)</span>.
</div>

<div class="proof">
 <span class="proof"><em>Proof. </em></span> The Law of Large Number applied to each sample gives the fact that the estimator is a weighted sum of <span class="math inline">\(\theta\)</span> with weights summing to one.
Hence the result.
</div>
<p>Theorem <a href="meta.html#thm:metafixedcons">13.1</a> says that the error we are making around the true effect of the treatment goes to zero as the sample size in each study decrease.
This is great: aggregating the studies is thus going to get us to the truth.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> One interesting question is whether Theorem <a href="meta.html#thm:metafixedcons">13.1</a> also holds when the size of the individual studies remains fixed and the number of studies goes to infinity, which seems a more natural way to do asymptotics in a meta-analysis.
I’m pretty sure that is the case.
Indeed, the studies constitute an enormous sample in which we take the average outcomes of the treated on the one hand and of the untreated on the other.
These averages differ from the usual ones in the Law of Large Numbers only by the fact that the weights are not equal to one.
But they (i) are independent from the outcomes and (ii) sum to one.
As a consequence, I’m pretty sure the Law of Large Numbers also apply in this dimension.
</div>
<p><strong><span class="smallcaps">Check if this is a consequence of Kolmogorov’s Law of Large Numbers.</span></strong></p>

<div class="theorem">
<span id="thm:metafixeddis" class="theorem"><strong>Theorem 13.2  (Asymptotic Distribution of the Weighted Meta-Analytic Estimator)  </strong></span>Under Assumptions <a href="meta.html#def:metahomo">13.2</a> and <a href="meta.html#def:metaind">13.3</a>, when the sample size of each study goes to infinity, <span class="math inline">\(\bar{\theta}\stackrel{d}{\rightarrow}\mathcal{N}(\theta,\sigma^2)\)</span>, with
<span class="math display">\[
\sigma^2 = \frac{1}{\sum_{k=1}^N\frac{1}{\sigma^2_k}}.
\]</span>
</div>

<div class="proof">
 <span class="proof"><em>Proof. </em></span> <strong><span class="smallcaps">To do using the Lindenberg-Levy version of the Central Limit Theorem.</span></strong>
</div>
<p>Theorem <a href="meta.html#thm:metafixeddis">13.2</a> shows that the distribution of the weighted meta-analytic estimator converges to a normal, which is very convenient in order to compute sampling noise.
In order to obtain an estimator <span class="math inline">\(\hat{\sigma}^2\)</span> of the variance of the meta-analytic estimator, we can simply replace the individual variance terms by their estimates: <span class="math inline">\(\hat{\sigma}_k^2\)</span>.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> I’ve taken Theorem <a href="meta.html#thm:metafixeddis">13.2</a> from Hedges and Olkin, but I think it is much more interesting and correct when the asymptotics goes in the number of studies.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> According to Hedges and Olkin, the weighted meta-analytic estimator is the most efficient estimator available.
</div>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="meta.html#cb216-1" aria-hidden="true" tabindex="-1"></a>wmae <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,sigma2){</span>
<span id="cb216-2"><a href="meta.html#cb216-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(<span class="fu">weighted.mean</span>(theta,(<span class="dv">1</span><span class="sc">/</span>sigma2)<span class="sc">/</span>(<span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>sigma2))),<span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>sigma2)))</span>
<span id="cb216-3"><a href="meta.html#cb216-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-234" class="example"><strong>Example 13.2  </strong></span>Let’s use our meta-analytic estimator to estimate the effect size of our treatment.
</div>
<p>The estimated treatment effect size with our sample is 0.19 <span class="math inline">\(\pm\)</span> 0.02.
A very simple way to implement such an estimator in R is to use the <code>rma</code> command of the <code>metafor</code> package.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="meta.html#cb217-1" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>var.ES <span class="ot">&lt;-</span> data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb217-2"><a href="meta.html#cb217-2" aria-hidden="true" tabindex="-1"></a>meta.example.FE <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>ES,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb217-3"><a href="meta.html#cb217-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(meta.example.FE)</span></code></pre></div>
<pre><code>## 
## Fixed-Effects Model (k = 20)
## 
##   logLik  deviance       AIC       BIC      AICc 
##  16.1375   12.7060  -30.2751  -29.2793  -30.0529   
## 
## I^2 (total heterogeneity / total variability):   0.00%
## H^2 (total variability / sampling variability):  0.67
## 
## Test for Heterogeneity:
## Q(df = 19) = 12.7060, p-val = 0.8533
## 
## Model Results:
## 
## estimate      se     zval    pval   ci.lb   ci.ub 
##   0.1950  0.0079  24.6975  &lt;.0001  0.1795  0.2104  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As seen above, the <code>metafor</code> package yields a meta-analytic estimate of 0.19 <span class="math inline">\(\pm\)</span> 0.02, as we have found using the weighted meta-analytic estimator.</p>
<p>It is customary to present the results of a meta-analysis using a forest plot.
A forest plows all the individual estimates along with the aggregated estimate.
Figure <a href="meta.html#fig:FEforestplot">13.3</a> presents the forest plot for our example using the very convenient <code>forest</code> function in the <code>metafor</code> package:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="meta.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.FE,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FEforestplot"></span>
<img src="STCI_files/figure-html/FEforestplot-1.png" alt="Example data set: forest plot" width="60%" />
<p class="caption">
Figure 13.3: Example data set: forest plot
</p>
</div>
</div>
<div id="meta-analysis-when-treatment-effects-are-heterogeneous-the-random-effects-approach" class="section level3" number="13.1.4">
<h3><span class="header-section-number">13.1.4</span> Meta-analysis when treatment effects are heterogeneous: the random effects approach</h3>
<p>One key assumption that we have just made so far is that of homogeneous treatment effect.
We have worked under the assumption that each study was drawn from the same population, where the treatment effect is a constant.
Why would the treatment effects differ in each study?</p>
<ol style="list-style-type: decimal">
<li>We do not study exactly the same treatment, but a family of similar treatments.
Each individual study covers a particular iteration of the treatment, each with its idiosyncratic parameterization.
The particular value of the transfer in a Cash Transfer program, or of the conditions to receive it, or the length of payment, whether it is in one time or over some period, might make a difference, for example.
The same is true for Job Training Programs, Payments for Environmental Services, microcredit, graduation programs, nudges, etc.
Actually, most programs that economists study differ from one implementation to the next.
In psychology and medecine, most treatments are accompanied by a rigorous protocol that makes them much more homogeneous.</li>
<li>The population on which the treatment is applied varies.
For example, similar Job Training Programs or microcredit initiatives might have very different outcomes depending on the business cycle.
Education interventions might have very different effects depending on the background of the students on which they are tested.
A drug might interact with patients’ phenotype and genotype to generate different effects, and the populations from which the experimental samples are drawn do not have to be similar.
As an extreme example, think of a vaccine tested in a population where the prevalence of a disease is null.
The treatment effect is zero.
Now, test the vaccine in a population where the disease is endemic: the treatment effect might be huge.</li>
</ol>
<p>When each study draws a treatment effect from a distinct population, meta-analysis has to take into account that treatment effects are heterogeneous.
The main consequence of treatment effect heterogeneity is that the weighting approach we have used so far underestimates the uncertainty around the true effect, since it does not acknowledge that there is additional variation within each study.</p>
<p>There are two main ways to account for heterogeneity in meta-analysis:</p>
<ol style="list-style-type: decimal">
<li><strong>Random effects</strong> allowing for additional random noise in each study.</li>
<li><strong>Meta-regression</strong> trying to capture the heterogeneity in treatment effects with observed covariates.</li>
</ol>
<p>In this section, we study the random effects estimator, and the next section will cover the meta-regression estimator.
Before implementing the random effects estimator, we need to decide whether there is heterogeneity in treatment effects or not.</p>
<p><strong><span class="smallcaps">Generate noise right now and show the plot.</span></strong></p>
<div id="estimating-the-heterogeneity-of-treatment-effects" class="section level4" number="13.1.4.1">
<h4><span class="header-section-number">13.1.4.1</span> Estimating the heterogeneity of treatment effects</h4>
<p>A necessary first step is to estimate the variance in treatment effects that is due to treatment effect heterogeneity, beyond sampling noise.
The observed effect size estimate for a given study <span class="math inline">\(k\)</span> is modelled as follows:</p>
<p><span class="math display">\[\begin{align*}
\hat{\theta}_k &amp; = \alpha + \epsilon_k + \nu_k,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\epsilon_k\)</span> is due to sampling noise and <span class="math inline">\(\nu_k\)</span> is due to the heterogeneity in effect sizes across sites, while <span class="math inline">\(\alpha\)</span> is the average of the effect size accross all populations.
We denote the variance of <span class="math inline">\(\nu_k\)</span> as <span class="math inline">\(\tau^2\)</span>.
<span class="math inline">\(\nu_k\)</span> is the random effect that gives the random effects approach its name.</p>
<p>There are several ways to estimate this variation.
I’m gooing to start with the most intuitive one, Hedges’ estimator, and I’ll then move on to the other ones available.
I’ll conclude with the formal statistical tests used to decide whether treatment effects are heterogeneous or not.</p>
<div id="hedges-estimator-of-treatment-effect-heterogeneity" class="section level5" number="13.1.4.1.1">
<h5><span class="header-section-number">13.1.4.1.1</span> Hedges’ estimator of treatment effect heterogeneity</h5>
<p>Since Hedges, <span class="math inline">\(\tau^2\)</span> is estimated as the residual variance in effect sizes that is not explained by sampling noise.
In order to compute this estimator, first estimate the overall variance in <span class="math inline">\(\hat{\theta}_k\)</span>, then estimate the component of the variance due to sampling noise and finally take the difference between the two.
Hedges’ estimator of the overall variance in effect sizes is:</p>
<p><span class="math display">\[\begin{align*}
\hat{\tau}^2 &amp; = \hat{\sigma}^2_{tot}-\hat{\sigma}^2_{\epsilon},
\end{align*}\]</span></p>
<p>with</p>
<p><span class="math display">\[\begin{align*}
\hat{\sigma^2_{tot}} &amp; = \frac{1}{N}\sum_{k=1}^N(\hat{\theta}_k-\bar{\theta}_u)^2\\
\bar{\theta}_u &amp; = \frac{1}{N}\sum_{k=1}^N\hat{\theta}_k \\
\hat{\sigma^2_{\epsilon}} &amp; = \frac{1}{N}\sum_{k=1}^N\hat{\sigma}_k^2.
\end{align*}\]</span></p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Hedges actually uses the unbiased estimator adapted to small samples and thus replaces <span class="math inline">\(N\)</span> by <span class="math inline">\(N-1\)</span> in the first equation.
</div>

<div class="example">
<span id="exm:unnamed-chunk-236" class="example"><strong>Example 13.3  </strong></span>Let’s compute Hedges’ esimator for <span class="math inline">\(\tau^2\)</span> in our numerical example.
</div>
<p>Let’s first define a few functions to compute each part:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="meta.html#cb220-1" aria-hidden="true" tabindex="-1"></a>tau<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,vartheta){</span>
<span id="cb220-2"><a href="meta.html#cb220-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">var</span>(theta)<span class="sc">-</span><span class="fu">mean</span>(vartheta))</span>
<span id="cb220-3"><a href="meta.html#cb220-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb220-4"><a href="meta.html#cb220-4" aria-hidden="true" tabindex="-1"></a>tau.<span class="fl">2.</span>theta <span class="ot">&lt;-</span> <span class="fu">tau.2</span>(data.meta<span class="sc">$</span>ES,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>Our estimate of <span class="math inline">\(\tau^2\)</span> in our example is thus -0.03.
This estimate is small, suggesting that there is no additional variance in the treatment effects on top of sammling variation, as we know is the case and has already been suggested by the results of the <span class="math inline">\(Q\)</span> statistic.
Let’s now create a new sample of effect sizes where we add noise to each estimate stemming not from sampling, but from heterogeneity in treatment effects across sites and studies.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="meta.html#cb221-1" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>)</span>
<span id="cb221-2"><a href="meta.html#cb221-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb221-3"><a href="meta.html#cb221-3" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>theta<span class="fl">.1</span> <span class="ot">&lt;-</span> data.meta<span class="sc">$</span>ES <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(data.meta),<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span>tau[[<span class="dv">1</span>]])</span>
<span id="cb221-4"><a href="meta.html#cb221-4" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>theta<span class="fl">.2</span> <span class="ot">&lt;-</span> data.meta<span class="sc">$</span>ES <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(data.meta),<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span>tau[[<span class="dv">2</span>]])</span></code></pre></div>
<p>I’ve simulated two new vectors of estimates for <span class="math inline">\(\theta\)</span>, both obtained adding a mean-zero normally distributed noise to the initial estimates of <span class="math inline">\(\theta\)</span>, one with a standard deviation of 0.5 and the other of 1.
Let’s visualize our two new datasets:</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="meta.html#cb222-1" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb222-2"><a href="meta.html#cb222-2" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-3"><a href="meta.html#cb222-3" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-4"><a href="meta.html#cb222-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-5"><a href="meta.html#cb222-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="dv">0</span>,<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))<span class="sc">+</span></span>
<span id="cb222-6"><a href="meta.html#cb222-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-7"><a href="meta.html#cb222-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb222-8"><a href="meta.html#cb222-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb222-9"><a href="meta.html#cb222-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-10"><a href="meta.html#cb222-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>theta<span class="fl">.1</span>)) <span class="sc">+</span></span>
<span id="cb222-11"><a href="meta.html#cb222-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-12"><a href="meta.html#cb222-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>theta<span class="fl">.1</span><span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>theta<span class="fl">.1</span><span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-13"><a href="meta.html#cb222-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-14"><a href="meta.html#cb222-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,tau[[<span class="dv">1</span>]],<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))<span class="sc">+</span></span>
<span id="cb222-15"><a href="meta.html#cb222-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-16"><a href="meta.html#cb222-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb222-17"><a href="meta.html#cb222-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb222-18"><a href="meta.html#cb222-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-19"><a href="meta.html#cb222-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>theta<span class="fl">.2</span>)) <span class="sc">+</span></span>
<span id="cb222-20"><a href="meta.html#cb222-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-21"><a href="meta.html#cb222-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>theta<span class="fl">.2</span><span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>theta<span class="fl">.2</span><span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb222-22"><a href="meta.html#cb222-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-23"><a href="meta.html#cb222-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,tau[[<span class="dv">2</span>]],<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))<span class="sc">+</span></span>
<span id="cb222-24"><a href="meta.html#cb222-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb222-25"><a href="meta.html#cb222-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb222-26"><a href="meta.html#cb222-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:metanoiseplot"></span>
<img src="STCI_files/figure-html/metanoiseplot-1.png" alt="Datasets with treatment effect heterogeneity" width="33%" /><img src="STCI_files/figure-html/metanoiseplot-2.png" alt="Datasets with treatment effect heterogeneity" width="33%" /><img src="STCI_files/figure-html/metanoiseplot-3.png" alt="Datasets with treatment effect heterogeneity" width="33%" />
<p class="caption">
Figure 13.4: Datasets with treatment effect heterogeneity
</p>
</div>
<p>Let’s see now how Hedge’s estimator performs:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="meta.html#cb223-1" aria-hidden="true" tabindex="-1"></a>tau.<span class="fl">2.</span>theta<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">tau.2</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb223-2"><a href="meta.html#cb223-2" aria-hidden="true" tabindex="-1"></a>tau.<span class="fl">2.</span>theta<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">tau.2</span>(data.meta<span class="sc">$</span>theta<span class="fl">.2</span>,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>Hedges’ estimates of <span class="math inline">\(\tau^2\)</span> in our examples are thus 0.2 and 0.73 respectively, while the true values are, respectively 0.25 and 1.</p>
</div>
<div id="other-estimators-of-treatment-effects-heterogeneity" class="section level5" number="13.1.4.1.2">
<h5><span class="header-section-number">13.1.4.1.2</span> Other estimators of treatment effects heterogeneity</h5>
<p><span class="math inline">\(\tau^2\)</span> is a pretty difficult measure of treatment effect heterogeneity to interpret.
That’s why other indicators have been built that are easier to interpret.
We are going to review several of them in this section.</p>
<p>The first alternative or complement to <span class="math inline">\(\tau^2\)</span> is Higgin’s <span class="math inline">\(I^2\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  I^2 &amp; = \frac{Q-(N-1)}{Q}*100
\end{align*}\]</span></p>
<p>The interpretation of <span class="math inline">\(I^2\)</span> is pretty straightforward: it is the distance between the actual value of the <span class="math inline">\(Q\)</span> statistic and its value under the null of treatment effect homogeneity (it is equal to the number of studies <span class="math inline">\(N\)</span>, with a correction for degress of freedom).
It can also be interpreted as the fraction of the overall variance (remember that <span class="math inline">\(Q\)</span> is the sum of variance ratios) that is not explained by within study sampling noise.</p>
<p>Another complement to <span class="math inline">\(\tau^2\)</span> is <span class="math inline">\(H^2\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  H^2 &amp; = \frac{Q}{N-1}
\end{align*}\]</span></p>
<p>If <span class="math inline">\(H^2\)</span> is above one, then there is unexplained heterogeneity, again by the fact that <span class="math inline">\(Q\)</span> has mean <span class="math inline">\(N-1\)</span> under the null of treatment effect homogeneity.</p>
<p>Finally, we can also define the Intra Class Correlation (<span class="math inline">\(ICC\)</span>), which precisely measures the share of total variance attributable to treatment effect heterogeneity:</p>
<p><span class="math display">\[\begin{align*}
  ICC &amp; = \frac{\tau^2}{\tau^2+S^2}
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(S^2\)</span> is the amount of variance due to sampling noise.
An estimator for <span class="math inline">\(S^2\)</span> is:</p>
<p><span class="math display">\[\begin{align*}
  S^2 &amp; = \frac{(N-1)\sum_{k=1}^N\frac{1}{\sigma^2_k}}{(\sum_{k=1}^N\frac{1}{\sigma^2_k})^2-\sum_{k=1}^N(\frac{1}{\sigma^2_k})^2}.
\end{align*}\]</span></p>
<p><strong><span class="smallcaps">I do not understand the formula for <span class="math inline">\(S^2\)</span>. Why does it estimate what we want? I’d take the average variance.</span></strong></p>
<p><span class="math inline">\(ICC\)</span> and <span class="math inline">\(I^2\)</span> are related by the following very simple relation: <span class="math inline">\(I^2=ICC*100\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-237" class="example"><strong>Example 13.4  </strong></span>Let’s see how these three estimators look like in our example.
The cool thing is that <code>rma</code> computes these estimators by default, so that a simple call to <code>summary()</code> is going to show them.
The default random effects estimator is <code>REML</code>, which is deemed to be the best of them all according to simulations <a href="https://journals.sagepub.com/doi/abs/10.3102/10769986030003261">(Viechtbauer, 2002)</a>.
</div>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="meta.html#cb224-1" aria-hidden="true" tabindex="-1"></a>meta.example.RE.ES <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>ES,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES)</span>
<span id="cb224-2"><a href="meta.html#cb224-2" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES)</span>
<span id="cb224-3"><a href="meta.html#cb224-3" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.2</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES)</span>
<span id="cb224-4"><a href="meta.html#cb224-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-5"><a href="meta.html#cb224-5" aria-hidden="true" tabindex="-1"></a>tau2.hat <span class="ot">&lt;-</span> <span class="fu">c</span>(meta.example.RE.ES<span class="sc">$</span>tau2,meta.example.RE.theta<span class="fl">.1</span><span class="sc">$</span>tau2,meta.example.RE.theta<span class="fl">.2</span><span class="sc">$</span>tau2)</span>
<span id="cb224-6"><a href="meta.html#cb224-6" aria-hidden="true" tabindex="-1"></a>I2 <span class="ot">&lt;-</span>  <span class="fu">c</span>(meta.example.RE.theta<span class="fl">.1</span><span class="sc">$</span>I2,meta.example.RE.theta<span class="fl">.2</span><span class="sc">$</span>I2,meta.example.RE.ES<span class="sc">$</span>I2)</span>
<span id="cb224-7"><a href="meta.html#cb224-7" aria-hidden="true" tabindex="-1"></a>H2 <span class="ot">&lt;-</span>  <span class="fu">c</span>(meta.example.RE.theta<span class="fl">.1</span><span class="sc">$</span>H2,meta.example.RE.theta<span class="fl">.2</span><span class="sc">$</span>H2,meta.example.RE.ES<span class="sc">$</span>H2)</span>
<span id="cb224-8"><a href="meta.html#cb224-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-9"><a href="meta.html#cb224-9" aria-hidden="true" tabindex="-1"></a><span class="co"># illustration of results returned by summary</span></span>
<span id="cb224-10"><a href="meta.html#cb224-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(meta.example.RE.theta<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Random-Effects Model (k = 20; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -24.7208   49.4417   53.4417   55.3305   54.1917   
## 
## tau^2 (estimated amount of total heterogeneity): 0.7507 (SE = 0.2583)
## tau (square root of estimated tau^2 value):      0.8664
## I^2 (total heterogeneity / total variability):   99.59%
## H^2 (total variability / sampling variability):  241.82
## 
## Test for Heterogeneity:
## Q(df = 19) = 1927.7020, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.6015  0.1997  3.0127  0.0026  0.2102  0.9929  ** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The estimate of <span class="math inline">\(I^2\)</span> in our example is of 0 when <span class="math inline">\(\tau^2\)</span> is equal to 0, of 98.71 when <span class="math inline">\(\tau^2\)</span> is equal to 0.25 and of 99.59 when <span class="math inline">\(\tau^2\)</span> is equal to 1.
The estimate of <span class="math inline">\(H^2\)</span> in our example is of 1 when <span class="math inline">\(\tau^2\)</span> is equal to 0, of 77.4 when <span class="math inline">\(\tau^2\)</span> is equal to 0.25 and of 241.82 when <span class="math inline">\(\tau^2\)</span> is equal to 1.</p>
</div>
<div id="testing-for-the-homogeneity-of-treatment-effects" class="section level5" number="13.1.4.1.3">
<h5><span class="header-section-number">13.1.4.1.3</span> Testing for the homogeneity of treatment effects</h5>
<p>What can we do in order to test whether there is heterogeneity in treatment effects?
One way is to build an index comparing the usual variation in treatment effects stemming from sampling noise to the one stemming from variation between studies.
If we find that the variation between studies dwarves the variation due to sampling noise in each study, then there is some heterogeneity for sure.
One statistics that does that is the <span class="math inline">\(Q\)</span> statistic where the variation in treatment effects between studies is estimated using the difference between the individual effect size and the average one squared:</p>
<p><span class="math display">\[\begin{align*}
  Q &amp; = \sum_{k=1}^N\frac{(\hat{\theta}_k-\bar{\theta})^2}{\hat{\sigma}^2_k}.
\end{align*}\]</span></p>
<p>What is great with the <span class="math inline">\(Q\)</span> statistic is that, under the Null hypothesis that all the treatment effects are equal to the same constant, it is distributed asymptotically as a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(N-1\)</span> degrees of freedom, and thus it can directly be used to test for the hypothesis of homogeneous treatment effects.</p>

<div class="example">
<span id="exm:unnamed-chunk-238" class="example"><strong>Example 13.5  </strong></span>In our example, we have already computed the <span class="math inline">\(Q\)</span> statistic when we have used the <code>rma</code> function in the <code>metafor</code> package.
In order to access it, we just need to extract it using <code>meta.example.FE$QE</code> for the <span class="math inline">\(Q\)</span> statistic and <code>meta.example.FE$QEp</code> for its p-value.
</div>
<p>The <span class="math inline">\(Q\)</span> statistic in our example has value 12.71, with associated p-value 0.85.
We end up not rejecting homogeneity, which is correct.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The problem with using test statistics for testing for treatment effect homogeneity is that, when precision increases, we might end up rejecting homogeneity despite the fact that it is there.
</div>
<p><strong><span class="smallcaps">Test with <span class="math inline">\(N=10^5\)</span>.</span></strong></p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(k\)</span> degrees of freedom is asymptotically distributed as a normal with mean <span class="math inline">\(k\)</span> and variance <span class="math inline">\(2k\)</span>.
So, when <span class="math inline">\(k\)</span> is large, a good rule of thumb for assessing the homogeneity of the treatment effect estimates is to compare the <span class="math inline">\(Q\)</span> statistic to the number of studies.
If it is much larger, homogeneity is probably not guaranteed.
</div>
</div>
</div>
<div id="sec:RE" class="section level4" number="13.1.4.2">
<h4><span class="header-section-number">13.1.4.2</span> Random effects models</h4>
<p>Hedges proposes a new estimator for the average effect of the treatment, an estimator that accounts for the additional noise due to heterogeneous treatment effects accross sites.</p>

<div class="definition">
<span id="def:Hmetaweights" class="definition"><strong>Definition 13.4  (Hedges Weighted Meta-Analytic Estimator)  </strong></span>Hedges weighted meta-analytic estimator for in the presence of random effects is
<span class="math display">\[
\bar{\theta}_H = \sum_{k=1}^Nv_k\hat{\theta}_k \text{ with } v_k=\frac{\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}}{\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}}.
\]</span>
</div>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="meta.html#cb226-1" aria-hidden="true" tabindex="-1"></a>Hwmae <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,sigma2,tau2){</span>
<span id="cb226-2"><a href="meta.html#cb226-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(<span class="fu">weighted.mean</span>(theta,(<span class="dv">1</span><span class="sc">/</span>sigma2)<span class="sc">/</span>(<span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>(sigma2<span class="sc">+</span>tau2))),<span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>sigma2<span class="sc">+</span>tau2))))</span>
<span id="cb226-3"><a href="meta.html#cb226-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb226-4"><a href="meta.html#cb226-4" aria-hidden="true" tabindex="-1"></a>ES.H.theta<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">Hwmae</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>,tau.<span class="fl">2.</span>theta<span class="fl">.1</span>)</span>
<span id="cb226-5"><a href="meta.html#cb226-5" aria-hidden="true" tabindex="-1"></a>ES.H.theta<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">Hwmae</span>(data.meta<span class="sc">$</span>theta<span class="fl">.2</span>,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>,tau.<span class="fl">2.</span>theta<span class="fl">.2</span>)</span></code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-241" class="example"><strong>Example 13.6  </strong></span>Let’s see how Hedges estimator performs in our example.
</div>
<p>Hedges’ estimates of the average effect size is equal to 0.3 and 0.65 respectively, while the true value is NA.
The main problem with Hedges’ estimator when treatment effects are heterogeneous is that very large effects for the more precise estimators dramatically affect the estimate.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Hedges’ estimate of <span class="math inline">\(\tau^2\)</span> is slightly negative, which is problem, since a variance is always positive.
Other estimators of <span class="math inline">\(\tau^2\)</span> have been proposed in the literature to account for this fact and to respond to various shortcomings of Hedges’ approach.
We will present them succinctly since they are part of the <code>metafor</code> package.
These other estimators have bames such as .
They are very well described in this <a href="http://www.edii.uclm.es/~useR-2013/Tutorials/kovalchik/kovalchik_meta_tutorial.pdf">amazing set of slides</a>.
Besides Hedges’ (denoted ‘HE’ in R), the other estimators are named:
</div>
<ul>
<li>DerSimonian-Laird (‘DL’)</li>
<li>Hunter-Schmidt (‘HS’)</li>
<li>Sidik-Jonkman (‘SJ’)</li>
<li>Maximum-likelihood (‘ML’)</li>
<li>Restricted maximum-likelihood (‘REML’)</li>
<li>Empirical Bayes (‘EB’)</li>
</ul>
<p>I’ll detail how they work later.</p>
<p><strong><span class="smallcaps">Detail other estimators of tau.</span></strong></p>

<div class="example">
<span id="exm:unnamed-chunk-243" class="example"><strong>Example 13.7  </strong></span>For the moment, let’s see how they perform in our numerical example.
</div>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="meta.html#cb227-1" aria-hidden="true" tabindex="-1"></a>estimators <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;DL&quot;</span>, <span class="st">&quot;REML&quot;</span>, <span class="st">&quot;HE&quot;</span>, <span class="st">&quot;HS&quot;</span>, <span class="st">&quot;SJ&quot;</span>, <span class="st">&quot;ML&quot;</span>, <span class="st">&quot;EB&quot;</span>)</span>
<span id="cb227-2"><a href="meta.html#cb227-2" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta.<span class="fl">1.</span>tau2 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method)<span class="sc">$</span>tau2)})</span>
<span id="cb227-3"><a href="meta.html#cb227-3" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta.<span class="fl">2.</span>tau2 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.2</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method)<span class="sc">$</span>tau2)})</span>
<span id="cb227-4"><a href="meta.html#cb227-4" aria-hidden="true" tabindex="-1"></a><span class="co">#meta.example.RE &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=method))})</span></span>
<span id="cb227-5"><a href="meta.html#cb227-5" aria-hidden="true" tabindex="-1"></a><span class="co">#meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;))</span></span>
<span id="cb227-6"><a href="meta.html#cb227-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-7"><a href="meta.html#cb227-7" aria-hidden="true" tabindex="-1"></a>result.RE <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Method=</span><span class="fu">rep</span>(estimators,<span class="dv">2</span>),<span class="at">tau2hat=</span><span class="fu">c</span>(meta.example.RE.theta.<span class="fl">1.</span>tau2,meta.example.RE.theta.<span class="fl">2.</span>tau2),<span class="at">tau2=</span><span class="fu">c</span>(<span class="fu">rep</span>(tau[[<span class="dv">1</span>]]<span class="sc">^</span><span class="dv">2</span>,<span class="fu">length</span>(estimators)),<span class="fu">rep</span>(tau[[<span class="dv">2</span>]]<span class="sc">^</span><span class="dv">2</span>,<span class="fu">length</span>(estimators))))</span>
<span id="cb227-8"><a href="meta.html#cb227-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-9"><a href="meta.html#cb227-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>result.RE, <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>tau2hat, <span class="at">fill=</span><span class="fu">as.factor</span>(tau2))) <span class="sc">+</span></span>
<span id="cb227-10"><a href="meta.html#cb227-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>())<span class="sc">+</span></span>
<span id="cb227-11"><a href="meta.html#cb227-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:RandomOthersTau"></span>
<img src="STCI_files/figure-html/RandomOthersTau-1.png" alt="Various estimators of $\tau^2$" width="60%" />
<p class="caption">
Figure 13.5: Various estimators of <span class="math inline">\(\tau^2\)</span>
</p>
</div>
<p>We are ready to estimate the overall treatment effect using random effects.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="meta.html#cb228-1" aria-hidden="true" tabindex="-1"></a>estimators <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;DL&quot;</span>, <span class="st">&quot;REML&quot;</span>, <span class="st">&quot;HE&quot;</span>, <span class="st">&quot;HS&quot;</span>, <span class="st">&quot;SJ&quot;</span>, <span class="st">&quot;ML&quot;</span>, <span class="st">&quot;EB&quot;</span>)</span>
<span id="cb228-2"><a href="meta.html#cb228-2" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta.<span class="fl">1.</span>ES <span class="ot">&lt;-</span> <span class="fu">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method)<span class="sc">$</span>beta)})</span>
<span id="cb228-3"><a href="meta.html#cb228-3" aria-hidden="true" tabindex="-1"></a>meta.example.RE.theta.<span class="fl">2.</span>ES <span class="ot">&lt;-</span> <span class="fu">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.2</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method)<span class="sc">$</span>beta)})</span>
<span id="cb228-4"><a href="meta.html#cb228-4" aria-hidden="true" tabindex="-1"></a><span class="co">#meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;))</span></span>
<span id="cb228-5"><a href="meta.html#cb228-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-6"><a href="meta.html#cb228-6" aria-hidden="true" tabindex="-1"></a>result.RE<span class="sc">$</span>ES.RE <span class="ot">&lt;-</span> <span class="fu">c</span>(meta.example.RE.theta.<span class="fl">1.</span>ES,meta.example.RE.theta.<span class="fl">2.</span>ES)</span>
<span id="cb228-7"><a href="meta.html#cb228-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-8"><a href="meta.html#cb228-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>result.RE, <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>ES.RE, <span class="at">fill=</span><span class="fu">as.factor</span>(tau2))) <span class="sc">+</span></span>
<span id="cb228-9"><a href="meta.html#cb228-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>())</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:RandomOthersES"></span>
<img src="STCI_files/figure-html/RandomOthersES-1.png" alt="Various estimators of the treatment effect with random effects" width="60%" />
<p class="caption">
Figure 13.6: Various estimators of the treatment effect with random effects
</p>
</div>
<p><strong><span class="smallcaps">Add error bars here.</span></strong></p>
<div id="presenting-the-results-of-a-random-effects-meta-analysis" class="section level5" number="13.1.4.2.1">
<h5><span class="header-section-number">13.1.4.2.1</span> Presenting the results of a random effects meta-analysis</h5>
<p>In order to illustrate the results of a random effects meta-analysis, you can first show the forest plot.
Let’s see how it works in our example:</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="meta.html#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.RE.ES,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))</span>
<span id="cb229-2"><a href="meta.html#cb229-2" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.RE.theta<span class="fl">.1</span>,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="st">&#39;0.25&#39;</span>,<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))</span>
<span id="cb229-3"><a href="meta.html#cb229-3" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.RE.theta<span class="fl">.2</span>,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="sc">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="st">&#39;1&#39;</span>,<span class="at">sep=</span><span class="st">&#39; &#39;</span>)))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:RERMAmetafor"></span>
<img src="STCI_files/figure-html/RERMAmetafor-1.png" alt="Forest plots with random effects" width="33%" /><img src="STCI_files/figure-html/RERMAmetafor-2.png" alt="Forest plots with random effects" width="33%" /><img src="STCI_files/figure-html/RERMAmetafor-3.png" alt="Forest plots with random effects" width="33%" />
<p class="caption">
Figure 13.7: Forest plots with random effects
</p>
</div>
<p>Another very nice and useful graphical presentation device is a radial (or Galbraith) plot.
It relates the invserse of the standard errors to the effect sizes normalized by their standard errors.
Each data point is also related a radius by the line passing through the origin.
The Radial plot enables to visualize the noise in the dataset, and is especially useful when comparing a fixed and a random effects estimator for the same study.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="meta.html#cb230-1" aria-hidden="true" tabindex="-1"></a>meta.example.FE.theta<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb230-2"><a href="meta.html#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="fu">radial</span>(meta.example.FE.theta<span class="fl">.1</span>)</span>
<span id="cb230-3"><a href="meta.html#cb230-3" aria-hidden="true" tabindex="-1"></a><span class="fu">radial</span>(meta.example.RE.theta<span class="fl">.1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Radial"></span>
<img src="STCI_files/figure-html/Radial-1.png" alt="Radial plots with fixed and random effects $\tau^2=$ 0.25" width="50%" /><img src="STCI_files/figure-html/Radial-2.png" alt="Radial plots with fixed and random effects $\tau^2=$ 0.25" width="50%" />
<p class="caption">
Figure 13.8: Radial plots with fixed and random effects <span class="math inline">\(\tau^2=\)</span> 0.25
</p>
</div>
<p>Figure <a href="meta.html#fig:Radial">13.8</a> shows how the mechanics of the fixed effects estimator differs from the mechanics of the random effects one.
In the presence of treatment effect heterogeneity, the fixed effect estimator faces two issues:</p>
<ol style="list-style-type: decimal">
<li>It gives too much weight to very precise estimators.
The random effects estimator undoes part of this importance by adding <span class="math inline">\(\tau^2\)</span> to the weights of each observation.</li>
<li>It overestimates overall precision by ignoring the sampling variance stemming from treatment effect heterogeneity across sites.
The random effects estimator corrects for that by estimating <span class="math inline">\(\tau^2\)</span> and adding it to the estimate of the total variance of the treatment effect.</li>
</ol>

<div class="example">
<span id="exm:unnamed-chunk-244" class="example"><strong>Example 13.8  </strong></span>Let’s see how big a difference using random versus fixed effects does to the estimation of treatment effects.
</div>
<p>Let’s plot the two forest plots for the example with <span class="math inline">\(\tau=\)</span> 0.25.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="meta.html#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.FE.theta<span class="fl">.1</span>,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</span>
<span id="cb231-2"><a href="meta.html#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.RE.theta<span class="fl">.1</span>,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FEvsRE"></span>
<img src="STCI_files/figure-html/FEvsRE-1.png" alt="Fixed vs random effects with $\tau^2=$ 0.25" width="50%" /><img src="STCI_files/figure-html/FEvsRE-2.png" alt="Fixed vs random effects with $\tau^2=$ 0.25" width="50%" />
<p class="caption">
Figure 13.9: Fixed vs random effects with <span class="math inline">\(\tau^2=\)</span> 0.25
</p>
</div>
<p>Figure <a href="meta.html#fig:FEvsRE">13.9</a> clearly shows that the inclusion of <span class="math inline">\(\tau^2\)</span> in the weights and precision estimates makes a huge difference to the meta-analytic estimate.
The fixed effects estimator yields an estimate of our treatment effect of 0.3 <span class="math inline">\(\pm\)</span> 0.02.
The random effects estimator yields an estimate of our treatment effect of 0.13 <span class="math inline">\(\pm\)</span> 0.23.
With <span class="math inline">\(\tau^2=\)</span> 1, the random effects estimator yields an estimate of our treatment effect of 0.6 <span class="math inline">\(\pm\)</span> 0.39.
Remember that the true effect size of our treatment is NA.
With <span class="math inline">\(\tau^2=\)</span> 1, the random effects estimator barely contains the truth in its 95 <span class="math inline">\(\%\)</span> confidence interval.</p>
</div>
</div>
</div>
<div id="meta-regression" class="section level3" number="13.1.5">
<h3><span class="header-section-number">13.1.5</span> Meta-regression</h3>
<p>A Meta-regression tries to explain the heterogeneity in treatment effects across studies using observed covariates.
The idea is to identify characteristics of the studies or of the sites that are correlated with how treatment effects vary.</p>
<div id="the-meta-regression-model" class="section level4" number="13.1.5.1">
<h4><span class="header-section-number">13.1.5.1</span> The Meta-regression model</h4>
<p>The main equation that we want to estimate is as follows <a href="https://www.jstor.org/stable/10.7758/9781610441384">(Raudenbusch, 2009)</a>:</p>
<p><span class="math display">\[\begin{align}
  \hat{\theta}_k &amp; = \mathbf{X}_k \mathbf{\beta}  + \epsilon_k + \nu_k,
\end{align}\]</span></p>
<p><strong><span class="smallcaps">Center regressors at the mean?</span></strong></p>
<p>where <span class="math inline">\(\mathbf{X}_k\)</span> is a line vector containing the value of the variables suspected to be correlated with treatment effect heterogeneity for study <span class="math inline">\(k\)</span> and <span class="math inline">\(\mathbf{\beta}\)</span> is a column vector of the corresponding coefficients, of the same dimension as <span class="math inline">\(\mathbf{X}_k\)</span>.
<span class="math inline">\(\mathbf{X}_k\)</span> contains a <span class="math inline">\(1\)</span> as its first term, so that <span class="math inline">\(\beta_0\)</span>, the first component of the vector <span class="math inline">\(\mathbf{\beta}\)</span> measures the effect of the treatment when all other regressors are set to zero.
It might thus be a good idea to set the regressors as deviations around their means if we want <span class="math inline">\(\beta_0\)</span> to capture the average effect of the treatment.
The error term <span class="math inline">\(\epsilon_k\)</span> captures the heterogeneity in estimated effect sizes that is due to sampling noise.
The error term <span class="math inline">\(\nu_k\)</span> captures the heterogeneity in effect sizes across sites that remains after conditioning on <span class="math inline">\(\mathbf{X}_k\)</span>.
In addition, it is generally assumed that <span class="math inline">\(\epsilon_k\sim\mathbf{N}(0,\hat{\sigma}^2_k)\)</span> and <span class="math inline">\(\nu_k\sim\mathbf{N}(0,\tau^2)\)</span>.</p>
<p>This model is in general called the <strong>mixed effects linear model</strong>.
It contains at the same time fixed effects captured by <span class="math inline">\(\mathbf{X}_k \mathbf{\beta}\)</span> and random effects captured by <span class="math inline">\(\nu_k\)</span>.
Setting <span class="math inline">\(\tau^2\)</span> to zero generates a <strong>fixed effects linear model</strong>.
It is possible, as usual, to test for whether <span class="math inline">\(\tau^2\)</span> is null or not, which is a test of whether the added covariates fully capture the heterogeneity in treatment effects across studies.</p>
</div>
<div id="estimating-the-meta-regression-model" class="section level4" number="13.1.5.2">
<h4><span class="header-section-number">13.1.5.2</span> Estimating the meta-regression model</h4>
<p>There are at least four ways to estimate the meta-regression model:</p>
<ol style="list-style-type: decimal">
<li>Weighted Least squares (WLS): mostly used for fixed effects models, where <span class="math inline">\(\tau^2\)</span> is assumed to be zero.</li>
<li>Full Maximum Likelihood Estimator (FMLE)</li>
<li>Restricted Maximum Likelihood Estimator (RMLE)</li>
<li>Method Of Moments (MOM)</li>
</ol>
<div id="weighted-least-squares" class="section level5" number="13.1.5.2.1">
<h5><span class="header-section-number">13.1.5.2.1</span> Weighted Least Squares</h5>
<p>The Weighted Least Squares (WLS) estimator imposes that <span class="math inline">\(\tau^2=0\)</span>.
It is thus appropriate when we have a fixed effects linear model.
It is also used as a starting point for estimating the other models.</p>
<p>The WLS estimator of <span class="math inline">\(\mathbf{\beta}\)</span> is written as follows:</p>
<p><span class="math display">\[\begin{align*}
  \mathbf{\hat{\beta}}_{WLS} &amp; = \left(\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k}\mathbf{X}_k&#39;\hat{\theta}_k.
\end{align*}\]</span></p>
<p>The WLS estimator is similar to the standard OLS estimator, except that it gives more weight to mmore precise estimates of the treatment effect.
This is a generalization of the weighted average that we have studied in Section <a href="meta.html#MetaWA">13.1.3</a>.</p>
</div>
<div id="full-maximum-likelihood-estimator" class="section level5" number="13.1.5.2.2">
<h5><span class="header-section-number">13.1.5.2.2</span> Full Maximum Likelihood Estimator</h5>
<p>The Full Maximum Likelihood Estimator (FMLE) is also a weighted estimator, but, as the random effects estimator presented in Section <a href="meta.html#sec:RE">13.1.4.2</a>, it uses as weigths not only the precision estimates (<span class="math inline">\(\frac{1}{\hat{\sigma}^2_k}\)</span>), but the inverse of the sum of the variance due to sampling noise and the variance due to variation in treatment effects across sites.
In order to make all of this clearer, let’s define <span class="math inline">\(\omega_k = \epsilon_k + \nu_k\)</span>, and let’s denote <span class="math inline">\(\zeta^2_{k}=\hat{\sigma}^2_k+\tau^2\)</span> the variance of <span class="math inline">\(\omega_k\)</span>.
The estimatingn equations for the FMLE estimator are:</p>
<p><span class="math display">\[\begin{align*}
  \mathbf{\hat{\beta}}_{FMLE} &amp; = \left(\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\hat{\theta}_k,\\
 \hat{\tau}^2_{FMLE} &amp; = \frac{\sum_{k=1}^N\frac{1}{\hat{\zeta}^4_k}\left((\hat{\theta}_k -\mathbf{X}_k\mathbf{\beta})^2-\hat{\sigma}^2_k\right)}{\sum_{k=1}^N\frac{1}{\hat{\zeta}^4_k}}
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\hat{\zeta}^2_k\)</span> is an estimate of <span class="math inline">\(\zeta^2_{k}\)</span>.
In general, the FEML model is estimated by using a first guess for <span class="math inline">\(\mathbf{\beta}\)</span>, for example <span class="math inline">\(\mathbf{\hat{\beta}}_{WLS}\)</span>.
Using this first estimate, we can compute a first estimate of <span class="math inline">\(\hat{\tau}^2\)</span> and update the set of weights, and iterate until convergence.</p>
</div>
<div id="restricted-maximum-likelihood-estimator" class="section level5" number="13.1.5.2.3">
<h5><span class="header-section-number">13.1.5.2.3</span> Restricted Maximum Likelihood Estimator</h5>
<p>The Restricted Maximum Likelihood Estimator (RMLE) is a weigthed estimator that is very similar to the FMLE estimator, except that the estimation procedure focuses on estimating <span class="math inline">\(\tau^2\)</span> first.
As a consequence, the formula for the <span class="math inline">\(\tau^2\)</span> estimator is different:</p>
<p><span class="math display">\[\begin{align*}
  \mathbf{\hat{\beta}}_{RMLE} &amp; = \left(\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\hat{\theta}_k,\\
 \hat{\tau}^2_{RMLE} &amp; = \frac{\sum_{k=1}^N\frac{1}{\hat{\zeta}^4_k}\left((\hat{\theta}_k -\mathbf{X}_k\mathbf{\beta})^2-\hat{\sigma}^2_k\right)
                          +\text{tr}\left[\left(\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\frac{1}{\hat{\zeta}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right]}
                          {\sum_{k=1}^N\frac{1}{\hat{\zeta}^4_k}}.
\end{align*}\]</span></p>
<p>Again, this estimator an be computed in a recursive way, starting with an initial guesstimate for the parameters <span class="math inline">\(\beta\)</span>, for example the simple <span class="math inline">\(WLS\)</span> estimator.</p>
</div>
<div id="method-of-moments-mom" class="section level5" number="13.1.5.2.4">
<h5><span class="header-section-number">13.1.5.2.4</span> Method Of Moments (MOM)</h5>
<p>The Methods Of Moments estimator (MOM) does not require to assume that the distirbution of <span class="math inline">\(\nu_k\)</span> is normal.
MOM only assumes that the distribution of <span class="math inline">\(\nu_k\)</span> is i.i.d. with mean zero and variance <span class="math inline">\(\tau^2\)</span>.
The MOM estimator is a three-step estimator:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(\beta\)</span> using a simple regression that does require knowing <span class="math inline">\(\tau^2\)</span>.</li>
<li>Estimate <span class="math inline">\(\tau^2\)</span> from the residuals of this regression.</li>
<li>Run a Weighted Least Squares regression including the new estimate of <span class="math inline">\(\tau^2\)</span> in the weights.</li>
</ol>
<p>When the first step uses a simple OLS estimator, we have:</p>
<p><span class="math display">\[\begin{align*}
  \mathbf{\hat{\beta}}_{OLS} &amp; = \left(\sum_{k=1}^N\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\mathbf{X}_k&#39;\hat{\theta}_k \\
  \hat{\tau}^2_{OLS} &amp; = \frac{RSS-\sum_{k=1}^N\hat{\sigma}^2_k-\text{tr}(S)}{k-p-1}, 
\end{align*}\]</span></p>
<p>where <span class="math inline">\(RSS\)</span> is the Residual Sum of Squares of the OLS regression, <span class="math inline">\(p\)</span> is the number of covariates and:</p>
<p><span class="math display">\[\begin{align*}
S &amp; = \left(\sum_{k=1}^N\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\mathbf{X}_k&#39;\mathbf{X}_k.
\end{align*}\]</span></p>
<p>When the first step uses the WLS estimator, we have:</p>
<p><span class="math display">\[\begin{align*}
  \hat{\tau}^2_{WLS} &amp; = \frac{WRSS-(k-p-1)}{\text{tr}(M)}, 
\end{align*}\]</span></p>
<p>where <span class="math inline">\(WRSS\)</span> is the Residual Sum of Squares of the WLS regression and:</p>
<p><span class="math display">\[\begin{align*}
\text{tr}(M) &amp; = \sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k} -\text{tr}\left(\left(\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}\sum_{k=1}^N\frac{1}{\hat{\sigma}^4_k}\mathbf{X}_k&#39;\mathbf{X}_k\right).
\end{align*}\]</span></p>
</div>
</div>
<div id="estimating-sampling-noise-in-the-meta-regression-model" class="section level4" number="13.1.5.3">
<h4><span class="header-section-number">13.1.5.3</span> Estimating sampling noise in the meta-regression model</h4>
<div id="under-homoskedasticity" class="section level5" number="13.1.5.3.1">
<h5><span class="header-section-number">13.1.5.3.1</span> Under homoskedasticity</h5>
<p>Under homoskedasticity, we’re assuming that the variance of the treatment effect at various sites does not depend on the site characteristics <span class="math inline">\(\mathbf{X}_k\)</span>.
In that case, the variance of the estimated coefficients is estimated by:</p>
<p><span class="math display">\[\begin{align*}
\hat{\text{Var}}_{Homo}(\hat{\mathbf{\beta}}) &amp; = \left(\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}.
\end{align*}\]</span></p>
</div>
<div id="under-heteroskedasticity" class="section level5" number="13.1.5.3.2">
<h5><span class="header-section-number">13.1.5.3.2</span> Under heteroskedasticity</h5>
<p>Under heteroskedasticity, we allow the variance <span class="math inline">\(\tau^2\)</span> to depend on <span class="math inline">\(\mathbf{X}_k\)</span>.
One correct estimator under that assumption is the Huber-White sandwich estimator:</p>
<p><span class="math display">\[\begin{align*}
\hat{\text{Var}}_{HW}(\hat{\mathbf{\beta}}) &amp; = \left(\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}
                                                  \sum_{k=1}^N\left(\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}\right)^2
                                                  \mathbf{X}_k&#39;(\hat{\theta}_k-\mathbf{X}_k\hat{\mathbf{\beta}})^2\mathbf{X}_k
                                                  \left(\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}\mathbf{X}_k&#39;\mathbf{X}_k\right)^{-1}.
\end{align*}\]</span></p>

<div class="example">
<span id="exm:unnamed-chunk-245" class="example"><strong>Example 13.9  </strong></span>Let’s see how all of these estimators work in our example.
In order to run a regression, I first need a covariate.
I’m going to use the exact value of the noise that I’ve added to the regressions, so that I should be able to perfectly capture the heterogeneity in treatment effects.
Let’s see how this works.
</div>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="meta.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let me generate the noise as a deviation from the true treatment effect</span></span>
<span id="cb232-2"><a href="meta.html#cb232-2" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>nu<span class="fl">.1</span> <span class="ot">&lt;-</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span> <span class="sc">-</span> data.meta<span class="sc">$</span>ES</span>
<span id="cb232-3"><a href="meta.html#cb232-3" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>nu<span class="fl">.2</span> <span class="ot">&lt;-</span> data.meta<span class="sc">$</span>theta<span class="fl">.2</span> <span class="sc">-</span> data.meta<span class="sc">$</span>ES</span>
<span id="cb232-4"><a href="meta.html#cb232-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-5"><a href="meta.html#cb232-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Let me now run a meta regression</span></span>
<span id="cb232-6"><a href="meta.html#cb232-6" aria-hidden="true" tabindex="-1"></a>metaReg.example.RE.theta.<span class="fl">1.</span>ES <span class="ot">&lt;-</span> <span class="fu">lapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> nu<span class="fl">.1</span>,<span class="at">data=</span>data.meta,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method))})</span>
<span id="cb232-7"><a href="meta.html#cb232-7" aria-hidden="true" tabindex="-1"></a>metaReg.example.RE.theta.<span class="fl">2.</span>ES <span class="ot">&lt;-</span> <span class="fu">lapply</span>(estimators,<span class="cf">function</span>(method){<span class="fu">return</span>(<span class="fu">rma</span>(theta<span class="fl">.2</span> <span class="sc">~</span> nu<span class="fl">.2</span>,<span class="at">data=</span>data.meta,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span>method))})</span>
<span id="cb232-8"><a href="meta.html#cb232-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-9"><a href="meta.html#cb232-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Let&#39;s see what the estimation looks like when we ran an REML regression:</span></span>
<span id="cb232-10"><a href="meta.html#cb232-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(metaReg.example.RE.theta.<span class="fl">1.</span>ES[[<span class="dv">2</span>]])</span></code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 20; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
##  12.3736  -24.7471  -18.7471  -16.0760  -17.0329   
## 
## tau^2 (estimated amount of residual heterogeneity):     0 (SE = 0.0005)
## tau (square root of estimated tau^2 value):             0
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   1.00
## R^2 (amount of heterogeneity accounted for):            100.00%
## 
## Test for Residual Heterogeneity:
## QE(df = 18) = 11.7947, p-val = 0.8577
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 1009.6599, p-val &lt; .0001
## 
## Model Results:
## 
##          estimate      se     zval    pval   ci.lb   ci.ub 
## intrcpt    0.1981  0.0085  23.1790  &lt;.0001  0.1813  0.2148  *** 
## nu.1       0.9708  0.0306  31.7751  &lt;.0001  0.9109  1.0307  *** 
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We can see that the estimated coefficient for the noise is large and almost equal to one, that the estimation of residual inter-site variance becomes zero and that the precision of our estimared treatment effect becomes much greater (since all variance due to site effects has been absorbed by the regressor).</p>
<p>Let’s now look at the estimated coefficients.
For that, we are going to use the function <code>coef(summary())</code> that extracts a dataframe of the coefficients along with their standard errors.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="meta.html#cb234-1" aria-hidden="true" tabindex="-1"></a>list.coef.tot<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lapply</span>(metaReg.example.RE.theta.<span class="fl">1.</span>ES,<span class="cf">function</span>(res){<span class="fu">return</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(res)))})</span>
<span id="cb234-2"><a href="meta.html#cb234-2" aria-hidden="true" tabindex="-1"></a>list.coef.tot<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lapply</span>(metaReg.example.RE.theta.<span class="fl">2.</span>ES,<span class="cf">function</span>(res){<span class="fu">return</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(res)))})</span>
<span id="cb234-3"><a href="meta.html#cb234-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-4"><a href="meta.html#cb234-4" aria-hidden="true" tabindex="-1"></a>list.coef<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(list.coef.tot<span class="fl">.1</span>,<span class="st">&#39;[[&#39;</span>,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)))</span>
<span id="cb234-5"><a href="meta.html#cb234-5" aria-hidden="true" tabindex="-1"></a>list.se<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(list.coef.tot<span class="fl">.1</span>,<span class="st">&#39;[[&#39;</span>,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>)))</span>
<span id="cb234-6"><a href="meta.html#cb234-6" aria-hidden="true" tabindex="-1"></a>list.coef<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(list.coef.tot<span class="fl">.2</span>,<span class="st">&#39;[[&#39;</span>,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)))</span>
<span id="cb234-7"><a href="meta.html#cb234-7" aria-hidden="true" tabindex="-1"></a>list.se<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(list.coef.tot<span class="fl">.2</span>,<span class="st">&#39;[[&#39;</span>,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>)))</span>
<span id="cb234-8"><a href="meta.html#cb234-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-9"><a href="meta.html#cb234-9" aria-hidden="true" tabindex="-1"></a>result.Meta <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Method=</span><span class="fu">rep</span>(estimators,<span class="dv">2</span>),<span class="at">ES.Meta=</span><span class="fu">c</span>(list.coef<span class="fl">.1</span>,list.coef<span class="fl">.2</span>),<span class="at">se.ES=</span><span class="fu">c</span>(list.se<span class="fl">.1</span>,list.se<span class="fl">.2</span>),<span class="at">tau2=</span><span class="fu">c</span>(<span class="fu">rep</span>(tau[[<span class="dv">1</span>]]<span class="sc">^</span><span class="dv">2</span>,<span class="fu">length</span>(estimators)),<span class="fu">rep</span>(tau[[<span class="dv">2</span>]]<span class="sc">^</span><span class="dv">2</span>,<span class="fu">length</span>(estimators))))</span>
<span id="cb234-10"><a href="meta.html#cb234-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-11"><a href="meta.html#cb234-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>result.Meta, <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>ES.Meta, <span class="at">group=</span><span class="fu">as.factor</span>(tau2), <span class="at">color=</span><span class="fu">as.factor</span>(tau2))) <span class="sc">+</span></span>
<span id="cb234-12"><a href="meta.html#cb234-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="fl">0.7</span>))<span class="sc">+</span></span>
<span id="cb234-13"><a href="meta.html#cb234-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">min=</span>ES.Meta<span class="sc">-</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES,<span class="at">max=</span>ES.Meta<span class="sc">+</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES),<span class="at">position=</span><span class="fu">position_dodge</span>(<span class="fl">0.7</span>),<span class="at">width=</span><span class="fl">0.1</span>)<span class="sc">+</span></span>
<span id="cb234-14"><a href="meta.html#cb234-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb234-15"><a href="meta.html#cb234-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">expand_limits</span>(<span class="at">y=</span><span class="dv">0</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MetaRegCoef"></span>
<img src="STCI_files/figure-html/MetaRegCoef-1.png" alt="Various estimators of Effect Size in a Meta-Regression" width="60%" />
<p class="caption">
Figure 13.10: Various estimators of Effect Size in a Meta-Regression
</p>
</div>
<p>Figure <a href="meta.html#fig:MetaRegCoef">13.10</a> shows that all estimators perform very well and deliver a precise estimate of the true effect.</p>
<p><strong><span class="smallcaps">I think SJn is the MOM estimator, check that.</span></strong></p>
</div>
</div>
</div>
<div id="constantly-updated-meta-analysis" class="section level3" number="13.1.6">
<h3><span class="header-section-number">13.1.6</span> Constantly updated meta-analysis</h3>
<p>Constantly updated meta-analysis performs the meta-analysis in a progressive manner, as the results keep arriving.
This is a very important tool that enables us to aggregate constantly the information coming from different studies.
Moreover, restrospectively, it helps us to assess when we would have reached enough precision so that we could have foregone an additional study.
The way constantly updated meta-analysis works is simply by performing a new meta-analysis each time a new results pops up.</p>

<div class="example">
<span id="exm:unnamed-chunk-246" class="example"><strong>Example 13.10  </strong></span>Figure <a href="meta.html#fig:cumWMAE">13.11</a> shows how constantly updated meta-analysis works in our example.
</div>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="meta.html#cb235-1" aria-hidden="true" tabindex="-1"></a>cum.wmae<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="cf">function</span>(k,theta,sigma2){</span>
<span id="cb235-2"><a href="meta.html#cb235-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(<span class="fu">weighted.mean</span>(theta[<span class="dv">1</span><span class="sc">:</span>k],(<span class="dv">1</span><span class="sc">/</span>sigma2[<span class="dv">1</span><span class="sc">:</span>k])<span class="sc">/</span>(<span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>sigma2[<span class="dv">1</span><span class="sc">:</span>k]))),<span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>(<span class="dv">1</span><span class="sc">/</span>sigma2[<span class="dv">1</span><span class="sc">:</span>k])))</span>
<span id="cb235-3"><a href="meta.html#cb235-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb235-4"><a href="meta.html#cb235-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-5"><a href="meta.html#cb235-5" aria-hidden="true" tabindex="-1"></a>cum.wmae <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,sigma2){</span>
<span id="cb235-6"><a href="meta.html#cb235-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(theta),cum.wmae<span class="fl">.1</span>,<span class="at">theta=</span>theta,<span class="at">sigma2=</span>sigma2))</span>
<span id="cb235-7"><a href="meta.html#cb235-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb235-8"><a href="meta.html#cb235-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-9"><a href="meta.html#cb235-9" aria-hidden="true" tabindex="-1"></a>cum.test <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">t</span>(<span class="fu">cum.wmae</span>(data.meta<span class="sc">$</span>ES,data.meta<span class="sc">$</span>se.ES<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb235-10"><a href="meta.html#cb235-10" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(cum.test) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;cum.ES&#39;</span>,<span class="st">&#39;cum.var&#39;</span>)</span>
<span id="cb235-11"><a href="meta.html#cb235-11" aria-hidden="true" tabindex="-1"></a>cum.test<span class="sc">$</span>id <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(cum.test)</span>
<span id="cb235-12"><a href="meta.html#cb235-12" aria-hidden="true" tabindex="-1"></a>cum.test<span class="sc">$</span>cum.se.ES <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(cum.test<span class="sc">$</span>cum.var)</span>
<span id="cb235-13"><a href="meta.html#cb235-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-14"><a href="meta.html#cb235-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span>forcats<span class="sc">::</span><span class="fu">fct_rev</span>(<span class="fu">as.factor</span>(id)), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb235-15"><a href="meta.html#cb235-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb235-16"><a href="meta.html#cb235-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb235-17"><a href="meta.html#cb235-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-18"><a href="meta.html#cb235-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-19"><a href="meta.html#cb235-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Initial effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-20"><a href="meta.html#cb235-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb235-21"><a href="meta.html#cb235-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">coord_flip</span>()</span>
<span id="cb235-22"><a href="meta.html#cb235-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-23"><a href="meta.html#cb235-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(cum.test, <span class="fu">aes</span>(<span class="at">x=</span>forcats<span class="sc">::</span><span class="fu">fct_rev</span>(<span class="fu">as.factor</span>(id)), <span class="at">y=</span>cum.ES)) <span class="sc">+</span></span>
<span id="cb235-24"><a href="meta.html#cb235-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_bar</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;black&#39;</span>) <span class="sc">+</span></span>
<span id="cb235-25"><a href="meta.html#cb235-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>cum.ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>cum.se.ES, <span class="at">ymax=</span>cum.ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>cum.se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb235-26"><a href="meta.html#cb235-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-27"><a href="meta.html#cb235-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-28"><a href="meta.html#cb235-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Cumulative effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb235-29"><a href="meta.html#cb235-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb235-30"><a href="meta.html#cb235-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">coord_flip</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cumWMAE"></span>
<img src="STCI_files/figure-html/cumWMAE-1.png" alt="Constantly updated meta-analysis" width="50%" /><img src="STCI_files/figure-html/cumWMAE-2.png" alt="Constantly updated meta-analysis" width="50%" />
<p class="caption">
Figure 13.11: Constantly updated meta-analysis
</p>
</div>
<p>Figure <a href="meta.html#fig:cumWMAE">13.11</a> shows that combining several imprecise estimates might help you reach the same precision as running a larger experiment.<br />
For instance, cumulating the first 10 studies with a small sample size (<span class="math inline">\(N=\)</span> 100), the meta-analytic effect is estimated at 0.2 <span class="math inline">\(\pm\)</span> 0.18.
This is very close to the individual estimate obtained from the first estimate with a larger sample size (sample 11 on Figure <a href="meta.html#fig:cumWMAE">13.11</a>, with <span class="math inline">\(N=\)</span> 1000): 0.17 <span class="math inline">\(\pm\)</span> 0.18.
Both estimates actually have the exact same precision (because they actually have the same sample size).
The same is true when combining the first 17 studies.
The meta-analytic effect is estimated at 0.24 <span class="math inline">\(\pm\)</span> 0.06, while the effect estimated using one unique RCT with a larger sample size (sample 18 on Figure <a href="meta.html#fig:cumWMAE">13.11</a>, with <span class="math inline">\(N=\)</span> 10^{4}) is 0.21 <span class="math inline">\(\pm\)</span> 0.05.
Finally, the same result occurs when combining the first 19 studies.
The meta-analytic effect is estimated at 0.21 <span class="math inline">\(\pm\)</span> 0.03, while the effect estimated using one unique RCT with a larger sample size (sample 20 on Figure <a href="meta.html#fig:cumWMAE">13.11</a>, with <span class="math inline">\(N=\)</span> 10^{5}) is 0.19 <span class="math inline">\(\pm\)</span> 0.02.</p>
<p>As a conclusion, constantly updated meta-analysis would have each time delivered the same result than the one found with a much larger study, rendering this additional study almost irrelevant.
This is a very important result: beyond the apparent messiness of the first noisy estimates in Figures <a href="meta.html#fig:confintervalESCLT">13.1</a> and <a href="meta.html#fig:FEforestplot">13.3</a> lies an order that can be retrieved and made apparent using constantly updated meta-analysis.
Sometimes, the answer is right there in front of our eyes, we just lack the ability to see it.
Constantly updated meta-analysis serves as a binocular to magnify what is there.
Think about how costly it woud be to run a very large study, just to find out that the we did not really need it because we had known the result all along.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Something pretty cool is that I can reproduce Figure <a href="meta.html#fig:cumWMAE">13.11</a> using the <code>metafor</code> package with much less lines of code.
</div>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="meta.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(meta.example.FE,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</span>
<span id="cb236-2"><a href="meta.html#cb236-2" aria-hidden="true" tabindex="-1"></a>cumul.meta.example.FE <span class="ot">&lt;-</span> <span class="fu">cumul</span>(meta.example.FE, <span class="at">order=</span>data.meta<span class="sc">$</span>id)</span>
<span id="cb236-3"><a href="meta.html#cb236-3" aria-hidden="true" tabindex="-1"></a><span class="fu">forest</span>(cumul.meta.example.FE,<span class="at">slab =</span> <span class="fu">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="sc">$</span>id,<span class="at">sep=</span><span class="st">&#39; &#39;</span>),<span class="at">xlab=</span><span class="st">&#39;Estimated Meta-analytic Cumulated Parameter&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cumWMAEmetafor"></span>
<img src="STCI_files/figure-html/cumWMAEmetafor-1.png" alt="Constantly updated meta-analysis with the `metafor` package" width="50%" /><img src="STCI_files/figure-html/cumWMAEmetafor-2.png" alt="Constantly updated meta-analysis with the `metafor` package" width="50%" />
<p class="caption">
Figure 13.12: Constantly updated meta-analysis with the <code>metafor</code> package
</p>
</div>
<p>You can also call each of the individual results of the cumulative meta-analysis using <code>cumul.meta.example.FE$estimate</code>.
For example, the cumulated effect size after the 10 first studies is equal to 0.2 <span class="math inline">\(\pm\)</span> 0.18.</p>
</div>
</div>
<div id="publication-bias-and-site-selection-bias" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Publication bias and site selection bias</h2>
<p>Up to now, we have made the assumption that a meta-analysis can access the results of <strong>ALL</strong> of the studies conducted on a topic.
Problems appear when the publisehd record does not contain <strong>ALL</strong> of the studies conducted on a topic, but only a non-representative sample of them.</p>
<p>In the first section below, I detail the two main types of biases: publication bias and site selection bias.
In the second section, I present methods that help to detect and correct for publication bias.
In the third section, I present methods tha help to detect and correct for site selection bias.
In the last section, I take a step back and ask whether publication bias can be somehow optimal.</p>
<div id="sources-of-publication-bias-and-of-site-selection-bias-and-questionable-research-practices" class="section level3" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Sources of publication bias and of site selection bias and Questionable Research Practices</h3>
<p>This section explains the sources of publication bias and site selection bias.
I also expalin how they trigger the use of Questionable Research Practices that bias the published record even more.</p>
<div id="publication-bias-1" class="section level4" number="13.2.1.1">
<h4><span class="header-section-number">13.2.1.1</span> Publication bias</h4>
<p>There is publication bias when the eventual publication of the results of a research project depends on the results themselves.
In general, the probability that a result is published increases drastically when the results reach the usual levels of statistical significance.
On the contrary, the probability that a non significant result is published decreases drastically.</p>
<p><strong><span class="smallcaps">Give evidence of that behavior.</span></strong></p>
<p>The reasons for this behavior are pretty well understood: editors and referees consider that only statistically significant results are of scientific interest, and that non significant results bring close to no information on a topic, especially if they are imprecise.
Knowing this, most researchers choose not to invest time in trying to send a paper with a non significant result for publication.</p>
<p>What are the consequences of publishing only statistically significant results?
Well, among imprecisely estimated effects, only the largest ones are going to reach publication, generating a pattern of overestimation of the true treatment effect.
They key trade-off is whether the resulting bias is very large or not.</p>

<div class="example">
<span id="exm:unnamed-chunk-248" class="example"><strong>Example 13.11  </strong></span>What does publication bias look like in our example?
Let’s assume that only statistically significant effects are published.
Would it change our estimate?
In order to see whether that is the case, let’s build Figure <a href="meta.html#fig:confintervalESCLT">13.1</a> with the addition of fixed effects estimator using all results and using only statistically significant results.
</div>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="meta.html#cb237-1" aria-hidden="true" tabindex="-1"></a>meta.example.FE.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb237-2"><a href="meta.html#cb237-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-3"><a href="meta.html#cb237-3" aria-hidden="true" tabindex="-1"></a>meta.example.FE.small <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>ES,<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb237-4"><a href="meta.html#cb237-4" aria-hidden="true" tabindex="-1"></a>meta.example.FE.small.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb237-5"><a href="meta.html#cb237-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-6"><a href="meta.html#cb237-6" aria-hidden="true" tabindex="-1"></a>meta.example.FE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>ES,<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb237-7"><a href="meta.html#cb237-7" aria-hidden="true" tabindex="-1"></a>meta.example.FE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb237-8"><a href="meta.html#cb237-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-9"><a href="meta.html#cb237-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>), <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb237-10"><a href="meta.html#cb237-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-11"><a href="meta.html#cb237-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-12"><a href="meta.html#cb237-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-13"><a href="meta.html#cb237-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE.small)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-14"><a href="meta.html#cb237-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE.small.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-15"><a href="meta.html#cb237-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (only small sample size)&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-16"><a href="meta.html#cb237-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-17"><a href="meta.html#cb237-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span>
<span id="cb237-18"><a href="meta.html#cb237-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-19"><a href="meta.html#cb237-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>), <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb237-20"><a href="meta.html#cb237-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-21"><a href="meta.html#cb237-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-22"><a href="meta.html#cb237-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-23"><a href="meta.html#cb237-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE.interm)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-24"><a href="meta.html#cb237-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE.interm.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-25"><a href="meta.html#cb237-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (only small and intermediate sample size)&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-26"><a href="meta.html#cb237-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-27"><a href="meta.html#cb237-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span>
<span id="cb237-28"><a href="meta.html#cb237-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-29"><a href="meta.html#cb237-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>ES)) <span class="sc">+</span></span>
<span id="cb237-30"><a href="meta.html#cb237-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-31"><a href="meta.html#cb237-31" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>ES<span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>ES<span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb237-32"><a href="meta.html#cb237-32" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-33"><a href="meta.html#cb237-33" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-34"><a href="meta.html#cb237-34" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.FE.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-35"><a href="meta.html#cb237-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (all)&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-36"><a href="meta.html#cb237-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb237-37"><a href="meta.html#cb237-37" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PubBias"></span>
<img src="STCI_files/figure-html/PubBias-1.png" alt="Illustration of publication bias" width="33%" /><img src="STCI_files/figure-html/PubBias-2.png" alt="Illustration of publication bias" width="33%" /><img src="STCI_files/figure-html/PubBias-3.png" alt="Illustration of publication bias" width="33%" />
<p class="caption">
Figure 13.13: Illustration of publication bias
</p>
</div>
<p>Figure <a href="meta.html#fig:PubBias">13.13</a> shows that publication bias can be a sizable problem.
Remember that the true effect that we are trying to estimate is NA.
When only imprecise studies with small sample size are available, the effect estimated using only the statistically significant studies (actually, the only study that reports a statistically significant result) is equal to 0.51 <span class="math inline">\(\pm\)</span> 0.5, while the effect estimated all the 10 studies with a small sample size is 0.2 <span class="math inline">\(\pm\)</span> 0.18.
When studies with small and intermediate sample size are available, the effect estimated using only the statistically significant studies is equal to 0.29 <span class="math inline">\(\pm\)</span> 0.08, while the effect estimated all the 17 studies with a small and intermediate sample size is 0.24 <span class="math inline">\(\pm\)</span> 0.06.
It is only when studies with large and very large sample size are added to the estimation that publication bias is not a problem anymore.
The effect estimated using only the statistically significant studies is equal to 0.2 <span class="math inline">\(\pm\)</span> 0.02, while the effect estimated all the studies is 0.19 <span class="math inline">\(\pm\)</span> 0.02.</p>
<p>As a conclusion of Figure <a href="meta.html#fig:PubBias">13.13</a>, publication bias biases the true effect by:</p>
<ul>
<li>NA %, or NA of a standard deviation, with studies with a small sample size,</li>
<li>NA %, or NA of a standard deviation, with studies with a small or intermediate sample size,</li>
<li>NA %, or NA of a standard deviation, with all studies.</li>
</ul>
<p>With random effects, this behavior becomes even more severe, since only the sites at which the program has worked are going to appear in the published record, thereby biasing downards the true heterogeneity in treatment effects.</p>

<div class="example">
<span id="exm:unnamed-chunk-249" class="example"><strong>Example 13.12  </strong></span>Here is how that impacts the truth in our example:
</div>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="meta.html#cb238-1" aria-hidden="true" tabindex="-1"></a>meta.example.RE <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-2"><a href="meta.html#cb238-2" aria-hidden="true" tabindex="-1"></a>meta.example.RE.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> data.meta<span class="sc">$</span>theta<span class="fl">.1</span>[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span>data.meta<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-3"><a href="meta.html#cb238-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-4"><a href="meta.html#cb238-4" aria-hidden="true" tabindex="-1"></a>meta.example.RE.small <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-5"><a href="meta.html#cb238-5" aria-hidden="true" tabindex="-1"></a>meta.example.RE.small.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>theta<span class="fl">.1</span>[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>)<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-6"><a href="meta.html#cb238-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-7"><a href="meta.html#cb238-7" aria-hidden="true" tabindex="-1"></a>meta.example.RE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-8"><a href="meta.html#cb238-8" aria-hidden="true" tabindex="-1"></a>meta.example.RE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(<span class="at">yi =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>theta<span class="fl">.1</span>[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES[<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)],<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb238-9"><a href="meta.html#cb238-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-10"><a href="meta.html#cb238-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">10</span>), <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>theta<span class="fl">.1</span>)) <span class="sc">+</span></span>
<span id="cb238-11"><a href="meta.html#cb238-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-12"><a href="meta.html#cb238-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>theta<span class="fl">.1</span><span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>theta<span class="fl">.1</span><span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-13"><a href="meta.html#cb238-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-14"><a href="meta.html#cb238-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE.small)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-15"><a href="meta.html#cb238-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE.small.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-16"><a href="meta.html#cb238-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (only small sample size)&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-17"><a href="meta.html#cb238-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-18"><a href="meta.html#cb238-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span>
<span id="cb238-19"><a href="meta.html#cb238-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-20"><a href="meta.html#cb238-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>), <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>theta<span class="fl">.1</span>)) <span class="sc">+</span></span>
<span id="cb238-21"><a href="meta.html#cb238-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-22"><a href="meta.html#cb238-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>theta<span class="fl">.1</span><span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>theta<span class="fl">.1</span><span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-23"><a href="meta.html#cb238-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-24"><a href="meta.html#cb238-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE.interm)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-25"><a href="meta.html#cb238-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE.interm.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-26"><a href="meta.html#cb238-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (only small and intermediate sample size)&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-27"><a href="meta.html#cb238-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-28"><a href="meta.html#cb238-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span>
<span id="cb238-29"><a href="meta.html#cb238-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-30"><a href="meta.html#cb238-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(data.meta, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.factor</span>(id), <span class="at">y=</span>theta<span class="fl">.1</span>)) <span class="sc">+</span></span>
<span id="cb238-31"><a href="meta.html#cb238-31" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_point</span>(<span class="at">position=</span><span class="fu">position_dodge</span>(), <span class="at">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="at">colour=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-32"><a href="meta.html#cb238-32" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin=</span>theta<span class="fl">.1</span><span class="sc">-</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES, <span class="at">ymax=</span>theta<span class="fl">.1</span><span class="sc">+</span><span class="fu">qnorm</span>((delta<span class="fl">.2</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>se.ES), <span class="at">width=</span>.<span class="dv">2</span>,<span class="at">position=</span><span class="fu">position_dodge</span>(.<span class="dv">9</span>),<span class="at">color=</span><span class="st">&#39;blue&#39;</span>) <span class="sc">+</span></span>
<span id="cb238-33"><a href="meta.html#cb238-33" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">ES</span>(param)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-34"><a href="meta.html#cb238-34" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE)), <span class="at">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-35"><a href="meta.html#cb238-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept=</span><span class="fu">coef</span>(meta.example.RE.pubbias)), <span class="at">colour=</span><span class="st">&quot;green&quot;</span>, <span class="at">linetype=</span><span class="st">&quot;dotted&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-36"><a href="meta.html#cb238-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">xlab</span>(<span class="st">&quot;Studies (all)&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-37"><a href="meta.html#cb238-37" aria-hidden="true" tabindex="-1"></a>      <span class="fu">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="sc">+</span></span>
<span id="cb238-38"><a href="meta.html#cb238-38" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PubBiasRE"></span>
<img src="STCI_files/figure-html/PubBiasRE-1.png" alt="Illustration of publication bias with Random Effects" width="33%" /><img src="STCI_files/figure-html/PubBiasRE-2.png" alt="Illustration of publication bias with Random Effects" width="33%" /><img src="STCI_files/figure-html/PubBiasRE-3.png" alt="Illustration of publication bias with Random Effects" width="33%" />
<p class="caption">
Figure 13.14: Illustration of publication bias with Random Effects
</p>
</div>
<p>Figure <a href="meta.html#fig:PubBiasRE">13.14</a> shows that publication bias can be a sizable problem with random effects as well.
Remember that the true effect that we are trying to estimate is NA.
When only imprecise studies with small sample size are available, the effect estimated using only the statistically significant studies is equal to 0.64 <span class="math inline">\(\pm\)</span> 0.29, while the effect estimated all the 10 studies with a small sample size is 0.17 <span class="math inline">\(\pm\)</span> 0.27.
When studies with small and intermediate sample size are available, the effect estimated using only the statistically significant studies is equal to 0.26 <span class="math inline">\(\pm\)</span> 0.39, while the effect estimated all the 17 studies with a small and intermediate sample size is 0.14 <span class="math inline">\(\pm\)</span> 0.27.
It is only when studies with large and very large sample size are added to the estimation that publication bias is not a problem anymore.
The effect estimated using only the statisticaly significant studies is equal to 0.22 <span class="math inline">\(\pm\)</span> 0.31, while the effect estimated all the studies is 0.13 <span class="math inline">\(\pm\)</span> 0.23.</p>
<p>As a conclusion of Figure <a href="meta.html#fig:PubBias">13.13</a>, publication bias biases the true effect by:</p>
<ul>
<li>NA %, or NA of a standard deviation, with studies with a small sample size,</li>
<li>NA %, or NA of a standard deviation, with studies with a small or intermediate sample size,</li>
<li>NA %, or NA of a standard deviation, with all studies.</li>
</ul>
</div>
<div id="site-selection-bias-1" class="section level4" number="13.2.1.2">
<h4><span class="header-section-number">13.2.1.2</span> Site selection bias</h4>
<p>There is site selection bias when researchers only implement an intervention in sites where they expect it to work.
How can they do so?
There are several informations that one can use to select sites for implementing a treatment and maximizing its effectiveness.
First, researchers might only be able to work with highly motivated implementation agents.
This might generate larger effects of the treatment.
Second, researchers might have an informal knowledge on the types of individuals who react to the treatment well, and might decide to include them preferentially in the experimental study.
Third, researchers might try out several different treatments in small informal pilots, and choose to run at scale only the most effective one(s).
Finally, researchers, by conducting an extensive diagnosis of the problem that they face on the ground, might end up selecting a treatment that is more appropriate than a randomly selected treatment.</p>
<p>What are the consequences of site selection bias?
If the selection process remains undocumented, a policy-maker trying to implement a treatment with a proven track record might fail to obtain the expected results because the site on which she decides to implement it is not representative of the distribution of sites in which the program has been evaluated.
Ommitting to detail the process of site selection is akin to not explaining the recommendations of use, or worse the diagnosis of the disease, for a drug.
If we do not know which disease the drug is effective against, we might end up expecting great results of a cold medecine against cancer.</p>
<p><strong><span class="smallcaps">Simulations.</span></strong></p>
</div>
<div id="questionable-research-practices" class="section level4" number="13.2.1.3">
<h4><span class="header-section-number">13.2.1.3</span> Questionable Research Practices</h4>
<p>Publication bias triggers and is aggravated by the use of Questionable Research Practices (QRPs).
QRPs enable researchers (sometimes unknowingly) to obtain more statistically significant results than should be the case in view of the true effect of the treatment that they are looking at and the power of their test.
Normally, when a treatment has no effect, only 5% of the treatment effects are going to turn out positive and significant when using a standard two-sided t-test.
But, with QRPs, this figure can increase to 10, 20 or even, 50% in some cases.</p>
<p><strong><span class="smallcaps">References.</span></strong></p>
<p>What are the most usual QRPs?</p>
<ul>
<li>Choosing a sample that generates significant effects: that includes stopping data collection when an effet of interest is found or deciding on critera of inclusion of observations based on statistical singificance.
Sometimes, simply stopping to do robustness checks when results are significant is enough to bias usual tests of statistical significance.</li>
<li>Choosing an outcome because the effect of the treatment is statistically significant.
If we test a treatment on 100 outcomes for which the true effect of the treatment is null, between 2 and 3 outcomes are expected to turn out with positive effects just by the sheer property of the tests that we are using.</li>
<li>Choosing an identification strategy that generates significant treatment effects.
Researcher smight try out various instruments and various natural experiments before settling down on the one that yields a statistically significant result.</li>
<li>Choosing a subgroup for which significant effects are obtained.
Analysis by subgroups offers a lot of opportunities for finding spurious significant effects.</li>
</ul>
<p>The key question is whether these QRPs only move borderline significant results into the realm of significance, and thus have small effects of the size of the treatment effect, or if they enable to transform small effects into much larger ones.
Note though that even if the QRPs only transform barely non-significant results in barely significant ones, the sheer repetition of these results in a meta-analysis is going to overestimate precision and might yield eventually to a confidence interval that does not contain the true effect, maybe by a large margin.</p>
<p><strong><span class="smallcaps">Simulations.</span></strong></p>
</div>
</div>
<div id="detection-of-and-correction-for-publication-bias" class="section level3" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Detection of and correction for publication bias</h3>
<p>Over the years, researchers have become aware of the problem that publication bias raises for meta-analyses and they have developed methods to detect and correct for it.</p>
<div id="funnel-plot-asymmetry" class="section level4" number="13.2.2.1">
<h4><span class="header-section-number">13.2.2.1</span> Funnel plot asymmetry</h4>
<p>The first tool to identify the extent of publication bias is the funnel plot.
The funnel plot plots the effect size as a function of its precision (or standard error).
In the absence of publication bias, results should be distributed symetrically around the mean treatment effect estimate.
We say that in this case the funnel plot is symmetric.
In the presence of publication bias, results that are not statistically significant will be missing.
They will be concentrated on the lower left part of the plot, were standard errors are large and estimated effects small.
Missing results generate an asymetric funnel plot.</p>

<div class="example">
<span id="exm:unnamed-chunk-250" class="example"><strong>Example 13.13  </strong></span>Let’s see how the funnel plot works in our example.
</div>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="meta.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="fu">funnel</span>(meta.example.FE.interm,<span class="at">xlab=</span><span class="st">&#39;Effect size (without publication bias)&#39;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.382</span>,<span class="dv">0</span>),<span class="at">refline=</span><span class="dv">0</span>)</span>
<span id="cb239-2"><a href="meta.html#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb239-3"><a href="meta.html#cb239-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">coef</span>(meta.example.FE.interm),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb239-4"><a href="meta.html#cb239-4" aria-hidden="true" tabindex="-1"></a><span class="fu">funnel</span>(meta.example.FE.interm.pubbias,<span class="at">xlab=</span><span class="st">&#39;Effect size (with publication bias)&#39;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.382</span>,<span class="dv">0</span>),<span class="at">refline=</span><span class="dv">0</span>)</span>
<span id="cb239-5"><a href="meta.html#cb239-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb239-6"><a href="meta.html#cb239-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">coef</span>(meta.example.FE.interm.pubbias),<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FunnelPlotFE"></span>
<img src="STCI_files/figure-html/FunnelPlotFE-1.png" alt="Funnel plot with and without publication bias (homogeneous treatment effects, small and intermediate precision)" width="50%" /><img src="STCI_files/figure-html/FunnelPlotFE-2.png" alt="Funnel plot with and without publication bias (homogeneous treatment effects, small and intermediate precision)" width="50%" />
<p class="caption">
Figure 13.15: Funnel plot with and without publication bias (homogeneous treatment effects, small and intermediate precision)
</p>
</div>
<p>Figure <a href="meta.html#fig:FunnelPlotFE">13.15</a> shows how a funnel plot works.
The x-axis presents the effect size of each study (here, in the homogeneous treatment effect case, analyzed using fixed effects).
The y-axis presents the standard error, in an inverted scale, so that the most precise studies appear at the top of the graph.
The two diagonal lines stemming out of zero present the 95% confidence intervals arounf zero, a.k.a. the two sided tests of statistical significance.
In the plot, we focus of studies with small to intermediate precision.
In our example, very precise studies are so much more precise that they make the problem of publication bias vanish.</p>
<p>When there is no publication bias, the funnel plot does not seem to exhibit asymmetry: there are as many imprecise studies on the left and on the right of the average effect.
When there is publication bias, all the studies that fall within the confidence interval compatible with a zero treatment effect disappear.
As a consequence, the remaining treatment effects are inflated versions of the truth.
Moreover, we see that there is an increasing relationship between standard error and effect size.
This is a sign of funnel plot asymmetry.</p>
<p>For the sake of completeness, Figure <a href="meta.html#fig:FunnelPlotRE">13.16</a> shows what the funnel plot looks like with heterogeneous treatment effects analyzed using a random effects approach.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="meta.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">funnel</span>(meta.example.RE.interm,<span class="at">xlab=</span><span class="st">&#39;Effect size (without publication bias)&#39;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.382</span>,<span class="dv">0</span>),<span class="at">refline=</span><span class="dv">0</span>)</span>
<span id="cb240-2"><a href="meta.html#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb240-3"><a href="meta.html#cb240-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">coef</span>(meta.example.RE.interm),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb240-4"><a href="meta.html#cb240-4" aria-hidden="true" tabindex="-1"></a><span class="fu">funnel</span>(meta.example.RE.interm.pubbias,<span class="at">xlab=</span><span class="st">&#39;Effect size (with publication bias)&#39;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">0.382</span>,<span class="dv">0</span>),<span class="at">refline=</span><span class="dv">0</span>)</span>
<span id="cb240-5"><a href="meta.html#cb240-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb240-6"><a href="meta.html#cb240-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">coef</span>(meta.example.RE.interm.pubbias),<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FunnelPlotRE"></span>
<img src="STCI_files/figure-html/FunnelPlotRE-1.png" alt="Funnel plot with and without publication bias (heterogeneous treatment effects, small and intermediate precision)" width="50%" /><img src="STCI_files/figure-html/FunnelPlotRE-2.png" alt="Funnel plot with and without publication bias (heterogeneous treatment effects, small and intermediate precision)" width="50%" />
<p class="caption">
Figure 13.16: Funnel plot with and without publication bias (heterogeneous treatment effects, small and intermediate precision)
</p>
</div>
<p>How do we implement these intuitions rigorously?
The next section present the tools developed to do just that.</p>
</div>
<div id="fat-pet-peese" class="section level4" number="13.2.2.2">
<h4><span class="header-section-number">13.2.2.2</span> FAT-PET-PEESE</h4>
<p><a href="https://books.google.fr/books?hl=fr&amp;lr=&amp;id=jSQEdEsL7VoC&amp;oi=fnd&amp;pg=PP2&amp;dq=doucouliagos+and+stanley+meta-regression+analysis+in+economics&amp;ots=jTXmePff2F&amp;sig=Dm5EOhOroc5K8EUYvqK4fvJrPs8#v=onepage&amp;q=doucouliagos%20and%20stanley%20meta-regression%20analysis%20in%20economics&amp;f=false">Docouliagos and Stanley (2012)</a> have developed a method based on funnel plot asymmetry to detect publication bias and correct for it.
Their approach is based on three steps:</p>
<ol style="list-style-type: decimal">
<li>The Funnel Asymmetry Test (FAT) that tests whether there is a relationship between effect sizes and their precision.</li>
<li>The Precision-Effect Test (PET) that estimates the effect corrected for publication bias and tests for its existence.</li>
<li>The Precision-Effect Estimate with Standard Error (PEESE) that estimates the effect corrected for publication bias using a non-linear model for the standard error.
When there is a genuine effect, PEESE offers a less biased estimate than PET.</li>
</ol>
<p>The authors suggest to implement these procedures in a sequence, starting with the existence of publication bias, evidence for the existence of a non-zero effect once publication bias is accounted for and then estimate the bias-corrected effect when it is detected to be non-zero.
Let’s examine these approaches in turn.</p>
<p>The FAT and the PET are based on the following meta-regression:</p>
<p><span class="math display">\[\begin{align*}
\hat{\theta}_k &amp; = \alpha_0 + \alpha_1\hat{\sigma}_k  + \epsilon_k + \nu_k,
\end{align*}\]</span></p>
<p>The PEESE is based on the following meta-regression:</p>
<p><span class="math display">\[\begin{align*}
\hat{\theta}_k &amp; = \beta_0 + \beta_1\hat{\sigma}^2_k  + \epsilon_k + \nu_k,
\end{align*}\]</span></p>
<p>Whether we assume that <span class="math inline">\(\tau^2\)</span>, the variance of <span class="math inline">\(\nu_k\)</span> is zero or not makes the FAT model a fixed or a random effects model.
We run this regression with either Weighted Least Squares (in the fixed effects model) or with one of the methods appropriate for random effects (I’m going to use REML in what follows).</p>
<p>The FAT tests the assumption that <span class="math inline">\(\alpha_1=0\)</span> using a standard two-sided t-test.
Rejecting the null means that there is sign of publication bias.
The PET tests whether <span class="math inline">\(\alpha_0=0\)</span>.
Rejecting the null means that there is evidence of a true effect.
The PEESE estimates the bias-corrected effect size by using <span class="math inline">\(\hat{\beta}_1\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-251" class="example"><strong>Example 13.14  </strong></span>Let’s see in practice how FAT, PET and PEESE work in our example.
We are going first to run the regressions on the sample with homogeneous treatment effects, and thus we are going to use the simple Weighted Least Squares approach.
</div>
<p>I’m focusing on the case with only small and intermediate precision estimates, as in the funnel plots in Figure <a href="meta.html#fig:FunnelPlotFE">13.15</a>.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="meta.html#cb241-1" aria-hidden="true" tabindex="-1"></a>FAT.PET.FE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(ES <span class="sc">~</span> <span class="fu">sqrt</span>(var.ES), <span class="at">data=</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb241-2"><a href="meta.html#cb241-2" aria-hidden="true" tabindex="-1"></a>FAT.PET.FE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(ES <span class="sc">~</span> <span class="fu">sqrt</span>(var.ES), <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb241-3"><a href="meta.html#cb241-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb241-4"><a href="meta.html#cb241-4" aria-hidden="true" tabindex="-1"></a>PEESE.FE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(ES <span class="sc">~</span> var.ES, <span class="at">data=</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb241-5"><a href="meta.html#cb241-5" aria-hidden="true" tabindex="-1"></a>PEESE.FE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(ES <span class="sc">~</span> var.ES, <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;FE&quot;</span>)</span>
<span id="cb241-6"><a href="meta.html#cb241-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb241-7"><a href="meta.html#cb241-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(FAT.PET.FE.interm)</span></code></pre></div>
<pre><code>## 
## Fixed-Effects with Moderators Model (k = 17)
## 
##   logLik  deviance       AIC       BIC      AICc 
##   8.6124    9.5293  -13.2247  -11.5583  -12.3676   
## 
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   0.64
## 
## Test for Residual Heterogeneity:
## QE(df = 15) = 9.5293, p-val = 0.8483
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 0.4952, p-val = 0.4816
## 
## Model Results:
## 
##               estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt         0.2791  0.0634   4.4053  &lt;.0001   0.1549  0.4033  *** 
## sqrt(var.ES)   -0.3397  0.4828  -0.7037  0.4816  -1.2861  0.6066      
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="meta.html#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(FAT.PET.FE.interm.pubbias)</span></code></pre></div>
<pre><code>## 
## Fixed-Effects with Moderators Model (k = 6)
## 
##   logLik  deviance       AIC       BIC      AICc 
##   6.4279    3.0645   -8.8557   -9.2722   -4.8557   
## 
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   0.77
## 
## Test for Residual Heterogeneity:
## QE(df = 4) = 3.0645, p-val = 0.5471
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 1.1380, p-val = 0.2861
## 
## Model Results:
## 
##               estimate      se    zval    pval    ci.lb   ci.ub 
## intrcpt         0.1352  0.1470  0.9195  0.3578  -0.1530  0.4233    
## sqrt(var.ES)    1.6351  1.5327  1.0668  0.2861  -1.3691  4.6392    
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="meta.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(PEESE.FE.interm)</span></code></pre></div>
<pre><code>## 
## Fixed-Effects with Moderators Model (k = 17)
## 
##   logLik  deviance       AIC       BIC      AICc 
##   8.6741    9.4058  -13.3483  -11.6818  -12.4911   
## 
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   0.63
## 
## Test for Residual Heterogeneity:
## QE(df = 15) = 9.4058, p-val = 0.8554
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 0.6187, p-val = 0.4315
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt    0.2568  0.0379   6.7699  &lt;.0001   0.1825  0.3312  *** 
## var.ES    -0.9426  1.1983  -0.7866  0.4315  -3.2912  1.4061      
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="meta.html#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(PEESE.FE.interm.pubbias)</span></code></pre></div>
<pre><code>## 
## Fixed-Effects with Moderators Model (k = 6)
## 
##   logLik  deviance       AIC       BIC      AICc 
##   6.3347    3.2508   -8.6694   -9.0859   -4.6694   
## 
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   0.81
## 
## Test for Residual Heterogeneity:
## QE(df = 4) = 3.2508, p-val = 0.5168
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 0.9516, p-val = 0.3293
## 
## Model Results:
## 
##          estimate      se    zval    pval    ci.lb    ci.ub 
## intrcpt    0.2460  0.0569  4.3210  &lt;.0001   0.1344   0.3576  *** 
## var.ES     4.3828  4.4928  0.9755  0.3293  -4.4229  13.1885      
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The results of the analysis are as expected, even though the small sample size prevents us from drawing conclusive results.
When running the regression on the whole sample, in the absence of publication bias, we find that the estimated coefficient for the standard error in the meta-analytic regression is -0.34 <span class="math inline">\(\pm\)</span> 0.95.
As a consequence, the FAT detects no sign of publication bias, with a pretty decent precision level.
When running the regression on the sample with publication bias, we find that the estimated coefficient for the standard error in the meta-analytic regression is 1.64 <span class="math inline">\(\pm\)</span> 3.
The coefficient is positive, as expected if larger results occur with smaller sample size, but the precision of this coefficient is too low for the FAT to be able to detect publication bias.
This is a characteristic of the FAT to have low power, especially in our case where only one observation with small sample size drives all the results.</p>
<p>In the absence of publication bias, the PET detects a positive effect (0.28 <span class="math inline">\(\pm\)</span> 0.12) that is significantly different from zero, which is a sign of existence of a true effect.
The PEESE is of 0.26 <span class="math inline">\(\pm\)</span> 0.07 .
Following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.24 <span class="math inline">\(\pm\)</span> 0.06), since the FAT has not detected signs of publication bias.
In the presence of publication bias, the PET does not detect a positive effect (0.14 <span class="math inline">\(\pm\)</span> 0.29).
The PEESE is of 0.25 <span class="math inline">\(\pm\)</span> 0.11 .
Again, following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.29 <span class="math inline">\(\pm\)</span> 0.08), since the FAT has not detected signs of publication bias.
Note nevertheless that in both cases the PEESE is almost as good as the meta-analytic estimate.</p>
<p>Let’s now look at what happens when we are in a random effects world.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="meta.html#cb249-1" aria-hidden="true" tabindex="-1"></a>FAT.PET.RE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> <span class="fu">sqrt</span>(var.ES), <span class="at">data=</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-2"><a href="meta.html#cb249-2" aria-hidden="true" tabindex="-1"></a>FAT.PET.RE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> <span class="fu">sqrt</span>(var.ES), <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-3"><a href="meta.html#cb249-3" aria-hidden="true" tabindex="-1"></a>FAT.PET.RE.interm.pubbias.pos <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> <span class="fu">sqrt</span>(var.ES), <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>),data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">&gt;</span><span class="dv">0</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>),data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">&gt;</span><span class="dv">0</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-4"><a href="meta.html#cb249-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb249-5"><a href="meta.html#cb249-5" aria-hidden="true" tabindex="-1"></a>PEESE.RE.interm <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> var.ES, <span class="at">data=</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-6"><a href="meta.html#cb249-6" aria-hidden="true" tabindex="-1"></a>PEESE.RE.interm.pubbias <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> var.ES, <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>)),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-7"><a href="meta.html#cb249-7" aria-hidden="true" tabindex="-1"></a>PEESE.RE.interm.pubbias.pos <span class="ot">&lt;-</span> <span class="fu">rma</span>(theta<span class="fl">.1</span> <span class="sc">~</span> var.ES, <span class="at">data =</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>),data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">&gt;</span><span class="dv">0</span>),<span class="at">vi=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>),data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">&gt;</span><span class="dv">0</span>)<span class="sc">$</span>var.ES,<span class="at">method=</span><span class="st">&quot;REML&quot;</span>)</span>
<span id="cb249-8"><a href="meta.html#cb249-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb249-9"><a href="meta.html#cb249-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(FAT.PET.RE.interm)</span></code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 17; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -12.7096   25.4191   31.4191   33.5433   33.6010   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.2872 (SE = 0.1228)
## tau (square root of estimated tau^2 value):             0.5359
## I^2 (residual heterogeneity / unaccounted variability): 94.22%
## H^2 (unaccounted variability / sampling variability):   17.30
## R^2 (amount of heterogeneity accounted for):            0.00%
## 
## Test for Residual Heterogeneity:
## QE(df = 15) = 391.5159, p-val &lt; .0001
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 0.0212, p-val = 0.8842
## 
## Model Results:
## 
##               estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt         0.1733  0.2929   0.5915  0.5542  -0.4009  0.7474    
## sqrt(var.ES)   -0.1876  1.2878  -0.1457  0.8842  -2.7116  2.3364    
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="meta.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(FAT.PET.RE.interm.pubbias)</span></code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 10; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
##  -7.3071   14.6142   20.6142   20.8526   26.6142   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3548 (SE = 0.1874)
## tau (square root of estimated tau^2 value):             0.5956
## I^2 (residual heterogeneity / unaccounted variability): 97.16%
## H^2 (unaccounted variability / sampling variability):   35.27
## R^2 (amount of heterogeneity accounted for):            5.24%
## 
## Test for Residual Heterogeneity:
## QE(df = 8) = 367.0309, p-val &lt; .0001
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 1.4973, p-val = 0.2211
## 
## Model Results:
## 
##               estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt        -0.1548  0.3876  -0.3993  0.6897  -0.9145  0.6050    
## sqrt(var.ES)    3.0194  2.4676   1.2236  0.2211  -1.8170  7.8558    
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="meta.html#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(PEESE.RE.interm)</span></code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 17; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
## -12.6655   25.3311   31.3311   33.4552   33.5129   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.2860 (SE = 0.1221)
## tau (square root of estimated tau^2 value):             0.5348
## I^2 (residual heterogeneity / unaccounted variability): 94.21%
## H^2 (unaccounted variability / sampling variability):   17.28
## R^2 (amount of heterogeneity accounted for):            0.00%
## 
## Test for Residual Heterogeneity:
## QE(df = 15) = 392.0762, p-val &lt; .0001
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 0.0801, p-val = 0.7772
## 
## Model Results:
## 
##          estimate      se     zval    pval    ci.lb   ci.ub 
## intrcpt    0.1801  0.2103   0.8562  0.3919  -0.2321  0.5923    
## var.ES    -0.8540  3.0178  -0.2830  0.7772  -6.7687  5.0607    
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="meta.html#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(PEESE.RE.interm.pubbias)</span></code></pre></div>
<pre><code>## 
## Mixed-Effects Model (k = 10; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc 
##  -7.3644   14.7288   20.7288   20.9671   26.7288   
## 
## tau^2 (estimated amount of residual heterogeneity):     0.3597 (SE = 0.1896)
## tau (square root of estimated tau^2 value):             0.5998
## I^2 (residual heterogeneity / unaccounted variability): 97.21%
## H^2 (unaccounted variability / sampling variability):   35.87
## R^2 (amount of heterogeneity accounted for):            3.91%
## 
## Test for Residual Heterogeneity:
## QE(df = 8) = 370.0068, p-val &lt; .0001
## 
## Test of Moderators (coefficient 2):
## QM(df = 1) = 1.3503, p-val = 0.2452
## 
## Model Results:
## 
##          estimate      se    zval    pval    ci.lb    ci.ub 
## intrcpt    0.0678  0.2540  0.2669  0.7895  -0.4301   0.5657    
## var.ES     7.5975  6.5381  1.1620  0.2452  -5.2169  20.4118    
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>In the absence of publication bias, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is -0.19 <span class="math inline">\(\pm\)</span> 2.52.
As a consequence, the FAT detects no sign of publication bias.
The PET does not detect a positive effect but its estimate is close to the truth, even if imprecise (0.28 <span class="math inline">\(\pm\)</span> 0.57).
We would interpret this as absence of evidence for an effect.
The PEESE is of 0.18 <span class="math inline">\(\pm\)</span> 0.41, close to the truth but highly imprecise.
Following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and should focus only on the simple meta-analytic one (0.14 <span class="math inline">\(\pm\)</span> 0.27), since the FAT has not detected signs of publication bias.</p>
<p>In the presence of publication bias, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is 3.02 <span class="math inline">\(\pm\)</span> 4.84.
The coefficient is positive, as expected if larger results occur with smaller sample size, but the precision of this coefficient is too low for the FAT to be able to detect publication bias.
The PET does not detect a positive effect, and even returns a negative one (-0.15 <span class="math inline">\(\pm\)</span> 0.76), however extremely imprecise.
The PEESE at least returns a positive even though imprecise effect of 0.07 <span class="math inline">\(\pm\)</span> 0.5.
Again, following the practice suggested by Docouliagos and Stanley, we should refrain from using these estimates and focus only on the simple meta-analytic one (0.26 <span class="math inline">\(\pm\)</span> 0.39), since the FAT has not detected signs of publication bias.
In both cases the PEESE contains the true value in its confidence interval, but it does much less well than in the fixed effects case.</p>
<p><strong><span class="smallcaps">Some simulations would be great here in order to assess whether the estimated sampling noise of PEESE is actually of the same magnitude as what would stem from Monte Carlos.</span></strong></p>
<p>I’d like to end this section on FAT-PET-PEESE by giving a graphical intuition of how this estimator corrects for publication bias.
I’ll supplement the graphical intuition with some intuition stemming from Heckman’s selection model.
The key intuition for understanding the FAT-PET and especially the PEESE estimator is the fact that, in the presence of publication bias, the meta-regression is akin to a censored or truncated model.
As a consequence, and as Stanley and Docouliagos explain, we have something like:</p>
<p><span class="math display">\[\begin{align*}
\esp{\hat{\theta}_k||\frac{\hat{\theta}_k}{\hat{\sigma}_k}|&gt;1.96} &amp; = \alpha_0 + \alpha_1\hat{\sigma}_k\lambda(\hat{\theta}_k,\hat{\sigma}_k) + \epsilon_k + \nu_k,
\end{align*}\]</span></p>
<p><strong><span class="smallcaps">Do the derivation.</span></strong></p>
<p>with <span class="math inline">\(\lambda\)</span> the Inverted Mills Ratio.
Approximating the nonlinear function of <span class="math inline">\(\hat{\sigma}_k\)</span> by a second order polynomial whose minium is when <span class="math inline">\(\hat{\sigma}_k=0\)</span> gives rise to PEESE.
FAT-PET approximate this function linearly instead.
One way to see how this operates is to add the FAT-PET and PEESE estimates to the funnel plots.</p>

<div class="example">
<span id="exm:unnamed-chunk-252" class="example"><strong>Example 13.15  </strong></span>Let’s see how the funnel plot works in our example.
</div>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="meta.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>ES <span class="sc">~</span> <span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES),<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.382</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>,<span class="dv">1</span>),<span class="at">xlab=</span><span class="st">&#39;Standard error&#39;</span>, <span class="at">ylab =</span><span class="st">&#39;Effect size&#39;</span>, <span class="at">main=</span><span class="st">&#39;Homogeneous effects&#39;</span>)</span>
<span id="cb257-2"><a href="meta.html#cb257-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb257-3"><a href="meta.html#cb257-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">coef</span>(meta.example.FE.interm.pubbias),<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb257-4"><a href="meta.html#cb257-4" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>((<span class="fu">coef</span>(FAT.PET.FE.interm.pubbias)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(FAT.PET.FE.interm.pubbias)[<span class="dv">2</span>]<span class="sc">*</span>x),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-5"><a href="meta.html#cb257-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr=</span><span class="fu">coef</span>(PEESE.FE.interm.pubbias)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(PEESE.FE.interm.pubbias)[<span class="dv">2</span>]<span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-6"><a href="meta.html#cb257-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</span>
<span id="cb257-7"><a href="meta.html#cb257-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Truth&quot;</span>, <span class="st">&quot;Meta&quot;</span>,<span class="st">&quot;FAT-PET&quot;</span>,<span class="st">&quot;PEESE&quot;</span>),</span>
<span id="cb257-8"><a href="meta.html#cb257-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;green&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>),</span>
<span id="cb257-9"><a href="meta.html#cb257-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>),</span>
<span id="cb257-10"><a href="meta.html#cb257-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">bg =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb257-11"><a href="meta.html#cb257-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-12"><a href="meta.html#cb257-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>theta<span class="fl">.1</span> <span class="sc">~</span> <span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES),<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.382</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">xlab=</span><span class="st">&#39;Standard error&#39;</span>, <span class="at">ylab =</span><span class="st">&#39;Effect size&#39;</span>, <span class="at">main=</span><span class="st">&#39;Heterogeneous effects&#39;</span>)</span>
<span id="cb257-13"><a href="meta.html#cb257-13" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">ES</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb257-14"><a href="meta.html#cb257-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">coef</span>(meta.example.RE.interm.pubbias),<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb257-15"><a href="meta.html#cb257-15" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>((<span class="fu">coef</span>(FAT.PET.RE.interm.pubbias)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(FAT.PET.RE.interm.pubbias)[<span class="dv">2</span>]<span class="sc">*</span>x),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-16"><a href="meta.html#cb257-16" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>((<span class="fu">coef</span>(FAT.PET.RE.interm.pubbias.pos)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(FAT.PET.RE.interm.pubbias.pos)[<span class="dv">2</span>]<span class="sc">*</span>x),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lty=</span><span class="dv">4</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-17"><a href="meta.html#cb257-17" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr=</span><span class="fu">coef</span>(PEESE.RE.interm.pubbias)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(PEESE.RE.interm.pubbias)[<span class="dv">2</span>]<span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-18"><a href="meta.html#cb257-18" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr=</span><span class="fu">coef</span>(PEESE.RE.interm.pubbias.pos)[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">coef</span>(PEESE.RE.interm.pubbias.pos)[<span class="dv">2</span>]<span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lty=</span><span class="dv">3</span>,<span class="at">add =</span> <span class="cn">TRUE</span>)</span>
<span id="cb257-19"><a href="meta.html#cb257-19" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</span>
<span id="cb257-20"><a href="meta.html#cb257-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Truth&quot;</span>, <span class="st">&quot;Meta&quot;</span>,<span class="st">&quot;FAT-PET&quot;</span>,<span class="st">&quot;FAT-PET+&quot;</span>,<span class="st">&quot;PEESE&quot;</span>,<span class="st">&quot;PEESE+&quot;</span>),</span>
<span id="cb257-21"><a href="meta.html#cb257-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;green&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>),</span>
<span id="cb257-22"><a href="meta.html#cb257-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">3</span>),</span>
<span id="cb257-23"><a href="meta.html#cb257-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">bg =</span> <span class="st">&quot;white&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FunnelPlotREPETPEESE"></span>
<img src="STCI_files/figure-html/FunnelPlotREPETPEESE-1.png" alt="Funnel plot with PET and PEESE" width="50%" /><img src="STCI_files/figure-html/FunnelPlotREPETPEESE-2.png" alt="Funnel plot with PET and PEESE" width="50%" />
<p class="caption">
Figure 13.17: Funnel plot with PET and PEESE
</p>
</div>
<p>On Figure <a href="meta.html#fig:FunnelPlotREPETPEESE">13.17</a>, we see how PET and PEESE operate to deliver an estimate corrected for publication bias: they fit a line (PET) or a curve (PEESE) and use the intercept of this line or curve as an estimate of the true treatment effect.
The plot for the hetergeneous treatment effects case suggests that both FAT-PET and PEESE are biased by a statistically significant negative result.
I think there is a good case to be made for focusing only on results of the same sign when using these tools.
When we get rid of that observation from the sample, the FAT estimate of the coefficient for the standard error in the meta-analytic regression is 0.9 <span class="math inline">\(\pm\)</span> 2.38.
The PET estimate is now 0.4 <span class="math inline">\(\pm\)</span> 0.34.
The PEESE estimates an effect of 0.47 <span class="math inline">\(\pm\)</span> 0.21.
This correction does not seem to improve the estimator much in our example.</p>
<p>Nevertheless, it is worth to investigate further how PEESE behaves when observations from the over side of zero enter the picture.
They seem to introduce a lot of noise.
I’d advocate for always using only values from one side, but we need theory and simulations to prove that intuition.</p>
</div>
<div id="p-curving" class="section level4" number="13.2.2.3">
<h4><span class="header-section-number">13.2.2.3</span> P-curving</h4>
<p><a href="http://www.p-curve.com">P-curving</a> has been proposed by Uri Simonsohn, Leif Nelson and Joseph Simmons in order to measure the evidential value of a set of published results.
The basic idea is rather simple: when there is a true effect, the distribution of p-values of statistically significant results should be denser at lower p-values.
This is because when there is a true effect, the density of the distribution of the p-values of statistically significant results decreases with the p-values.
When there is no effect and in the absence of QRPs, p-values of statistically significant results are uniformly distributed, and their density is thus flat.
When there is no effect and there are QRPs, the density of the distribution of the p-values of statistically significant results increases with the p-values.
P-curving interprets the shape of teh p-curve as showing signs of true effect (we say it has evidential value), no effect, or QRPs.
P-curving has two applications: detection of publication bias and QRPs and correction for publication bias and QRPs.</p>
<div id="proof-of-evidential-value-using-p-curving" class="section level5" number="13.2.2.3.1">
<h5><span class="header-section-number">13.2.2.3.1</span> Proof of evidential value using p-curving</h5>
<p>The basic idea behind using p-curving for measuring whether a result has evidential value rests on the fact that, when there is no effects and no QPRs, p-values of statistically significant results are distributed uniformly.
This is because, in the absence of any effect and of QRPs, the p-value measures the probability that a result of the same size or higher happens.
When the effect is non existent and there are no QRPs, a p-value of 0.05 will occur 5% of the time and a p-value of 0.04 will occur 4% of the time
So, p-values between 0.05 and 0.04 will occur 1% of the time, as p-values between 0.04 and 0.03 and so on.
When there is a true effect, more small p-values are observed than larger ones.
When there is no effet and there are QRPs, more p-values are observed closer to 0.05 than further away.</p>
<p>How to go from this intuition to testing for the existence of evidential value?
One first very simple approach would simply be to separate the set of statistically significant p-values <span class="math inline">\(\left[0,0.05\right]\)</span> in half.
In the absence of effect and of QRPs, the probability that a statistically significant p-value falls into one of these two sets (<span class="math inline">\(\left[0,0.025\right]\)</span> and <span class="math inline">\(\left]0.025,0.05\right]\)</span>) is 0.5.
Comparing the actual proportion of p-values falling in these sets to the theoretical uniform value gives a first simple test of evidential value.</p>
<p>A rigorous test can be built by computing the probability that an event such as observed would have happened under the null of no effect and no QRPs.
This can be done using the Binomial law, since under the null of no effect and no QRPs, <span class="math inline">\(X\)</span>, the number of results falling in the <span class="math inline">\(\left]0.025,0.05\right]\)</span> set, follows a binomial <span class="math inline">\(Bi(n,p)\)</span>, with <span class="math inline">\(n\)</span> the number of studies and <span class="math inline">\(p=0.5\)</span>.
The probability of observing <span class="math inline">\(x\)</span> studies among <span class="math inline">\(n\)</span> in the <span class="math inline">\(\left]0.025,0.05\right]\)</span> set is thus <span class="math inline">\(\Pr(X=x)=b(x,n,p)\)</span>, where <span class="math inline">\(b(x,n,p)\)</span> is the density of the binomial distribution.
The probability of observing <span class="math inline">\(x\)</span> studies or more among <span class="math inline">\(n\)</span> in the <span class="math inline">\(\left]0.025,0.05\right]\)</span> set is <span class="math inline">\(\Pr(X\geq x)=1-B(x-1,n,p)\)</span>, where <span class="math inline">\(B(x,n,p)\)</span> is the cumulative of the binomial distribution.</p>
<p>For example, if we have 6 studies, with five of them falling in the <span class="math inline">\(\left]0.025,0.05\right]\)</span> set, we have <span class="math inline">\(5/6=\)</span> 83 % of studies close to 0.05.
Under the null of no effect and no QRPs, this would have happened with probability 0.09.
If we define the alternative to be the existence of QRPs, this or something worse (meaning more QRPs) would have happened with probability 0.11.
This is not definitive evidence against the null and in favor of QRPs, but we’re getting there.
If we define the alternative as being a true effect, we would obtain the same results per symmetry of the binomail distribution.
Let’s write a function that takes a vector of p-values and returns the binomial test statistic and p-value for the null of no effect and no QRPs.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="meta.html#cb258-1" aria-hidden="true" tabindex="-1"></a>pcurve.binom <span class="ot">&lt;-</span> <span class="cf">function</span>(pvalues,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>){</span>
<span id="cb258-2"><a href="meta.html#cb258-2" aria-hidden="true" tabindex="-1"></a>  p.upper <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pvalues<span class="sc">&gt;</span><span class="fl">0.025</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb258-3"><a href="meta.html#cb258-3" aria-hidden="true" tabindex="-1"></a>  p.lower <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pvalues<span class="sc">&lt;=</span><span class="fl">0.025</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb258-4"><a href="meta.html#cb258-4" aria-hidden="true" tabindex="-1"></a>  pbinom.True <span class="ot">&lt;-</span> <span class="fu">pbinom</span>(<span class="fu">sum</span>(p.lower),<span class="fu">length</span>(pvalues),<span class="fl">0.5</span>)</span>
<span id="cb258-5"><a href="meta.html#cb258-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (alter<span class="sc">==</span><span class="st">&#39;QRP&#39;</span>){</span>
<span id="cb258-6"><a href="meta.html#cb258-6" aria-hidden="true" tabindex="-1"></a>    pbinom.True <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">pbinom</span>(<span class="fu">sum</span>(p.upper)<span class="sc">-</span><span class="dv">1</span>,<span class="fu">length</span>(pvalues),<span class="fl">0.5</span>)</span>
<span id="cb258-7"><a href="meta.html#cb258-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb258-8"><a href="meta.html#cb258-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(pbinom.True)</span>
<span id="cb258-9"><a href="meta.html#cb258-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Another test use the distribution of the p-values of the p-values, or pp-value.
The test works as follows.
Let’s say you have a set of p-values <span class="math inline">\(p_i\)</span>.
For each <span class="math inline">\(p_i\)</span>, compute the probability to observe this p-value or a more extreme one if the null were true.
This is not too hard since <span class="math inline">\(p_i\)</span> is distributed uniformly on <span class="math inline">\(\left[0,0.05\right]\)</span> under the null and thus both its density and cumulative are known.
The only twist you have to pay attention to is how you define extreme.
This depends on what is your alternative hypothesis.
If you are comparing the null to a case with QRPs, then more extreme means a p-value closer to 0.05.
If you are comparing the null to a case where there is a true effect, then more extreme means a p-value closer to 0.
In the latter case, the pp-value of <span class="math inline">\(p_i=p_k\)</span> is <span class="math inline">\(pp^r_k=\Pr(p_i\leq p)=p_k/0.05\)</span>, from the cumulative of a uniform.
In the former case, the pp-value of <span class="math inline">\(p_i=p_k\)</span> is <span class="math inline">\(pp^l_k=\Pr(p_i\geq p)=1-p_k/0.05\)</span>.
Now, you can aggregate the pp-values using Fisher’s method: <span class="math inline">\(F_{pp}^s=-2\sum_k\ln(pp^s_k)\)</span>, for <span class="math inline">\(s\in\left\{l,r\right\}\)</span>.
<span class="math inline">\(F_{pp}^s\)</span> is distributed <span class="math inline">\(\chi^2(2k)\)</span> under the null.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="meta.html#cb259-1" aria-hidden="true" tabindex="-1"></a>pp.test <span class="ot">&lt;-</span> <span class="cf">function</span>(pvalues,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>){</span>
<span id="cb259-2"><a href="meta.html#cb259-2" aria-hidden="true" tabindex="-1"></a>  pp <span class="ot">&lt;-</span> pvalues<span class="sc">/</span><span class="fl">0.05</span></span>
<span id="cb259-3"><a href="meta.html#cb259-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (alter<span class="sc">==</span><span class="st">&#39;QRP&#39;</span>){</span>
<span id="cb259-4"><a href="meta.html#cb259-4" aria-hidden="true" tabindex="-1"></a>    pp <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span>pp</span>
<span id="cb259-5"><a href="meta.html#cb259-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb259-6"><a href="meta.html#cb259-6" aria-hidden="true" tabindex="-1"></a>  Fpp <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sum</span>(<span class="fu">log</span>(pp))</span>
<span id="cb259-7"><a href="meta.html#cb259-7" aria-hidden="true" tabindex="-1"></a>  dfChis <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">length</span>(pvalues)</span>
<span id="cb259-8"><a href="meta.html#cb259-8" aria-hidden="true" tabindex="-1"></a>  pChisquare.Fpp <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(Fpp,dfChis,<span class="at">lower.tail=</span>F)</span>
<span id="cb259-9"><a href="meta.html#cb259-9" aria-hidden="true" tabindex="-1"></a>  qChisquare<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(<span class="fl">0.05</span>,dfChis,<span class="at">lower.tail=</span>F)</span>
<span id="cb259-10"><a href="meta.html#cb259-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(pChisquare.Fpp,Fpp,dfChis,qChisquare<span class="fl">.5</span>))</span>
<span id="cb259-11"><a href="meta.html#cb259-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Imagine for example that we have three studies with p-values 0.001, 0.002 and 0.04.
Let’s compute the test against both alternatives:</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="meta.html#cb260-1" aria-hidden="true" tabindex="-1"></a>pvalex <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.001</span>,<span class="fl">0.002</span>,<span class="fl">0.04</span>)</span>
<span id="cb260-2"><a href="meta.html#cb260-2" aria-hidden="true" tabindex="-1"></a>p.binom.test.True <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span>
<span id="cb260-3"><a href="meta.html#cb260-3" aria-hidden="true" tabindex="-1"></a>p.binom.test.QRP <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb260-4"><a href="meta.html#cb260-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb260-5"><a href="meta.html#cb260-5" aria-hidden="true" tabindex="-1"></a>pp.ex.QRP <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb260-6"><a href="meta.html#cb260-6" aria-hidden="true" tabindex="-1"></a>pp.ex.True <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span></code></pre></div>
<p>The Chi-square statistic against QRPs is 3.34 and the corresponding p-value is 0.76.
The Chi-square statistic against a true effect is 14.71 and the corresponding p-value is 0.02.</p>
<p>There is a last test based on the p-curve tool that compares the actual distribution of statistically significant p-values to that that would be generated by a real but small effect, one that we would be powered to detect in only 33% of the samples.
The test simply reverses the null and alternative of the previous test when the alternative was that there exists a true effect.
I do not really see what one has to gain from this additional test so I’m going to abstain from encoding for now.
It uses non-central distributions to compute the pp-values.</p>
<p><strong><span class="smallcaps">Code the additional pp-value test.</span></strong></p>

<div class="example">
<span id="exm:unnamed-chunk-253" class="example"><strong>Example 13.16  </strong></span>Let’s see how these tests work in our example.
</div>
<p>We first have to compute the p-values for each statistically significant effect.
Then, we can implement our tests.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="meta.html#cb261-1" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>p.FE <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)),<span class="at">lower.tail=</span>F)</span>
<span id="cb261-2"><a href="meta.html#cb261-2" aria-hidden="true" tabindex="-1"></a>data.meta<span class="sc">$</span>p.RE <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)),<span class="at">lower.tail=</span>F)</span>
<span id="cb261-3"><a href="meta.html#cb261-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-4"><a href="meta.html#cb261-4" aria-hidden="true" tabindex="-1"></a>pvalex.FE <span class="ot">&lt;-</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>p.FE</span>
<span id="cb261-5"><a href="meta.html#cb261-5" aria-hidden="true" tabindex="-1"></a>pvalex.RE <span class="ot">&lt;-</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>p.RE</span>
<span id="cb261-6"><a href="meta.html#cb261-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-7"><a href="meta.html#cb261-7" aria-hidden="true" tabindex="-1"></a>p.binom.test.True.FE <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex.FE,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span>
<span id="cb261-8"><a href="meta.html#cb261-8" aria-hidden="true" tabindex="-1"></a>p.binom.test.QRP.FE <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex.FE,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb261-9"><a href="meta.html#cb261-9" aria-hidden="true" tabindex="-1"></a>pp.ex.QRP.FE <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex.FE,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb261-10"><a href="meta.html#cb261-10" aria-hidden="true" tabindex="-1"></a>pp.ex.True.FE <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex.FE,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span>
<span id="cb261-11"><a href="meta.html#cb261-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-12"><a href="meta.html#cb261-12" aria-hidden="true" tabindex="-1"></a>p.binom.test.True.RE <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex.RE,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span>
<span id="cb261-13"><a href="meta.html#cb261-13" aria-hidden="true" tabindex="-1"></a>p.binom.test.QRP.RE <span class="ot">&lt;-</span> <span class="fu">pcurve.binom</span>(pvalex.RE,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb261-14"><a href="meta.html#cb261-14" aria-hidden="true" tabindex="-1"></a>pp.ex.QRP.RE <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex.RE,<span class="at">alter=</span><span class="st">&#39;QRP&#39;</span>)</span>
<span id="cb261-15"><a href="meta.html#cb261-15" aria-hidden="true" tabindex="-1"></a>pp.ex.True.RE <span class="ot">&lt;-</span> <span class="fu">pp.test</span>(pvalex.RE,<span class="at">alter=</span><span class="st">&#39;True&#39;</span>)</span></code></pre></div>
<p>In the homogeneous effects case, the p-value of the null of an absence of an effect versus QRPs is of 0.76.
The p-value of a null of an absence of an effect versus a true effect is 0.
In the heterogeneous effects case, the p-value of a null of an absence of an effect versus QRPs is of 1 while the test statistic of a null of an absence of an effect versus a true effect is 0.
In both case, we clearly reject the absence of an effect.
As a consequence, the set of p-values has evidential value.
We also reject the existence of QRPs.
That means that there is no p-hacking creating an undue mass of p-values close to 0.05, but that does not mean that there is no publicaiton bias.
P-curving has nothing to say about publication bias.
It can only say whether there is a true effect or not and whether there are signs of QRPs.</p>
<p>A cool way to present the results of p-curving is to draw the density of the statistically significant p-values against a uniform and the density that would occur under 33% power.
Let me try and build such a graph in our example.
First, we have to split the overall set <span class="math inline">\(\left[0,0.05\right]\)</span> into equal-sized p-values bins, lets say <span class="math inline">\(\left[0,0.01\right[\)</span>, <span class="math inline">\(\left[0.01,0.02\right[\)</span>, <span class="math inline">\(\left[0.02,0.03\right[\)</span>, <span class="math inline">\(\left[0.03,0.04\right[\)</span>, <span class="math inline">\(\left[0.04,0.05\right]\)</span>.
I’m gonna name each interval after its higher end point.
Second, we have to compute how many of our observations fall in each of the bins.
Third, just plot the corresponding density.</p>
<p>The addition of the density of p-values if the real test had 33% power is slightly more involved, because it requires the notions of power and MDE that we studied in Chapter <a href="Power.html#Power">7</a>.
As in Chapter <a href="Power.html#Power">7</a>, we’re going to use the CLT approximation to the distribution of the treatment effect estimate over sampling replications.
The key idea is to recognize that, with a power of <span class="math inline">\(\kappa\)</span> for a two-sided test, the distribution of the treatment effect divided by its standard error <span class="math inline">\(\sqrt{V[\hat{E}]}\)</span> is a standard normal centered at <span class="math inline">\(MDE^n_{\kappa,\alpha}=\frac{MDE_{\kappa,\alpha}}{\sqrt{V[\hat{E}]}}=\Phi^{-1}(\kappa)+\Phi^{-1}(1-\alpha/2)\)</span>.
This is an approximation that assumes away the mass of the distribution that lies below zero.
This appromixation is useful since it delivers closed form solutions and it most of the time is accurate enough.
The lower below <span class="math inline">\(\kappa=\)</span> 33% we’re going, the likelier it is that this approximation is at fault.
Now, the probability that this distribution gives a p-value of 0.05 or smaller for a two-sided test of the true effect being zero with size 5% is equal to <span class="math inline">\(\Phi(MDE^n_{\kappa,\alpha}-\Phi^{-1}(1-\alpha/2))=\kappa\)</span> by definition.
The probability that it gives a p-value of <span class="math inline">\(p\)</span> for the same test is of <span class="math inline">\(\Phi(MDE^n_{\kappa,\alpha}-\Phi^{-1}(1-p/2))\)</span>.
Conditionnal on having a p-value inferior to 5% ( a statistically significant result), the probability of having a p-value between <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> ( the pp-value) is thus:</p>
<p><span class="math display">\[\begin{align*}
  pp_{\kappa,\alpha}(p_1,p_2) &amp; = \frac{1}{\kappa}\left(\Phi(MDE^n_{\kappa,\alpha}-\Phi^{-1}(1-p_2/2))-\Phi(MDE^n_{\kappa,\alpha}-\Phi^{-1}(1-p_1/2))\right).
\end{align*}\]</span></p>
<p>Let’s write a function that gives us this result.</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="meta.html#cb262-1" aria-hidden="true" tabindex="-1"></a>MDE.var <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">kappa=</span><span class="fl">0.33</span>,<span class="at">varE=</span><span class="dv">1</span>){</span>
<span id="cb262-2"><a href="meta.html#cb262-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>((<span class="fu">qnorm</span>(kappa)<span class="sc">+</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))<span class="sc">*</span><span class="fu">sqrt</span>(varE))</span>
<span id="cb262-3"><a href="meta.html#cb262-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb262-4"><a href="meta.html#cb262-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb262-5"><a href="meta.html#cb262-5" aria-hidden="true" tabindex="-1"></a>ppCurvePower <span class="ot">&lt;-</span> <span class="cf">function</span>(p1,p2,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">kappa=</span><span class="fl">0.33</span>,<span class="at">varE=</span><span class="dv">1</span>){</span>
<span id="cb262-6"><a href="meta.html#cb262-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>((<span class="fu">pnorm</span>(<span class="fu">MDE.var</span>(<span class="at">alpha=</span>alpha,<span class="at">kappa=</span>kappa)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>p2<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb262-7"><a href="meta.html#cb262-7" aria-hidden="true" tabindex="-1"></a>          <span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">MDE.var</span>(<span class="at">alpha=</span>alpha,<span class="at">kappa=</span>kappa)<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>p1<span class="sc">/</span><span class="dv">2</span>)))<span class="sc">/</span>kappa)</span>
<span id="cb262-8"><a href="meta.html#cb262-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, let’s plot the p-curve plot.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="meta.html#cb263-1" aria-hidden="true" tabindex="-1"></a>pCurve.hist <span class="ot">&lt;-</span> <span class="cf">function</span>(pvalues,<span class="at">power=</span>.<span class="dv">33</span>){</span>
<span id="cb263-2"><a href="meta.html#cb263-2" aria-hidden="true" tabindex="-1"></a>  dens1 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(pvalues<span class="fl">-0.005</span>)<span class="sc">&lt;</span><span class="fl">0.005</span>,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">/</span><span class="fu">length</span>(pvalues))</span>
<span id="cb263-3"><a href="meta.html#cb263-3" aria-hidden="true" tabindex="-1"></a>  dens2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(pvalues<span class="fl">-0.015</span>)<span class="sc">&lt;</span><span class="fl">0.005</span>,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">/</span><span class="fu">length</span>(pvalues))</span>
<span id="cb263-4"><a href="meta.html#cb263-4" aria-hidden="true" tabindex="-1"></a>  dens3 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(pvalues<span class="fl">-0.025</span>)<span class="sc">&lt;</span><span class="fl">0.005</span>,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">/</span><span class="fu">length</span>(pvalues))</span>
<span id="cb263-5"><a href="meta.html#cb263-5" aria-hidden="true" tabindex="-1"></a>  dens4 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(pvalues<span class="fl">-0.035</span>)<span class="sc">&lt;</span><span class="fl">0.005</span>,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">/</span><span class="fu">length</span>(pvalues))</span>
<span id="cb263-6"><a href="meta.html#cb263-6" aria-hidden="true" tabindex="-1"></a>  dens5 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(pvalues<span class="fl">-0.045</span>)<span class="sc">&lt;</span><span class="fl">0.005</span>,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">/</span><span class="fu">length</span>(pvalues))</span>
<span id="cb263-7"><a href="meta.html#cb263-7" aria-hidden="true" tabindex="-1"></a>  dens <span class="ot">&lt;-</span> <span class="fu">c</span>(dens1,dens2,dens3,dens4,dens5)</span>
<span id="cb263-8"><a href="meta.html#cb263-8" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>,<span class="fl">0.03</span>,<span class="fl">0.04</span>,<span class="fl">0.05</span>),dens)</span>
<span id="cb263-9"><a href="meta.html#cb263-9" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(p.hist<span class="fl">.1</span>)</span>
<span id="cb263-10"><a href="meta.html#cb263-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(p.hist<span class="fl">.1</span>) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;p&#39;</span>,<span class="st">&#39;density&#39;</span>)</span>
<span id="cb263-11"><a href="meta.html#cb263-11" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.1</span><span class="sc">$</span>Data <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Observed&quot;</span>)</span>
<span id="cb263-12"><a href="meta.html#cb263-12" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>,<span class="fl">0.03</span>,<span class="fl">0.04</span>,<span class="fl">0.05</span>),<span class="fl">0.2</span>)</span>
<span id="cb263-13"><a href="meta.html#cb263-13" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(p.hist<span class="fl">.2</span>)</span>
<span id="cb263-14"><a href="meta.html#cb263-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(p.hist<span class="fl">.2</span>) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;p&#39;</span>,<span class="st">&#39;density&#39;</span>)</span>
<span id="cb263-15"><a href="meta.html#cb263-15" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.2</span><span class="sc">$</span>Data <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Uniform&quot;</span>)</span>
<span id="cb263-16"><a href="meta.html#cb263-16" aria-hidden="true" tabindex="-1"></a>  dens331 <span class="ot">&lt;-</span> <span class="fu">ppCurvePower</span>(<span class="dv">0</span>,<span class="fl">0.01</span>)</span>
<span id="cb263-17"><a href="meta.html#cb263-17" aria-hidden="true" tabindex="-1"></a>  dens332 <span class="ot">&lt;-</span> <span class="fu">ppCurvePower</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>)</span>
<span id="cb263-18"><a href="meta.html#cb263-18" aria-hidden="true" tabindex="-1"></a>  dens333 <span class="ot">&lt;-</span> <span class="fu">ppCurvePower</span>(<span class="fl">0.02</span>,<span class="fl">0.03</span>)</span>
<span id="cb263-19"><a href="meta.html#cb263-19" aria-hidden="true" tabindex="-1"></a>  dens334 <span class="ot">&lt;-</span> <span class="fu">ppCurvePower</span>(<span class="fl">0.03</span>,<span class="fl">0.04</span>)</span>
<span id="cb263-20"><a href="meta.html#cb263-20" aria-hidden="true" tabindex="-1"></a>  dens335 <span class="ot">&lt;-</span> <span class="fu">ppCurvePower</span>(<span class="fl">0.04</span>,<span class="fl">0.05</span>)</span>
<span id="cb263-21"><a href="meta.html#cb263-21" aria-hidden="true" tabindex="-1"></a>  dens33 <span class="ot">&lt;-</span> <span class="fu">c</span>(dens331,dens332,dens333,dens334,dens335)</span>
<span id="cb263-22"><a href="meta.html#cb263-22" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>,<span class="fl">0.03</span>,<span class="fl">0.04</span>,<span class="fl">0.05</span>),dens33)</span>
<span id="cb263-23"><a href="meta.html#cb263-23" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(p.hist<span class="fl">.3</span>)</span>
<span id="cb263-24"><a href="meta.html#cb263-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(p.hist<span class="fl">.3</span>) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;p&#39;</span>,<span class="st">&#39;density&#39;</span>)</span>
<span id="cb263-25"><a href="meta.html#cb263-25" aria-hidden="true" tabindex="-1"></a>  p.hist<span class="fl">.3</span><span class="sc">$</span>Data <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Power33&quot;</span>)</span>
<span id="cb263-26"><a href="meta.html#cb263-26" aria-hidden="true" tabindex="-1"></a>  p.hist <span class="ot">&lt;-</span> <span class="fu">rbind</span>(p.hist<span class="fl">.1</span>,p.hist<span class="fl">.2</span>,p.hist<span class="fl">.3</span>)</span>
<span id="cb263-27"><a href="meta.html#cb263-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(p.hist)</span>
<span id="cb263-28"><a href="meta.html#cb263-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb263-29"><a href="meta.html#cb263-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-30"><a href="meta.html#cb263-30" aria-hidden="true" tabindex="-1"></a>p.hist.FE <span class="ot">&lt;-</span> <span class="fu">pCurve.hist</span>(pvalex.FE)</span>
<span id="cb263-31"><a href="meta.html#cb263-31" aria-hidden="true" tabindex="-1"></a>p.hist.FE<span class="sc">$</span>Effect <span class="ot">&lt;-</span> <span class="st">&quot;Homogeneous&quot;</span></span>
<span id="cb263-32"><a href="meta.html#cb263-32" aria-hidden="true" tabindex="-1"></a>p.hist.RE <span class="ot">&lt;-</span> <span class="fu">pCurve.hist</span>(pvalex.RE)</span>
<span id="cb263-33"><a href="meta.html#cb263-33" aria-hidden="true" tabindex="-1"></a>p.hist.RE<span class="sc">$</span>Effect <span class="ot">&lt;-</span> <span class="st">&quot;Heterogeneous&quot;</span></span>
<span id="cb263-34"><a href="meta.html#cb263-34" aria-hidden="true" tabindex="-1"></a>p.hist.ex <span class="ot">&lt;-</span> <span class="fu">rbind</span>(p.hist.FE,p.hist.RE)</span>
<span id="cb263-35"><a href="meta.html#cb263-35" aria-hidden="true" tabindex="-1"></a>p.hist.ex<span class="sc">$</span>Effect <span class="ot">&lt;-</span> <span class="fu">factor</span>(p.hist.ex<span class="sc">$</span>Effect,<span class="at">levels=</span><span class="fu">c</span>(<span class="st">&quot;Homogeneous&quot;</span>,<span class="st">&quot;Heterogeneous&quot;</span>))</span>
<span id="cb263-36"><a href="meta.html#cb263-36" aria-hidden="true" tabindex="-1"></a>p.hist.ex<span class="sc">$</span>Data <span class="ot">&lt;-</span> <span class="fu">factor</span>(p.hist.ex<span class="sc">$</span>Data,<span class="at">levels=</span><span class="fu">c</span>(<span class="st">&quot;Observed&quot;</span>,<span class="st">&quot;Uniform&quot;</span>,<span class="st">&quot;Power33&quot;</span>))</span>
<span id="cb263-37"><a href="meta.html#cb263-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-38"><a href="meta.html#cb263-38" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>p.hist.ex, <span class="fu">aes</span>(<span class="at">x=</span>p, <span class="at">y=</span>density, <span class="at">color=</span>Data)) <span class="sc">+</span></span>
<span id="cb263-39"><a href="meta.html#cb263-39" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb263-40"><a href="meta.html#cb263-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb263-41"><a href="meta.html#cb263-41" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_grid</span>(. <span class="sc">~</span> Effect)<span class="sc">+</span></span>
<span id="cb263-42"><a href="meta.html#cb263-42" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pCurvePlot"></span>
<img src="STCI_files/figure-html/pCurvePlot-1.png" alt="P-curve plot in our example" width="75%" />
<p class="caption">
Figure 13.18: P-curve plot in our example
</p>
</div>
</div>
<div id="correction-for-publication-bias-using-p-curving" class="section level5" number="13.2.2.3.2">
<h5><span class="header-section-number">13.2.2.3.2</span> Correction for publication bias using p-curving</h5>
<p>In a <a href="https://poseidon01.ssrn.com/delivery.php?ID=968120070017096022067095015077090081127015066012065038099103064095066125118101087000019101125033110002058114102117068031082117013010054030001011069073086069105087004037003126007029115080118115116004080116094099076097092111007065003101127024028025084&amp;EXT=pdf">separate paper</a>, Simonsohn, Nelson and Simmons proposed a way to use p-curve to correct treatment effect estimates from publication bias.
The underlying idea is rather simple, but also brilliant: the shape of the p-curve changes with the true underlying effect.
It goes from uniform in the absence of any effect to right-skewed when there is an effect.
The strength of the right-skewness tells us something about the underlying strength of the measured effect.
For a given sample size, an increase in right-skewness will mean an increasae in effect size.
The key difficulty is to separate the impact of sample size from that of effect size on the shape of the p-curve.
Since sample size is known, it should be doable.
Let’s see how.</p>
<p>The key technical intuition behind the p-curve approach to correction for publication bias is to notice that the pp-curve computed for the true treatment effect should be uniform on <span class="math inline">\(\left[0,1\right]\)</span>.
We have seen in the previous section that the pp-curve (the proportion of p-values that fall within identical intervals) is uniform when the true effect is zero.
If we compute the pp-curve with a different assumption and apply it to the actual p-values that we observe, it is going to be uniform only for the actual treatment effect.
So the only thing to do is to take all of the significant p-values and to compute their pp-curve for various levels of treatment effect, or, better, to look for the treatment effect that minimizes the distance between the observed pp-curve and a uniform.
The authors propose to minimize a Kolmogorov-Smirnov metric to do so.</p>
<p>Let’s first explore the way the concept works.
For each treatment effect <span class="math inline">\(\hat{\theta}_k\)</span> and its estimated standard error <span class="math inline">\(\hat{\sigma}_k\)</span> we know from the CLT that they are distributed approximately as a normal.
If we assume that the true treatment effect is <span class="math inline">\(\theta_c\)</span>, with <span class="math inline">\(c\)</span> for candidate value, we know that <span class="math inline">\(\frac{\hat{\theta}_k-\theta_c}{\hat{\sigma}_k}\)</span> is distributed as a centered standardized normal distribution, under the assumption of homogeneous treatment effect across studies.
Homogeneity is a crucial assumption for the pp-curve approach to correction for publication bias.
I’ll try to see how we can relax it later, but for now, I’m going to assume <span class="math inline">\(\tau^2=0\)</span>.
One way to compute the pp-value is to start directly with the treatment effect and its standard error, and to recover the pp-value from there.
The pp-value is the probability that we have a draw of an estimator <span class="math inline">\(\hat{\theta}\)</span> of mean <span class="math inline">\(\theta_c\)</span> and standard error <span class="math inline">\(\hat{\sigma}_k\)</span> that is greater or equal to <span class="math inline">\(\hat{\theta}_k\)</span> given that it is a statistically significant result:</p>
<p><span class="math display">\[\begin{align*}
  pp(\hat{\theta}_k,\hat{\sigma}_k,\theta_c) &amp; = \Pr\left(\hat{\theta}\geq\hat{\theta}_k\left|
                                            \left|\frac{\hat{\theta}}{\hat{\sigma}_k}\right|
                                            \geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right.\right).
\end{align*}\]</span></p>
<p>Let’s assume that we are only looking at statistically significant results for two-sided t-tests, but that are located on the positive side of the threshold: <span class="math inline">\(\frac{\hat{\theta}_k}{\hat{\sigma}_k}\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\)</span>.
This assumption will be innocuous in most cases of homogeneous treatment effect when the true effect we examine is positive since the mass of the distribution will fall on the positive side of the threshold, especially for significant results.</p>
<p>How do we compute the pp-value for a candidate value <span class="math inline">\(\theta_c\)</span>?</p>

<div class="theorem">
<p><span id="thm:ppvalueHomogPos" class="theorem"><strong>Theorem 13.3  (pp-value with homogeneous positive treatment effect)  </strong></span>Under the assumption that the treatment effect is homogeneous across studies and equal to <span class="math inline">\(\theta_c\)</span>, that the estimated effects <span class="math inline">\(\hat{\theta}_k\)</span> are approximately normally distributed with mean <span class="math inline">\(\theta_c\)</span> and standard error <span class="math inline">\(\hat{\sigma}_k\)</span> and that we use only effects that are positive and significant at the level <span class="math inline">\(\alpha\)</span> following a two-sided test, the pp-value of a result with estimated effect <span class="math inline">\(\hat{\theta}_k\)</span> and estimated standard error is <span class="math inline">\(\hat{\sigma}_k\)</span>:</p>
<span class="math display">\[\begin{align*}
  pp(\hat{\theta}_k,\hat{\sigma}_k,\theta_c) &amp; = \frac{\Phi\left(\frac{\theta_c-\hat{\theta}_k}{\hat{\sigma}_k}\right)}
                                                      {\Phi\left(\frac{\theta_c}{\hat{\sigma}_k}-\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right)}.
 \end{align*}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> <span class="math display">\[\begin{align*}
  pp(\hat{\theta}_k,\hat{\sigma}_k,\theta_c) &amp; = \Pr\left(\hat{\theta}\geq\hat{\theta}_k\left|\frac{\hat{\theta}}{\hat{\sigma}_k}
                                                    \geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right.\right)\\
                                              &amp; = \frac{\Pr\left(\hat{\theta}\geq\hat{\theta}_k\land\hat{\theta}\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k\right)}
            {\Pr\left(\hat{\theta}\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k\right)} \\
              &amp; = \frac{\Pr\left(\hat{\theta}\geq\hat{\theta}_k\right)}
            {\Pr\left(\hat{\theta}\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k\right)} \\
  &amp; \approx \frac{1-\Phi\left(\frac{\hat{\theta}_k-\theta_c}{\hat{\sigma}_k}\right)}
                                                      {1-\Phi\left(\frac{\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k-\theta_c}
                                                                  {\hat{\sigma}_k}\right)}\\
 &amp; \approx \frac{\Phi\left(\frac{\theta_c-\hat{\theta}_k}{\hat{\sigma}_k}\right)}
                                                      {\Phi\left(\frac{\theta_c}{\hat{\sigma}_k}-\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right)}.
\end{align*}\]</span></p>
The second equality stems from Bayes theorem.
The third equality stems from the fact that <span class="math inline">\(\hat{\theta}\geq\hat{\theta}_k\Rightarrow\hat{\theta}\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k\)</span> since <span class="math inline">\(\hat{\theta}_k\geq\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\hat{\sigma}_k\)</span> by assumption.
The fourth equality stems from using the normality approximation to the distribution of <span class="math inline">\(\hat{\theta}\)</span>.
The fifth equality uses the usual property of the cumulative of the standardized and centered normal distribution that <span class="math inline">\(1-\Phi(x)=\Phi(-x)\)</span>.
</div>
<p>Another way to compute the pp-value is to start from the p-value.
This approach is especially useful when we do not have access to an estimate of the treatment effect, but only to the p-value of a two-sided t-test and to the sample size.
In this case, we can generally only recover the effect size of the treatment effect <span class="math inline">\(d_c\)</span>, that is the treatment effect scaled by the standard error of the outcome <span class="math inline">\(\sigma_{Y}\)</span> (under the assumption of homogeneous treatment effects, there is no heteroskedasticity, and the variance of outcomes is identical in both the treatment and control groups).
In order to do so, we use the fact that <span class="math inline">\(d_c=\frac{\theta_c}{\sqrt{N}\hat{\sigma_k}}\)</span> since <span class="math inline">\(\hat{\sigma_k}\approx\frac{\sigma_{Y}}{\sqrt{N}}\)</span> for the With/Without estimator without control variables (using the CLT).
Note that this is a highly restrictive assumption, excluding that the With/Without estimator controls for covariates, or the use of other estimators.</p>

<div class="corollary">
<p><span id="cor:pppvalueHomogPos" class="corollary"><strong>Corollary 13.1  (Building pp-value from p-values)  </strong></span>Under the assumption that the effect size is homogeneous across studies and equal to <span class="math inline">\(d_c\)</span>, that the estimated effects sizes <span class="math inline">\(\hat{d}_k\)</span> are approximately normally distributed with mean <span class="math inline">\(d_c\)</span>, that we use only effects are positive and significant at the level <span class="math inline">\(\alpha\)</span> following a two-sided test, and that <span class="math inline">\(\hat{\sigma_k}\approx\frac{\sigma_{Y}}{\sqrt{N}}\)</span>, the pp-value of a result with sample size <span class="math inline">\(N_k\)</span> and p-value <span class="math inline">\(\hat{p}_k\)</span> is:</p>
<span class="math display">\[\begin{align*}
  pp_p(\hat{p}_k,N_k,d_c) &amp; \approx \frac{\Phi\left(\sqrt{N}d_c-\Phi^{-1}\left(1-\frac{p_k}{2}\right)\right)}
                                        {\Phi\left(\sqrt{N}d_c-\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right)}.
 \end{align*}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> From the formula for two-sided t-tests, we have that:</p>
<p><span class="math display">\[\begin{align*}
  p_k &amp; = 2\left(1-\Phi\left(\left|\frac{\hat{\theta}_k}{\hat{\sigma}_k}\right|\right)\right).
\end{align*}\]</span></p>
<p>As a consequence:</p>
<p><span class="math display">\[\begin{align*}
  \left|\frac{\hat{\theta}_k}{\hat{\sigma}_k}\right| &amp; = \Phi^{-1}\left(1-\frac{p_k}{2}\right).
\end{align*}\]</span></p>
Using the assumption that all significant effects are positive, and the fact that <span class="math inline">\(\sqrt{N}d_c\approx\frac{\theta_c}{\hat{\sigma}_k}\)</span> under the assumption that <span class="math inline">\(\hat{\sigma_k}\approx\frac{\sigma_{Y}}{\sqrt{N}}\)</span>, we obtain the result by using Theorem <a href="meta.html#thm:ppvalueHomogPos">13.3</a>.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Using only positive values is a benefit, since the preferred direction is less likely to have been slectively underreported.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The authors use Student <span class="math inline">\(t\)</span> distributions instead of a normal approximation.
This will not matter as loong as sample size is large enough.
Generalizing the results of this section to Student-<span class="math inline">\(t\)</span> distributions is simple, but the normal approximation should work most of the time.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> There seems to be a mistake in the numerator in the original paper: the authors subtract power whereas it does not seem to be required.
At least, I do not understand their derivation.
Both appraoches yield similar results in their example, except for one case.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The assumption of homogeneous treatment effects is key here: it enables to use the standard normal as an approximation.
The test has to be modified to account for heterogeneous treatment effects.
Heterogeneity in treatment effects might bias the estimate.
</div>
<p>In order to estimate the parameter <span class="math inline">\(\theta_c\)</span> (or <span class="math inline">\(d_c\)</span> if using p-values only), the authors make use of the fact that, under the true <span class="math inline">\(\theta_c\)</span>, the pp-values are uniformly distributed on <span class="math inline">\(\left[0,1\right]\)</span>.
The authors propose to choose the value <span class="math inline">\(\hat{\theta}_c\)</span> that makes the pp-curve as close to a uniform as possible as an estimator of <span class="math inline">\(\theta_c\)</span>.
As a metric for estimating the distance between the observed pp-curve and the uniform <span class="math inline">\(\left[0,1\right]\)</span>, the authors propose to use the <a href="https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test">Kolmogorov-Smirnov statistic</a>: the maximum value of the absolute difference between the empirical cdf of pp-values and the theoretical values of the cdf of the uniform <span class="math inline">\(\left[0,1\right]\)</span>.
The objective function proposed by the authors minimizes this distance.</p>
<p>Let’s write the functions to compute just that:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="meta.html#cb264-1" aria-hidden="true" tabindex="-1"></a>ppCurveEst <span class="ot">&lt;-</span> <span class="cf">function</span>(thetac,thetak,sigmak,<span class="at">alpha=</span><span class="fl">0.05</span>){</span>
<span id="cb264-2"><a href="meta.html#cb264-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>((<span class="fu">pnorm</span>((thetac<span class="sc">-</span>thetak)<span class="sc">/</span>sigmak)<span class="sc">/</span><span class="fu">pnorm</span>(thetac<span class="sc">/</span>sigmak<span class="sc">-</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))))</span>
<span id="cb264-3"><a href="meta.html#cb264-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb264-4"><a href="meta.html#cb264-4" aria-hidden="true" tabindex="-1"></a><span class="co">#KS statistic</span></span>
<span id="cb264-5"><a href="meta.html#cb264-5" aria-hidden="true" tabindex="-1"></a>KS.stat.unif <span class="ot">&lt;-</span> <span class="cf">function</span>(vector){</span>
<span id="cb264-6"><a href="meta.html#cb264-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">ks.test</span>(<span class="at">x=</span>vector,<span class="at">y=</span>punif)<span class="sc">$</span>statistic)</span>
<span id="cb264-7"><a href="meta.html#cb264-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb264-8"><a href="meta.html#cb264-8" aria-hidden="true" tabindex="-1"></a>ppCurve.Loss.KS <span class="ot">&lt;-</span> <span class="cf">function</span>(thetac,thetak,sigmak,<span class="at">alpha=</span><span class="fl">0.05</span>){</span>
<span id="cb264-9"><a href="meta.html#cb264-9" aria-hidden="true" tabindex="-1"></a>  ppvalues <span class="ot">&lt;-</span> <span class="fu">ppCurveEst</span>(<span class="at">thetac=</span>thetac,<span class="at">thetak=</span>thetak,<span class="at">sigmak=</span>sigmak,<span class="at">alpha=</span>alpha)</span>
<span id="cb264-10"><a href="meta.html#cb264-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">KS.stat.unif</span>(ppvalues))</span>
<span id="cb264-11"><a href="meta.html#cb264-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb264-12"><a href="meta.html#cb264-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Estimating thetac that minimizes the KS distance by brute grid search first</span></span>
<span id="cb264-13"><a href="meta.html#cb264-13" aria-hidden="true" tabindex="-1"></a><span class="co"># will program the optimize function after</span></span>
<span id="cb264-14"><a href="meta.html#cb264-14" aria-hidden="true" tabindex="-1"></a>ppCurveEstES <span class="ot">&lt;-</span> <span class="cf">function</span>(thetak,sigmak,thetacl,thetach,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">ngrid=</span><span class="dv">100</span>){</span>
<span id="cb264-15"><a href="meta.html#cb264-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># break thetac values in a grid</span></span>
<span id="cb264-16"><a href="meta.html#cb264-16" aria-hidden="true" tabindex="-1"></a>  thetac.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span>thetacl,<span class="at">to=</span>thetach,<span class="at">length.out=</span>ngrid)</span>
<span id="cb264-17"><a href="meta.html#cb264-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># computes the ppcurve for each point of the grid: outputs a matrix where columns are the ppcurves at each values of thetac</span></span>
<span id="cb264-18"><a href="meta.html#cb264-18" aria-hidden="true" tabindex="-1"></a>  ppCurve.grid <span class="ot">&lt;-</span> <span class="fu">sapply</span>(thetac.grid,ppCurveEst,<span class="at">thetak=</span>thetak,<span class="at">sigmak=</span>sigmak,<span class="at">alpha=</span>alpha)</span>
<span id="cb264-19"><a href="meta.html#cb264-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute KS stat for each value of thetac (over columns)</span></span>
<span id="cb264-20"><a href="meta.html#cb264-20" aria-hidden="true" tabindex="-1"></a>  KS.grid <span class="ot">&lt;-</span> <span class="fu">apply</span>(ppCurve.grid,<span class="dv">2</span>,KS.stat.unif)</span>
<span id="cb264-21"><a href="meta.html#cb264-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># computes the value of thetac for which the KS stat is minimum (match identifies the rank of the min in the KSgrid)</span></span>
<span id="cb264-22"><a href="meta.html#cb264-22" aria-hidden="true" tabindex="-1"></a>  min.theta.c <span class="ot">&lt;-</span> thetac.grid[<span class="fu">match</span>(<span class="fu">min</span>(KS.grid),KS.grid)]</span>
<span id="cb264-23"><a href="meta.html#cb264-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># optimizes over KS stat to find value of thetac that minimizes the KS stat</span></span>
<span id="cb264-24"><a href="meta.html#cb264-24" aria-hidden="true" tabindex="-1"></a>  thetahat <span class="ot">&lt;-</span> <span class="fu">optimize</span>(ppCurve.Loss.KS,<span class="fu">c</span>(min.theta.c<span class="fl">-0.1</span>,min.theta.c<span class="fl">+0.1</span>),<span class="at">thetak=</span>thetak,<span class="at">sigmak=</span>sigmak,<span class="at">alpha=</span>alpha)</span>
<span id="cb264-25"><a href="meta.html#cb264-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># returns the optimal thetac, the grid of thetac, the KS stats on the grid, for potential plot, and the ecdf of ppvalues at the optimum theta for graph against the uniform</span></span>
<span id="cb264-26"><a href="meta.html#cb264-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(thetahat<span class="sc">$</span>minimum,thetac.grid,KS.grid,<span class="fu">ecdf</span>(ppCurve.grid[,<span class="fu">match</span>(<span class="fu">min</span>(KS.grid),KS.grid)])))</span>
<span id="cb264-27"><a href="meta.html#cb264-27" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-260" class="example"><strong>Example 13.17  </strong></span>Let’s see how this approach works in our example.
</div>
<p>Let’s start with the homogeneous treatment effect case</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="meta.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="co"># I&#39;m keeping only significant and positive estimates</span></span>
<span id="cb265-2"><a href="meta.html#cb265-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Maybe this could be enforced within the function for ease of reading and use</span></span>
<span id="cb265-3"><a href="meta.html#cb265-3" aria-hidden="true" tabindex="-1"></a>ppCurveBiasCorrFE <span class="ot">&lt;-</span> <span class="fu">ppCurveEstES</span>(<span class="at">thetak=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">&gt;</span><span class="dv">0</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>ES,<span class="at">sigmak=</span><span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES),<span class="at">thetacl=</span><span class="dv">0</span>,<span class="at">thetach=</span><span class="dv">10</span>,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">ngrid=</span><span class="dv">100</span>)</span>
<span id="cb265-4"><a href="meta.html#cb265-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ppCurveBiasCorrFE[[<span class="dv">2</span>]],ppCurveBiasCorrFE[[<span class="dv">3</span>]],<span class="at">xlab=</span><span class="st">&quot;thetac&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;KS statistic&quot;</span>)</span>
<span id="cb265-5"><a href="meta.html#cb265-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ppCurveBiasCorrFE[[<span class="dv">4</span>]],<span class="at">xlab =</span> <span class="st">&quot;ppvalues&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,<span class="at">main=</span><span class="st">&quot;Cumulative density of pp-values at the optimum&quot;</span>)</span>
<span id="cb265-6"><a href="meta.html#cb265-6" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(punif,<span class="at">add=</span>T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pCurvePubBiasFEPlot"></span>
<img src="STCI_files/figure-html/pCurvePubBiasFEPlot-1.png" alt="Correction for publication bias using p-curving with homogeneous effects" width="45%" /><img src="STCI_files/figure-html/pCurvePubBiasFEPlot-2.png" alt="Correction for publication bias using p-curving with homogeneous effects" width="45%" /><img src="STCI_files/figure-html/pCurvePubBiasFEPlot-3.png" alt="Correction for publication bias using p-curving with homogeneous effects" width="45%" />
<p class="caption">
Figure 13.19: Correction for publication bias using p-curving with homogeneous effects
</p>
</div>
<p>The bias corrected estimate using p-curving in the homogeneous treatment effect case is equal to 0.2, which is spot on.
Remember the true treatment effect is NA.
Let’s see what happens when effects are heterogeneous.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="meta.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="co"># I&#39;m keeping only significant and positive estimates</span></span>
<span id="cb266-2"><a href="meta.html#cb266-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Maybe this could be enforced within the function for ease of reading and use</span></span>
<span id="cb266-3"><a href="meta.html#cb266-3" aria-hidden="true" tabindex="-1"></a>ppCurveBiasCorrRE <span class="ot">&lt;-</span> <span class="fu">ppCurveEstES</span>(<span class="at">thetak=</span><span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">&gt;</span><span class="dv">0</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>theta<span class="fl">.1</span>,<span class="at">sigmak=</span><span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES),<span class="at">thetacl=</span><span class="dv">0</span>,<span class="at">thetach=</span><span class="dv">10</span>,<span class="at">alpha=</span><span class="fl">0.05</span>,<span class="at">ngrid=</span><span class="dv">100</span>)</span>
<span id="cb266-4"><a href="meta.html#cb266-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ppCurveBiasCorrRE[[<span class="dv">2</span>]],ppCurveBiasCorrRE[[<span class="dv">3</span>]],<span class="at">xlab=</span><span class="st">&quot;thetac&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;KS statistic&quot;</span>)</span>
<span id="cb266-5"><a href="meta.html#cb266-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ppCurveBiasCorrRE[[<span class="dv">4</span>]],<span class="at">xlab =</span> <span class="st">&quot;ppvalues&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;cumulative density&quot;</span>,<span class="at">main=</span><span class="st">&quot;Cumulative density of pp-values at the optimum&quot;</span>)</span>
<span id="cb266-6"><a href="meta.html#cb266-6" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(punif,<span class="at">add=</span>T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pCurvePubBiasREPlot"></span>
<img src="STCI_files/figure-html/pCurvePubBiasREPlot-1.png" alt="Correction for publication bias using p-curving with heterogeneous effects" width="45%" /><img src="STCI_files/figure-html/pCurvePubBiasREPlot-2.png" alt="Correction for publication bias using p-curving with heterogeneous effects" width="45%" /><img src="STCI_files/figure-html/pCurvePubBiasREPlot-3.png" alt="Correction for publication bias using p-curving with heterogeneous effects" width="45%" />
<p class="caption">
Figure 13.20: Correction for publication bias using p-curving with heterogeneous effects
</p>
</div>
<p>The bias corrected estimate using p-curving in the heterogeneous treatment effect case is equal to 0.35.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The approach might be incorrect in the heterogeneous treatment effect case since we do not normalize using <span class="math inline">\(\tau^2\)</span>.
I think using an estimate of <span class="math inline">\(\tau^2\)</span> to normalize the estimates would restore the validity of the procedure.
It is also possible that the distribution of significant p-values is uniform even under heterogeneity of the treatment effect.
In that case, the p-curve approach would still be valid.
This is scope for further reasearch: first some simulations would be welcome.
Simulations by the authors seem to suggest that p-curve does fine when treatment effects are heterogeneous: see <a href="http://datacolada.org/67">here</a>
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Anther problem with p-curving when correcting for publication bias is the existence of QRPs: QRPs might bias the bias correction because of an excess mass around 0.05.
Simulations by the author in the original paper show that this biases the estimate downward.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Another approach than using the KS statistic could use the distance between the observed pp-curve in Figure <a href="meta.html#fig:pCurvePlot">13.18</a> and the pp-curve with various levels of power.
Once the power is identified, the effect size is identified.
Still another approach would be to use the standardized distribution of effects (distributed as a standardized normal) to estimate the mean of the distribution and then recover the treatment effect.
</div>
</div>
</div>
<div id="z-curving" class="section level4" number="13.2.2.4">
<h4><span class="header-section-number">13.2.2.4</span> Z-curving</h4>
<p>See <a href="https://replicationindex.files.wordpress.com/2018/10/final-revision-874-manuscript-in-pdf-2236-1-4-20180425-mva-final-002.pdf">here</a>.</p>
</div>
<div id="selection-models" class="section level4" number="13.2.2.5">
<h4><span class="header-section-number">13.2.2.5</span> Selection models</h4>
<p>Publication bias generates a usual pattern for economists: a selection model.
The probability that a result is published depends on several properties, let’s say its significance, as measured for example by the t-statistic of a two-sided t-test of the estimated parameter being null.
The resulting distribution of observed effect sizes is a truncated or censored distribution compared to the distribution of true effect sizes.
It has been a long goal of statisticians and economists to try to recover properties of the distribution of a latent unobserved variable from what is observed (think distribution of wages for women, when labor force participation for women was far lower than it is today).</p>
<p>Statisticians have been using selection models to try to correct for publication bias since at least Hedges.
In this section, I’m going to follow closely <a href="https://www.aeaweb.org/articles?id=10.1257/aer.20180310">Andrews and Kasy’s approach</a>.
Andrews and Kasy carefully delineate non-parameteric identification of a selection model in the case of heterogeneous treatment effects.
They then present ways to estimate the parameters of this model and propose a <a href="https://maxkasy.github.io/home/metastudy/">web-app</a> to perform their estimation strategy.</p>
<p>Andrews and Kasy assume that there is a true treatment effect in all the populations that is equal to <span class="math inline">\(\theta^*_c\)</span>.
In each study <span class="math inline">\(k\)</span>, the true treatment effect <span class="math inline">\(\theta^*_k\)</span> is drawn from a distribution with mean <span class="math inline">\(\theta^*_c\)</span>.
If the distribution of <span class="math inline">\(\theta^*_k\)</span> is degenerate, then we have homogeneous treatment effects.
The estimator of <span class="math inline">\(\theta^*_k\)</span> in each study, <span class="math inline">\(\hat{\theta}^*_k\)</span>, is distributed as a normal centered at <span class="math inline">\(\theta^*_k\)</span> with variance <span class="math inline">\(\sigma^{*2}_k\)</span>, whose estimator in the sample <span class="math inline">\(k\)</span> is <span class="math inline">\(\hat{\sigma}^{*2}_k\)</span>.
The normality assumption is not too crazy here: it follows from the CLT.</p>
<p>Andrews and Kasy posit that, because of selection bias, we observe only a subset of these latent effects, noted <span class="math inline">\(\hat{\theta}_k\)</span>, those for which <span class="math inline">\(D_k=1\)</span>.
<span class="math inline">\(D_k\)</span> is distributed as a Bernoulli random variable, with probability of success <span class="math inline">\(p(\hat{Z}_k^*)\)</span>, where <span class="math inline">\(\hat{Z}_k^*=\frac{\hat{\theta}^*_k}{\hat{\sigma}^{*}_k}\)</span> is the test statistic of t-test for the null assumption that <span class="math inline">\(\theta_k=0\)</span>.
So Andrews and Kasy assume that all publication bias is driven by the value of the t-statistic <span class="math inline">\(\hat{Z}_k^*\)</span>.
Note that it is equivalent to assuming that it is driven by the p-value of this test, since one is a monotone transformation of the other.</p>
<p>As a consequence of the assumed selection model, the density of observed t-stats is (noting <span class="math inline">\(Z_k^*=\frac{\theta^*_k}{\sigma^{*}_k}\)</span> and <span class="math inline">\(Z_k=\frac{\theta_k}{\sigma_k}\)</span>):</p>
<p><span class="math display">\[\begin{align*}
  f_{\hat{Z}|Z}(\hat{z}|z) &amp; = f_{\hat{Z}^*|Z^*,D=1}(\hat{z}|z)\\
                           &amp; = \frac{\Pr(D_k=1|\hat{Z}_k^*=\hat{z},Z_k^*=z)}{\Pr(D_k=1|Z_k^*=z)}\phi(\hat{z}-z)\\
                           &amp; = \frac{p(\hat{z})}{\esp{p(\hat{Z}^*_k)|Z_k^*=z}}\phi(\hat{z}-z).
\end{align*}\]</span></p>
<p>The first equality is obtained by using Bayes’ equality twice (once to undo the conditioning on <span class="math inline">\(D=1\)</span> and once to generate the conditioning on <span class="math inline">\(Z^*_k=z\)</span>) and the fact that <span class="math inline">\(f_{\hat{Z}^*|Z^*}\)</span> is normally distributed with mean <span class="math inline">\(Z^*\)</span> and variance 1.</p>
<p>The key result in Andrews and Kasy is their Proposition 3:</p>

<div class="proposition">
<span id="prp:AKident" class="proposition"><strong>Proposition 13.1  (Identification of the true effect in meta-analysis)  </strong></span>Under the assumption that <span class="math inline">\(\theta^*_k\Ind\sigma^*_k\)</span>, and that the support of <span class="math inline">\(\sigma_k\)</span> contains an open interval, <span class="math inline">\(p(.)\)</span> is identified up to scale and the distribution of <span class="math inline">\(\theta^*_k\)</span> is identified.
</div>

<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> See <a href="https://www.aeaweb.org/content/file?id=10286">Andrews and Kasy’s supplementary material</a>.
Let’s detail the proof somehow.
The proof works by using the way the density of observed <span class="math inline">\(\hat{Z}\)</span> changes with precision (<span class="math inline">\(\hat{\pi_k}=\frac{1}{\hat{\sigma}_k}\)</span>).
Without loss of generality, the authors choose to look at the density of <span class="math inline">\(\hat{Z}\)</span> when <span class="math inline">\(\hat{\sigma}_k=1\)</span>.
They define <span class="math inline">\(h(z)=f_{\hat{Z}^*|\hat{\sigma}^*_k}(z|1)\)</span>.
The first insight of the proof is that identifying <span class="math inline">\(h(.)\)</span> identifies <span class="math inline">\(p(.)\)</span> and the distribution of <span class="math inline">\(\theta^*_k\)</span>, <span class="math inline">\(f_{\theta^*}\)</span>.
When <span class="math inline">\(h(.)\)</span> is identified, <span class="math inline">\(f_{\theta^*}\)</span> is identified by deconvolution since <span class="math inline">\(h=f_{\theta^*}*\phi\)</span>, where <span class="math inline">\(*\)</span> is the convolution operator.
This is because we can think of <span class="math inline">\(\hat{\theta}^*_k=\theta^*_k+\epsilon^*_k\)</span>, where <span class="math inline">\(\epsilon^*_k\)</span> is independent from <span class="math inline">\(\theta^*_k\)</span> (since <span class="math inline">\(\theta^*_k\Ind\sigma^*_k\)</span>) and follows a normal with mean zero and variance <span class="math inline">\(\hat{\sigma}^{*2}_k\)</span>, here one.
The density of a sum of independent random variables is the convolution of their densities, hence the result.
Now, we have:</p>
<p><span class="math display">\[\begin{align*}
  f_{\hat{Z}|\hat{\sigma}}(z|s) &amp; = f_{\hat{Z}^*|\hat{\sigma}^*,D=1}(z|z)\\
                           &amp; = \frac{\Pr(D_k=1|\hat{Z}_k^*=z,\hat{\sigma}^*_k=s)}{\Pr(D_k=1|\hat{\sigma}_k^*=s)}f_{\hat{Z}^*|\hat{\sigma}^*}(z|s)\\
                           &amp; = \frac{p(z)}{\esp{p(\hat{Z}^*_k)|\hat{\sigma}^*_k=s}}f_{\hat{Z}^*|\hat{\sigma}^*}(z|s).
\end{align*}\]</span></p>
<p>As a consequence, we have:</p>
<p><span class="math display">\[\begin{align*}
  p(z)&amp; = \esp{p(\hat{Z}^*_k)|\hat{\sigma}_k^*=s}\frac{f_{\hat{Z}|\hat{\sigma}}(z|s)}{h(z)}.
\end{align*}\]</span></p>
<p>So, once we know <span class="math inline">\(h(z)\)</span>, we know <span class="math inline">\(p(z)\)</span> up to a constant, since <span class="math inline">\(f_{\hat{Z}|\hat{\sigma}}(z|s)\)</span> is known by definition, and <span class="math inline">\(\esp{p(\hat{Z}^*_k)|\hat{\sigma}_k^*=s}\)</span> does not change with <span class="math inline">\(z\)</span>.</p>
<p>In order to identify <span class="math inline">\(h(z)\)</span>, we look at how the density of observed effects changes when precision changes:</p>
<p><span class="math display">\[\begin{align*}
  g(z) &amp; = \partder{\ln f_{\hat{Z}|\hat{\sigma}}(z|\frac{1}{\pi})}{\pi}|_{\pi=1}\\
      &amp; = C_1 + \partder{\ln f_{\hat{Z}^*|\hat{\sigma}^*}(z|\frac{1}{\pi})}{\pi}|_{\pi=1}.
\end{align*}\]</span></p>
<p><span class="math inline">\(C_1\)</span> is a constant in <span class="math inline">\(z\)</span>.
This is because <span class="math inline">\(p(z)\)</span> does not depend on <span class="math inline">\(\pi\)</span> and because <span class="math inline">\(\esp{p(\hat{Z}^*_k)|\hat{\sigma}_k^*=s}\)</span> does not depend on <span class="math inline">\(z\)</span>.
Note that <span class="math inline">\(g(z)\)</span> is identified in the population.</p>
<p>Now, using the fact that, because <span class="math inline">\(\theta^*_k\Ind\sigma^*_k\)</span>, we have <span class="math inline">\(h=f_{\theta^*}*\phi\)</span>, and thus <span class="math inline">\(f_{\hat{Z}^*|\hat{\sigma}^*}(z|\frac{1}{\pi})=\int\phi(z-t\pi)df_{\theta^*}(t)\)</span>, and the fact that <span class="math inline">\(\phi&#39;(z)=-z\phi(z)\)</span>, we have:</p>
<p><span class="math display">\[\begin{align*}
  \partder{f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)}{z} &amp; = -\int(z-t)\phi(z-t)df_{\theta^*}(t)\\
   \partdersq{f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)}{z} &amp; = - f_{\hat{Z}^*|\hat{\sigma}^*}(z|1) +\int(z-t)^2\phi(z-t)df_{\theta^*}(t)\\
   \partder{f_{\hat{Z}^*|\hat{\sigma}^*}(z|\frac{1}{\pi})}{\pi}|_{\pi=1} &amp; = \int t(z-t)\phi(z-t)df_{\theta^*}(t)\\
            &amp; = - \left[f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)+z\partder{f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)}{z} + \partdersq{f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)}{z}\right].
\end{align*}\]</span></p>
<p>The last equation comes from rearranging all the terms in the various terms and factoring what remains.
Note that <span class="math inline">\(f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)\)</span> disappears when you add <span class="math inline">\(\partdersq{f_{\hat{Z}^*|\hat{\sigma}^*}(z|1)}{z}\)</span>.
REgrouping under the intergal sign, factoring and simplifying gives the result.</p>
<p>Now, using the expression for <span class="math inline">\(g(z)\)</span> above, we have a second order differential equation in <span class="math inline">\(h(.)\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  h&#39;&#39;(z) &amp; = (C_1-1-g(z))h(z)-zh&#39;(z).
\end{align*}\]</span></p>
Given <span class="math inline">\(C_1\)</span> and initial conditions <span class="math inline">\(h(0)=h_0\)</span> and <span class="math inline">\(h&#39;(0)=h&#39;_0\)</span>, there is a unique solution to this equation, thereby identifying <span class="math inline">\(h(.)\)</span>, <span class="math inline">\(p(.)\)</span> and <span class="math inline">\(f_{\theta^*}\)</span>.
The rest of the proof in <a href="https://www.aeaweb.org/content/file?id=10286">Andrews and Kasy’s supplementary material</a> shows that <span class="math inline">\(C_1\)</span>, <span class="math inline">\(h_0\)</span> and <span class="math inline">\(h&#39;_0\)</span> are all identified.
The proof builds new differential equations involving the second order derivative of <span class="math inline">\(f_{\hat{Z}|\frac{1}{\pi}}\)</span> with respect to <span class="math inline">\(\pi\)</span>.
The constants are identified after successive derivations with respect to <span class="math inline">\(z\)</span> so that we have an equation for them that depends on the third order derivative of <span class="math inline">\(g\)</span>.
</div>

<div class="remark">
<p> <span class="remark"><em>Remark. </em></span> The authors derive an equation for the case where <span class="math inline">\(\theta^*\)</span> is normally distributed with mean <span class="math inline">\(\theta\)</span> and variance <span class="math inline">\(\tau^2\)</span>.
The second order differential equation becomes:</p>
<p><span class="math display">\[\begin{align*}
  -\frac{1}{\tau^2+1} &amp; = C_1-g(z)-1+z\frac{z-\theta}{\tau^2+1}-\left(\frac{z-\theta}{\tau^2+1}\right).
\end{align*}\]</span></p>
The authors argue that evaluating this equation for different values of <span class="math inline">\(z\)</span> pins down <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\tau^2\)</span>.
It seems not enough to prove identification since we need uniqueness of the parameter values obtained.
There are already two values of <span class="math inline">\(\theta\)</span> compatible for agiven <span class="math inline">\(z\)</span> and <span class="math inline">\(\tau^2\)</span>.
We need more to ensure uniqueness.
</div>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Note that <span class="math inline">\(p(z)\)</span> does not depend on <span class="math inline">\(\pi\)</span> is not a trivial assumption.
It stems from assuming that the probability of publication only depends on <span class="math inline">\(\pi\)</span> through <span class="math inline">\(\hat{Z}^*\)</span>.
It means for example that editors and authors do not look at precision independently of its effect on the t-statistic.
The authors study identification in this case, assuming independence of the probabilities of selection based on both approaches.
</div>
<p>For estimation, Andrews and Kasy follow the approach in <a href="https://projecteuclid.org/euclid.ss/1177011364">Hedges</a> and estimate their model by parametric maximum likelihood.
They also propose in their <a href="https://www.aeaweb.org/content/file?id=10286">supplementary material</a> an approach based on a Generalized Method of Moments estimator that tries to emulate their identification strategy.
Finally, they offer a <a href="https://maxkasy.github.io/home/metastudy/">web-app</a> to implement their most straightforward estimators.</p>
<p>The likelihood can be written as:</p>
<p><span class="math display">\[\begin{align*}
  f_{\hat{\theta},\hat{\sigma}}(t,s) &amp; = \frac{p\left(\frac{t}{s}\right)\int\phi\left(\frac{t-\theta}{s}\right)f_{\theta^*}(\theta) d\theta}
                                              {\int p\left(\frac{t&#39;}{s}\right)\int\phi\left(\frac{t&#39;-\theta}{s}\right)f_{\theta^*}(\theta) d\theta dt&#39;}f_{\sigma}(s).
\end{align*}\]</span></p>
<p>Under the assumption that <span class="math inline">\(\theta^*\)</span> is normally distributed with mean <span class="math inline">\(\theta^*_c\)</span> and variance <span class="math inline">\(\tau^2\)</span>, we have the following likelihood:</p>
<p><span class="math display">\[\begin{align*}
  f^n_{\hat{\theta},\hat{\sigma}}(t,s) &amp; = \frac{p\left(\frac{t}{s}\right)\phi\left(\frac{t-\theta^*_c}{\sqrt{s^2+\tau^2}}\right)}
                                              {\int p\left(\frac{t&#39;}{s}\right)\phi\left(\frac{t&#39;-\theta^*_c}{\sqrt{s^2+\tau^2}}\right)dt&#39;}f_{\sigma}(s).
\end{align*}\]</span></p>
<p>Assuming that <span class="math inline">\(p(.)\)</span> is a step function such that <span class="math inline">\(p(z)=p_1\)</span> if <span class="math inline">\(z&lt;1.96\)</span> and <span class="math inline">\(p(z)=1\)</span> if <span class="math inline">\(z\geq1.96\)</span>, we have:</p>
<p><span class="math display">\[\begin{align*}
  f^n_{\hat{\theta},\hat{\sigma}}(t,s) &amp; = \frac{p\left(\frac{t}{s}\right)\phi\left(\frac{t-\theta^*_c}{\sqrt{s^2+\tau^2}}\right)}
                                              {p_1\Phi\left(\frac{1.96s-\theta^*_c}{\sqrt{s^2+\tau^2}}\right)+1-\Phi\left(\frac{1.96s-\theta^*_c}{\sqrt{s^2+\tau^2}}\right)}f_{\sigma}(s).
\end{align*}\]</span></p>
<p>The likelihood is simply the product of this term computed at each values <span class="math inline">\(t=\hat{\theta}_k\)</span> and <span class="math inline">\(s=\hat{\sigma}_k\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\mathcal{L}(p_1,\theta^*_c,\tau^2)=\Pi_{k=1}^Nf^n_{\hat{\theta},\hat{\sigma}}(\hat{\theta}_k,\hat{\sigma}_k)
\end{align*}\]</span></p>
<p>Taking logs, we see that <span class="math inline">\(f_{\sigma}(s)\)</span> is a constant that does not contribute to the likelihood.
We solve for the optimal vector of parameters by using a nonlinear optimisation routine.
The authors use <code>nlminb</code>.
One could also probably use <code>optim</code>.
What is nice with these procedures is that they do not require computing the first and second order derivatives of the objective function: they compute them numerically.</p>
<p>Let’s write an R function that maximizes this log likelihood:</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="meta.html#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co"># log-likelihood</span></span>
<span id="cb267-2"><a href="meta.html#cb267-2" aria-hidden="true" tabindex="-1"></a>Lk <span class="ot">&lt;-</span> <span class="cf">function</span>(thetak,sigmak,p1,thetac,tau){</span>
<span id="cb267-3"><a href="meta.html#cb267-3" aria-hidden="true" tabindex="-1"></a>  f <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(thetak<span class="sc">/</span>sigmak<span class="sc">&lt;</span><span class="fu">qnorm</span>(<span class="dv">1</span><span class="fl">-0.05</span><span class="sc">/</span><span class="dv">2</span>),p1,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">dnorm</span>((thetak<span class="sc">-</span>thetac)<span class="sc">/</span><span class="fu">sqrt</span>(sigmak<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>tau<span class="sc">^</span><span class="dv">2</span>))<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">qnorm</span>(<span class="dv">1</span><span class="fl">-0.05</span><span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span>sigmak<span class="sc">-</span>thetac<span class="sc">/</span><span class="fu">sqrt</span>(sigmak<span class="sc">^</span><span class="dv">2</span><span class="sc">+</span>tau<span class="sc">^</span><span class="dv">2</span>))<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p1))</span>
<span id="cb267-4"><a href="meta.html#cb267-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">sum</span>(<span class="fu">log</span>(f)))</span>
<span id="cb267-5"><a href="meta.html#cb267-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb267-6"><a href="meta.html#cb267-6" aria-hidden="true" tabindex="-1"></a><span class="co">#log-likelihood prepared for nlminb: vector of parameters and minimization</span></span>
<span id="cb267-7"><a href="meta.html#cb267-7" aria-hidden="true" tabindex="-1"></a>Lk.param <span class="ot">&lt;-</span> <span class="cf">function</span>(param,thetak,sigmak){</span>
<span id="cb267-8"><a href="meta.html#cb267-8" aria-hidden="true" tabindex="-1"></a>  f <span class="ot">&lt;-</span> <span class="fu">Lk</span>(<span class="at">thetak=</span>thetak,<span class="at">sigmak=</span>sigmak,<span class="at">p1=</span>param[[<span class="dv">1</span>]],<span class="at">thetac=</span>param[<span class="dv">2</span>],<span class="at">tau=</span>param[<span class="dv">3</span>])</span>
<span id="cb267-9"><a href="meta.html#cb267-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>f)</span>
<span id="cb267-10"><a href="meta.html#cb267-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-267" class="example"><strong>Example 13.18  </strong></span>Let’s see how this works in our example.
Let’s first prepare the sample.
We are going to simulate two procedures of censoring: one with <span class="math inline">\(p_1=0.5\)</span> and one with <span class="math inline">\(p_1=0\)</span>.
</div>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="meta.html#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample with p1=0: only positive significant results</span></span>
<span id="cb268-2"><a href="meta.html#cb268-2" aria-hidden="true" tabindex="-1"></a><span class="co"># homogeneous effects</span></span>
<span id="cb268-3"><a href="meta.html#cb268-3" aria-hidden="true" tabindex="-1"></a>thetak.FE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">&gt;</span><span class="dv">0</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>ES</span>
<span id="cb268-4"><a href="meta.html#cb268-4" aria-hidden="true" tabindex="-1"></a>sigmak.FE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES)</span>
<span id="cb268-5"><a href="meta.html#cb268-5" aria-hidden="true" tabindex="-1"></a><span class="co"># heterogeneous effects</span></span>
<span id="cb268-6"><a href="meta.html#cb268-6" aria-hidden="true" tabindex="-1"></a>thetak.RE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">&gt;</span><span class="dv">0</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>theta<span class="fl">.1</span></span>
<span id="cb268-7"><a href="meta.html#cb268-7" aria-hidden="true" tabindex="-1"></a>sigmak.RE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,<span class="fu">abs</span>(data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES))<span class="sc">&gt;=</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES)</span>
<span id="cb268-8"><a href="meta.html#cb268-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-9"><a href="meta.html#cb268-9" aria-hidden="true" tabindex="-1"></a><span class="co"># sample with p1=0.1, for insignificant or negative results</span></span>
<span id="cb268-10"><a href="meta.html#cb268-10" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb268-11"><a href="meta.html#cb268-11" aria-hidden="true" tabindex="-1"></a><span class="co"># drawing 10% among insignificant and negative observations</span></span>
<span id="cb268-12"><a href="meta.html#cb268-12" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb268-13"><a href="meta.html#cb268-13" aria-hidden="true" tabindex="-1"></a>set.FE <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="fu">runif</span>(<span class="fu">length</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>ES))<span class="sc">&lt;=</span>p1,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">==</span><span class="dv">1</span></span>
<span id="cb268-14"><a href="meta.html#cb268-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb268-15"><a href="meta.html#cb268-15" aria-hidden="true" tabindex="-1"></a>set.RE <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="fu">runif</span>(<span class="fu">length</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>theta<span class="fl">.1</span>))<span class="sc">&lt;=</span>p1,<span class="dv">1</span>,<span class="dv">0</span>)<span class="sc">==</span><span class="dv">1</span></span>
<span id="cb268-16"><a href="meta.html#cb268-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-17"><a href="meta.html#cb268-17" aria-hidden="true" tabindex="-1"></a><span class="co"># homogeneous effects</span></span>
<span id="cb268-18"><a href="meta.html#cb268-18" aria-hidden="true" tabindex="-1"></a>thetak.FE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(thetak.FE<span class="fl">.0</span>,<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>ES[<span class="fu">which</span>(set.FE)]) </span>
<span id="cb268-19"><a href="meta.html#cb268-19" aria-hidden="true" tabindex="-1"></a>sigmak.FE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(sigmak.FE<span class="fl">.0</span>,<span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>ES<span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES[<span class="fu">which</span>(set.FE)]))</span>
<span id="cb268-20"><a href="meta.html#cb268-20" aria-hidden="true" tabindex="-1"></a><span class="co"># heterogeneous effects</span></span>
<span id="cb268-21"><a href="meta.html#cb268-21" aria-hidden="true" tabindex="-1"></a>thetak.RE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(thetak.RE<span class="fl">.0</span>,<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>theta<span class="fl">.1</span>[<span class="fu">which</span>(set.RE)])</span>
<span id="cb268-22"><a href="meta.html#cb268-22" aria-hidden="true" tabindex="-1"></a>sigmak.RE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(sigmak.RE<span class="fl">.0</span>,<span class="fu">sqrt</span>(<span class="fu">filter</span>(data.meta,id<span class="sc">&lt;=</span><span class="dv">17</span>,data.meta<span class="sc">$</span>theta<span class="fl">.1</span><span class="sc">/</span><span class="fu">sqrt</span>(data.meta<span class="sc">$</span>var.ES)<span class="sc">&lt;</span><span class="fu">qnorm</span>((<span class="dv">1</span><span class="sc">+</span>delta<span class="fl">.2</span>)<span class="sc">/</span><span class="dv">2</span>))<span class="sc">$</span>var.ES[<span class="fu">which</span>(set.RE)]))</span></code></pre></div>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="meta.html#cb269-1" aria-hidden="true" tabindex="-1"></a><span class="co"># optimization procedure using nlminb</span></span>
<span id="cb269-2"><a href="meta.html#cb269-2" aria-hidden="true" tabindex="-1"></a>MaxEval<span class="ot">&lt;-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">5</span></span>
<span id="cb269-3"><a href="meta.html#cb269-3" aria-hidden="true" tabindex="-1"></a>MaxIter<span class="ot">&lt;-</span><span class="dv">10</span><span class="sc">^</span><span class="dv">5</span></span>
<span id="cb269-4"><a href="meta.html#cb269-4" aria-hidden="true" tabindex="-1"></a>Tol<span class="ot">&lt;-</span><span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">8</span>)</span>
<span id="cb269-5"><a href="meta.html#cb269-5" aria-hidden="true" tabindex="-1"></a>stepsize<span class="ot">&lt;-</span><span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">6</span>)</span>
<span id="cb269-6"><a href="meta.html#cb269-6" aria-hidden="true" tabindex="-1"></a>lower.b <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="sc">-</span><span class="cn">Inf</span>,<span class="dv">0</span>)</span>
<span id="cb269-7"><a href="meta.html#cb269-7" aria-hidden="true" tabindex="-1"></a>upper.b <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="cn">Inf</span>,<span class="cn">Inf</span>)</span>
<span id="cb269-8"><a href="meta.html#cb269-8" aria-hidden="true" tabindex="-1"></a>start.val <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb269-9"><a href="meta.html#cb269-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb269-10"><a href="meta.html#cb269-10" aria-hidden="true" tabindex="-1"></a>optim.Lk.FE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(<span class="at">objective=</span>Lk.param, <span class="at">start=</span>start.val,<span class="at">lower=</span>lower.b,<span class="at">upper=</span>upper.b,<span class="at">control=</span><span class="fu">list</span>(<span class="at">eval.max=</span>MaxEval,<span class="at">iter.max=</span>MaxIter,<span class="at">abs.tol=</span>Tol),<span class="at">thetak=</span>thetak.FE<span class="fl">.0</span>,<span class="at">sigmak=</span>sigmak.FE<span class="fl">.0</span>)</span>
<span id="cb269-11"><a href="meta.html#cb269-11" aria-hidden="true" tabindex="-1"></a>optim.Lk.FE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(<span class="at">objective=</span>Lk.param, <span class="at">start=</span>start.val,<span class="at">lower=</span>lower.b,<span class="at">upper=</span>upper.b,<span class="at">control=</span><span class="fu">list</span>(<span class="at">eval.max=</span>MaxEval,<span class="at">iter.max=</span>MaxIter,<span class="at">abs.tol=</span>Tol),<span class="at">thetak=</span>thetak.FE<span class="fl">.1</span>,<span class="at">sigmak=</span>sigmak.FE<span class="fl">.1</span>)</span>
<span id="cb269-12"><a href="meta.html#cb269-12" aria-hidden="true" tabindex="-1"></a>optim.Lk.RE<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(<span class="at">objective=</span>Lk.param, <span class="at">start=</span>start.val,<span class="at">lower=</span>lower.b,<span class="at">upper=</span>upper.b,<span class="at">control=</span><span class="fu">list</span>(<span class="at">eval.max=</span>MaxEval,<span class="at">iter.max=</span>MaxIter,<span class="at">abs.tol=</span>Tol),<span class="at">thetak=</span>thetak.RE<span class="fl">.0</span>,<span class="at">sigmak=</span>sigmak.RE<span class="fl">.0</span>)</span>
<span id="cb269-13"><a href="meta.html#cb269-13" aria-hidden="true" tabindex="-1"></a>optim.Lk.RE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(<span class="at">objective=</span>Lk.param, <span class="at">start=</span>start.val,<span class="at">lower=</span>lower.b,<span class="at">upper=</span>upper.b,<span class="at">control=</span><span class="fu">list</span>(<span class="at">eval.max=</span>MaxEval,<span class="at">iter.max=</span>MaxIter,<span class="at">abs.tol=</span>Tol),<span class="at">thetak=</span>thetak.RE<span class="fl">.1</span>,<span class="at">sigmak=</span>sigmak.RE<span class="fl">.1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="meta.html#cb270-1" aria-hidden="true" tabindex="-1"></a>paramAK <span class="ot">&lt;-</span> <span class="fu">rbind</span>(optim.Lk.FE<span class="fl">.0</span><span class="sc">$</span>par,optim.Lk.FE<span class="fl">.1</span><span class="sc">$</span>par,optim.Lk.RE<span class="fl">.0</span><span class="sc">$</span>par,optim.Lk.RE<span class="fl">.1</span><span class="sc">$</span>par)</span>
<span id="cb270-2"><a href="meta.html#cb270-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(paramAK) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;$p_1$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">theta_c$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">tau$&quot;</span>)</span>
<span id="cb270-3"><a href="meta.html#cb270-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(paramAK) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;FE0&quot;</span>,<span class="st">&quot;FE50&quot;</span>,<span class="st">&quot;RE0&quot;</span>,<span class="st">&quot;RE50&quot;</span>)</span>
<span id="cb270-4"><a href="meta.html#cb270-4" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(paramAK,<span class="at">digits=</span><span class="dv">2</span>,<span class="at">caption=</span><span class="st">&#39;Parameter estimates of Andrews and Kasy selection model&#39;</span>,<span class="at">align=</span><span class="fu">c</span>(<span class="st">&#39;l&#39;</span>,<span class="st">&#39;c&#39;</span>,<span class="st">&#39;c&#39;</span>,<span class="st">&#39;c&#39;</span>),<span class="at">booktabs=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<table>
<caption><span id="tab:resultsMatrixAK">Table 13.1: </span>Parameter estimates of Andrews and Kasy selection model</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left"><span class="math inline">\(p_1\)</span></th>
<th align="center"><span class="math inline">\(\theta_c\)</span></th>
<th align="center"><span class="math inline">\(\tau\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">FE0</td>
<td align="left">0.00</td>
<td align="center">-100842.0</td>
<td align="center">15537.35</td>
</tr>
<tr class="even">
<td align="left">FE50</td>
<td align="left">0.04</td>
<td align="center">-245889.4</td>
<td align="center">219861.04</td>
</tr>
<tr class="odd">
<td align="left">RE0</td>
<td align="left">0.00</td>
<td align="center">-5.4</td>
<td align="center">0.19</td>
</tr>
<tr class="even">
<td align="left">RE50</td>
<td align="left">0.03</td>
<td align="center">-352375.7</td>
<td align="center">277781.96</td>
</tr>
</tbody>
</table>
<p>Table  shows the parameter estimates of the model for various data configurations (no treatment effect heterogeneity vs treatment effect heterogeneity and 0% or 50% of non significant observations published).
The results do not look great.
The estimates of <span class="math inline">\(p_1\)</span> are correct when no non significant effects are published, by they are not nearly large enough when <span class="math inline">\(50\%\)</span> of insignificant observations are published.
The estimates of <span class="math inline">\(\theta_c\)</span> are completely crazy: all negative and large in asbolute value while the true value of <span class="math inline">\(\theta_c\)</span> is <span class="math inline">\(\theta_c=\)</span> NA.
The estimates of <span class="math inline">\(\tau\)</span> are also all misleading.
For fixed effects, the estimates should be zero.
For random effects, the true <span class="math inline">\(\tau\)</span> is <span class="math inline">\(\tau=\)</span> 0.5.
The estimates are much too large, apart from the third one that is close to home.
Overall, barring a coding error, selection models do not look super promising here.</p>
</div>
<div id="fukumura" class="section level4" number="13.2.2.6">
<h4><span class="header-section-number">13.2.2.6</span> Fukumura</h4>
</div>
<div id="trim-and-fill" class="section level4" number="13.2.2.7">
<h4><span class="header-section-number">13.2.2.7</span> Trim and fill</h4>
</div>
</div>
<div id="getting-rid-of-publication-bias-registered-reports-and-pre-analysis-plans" class="section level3" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Getting rid of publication bias: registered reports and pre-analysis plans</h3>
</div>
<div id="detection-of-and-correction-for-site-selection-bias" class="section level3" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Detection of and correction for site selection bias</h3>
</div>
<div id="vote-counting-and-publication-bias" class="section level3" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Vote counting and publication bias</h3>
</div>
<div id="the-value-of-a-statistically-significant-result" class="section level3" number="13.2.6">
<h3><span class="header-section-number">13.2.6</span> The value of a statistically significant result</h3>
<p><strong><span class="smallcaps">Publication bias and random effects</span></strong></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Distribution.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Bounds.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/chabefer/STCI/blob/master/12_Meta.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["STCI.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 1
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
