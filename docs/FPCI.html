<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Fundamental Problem of Causal Inference | Statistical Tools for Causal Inference</title>
  <meta name="description" content="This is an open source collaborative book." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Fundamental Problem of Causal Inference | Statistical Tools for Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source collaborative book." />
  <meta name="github-repo" content="chabefer/STCI" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Fundamental Problem of Causal Inference | Statistical Tools for Causal Inference" />
  
  <meta name="twitter:description" content="This is an open source collaborative book." />
  

<meta name="author" content="The SKY Community" />


<meta name="date" content="2020-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-the-two-fundamental-problems-of-inference.html"/>
<link rel="next" href="FPSI.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









$$
\newcommand{\uns}[1]{\mathbf{1}[#1]}
\newcommand{\esp}[1]{\mathbf{E}[#1]}
\newcommand{\Ind}{\perp\kern-5pt\perp}
\newcommand{\var}[1]{\mathbf{V}[ #1 ]}
\newcommand{\cov}[1]{\mathbf{C}[ #1 ]}
\newcommand{\plim}[1]{\text{plim}_{ #1 \rightarrow \infty}}
\newcommand{\plims}{\text{plim}}
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\DeclareMathOperator{\diag}{diag}
$$


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Tools for Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Fundamental Problems of Inference</b></span></li>
<li class="chapter" data-level="" data-path="introduction-the-two-fundamental-problems-of-inference.html"><a href="introduction-the-two-fundamental-problems-of-inference.html"><i class="fa fa-check"></i>Introduction: the Two Fundamental Problems of Inference</a></li>
<li class="chapter" data-level="1" data-path="FPCI.html"><a href="FPCI.html"><i class="fa fa-check"></i><b>1</b> Fundamental Problem of Causal Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="FPCI.html"><a href="FPCI.html#rubin-causal-model"><i class="fa fa-check"></i><b>1.1</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="1.1.1" data-path="FPCI.html"><a href="FPCI.html#treatment-allocation-rule"><i class="fa fa-check"></i><b>1.1.1</b> Treatment allocation rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="FPCI.html"><a href="FPCI.html#potential-outcomes"><i class="fa fa-check"></i><b>1.1.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="1.1.3" data-path="FPCI.html"><a href="FPCI.html#switching-equation"><i class="fa fa-check"></i><b>1.1.3</b> Switching equation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="FPCI.html"><a href="FPCI.html#treatment-effects"><i class="fa fa-check"></i><b>1.2</b> Treatment effects</a><ul>
<li class="chapter" data-level="1.2.1" data-path="FPCI.html"><a href="FPCI.html#individual-level-treatment-effects"><i class="fa fa-check"></i><b>1.2.1</b> Individual level treatment effects</a></li>
<li class="chapter" data-level="1.2.2" data-path="FPCI.html"><a href="FPCI.html#average-treatment-effect-on-the-treated"><i class="fa fa-check"></i><b>1.2.2</b> Average treatment effect on the treated</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="FPCI.html"><a href="FPCI.html#fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Fundamental problem of causal inference</a></li>
<li class="chapter" data-level="1.4" data-path="FPCI.html"><a href="FPCI.html#intuitive-estimators-confounding-factors-and-selection-bias"><i class="fa fa-check"></i><b>1.4</b> Intuitive estimators, confounding factors and selection bias</a><ul>
<li class="chapter" data-level="1.4.1" data-path="FPCI.html"><a href="FPCI.html#withwithout-comparison-selection-bias-and-cross-sectional-confounders"><i class="fa fa-check"></i><b>1.4.1</b> With/Without comparison, selection bias and cross-sectional confounders</a></li>
<li class="chapter" data-level="1.4.2" data-path="FPCI.html"><a href="FPCI.html#the-beforeafter-comparison-temporal-confounders-and-time-trend-bias"><i class="fa fa-check"></i><b>1.4.2</b> The before/after comparison, temporal confounders and time trend bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FPSI.html"><a href="FPSI.html"><i class="fa fa-check"></i><b>2</b> Fundamental Problem of Statistical Inference</a><ul>
<li class="chapter" data-level="2.1" data-path="FPSI.html"><a href="FPSI.html#sec:sampnoise"><i class="fa fa-check"></i><b>2.1</b> What is sampling noise? Definition and illustration</a><ul>
<li class="chapter" data-level="2.1.1" data-path="FPSI.html"><a href="FPSI.html#sec:definitionnoise"><i class="fa fa-check"></i><b>2.1.1</b> Sampling noise, a definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisepop"><i class="fa fa-check"></i><b>2.1.2</b> Sampling noise for the population treatment effect</a></li>
<li class="chapter" data-level="2.1.3" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisesamp"><i class="fa fa-check"></i><b>2.1.3</b> Sampling noise for the sample treatment effect</a></li>
<li class="chapter" data-level="2.1.4" data-path="FPSI.html"><a href="FPSI.html#sec:confinterv"><i class="fa fa-check"></i><b>2.1.4</b> Building confidence intervals from estimates of sampling noise</a></li>
<li class="chapter" data-level="2.1.5" data-path="FPSI.html"><a href="FPSI.html#reporting-sampling-noise-a-proposal"><i class="fa fa-check"></i><b>2.1.5</b> Reporting sampling noise: a proposal</a></li>
<li class="chapter" data-level="2.1.6" data-path="FPSI.html"><a href="FPSI.html#sec:effectsize"><i class="fa fa-check"></i><b>2.1.6</b> Using effect sizes to normalize the reporting of treatment effects and their precision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FPSI.html"><a href="FPSI.html#sec:estimsampnoise"><i class="fa fa-check"></i><b>2.2</b> Estimating sampling noise</a><ul>
<li class="chapter" data-level="2.2.1" data-path="FPSI.html"><a href="FPSI.html#sec:assumptions"><i class="fa fa-check"></i><b>2.2.1</b> Assumptions</a></li>
<li class="chapter" data-level="2.2.2" data-path="FPSI.html"><a href="FPSI.html#sec:cheb"><i class="fa fa-check"></i><b>2.2.2</b> Using Chebyshev’s inequality</a></li>
<li class="chapter" data-level="2.2.3" data-path="FPSI.html"><a href="FPSI.html#sec:CLT"><i class="fa fa-check"></i><b>2.2.3</b> Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.4" data-path="FPSI.html"><a href="FPSI.html#sec:resamp"><i class="fa fa-check"></i><b>2.2.4</b> Using resampling methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Methods of Causal Inference</b></span></li>
<li class="chapter" data-level="3" data-path="RCT.html"><a href="RCT.html"><i class="fa fa-check"></i><b>3</b> Randomized Controlled Trials</a><ul>
<li class="chapter" data-level="3.1" data-path="RCT.html"><a href="RCT.html#sec:design1"><i class="fa fa-check"></i><b>3.1</b> Brute Force Design</a><ul>
<li class="chapter" data-level="3.1.1" data-path="RCT.html"><a href="RCT.html#identification"><i class="fa fa-check"></i><b>3.1.1</b> Identification</a></li>
<li class="chapter" data-level="3.1.2" data-path="RCT.html"><a href="RCT.html#estimating-ate"><i class="fa fa-check"></i><b>3.1.2</b> Estimating ATE</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="RCT.html"><a href="RCT.html#sec:design2"><i class="fa fa-check"></i><b>3.2</b> Self-Selection design</a><ul>
<li class="chapter" data-level="3.2.1" data-path="RCT.html"><a href="RCT.html#identification-1"><i class="fa fa-check"></i><b>3.2.1</b> Identification</a></li>
<li class="chapter" data-level="3.2.2" data-path="RCT.html"><a href="RCT.html#estimating-tt"><i class="fa fa-check"></i><b>3.2.2</b> Estimating TT</a></li>
<li class="chapter" data-level="3.2.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="RCT.html"><a href="RCT.html#sec:design3"><i class="fa fa-check"></i><b>3.3</b> Eligibility design</a><ul>
<li class="chapter" data-level="3.3.1" data-path="RCT.html"><a href="RCT.html#identification-2"><i class="fa fa-check"></i><b>3.3.1</b> Identification</a></li>
<li class="chapter" data-level="3.3.2" data-path="RCT.html"><a href="RCT.html#estimating-the-ite-and-the-tt"><i class="fa fa-check"></i><b>3.3.2</b> Estimating the ITE and the TT</a></li>
<li class="chapter" data-level="3.3.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-2"><i class="fa fa-check"></i><b>3.3.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="RCT.html"><a href="RCT.html#sec:design4"><i class="fa fa-check"></i><b>3.4</b> Encouragement Design</a><ul>
<li class="chapter" data-level="3.4.1" data-path="RCT.html"><a href="RCT.html#identification-3"><i class="fa fa-check"></i><b>3.4.1</b> Identification</a></li>
<li class="chapter" data-level="3.4.2" data-path="RCT.html"><a href="RCT.html#estimating-the-local-average-treatment-effect-and-the-intention-to-treat-effect"><i class="fa fa-check"></i><b>3.4.2</b> Estimating the Local Average Treatment Effect and the Intention to Treat Effect</a></li>
<li class="chapter" data-level="3.4.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-3"><i class="fa fa-check"></i><b>3.4.3</b> Estimating sampling noise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="NE.html"><a href="NE.html"><i class="fa fa-check"></i><b>4</b> Natural Experiments</a><ul>
<li class="chapter" data-level="4.1" data-path="NE.html"><a href="NE.html#instrumental-variables"><i class="fa fa-check"></i><b>4.1</b> Instrumental Variables</a><ul>
<li class="chapter" data-level="4.1.1" data-path="NE.html"><a href="NE.html#an-example-where-monotonicity-does-not-hold"><i class="fa fa-check"></i><b>4.1.1</b> An example where Monotonicity does not hold</a></li>
<li class="chapter" data-level="4.1.2" data-path="NE.html"><a href="NE.html#identification-4"><i class="fa fa-check"></i><b>4.1.2</b> Identification</a></li>
<li class="chapter" data-level="4.1.3" data-path="NE.html"><a href="NE.html#estimation"><i class="fa fa-check"></i><b>4.1.3</b> Estimation</a></li>
<li class="chapter" data-level="4.1.4" data-path="NE.html"><a href="NE.html#estimation-of-sampling-noise"><i class="fa fa-check"></i><b>4.1.4</b> Estimation of sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="NE.html"><a href="NE.html#regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2</b> Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="4.3" data-path="NE.html"><a href="NE.html#difference-in-differences"><i class="fa fa-check"></i><b>4.3</b> Difference In Differences</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sec-OM.html"><a href="sec-OM.html"><i class="fa fa-check"></i><b>5</b> Observational Methods</a></li>
<li class="chapter" data-level="6" data-path="sec-threats.html"><a href="sec-threats.html"><i class="fa fa-check"></i><b>6</b> Threats to the validity of Causal Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="sec-threats.html"><a href="sec-threats.html#threats-to-internal-validity"><i class="fa fa-check"></i><b>6.1</b> Threats to internal validity</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sec-threats.html"><a href="sec-threats.html#survey-bias"><i class="fa fa-check"></i><b>6.1.1</b> Survey bias</a></li>
<li class="chapter" data-level="6.1.2" data-path="sec-threats.html"><a href="sec-threats.html#experimenter-bias"><i class="fa fa-check"></i><b>6.1.2</b> Experimenter bias</a></li>
<li class="chapter" data-level="6.1.3" data-path="sec-threats.html"><a href="sec-threats.html#substitution-bias"><i class="fa fa-check"></i><b>6.1.3</b> Substitution bias</a></li>
<li class="chapter" data-level="6.1.4" data-path="sec-threats.html"><a href="sec-threats.html#diffusion-bias"><i class="fa fa-check"></i><b>6.1.4</b> Diffusion bias</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="sec-threats.html"><a href="sec-threats.html#threats-to-the-measurement-of-precision"><i class="fa fa-check"></i><b>6.2</b> Threats to the measurement of precision</a><ul>
<li class="chapter" data-level="6.2.1" data-path="sec-threats.html"><a href="sec-threats.html#insufficient-precision"><i class="fa fa-check"></i><b>6.2.1</b> Insufficient precision</a></li>
<li class="chapter" data-level="6.2.2" data-path="sec-threats.html"><a href="sec-threats.html#clustering"><i class="fa fa-check"></i><b>6.2.2</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sec-threats.html"><a href="sec-threats.html#threats-to-external-validity"><i class="fa fa-check"></i><b>6.3</b> Threats to external validity</a><ul>
<li class="chapter" data-level="6.3.1" data-path="sec-threats.html"><a href="sec-threats.html#randomization-bias"><i class="fa fa-check"></i><b>6.3.1</b> Randomization bias</a></li>
<li class="chapter" data-level="6.3.2" data-path="sec-threats.html"><a href="sec-threats.html#equilibrium-effects"><i class="fa fa-check"></i><b>6.3.2</b> Equilibrium effects</a></li>
<li class="chapter" data-level="6.3.3" data-path="sec-threats.html"><a href="sec-threats.html#context-effects"><i class="fa fa-check"></i><b>6.3.3</b> Context effects</a></li>
<li class="chapter" data-level="6.3.4" data-path="sec-threats.html"><a href="sec-threats.html#site-selection-bias"><i class="fa fa-check"></i><b>6.3.4</b> Site selection bias</a></li>
<li class="chapter" data-level="6.3.5" data-path="sec-threats.html"><a href="sec-threats.html#publication-bias"><i class="fa fa-check"></i><b>6.3.5</b> Publication bias</a></li>
<li class="chapter" data-level="6.3.6" data-path="sec-threats.html"><a href="sec-threats.html#ethical-and-political-issues"><i class="fa fa-check"></i><b>6.3.6</b> Ethical and political issues</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Additional Topics</b></span></li>
<li class="chapter" data-level="7" data-path="Power.html"><a href="Power.html"><i class="fa fa-check"></i><b>7</b> Power Analysis</a></li>
<li class="chapter" data-level="8" data-path="Placebo.html"><a href="Placebo.html"><i class="fa fa-check"></i><b>8</b> Placebo Tests</a></li>
<li class="chapter" data-level="9" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>9</b> Clustering</a></li>
<li class="chapter" data-level="10" data-path="LaLonde.html"><a href="LaLonde.html"><i class="fa fa-check"></i><b>10</b> LaLonde Tests</a></li>
<li class="chapter" data-level="11" data-path="Diffusion.html"><a href="Diffusion.html"><i class="fa fa-check"></i><b>11</b> Diffusion effects</a></li>
<li class="chapter" data-level="12" data-path="Distribution.html"><a href="Distribution.html"><i class="fa fa-check"></i><b>12</b> Distributional effects</a></li>
<li class="chapter" data-level="13" data-path="sec-meta.html"><a href="sec-meta.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and Publication Bias</a><ul>
<li class="chapter" data-level="13.1" data-path="sec-meta.html"><a href="sec-meta.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a><ul>
<li class="chapter" data-level="13.1.1" data-path="sec-meta.html"><a href="sec-meta.html#basic-setting"><i class="fa fa-check"></i><b>13.1.1</b> Basic setting</a></li>
<li class="chapter" data-level="13.1.2" data-path="sec-meta.html"><a href="sec-meta.html#why-vote-counting-does-not-work"><i class="fa fa-check"></i><b>13.1.2</b> Why vote-counting does not work</a></li>
<li class="chapter" data-level="13.1.3" data-path="sec-meta.html"><a href="sec-meta.html#MetaWA"><i class="fa fa-check"></i><b>13.1.3</b> Meta-analysis when treatment effects are homogeneous: the fixed effects approach</a></li>
<li class="chapter" data-level="13.1.4" data-path="sec-meta.html"><a href="sec-meta.html#meta-analysis-when-treatment-effects-are-heterogeneous-the-random-effects-approach"><i class="fa fa-check"></i><b>13.1.4</b> Meta-analysis when treatment effects are heterogeneous: the random effects approach</a></li>
<li class="chapter" data-level="13.1.5" data-path="sec-meta.html"><a href="sec-meta.html#meta-regression"><i class="fa fa-check"></i><b>13.1.5</b> Meta-regression</a></li>
<li class="chapter" data-level="13.1.6" data-path="sec-meta.html"><a href="sec-meta.html#constantly-updated-meta-analysis"><i class="fa fa-check"></i><b>13.1.6</b> Constantly updated meta-analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="sec-meta.html"><a href="sec-meta.html#publication-bias-and-site-selection-bias"><i class="fa fa-check"></i><b>13.2</b> Publication bias and site selection bias</a><ul>
<li class="chapter" data-level="13.2.1" data-path="sec-meta.html"><a href="sec-meta.html#sources-of-publication-bias-and-of-site-selection-bias-and-questionable-research-practices"><i class="fa fa-check"></i><b>13.2.1</b> Sources of publication bias and of site selection bias and Questionable Research Practices</a></li>
<li class="chapter" data-level="13.2.2" data-path="sec-meta.html"><a href="sec-meta.html#detection-of-and-correction-for-publication-bias"><i class="fa fa-check"></i><b>13.2.2</b> Detection of and correction for publication bias</a></li>
<li class="chapter" data-level="13.2.3" data-path="sec-meta.html"><a href="sec-meta.html#detection-of-and-correction-for-site-selection-bias"><i class="fa fa-check"></i><b>13.2.3</b> Detection of and correction for site selection bias</a></li>
<li class="chapter" data-level="13.2.4" data-path="sec-meta.html"><a href="sec-meta.html#vote-counting-and-publication-bias"><i class="fa fa-check"></i><b>13.2.4</b> Vote counting and publication bias</a></li>
<li class="chapter" data-level="13.2.5" data-path="sec-meta.html"><a href="sec-meta.html#the-value-of-a-statistically-significant-result"><i class="fa fa-check"></i><b>13.2.5</b> The value of a statistically significant result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Bounds.html"><a href="Bounds.html"><i class="fa fa-check"></i><b>14</b> Bounds</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="proofs.html"><a href="proofs.html"><i class="fa fa-check"></i><b>A</b> Proofs</a><ul>
<li class="chapter" data-level="A.1" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-reffpsi"><i class="fa fa-check"></i><b>A.1</b> Proofs of results in Chapter @ref(FPSI)</a><ul>
<li class="chapter" data-level="A.1.1" data-path="proofs.html"><a href="proofs.html#proofcheb"><i class="fa fa-check"></i><b>A.1.1</b> Proof of Theorem @ref(thm:uppsampnoise)</a></li>
<li class="chapter" data-level="A.1.2" data-path="proofs.html"><a href="proofs.html#proofCLT"><i class="fa fa-check"></i><b>A.1.2</b> Proof of Theorem @ref(thm:asympnoiseWW)</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refrct"><i class="fa fa-check"></i><b>A.2</b> Proofs of results in Chapter @ref(RCT)</a><ul>
<li class="chapter" data-level="A.2.1" data-path="proofs.html"><a href="proofs.html#proofIdentLATE"><i class="fa fa-check"></i><b>A.2.1</b> Proof of Theorem @ref(thm:IdentLATE)</a></li>
<li class="chapter" data-level="A.2.2" data-path="proofs.html"><a href="proofs.html#proofWaldIV"><i class="fa fa-check"></i><b>A.2.2</b> Proof of Theorem @ref(thm:WaldIV)</a></li>
<li class="chapter" data-level="A.2.3" data-path="proofs.html"><a href="proofs.html#ProofAsymWald"><i class="fa fa-check"></i><b>A.2.3</b> Proof of Theorem @ref(thm:asymWald)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Tools for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="FPCI" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Fundamental Problem of Causal Inference</h1>
<p>In order to state the FPCI, we are going to describe the basic language to encode causality set up by Rubin, and named <a href="RCM.html">Rubin Causal Model (RCM)</a>.
RCM being about partly observed random variables, it is hard to make these notions concrete with real data.
That’s why we are going to use simulations from a simple model in order to make it clear how these variables are generated.
The second virtue of this model is that it is going to make it clear the source of selection into the treatment.
This is going to be useful when understanding biases of intuitive comparisons, but also to discuss the methods of causal inference.
A third virtue of this approach is that it makes clear the connexion between the treatment effects literature and models.
Finally, a fourth reason that it is useful is that it is going to give us a source of sampling variation that we are going to use to visualize and explore the properties of our estimators.</p>
<p>I use <span class="math inline">\(X_i\)</span> to denote random variable <span class="math inline">\(X\)</span> all along the notes.
I assume that we have access to a sample of <span class="math inline">\(N\)</span> observations indexed by <span class="math inline">\(i\in\left\{1,\dots,N\right\}\)</span>.
’‘<span class="math inline">\(i\)</span>’’ will denote the basic sampling units when we are in a sample, and a basic element of the probability space when we are in populations.
Introducing rigorous measure-theoretic notations for the population is feasible but is not necessary for comprehension.</p>
<p>When the sample size is infinite, we say that we have a population.
A population is a very useful fiction for two reasons.
First, in a population, there is no sampling noise: we observe an infinite amount of observations, and our estimators are infinitely precise.
This is useful to study phenomena independently of sampling noise.
For example, it is in general easier to prove that an estimator is equal to <span class="math inline">\(TT\)</span> under some conditions in the population.
Second, we are most of the time much more interested in estimating the values of parameters in the population rather than in the sample.
The population parameter, independent of sampling noise, gives a much better idea of the causal parameter for the population of interest than the parameter in the sample.
In general, the estimator for both quantities will be the same, but the estimators for the effetc of sampling noise on these estimators will differ.
Sampling noise for the population parameter will generally be larger, since it is affected by another source of variability (sample choice).</p>
<div id="rubin-causal-model" class="section level2">
<h2><span class="header-section-number">1.1</span> Rubin Causal Model</h2>
<p>RCM is made of three distinct building blocks: a treatment allocation rule, that decides who receives the treatment; potential outcomes, that measure how each individual reacts to the treatment; the switching equation that relates potential outcomes to observed outcomes through the allocation rule.</p>
<div id="treatment-allocation-rule" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Treatment allocation rule</h3>
<p>The first building block of RCM is the treatment allocation rule.
Throughout this class, we are going to be interested in inferring the causal effect of only one treatment with respect to a control condition.
Extensions to multi-valued treatments are in general self-explanatory.</p>
<p>In RCM, treatment allocation is captured by the variable <span class="math inline">\(D_i\)</span>.
<span class="math inline">\(D_i=1\)</span> if unit <span class="math inline">\(i\)</span> receives the treatment and <span class="math inline">\(D_i=0\)</span> if unit <span class="math inline">\(i\)</span> does not receive the treatment and thus remains in the control condition.</p>
<p>The treatment allocation rule is critical for several reasons.
First, because it switches the treatment on or off for each unit, it is going to be at the source of the FPCI.
Second, the specific properties of the treatment allocatoin rule are going to matter for the feasibility and bias of the various econometric methods that we are going to study.</p>
<p>Let’s take a few examples of allocation rules.
These allocation rules are just examples.
They do not cover the space of all possible allocation rules.
They are especially useful as concrete devices to understand the sources of biases and the nature of the allocation rule.
In reality, there exists even more complex allocation rules (awareness, eligibility, application, acceptance, active participation).
Awareness seems especially important for program participation and has only been tackled recently by economists.</p>
<p>First, some notation.
Let’s imagine a treatment that is given to individuals.
Whether each individual receives the treatment partly depends on the level of her outcome before receiving the treatment.
Let’s denote this variable <span class="math inline">\(Y^B_i\)</span>, with <span class="math inline">\(B\)</span> standing for “Before”.
It can be the health status assessed by a professional before deciding to give a drug to a patient.
It can be the poverty level of a household used to assess its eligibilty to a cash transfer program.</p>
<div id="sharp-cutoff-rule" class="section level4">
<h4><span class="header-section-number">1.1.1.1</span> Sharp cutoff rule</h4>
<p>The sharp cutoff rule means that everyone below some threshold <span class="math inline">\(\bar{Y}\)</span> is going to receive the treatment.
Everyone whose outcome before the treatment lies above <span class="math inline">\(\bar{Y}\)</span> does not receive the treatment.
Such rules can be found in reality in a lot of situations.
They might be generated by administrative rules.
One very simple way to model this rule is as follows:</p>
<p><span class="math display">\[\begin{align}\label{eq:cutoff}
  D_i &amp; = \uns{Y_i^B\leq\bar{Y}},
\end{align}\]</span></p>
<p>where <span class="math inline">\(\uns{A}\)</span> is the indicator function, taking value <span class="math inline">\(1\)</span> when <span class="math inline">\(A\)</span> is true and <span class="math inline">\(0\)</span> otherwise.</p>

<div class="example">
<span id="exm:unnamed-chunk-1" class="example"><strong>Example 1.1  (Sharp cutoff rule)  </strong></span>Imagine that <span class="math inline">\(Y_i^B=\exp(y_i^B)\)</span>, with <span class="math inline">\(y_i^B=\mu_i+U_i^B\)</span>, <span class="math inline">\(\mu_i\sim\mathcal{N}(\bar{\mu},\sigma^2_{\mu})\)</span> and <span class="math inline">\(U_i^B\sim\mathcal{N}(0,\sigma^2_{U})\)</span>.
Now, let’s choose some values for these parameters so that we can generate a sample of individuals and allocate the treatment among them.
I’m going to switch to R for that.
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">param &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">8</span>,.<span class="dv">5</span>,.<span class="dv">28</span>,<span class="dv">1500</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">names</span>(param) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">param</a></code></pre></div>
<pre><code>##    barmu sigma2mu  sigma2U     barY 
##     8.00     0.50     0.28  1500.00</code></pre>
<p>Now, I have choosen values for the parameters in my model.
For example, <span class="math inline">\(\bar{\mu}=\)</span> 8 and <span class="math inline">\(\bar{Y}=\)</span> 1500.
What remains to be done is to generate <span class="math inline">\(Y_i^B\)</span> and then <span class="math inline">\(D_i\)</span>.
For this, I have to choose a sample size (<span class="math inline">\(N=1000\)</span>) and then generate the shocks from a normal.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># for reproducibility, I choose a seed that will give me the same random sample each time I run the program</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">N &lt;-<span class="dv">1000</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB </a>
<a class="sourceLine" id="cb3-7" data-line-number="7">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">Ds &lt;-<span class="st"> </span><span class="kw">ifelse</span>(YB<span class="op">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>],<span class="dv">1</span>,<span class="dv">0</span>) </a></code></pre></div>
<p>Let’s now build a histogram of the data that we have just generated.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co"># building histogram of yB with cutoff point at ybar</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="co"># Number of steps</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">Nsteps<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="dv">15</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="co">#step width</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5">step<span class="fl">.1</span> &lt;-<span class="st"> </span>(<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span><span class="kw">min</span>(yB[Ds<span class="op">==</span><span class="dv">1</span>]))<span class="op">/</span>Nsteps<span class="fl">.1</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">Nsteps<span class="fl">.0</span> &lt;-<span class="st"> </span>(<span class="op">-</span><span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">+</span><span class="kw">max</span>(yB[Ds<span class="op">==</span><span class="dv">0</span>]))<span class="op">/</span>step<span class="fl">.1</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7">breaks &lt;-<span class="st"> </span><span class="kw">cumsum</span>(<span class="kw">c</span>(<span class="kw">min</span>(yB[Ds<span class="op">==</span><span class="dv">1</span>]),<span class="kw">c</span>(<span class="kw">rep</span>(step<span class="fl">.1</span>,Nsteps<span class="fl">.1</span><span class="op">+</span>Nsteps<span class="fl">.0</span><span class="op">+</span><span class="dv">1</span>))))</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="kw">hist</span>(yB,<span class="dt">breaks=</span>breaks,<span class="dt">main=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:histyb"></span>
<img src="STCI_files/figure-html/histyb-1.png" alt="Histogram of $y_B$" width="60%" />
<p class="caption">
Figure 1.1: Histogram of <span class="math inline">\(y_B\)</span>
</p>
</div>
<p>You can see on Figure <a href="FPCI.html#fig:histyb">1.1</a> a histogram of <span class="math inline">\(y_i^B\)</span> with the red line indicating the cutoff point: <span class="math inline">\(\bar{y}=\ln(\bar{Y})=\)</span> 7.3.
All the observations below the red line are treated according to the sharp rule while all the one located above are not.
In order to see how many observations eventually receive the treatment with this allocation rule, let’s build a contingency table.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">table.D.sharp &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">table</span>(Ds))</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">knitr<span class="op">::</span><span class="kw">kable</span>(table.D.sharp,<span class="dt">caption=</span><span class="st">&#39;Treatment allocation with sharp cutoff rule&#39;</span>,<span class="dt">booktabs=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<table>
<caption><span id="tab:tableDsharp">Table 1.1: </span>Treatment allocation with sharp cutoff rule</caption>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="right">771</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="right">229</td>
</tr>
</tbody>
</table>
<p>We can see on Table <a href="FPCI.html#tab:tableDsharp">1.1</a> that there are 229 treated observations.</p>
</div>
<div id="fuzzy-cutoff-rule" class="section level4">
<h4><span class="header-section-number">1.1.1.2</span> Fuzzy cutoff rule</h4>
<p>This rule is less sharp than the sharp cutoff rule.
Here, other criteria than <span class="math inline">\(Y_i^B\)</span> enter into the decision to allocate the treatment.
The doctor might measure the health status of a patient following official guidelines, but he might also measure other factors that will also influence his decision of giving the drug to the patient.
The officials administering a program might measure the official income level of a household, but they might also consider other features of the household situation when deciding to enroll the household into the program or not.
If these additional criteria are unobserved to the econometrician, then we have the fuzzy cutoff rule.
A very simple way to model this rule is as follows:</p>
<p><span class="math display">\[\begin{align}\label{eq:fuzzcutoff}
  D_i &amp; = \uns{Y_i^B+V_i\leq\bar{Y}},
\end{align}\]</span></p>
<p>where <span class="math inline">\(V_i\)</span> is a random variable unobserved to the econometrician and standing for the other influences that might drive the allocation of the treatment.
<span class="math inline">\(V_i\)</span> is distributed according to a, for the moment, unspecified cumulative distribution function <span class="math inline">\(F_V\)</span>.
When <span class="math inline">\(V_i\)</span> is degenerate ( it has only one point of support: it is a constant), the fuzzy cutoff rule becomes the sharp cutoff rule.</p>
</div>
<div id="eligibility-self-selection-rule" class="section level4">
<h4><span class="header-section-number">1.1.1.3</span> Eligibility <span class="math inline">\(+\)</span> self-selection rule</h4>
<p>It is also possible that households, once they have been made eligible to the treatment, can decide whether they want to receive it or not.
A patient might be able to refuse the drug that the doctor suggests she should take.
A household might refuse to participate in a cash transfer program to which it has been made eligible.
Not all programs have this feature, but most of them have some room for decisions by the agents themselves of whether they want to receive the treatment or not.
One simple way to model this rule is as follows:</p>
<p><span class="math display">\[\begin{align}\label{eq:eligself}
  D_i &amp; = \uns{D^*_i\geq0}E_i,
\end{align}\]</span></p>
<p>where <span class="math inline">\(D^*_i\)</span> is individual <span class="math inline">\(i\)</span>’s valuation of the treatment and <span class="math inline">\(E_i\)</span> is whether or not she is deemed eligible for the treatment.
<span class="math inline">\(E_i\)</span> might be choosen according to the sharp cutoff rule of to the fuzzy cutoff rule, or to any other eligibility rule.
We will be more explicit about <span class="math inline">\(D_i^*\)</span> in what follows.</p>
<p><strong>SIMULATIONS ARE MISSING FOR THESE LAST TWO RULES</strong></p>
</div>
</div>
<div id="potential-outcomes" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Potential outcomes</h3>
<p>The second main building block of RCM are potential outcomes.
Let’s say that we are interested in the effect of a treatment on an outcome <span class="math inline">\(Y\)</span>.
Each unit <span class="math inline">\(i\)</span> can thus be in two potential states: treated or non treated.
Before the allocation of the treatment is decided, both of these states are feasible for each unit.</p>

<div class="definition">
<span id="def:unnamed-chunk-2" class="definition"><strong>Definition 1.1  (Potential outcomes)  </strong></span>For each unit <span class="math inline">\(i\)</span>, we define two potential outcomes:
</div>

<ul>
<li><span class="math inline">\(Y_i^1\)</span>: the outcome that unit <span class="math inline">\(i\)</span> is going to have if it receives the treatment,</li>
<li><span class="math inline">\(Y_i^0\)</span>: the outcome that unit <span class="math inline">\(i\)</span> is going to have if it <strong>does not</strong> receive the treatment.</li>
</ul>

<div class="example">
<span id="exm:unnamed-chunk-3" class="example"><strong>Example 1.2  </strong></span>Let’s choose functional forms for our potential outcomes.
For simplicity, all lower case letters will denote log outcomes.
<span class="math inline">\(y_i^0=\mu_i+\delta+U_i^0\)</span>, with <span class="math inline">\(\delta\)</span> a time shock common to all the observations and <span class="math inline">\(U_i^0=\rho U_i^B+\epsilon_i\)</span>, with <span class="math inline">\(|\rho|&lt;1\)</span>.
In the absence of the treatment, part of the shocks <span class="math inline">\(U_i^B\)</span> that the individuals experienced in the previous period persist, while some part vanish.
<span class="math inline">\(y_i^1=y_i^0+\bar{\alpha}+\theta\mu_i+\eta_i\)</span>.
In order to generate the potential outcomes, one has to define the laws for the shocks and to choose parameter values.
Let’s assume that <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma^2_{\epsilon})\)</span> and <span class="math inline">\(\eta_i\sim\mathcal{N}(0,\sigma^2_{\eta})\)</span>.
Now let’s choose some parameter values:
</div>

<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">l &lt;-<span class="st"> </span><span class="kw">length</span>(param)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">param &lt;-<span class="st"> </span><span class="kw">c</span>(param,<span class="fl">0.9</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="kw">names</span>(param)[(l<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span><span class="kw">length</span>(param)] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</a>
<a class="sourceLine" id="cb6-4" data-line-number="4">param</a></code></pre></div>
<pre><code>##         barmu      sigma2mu       sigma2U          barY           rho 
##          8.00          0.50          0.28       1500.00          0.90 
##         theta sigma2epsilon     sigma2eta         delta      baralpha 
##          0.01          0.05          0.05          0.05          0.10</code></pre>
<p>We can finally generate the potential outcomes;</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a></code></pre></div>
<p>Now, I would like to visualize my potential outcomes:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">plot</span>(y0,y1)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:histpotout"></span>
<img src="STCI_files/figure-html/histpotout-1.png" alt="Potential outcomes" width="60%" />
<p class="caption">
Figure 1.2: Potential outcomes
</p>
</div>
<p>You can see on the resulting Figure <a href="FPCI.html#fig:histpotout">1.2</a> that both potential outcomes are positively correlated.
Those with a large potential outcome when untreated (<em>e.g.</em> in good health without the treatment) also have a positive health with the treatment.
It is also true that individuals with bad health in the absence of the treatment also have bad health with the treatment.</p>
</div>
<div id="switching-equation" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Switching equation</h3>
<p>The last building block of RCM is the switching equation.
It links the observed outcome to the potential outcomes through the allocation rule:</p>
<p><span class="math display" id="eq:switch">\[\begin{align}
 \tag{1.1}
  Y_i &amp; = 
    \begin{cases}
    Y_i^1 &amp; \text{if } D_i=1\\
    Y_i^0 &amp; \text{if } D_i=0
    \end{cases} \\
    &amp; = Y_i^1D_i + Y_i^0(1-D_i) \nonumber
\end{align}\]</span></p>

<div class="example">
<span id="exm:unnamed-chunk-4" class="example"><strong>Example 1.3  </strong></span>In order to generate observed outcomes in our numerical example, we simply have to enforce the switching equation:
</div>

<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<p>What the switching equation <a href="FPCI.html#eq:switch">(1.1)</a> means is that, for each individual <span class="math inline">\(i\)</span>, we get to observe only one of the two potential outcomes.
When individual <span class="math inline">\(i\)</span> belongs to the treatment group (<em>i.e.</em> <span class="math inline">\(D_i=1\)</span>), we get to observe <span class="math inline">\(Y_i^1\)</span>.
When individual <span class="math inline">\(i\)</span> belongs to the control group (<em>i.e.</em> <span class="math inline">\(D_i=0\)</span>), we get to observe <span class="math inline">\(Y_i^0\)</span>.
Because the same individual cannot be at the same time in both groups, we can NEVER see both potential outcomes for the same individual at the same time.</p>
<p>For each of the individuals, one of the two potential outcomes is unobserved.
We say that it is a <strong>counterfactual</strong>.
A counterfactual quantity is a quantity that is, according to Hume’s definition, contrary to the observed facts.
A counterfactual cannot be observed, but it can be conceived by an effort of reason: it is the consequence of what would have happened had some action not been taken.</p>

<div class="remark">
<p> <span class="remark"><em>Remark. </em></span> One very nice way of visualising the switching equation has been proposed by Jerzy Neyman in a 1923 prescient paper.
Neyman proposes to imagine two urns, each one filled with <span class="math inline">\(N\)</span> balls.
One urn is the treatment urn and contains balls with the id of the unit and the value of its potential outcome <span class="math inline">\(Y_i^1\)</span>.
The other urn is the control urn, and it contains balls with the value of the potential outcome <span class="math inline">\(Y_i^0\)</span> for each unit <span class="math inline">\(i\)</span>.
Following the allocation rule <span class="math inline">\(D_i\)</span>, we decide whether unit <span class="math inline">\(i\)</span> is in the treatment or control group.
When unit <span class="math inline">\(i\)</span> is in the treatment group, we take the corresponding ball from the first urn and observe the potential outcome on it.
But, at the same time, the urns are connected so that the corresponding ball with the potential outcome of unit <span class="math inline">\(i\)</span> in the control urn disappears as soon as we draw ball <span class="math inline">\(i\)</span> from the treatment urn.</p>
The switching equation works a lot like Schrodinger’s cat paradox.
Schrodinger’s cat is placed in a sealed box and receives a dose of poison when an atom emits a radiation.
As long as the box is sealed, there is no way we can know whether the cat is dead or alive.
When we open the box, we observe either a dead cat or a living cat, but we cannot observe the cat both alive and dead at the same time.
The switching equation is like opening the box, it collapses the observed outcome into one of the two potential ones.
</div>


<div class="example">
<span id="exm:unnamed-chunk-6" class="example"><strong>Example 1.4  </strong></span>One way to visualize the inner workings of the switching equation is to plot the potential outcomes along with the criteria driving the allocation rule.
In our simple example, it simply amounts to plotting observed (<span class="math inline">\(y_i\)</span>) and potential outcomes (<span class="math inline">\(y_i^1\)</span> and <span class="math inline">\(y_i^0\)</span>) along <span class="math inline">\(y_i^B\)</span>.
</div>

<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">plot</span>(yB[Ds<span class="op">==</span><span class="dv">0</span>],y0[Ds<span class="op">==</span><span class="dv">0</span>],<span class="dt">pch=</span><span class="dv">1</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="dt">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="kw">points</span>(yB[Ds<span class="op">==</span><span class="dv">1</span>],y1[Ds<span class="op">==</span><span class="dv">1</span>],<span class="dt">pch=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="kw">points</span>(yB[Ds<span class="op">==</span><span class="dv">0</span>],y1[Ds<span class="op">==</span><span class="dv">0</span>],<span class="dt">pch=</span><span class="dv">3</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="kw">points</span>(yB[Ds<span class="op">==</span><span class="dv">1</span>],y0[Ds<span class="op">==</span><span class="dv">1</span>],<span class="dt">pch=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">test &lt;-<span class="st"> </span><span class="fl">5.8</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6">i.test &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test)<span class="op">==</span><span class="kw">min</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test)))</a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="kw">points</span>(yB[<span class="kw">abs</span>(yB<span class="op">-</span>test)<span class="op">==</span><span class="kw">min</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test))],y1[<span class="kw">abs</span>(yB<span class="op">-</span>test)<span class="op">==</span><span class="kw">min</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test))],<span class="dt">col=</span><span class="st">&#39;green&#39;</span>,<span class="dt">pch=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb11-8" data-line-number="8"><span class="kw">points</span>(yB[<span class="kw">abs</span>(yB<span class="op">-</span>test)<span class="op">==</span><span class="kw">min</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test))],y0[<span class="kw">abs</span>(yB<span class="op">-</span>test)<span class="op">==</span><span class="kw">min</span>(<span class="kw">abs</span>(yB<span class="op">-</span>test))],<span class="dt">col=</span><span class="st">&#39;green&#39;</span>)</a>
<a class="sourceLine" id="cb11-9" data-line-number="9"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb11-10" data-line-number="10"><span class="kw">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="kw">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="st">&#39;y1|D=0&#39;</span>,<span class="kw">paste</span>(<span class="st">&#39;y0&#39;</span>,i.test,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>),<span class="kw">paste</span>(<span class="st">&#39;y1&#39;</span>,i.test,<span class="dt">sep=</span><span class="st">&#39;&#39;</span>)),<span class="dt">pch=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">3</span>),<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;black&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;green&#39;</span>,<span class="st">&#39;green&#39;</span>),<span class="dt">ncol=</span><span class="dv">3</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ploty1y0yB"></span>
<img src="STCI_files/figure-html/ploty1y0yB-1.png" alt="Potential outcomes" width="60%" />
<p class="caption">
Figure 1.3: Potential outcomes
</p>
</div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">plot</span>(yB[Ds<span class="op">==</span><span class="dv">0</span>],y0[Ds<span class="op">==</span><span class="dv">0</span>],<span class="dt">pch=</span><span class="dv">1</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="dt">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="kw">points</span>(yB[Ds<span class="op">==</span><span class="dv">1</span>],y1[Ds<span class="op">==</span><span class="dv">1</span>],<span class="dt">pch=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="kw">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="kw">c</span>(<span class="st">&#39;y|D=0&#39;</span>,<span class="st">&#39;y|D=1&#39;</span>),<span class="dt">pch=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:plotyyB"></span>
<img src="STCI_files/figure-html/plotyyB-1.png" alt="Observed outcomes" width="60%" />
<p class="caption">
Figure 1.4: Observed outcomes
</p>
</div>
<p>Figure <a href="FPCI.html#fig:ploty1y0yB">1.3</a> plots the observed outcomes <span class="math inline">\(y_i\)</span> along with the unobserved potential outcomes.
Figure <a href="FPCI.html#fig:ploty1y0yB">1.3</a> shows that each individual in the sample is endowed with two potential outcomes, represented by a circle and a cross.
Figure <a href="FPCI.html#fig:plotyyB">1.4</a> plots the observed outcomes <span class="math inline">\(y_i\)</span> that results from applying the switching equation.
Only one of the two potential outcomes is observed (the cross for the treated group and the circle for the untreated group) and the other is not.
The observed sample in Figure <a href="FPCI.html#fig:plotyyB">1.4</a> only shows observed outcomes, and is thus silent on the values of the missing potential outcomes.</p>
</div>
</div>
<div id="treatment-effects" class="section level2">
<h2><span class="header-section-number">1.2</span> Treatment effects</h2>
<p>RCM enables the definition of causal effects at the individual level.
In practice though, we generally focus on a summary measure: the effect of the treatment on the treated.</p>
<div id="individual-level-treatment-effects" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Individual level treatment effects</h3>
<p>Potential outcomes enable us to define the central notion of causal inference: the causal effect, also labelled the treatment effect, which is the difference between the two potential outcomes.</p>

<div class="definition">
<span id="def:causaleff" class="definition"><strong>Definition 1.2  (Individual level treatment effect)  </strong></span>For each unit <span class="math inline">\(i\)</span>, the causal effect of the treatment on outcome <span class="math inline">\(Y\)</span> is: <span class="math inline">\(\Delta^Y_i=Y_i^1-Y_i^0\)</span>.
</div>


<div class="example">
<span id="exm:unnamed-chunk-7" class="example"><strong>Example 1.5  </strong></span>The individual level causal effect in log terms is: <span class="math inline">\(\Delta^y_i=\alpha_i=\bar{\alpha}+\theta\mu_i+\eta_i\)</span>.
The effect is the sum of a part common to all individuals, a part correlated with <span class="math inline">\(\mu_i\)</span>: the treatment might have a larger or a smaller effect depending on the unobserved permanent ability or health status of individuals, and a random shock.
It is possible to make the effect of the treatment to depend on <span class="math inline">\(U_i^B\)</span> also, but it would complicate the model.
</div>

<p>In Figure <a href="FPCI.html#fig:ploty1y0yB">1.3</a>, the individual level treatment effects are the differences between each cross and its corresponding circle.
For example, for observation 264, the two potential outcomes appear in green in Figure <a href="FPCI.html#fig:ploty1y0yB">1.3</a>.
The effect of the treatment on unit 264 is equal to:
<span class="math display">\[
\Delta^y_{264}=y^1_{264}-y^0_{264}=6.98-6.64=0.34.
\]</span></p>
<p>Since observation 264 belongs to the treatment group, we can only observe the potential outcome in the presence of the treatment, <span class="math inline">\(y^1_{264}\)</span>.</p>
<p>RCM allows for heterogeneity of treatment effects.
The treatment has a large effect on some units and a much smaller effect on other units.
We can even have some units that benefit from the treatment and some units that are harmed by the treatment.
The individual level effect of the treatment is itself a random variable (and not a fixed parameter).
It has a distribution, <span class="math inline">\(F_{\Delta^Y}\)</span>.</p>
<p>Heterogeneity of treatment effects seems very natural: the treatment might interact with individuals’ different backgrounds.
The effect of a drug might depend on the genetic background of an individual.
An education program might only work for children that already have sufficient non-cognitive skills, and thus might depend in turn on family background.
An environmental regulation or a behavioral intervention might only trigger reactions by already environmentally aware individuals.
A CCT might have a larger effect when indiviuals are credit-constrained or face shocks.</p>

<div class="example">
<span id="exm:unnamed-chunk-8" class="example"><strong>Example 1.6  </strong></span>In our numerical example, the distribution of <span class="math inline">\(\Delta^y_i=\alpha_i\)</span> is a normal: <span class="math inline">\(\alpha_i\sim\mathcal{N}(\bar{\alpha}+\theta\bar{\mu},\theta^2\sigma^2_{\mu}+\sigma^2_{\eta})\)</span>.
We would like to visualize treatment effect heterogeneity.
For that, we can build a histogram of the individual level causal effect.
</div>

<p>On top of the histogram, we can also draw the theoretical distribution of the treatment effect: a normal with mean 0.18 and variance 0.05.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">hist</span>(alpha,<span class="dt">main=</span><span class="st">&quot;&quot;</span>,<span class="dt">prob=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean=</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;barmu&quot;</span>]), <span class="dt">sd=</span><span class="kw">sqrt</span>(param[<span class="st">&quot;theta&quot;</span>]<span class="op">^</span><span class="dv">2</span><span class="op">*</span>param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2eta&quot;</span>])), <span class="dt">add=</span><span class="ot">TRUE</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:histalpha"></span>
<img src="STCI_files/figure-html/histalpha-1.png" alt="Histogram of $\Delta^y$" width="60%" />
<p class="caption">
Figure 1.5: Histogram of <span class="math inline">\(\Delta^y\)</span>
</p>
</div>
<p>The first thing that we can see on Figure <a href="FPCI.html#fig:histalpha">1.5</a> is that the theoretical and the empirical distributions nicely align with each other.
We also see that the majority of the observations lies to the right of zero: most people experience a positive effect of the treatment.
But there are some individuals that do not benefit from the treatment: the effect of the treatment on them is negative.</p>
</div>
<div id="average-treatment-effect-on-the-treated" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Average treatment effect on the treated</h3>
<p>We do not generally estimate individual-level treatment effects.
We generally look for summary statistics of the effect of the treatment.
By far the most widely reported causal parameter is the Treatment on the Treated parameter (TT).
It can be defined in the sample at hand or in the population.</p>

<div class="definition">
<span id="def:TT" class="definition"><strong>Definition 1.3  (Average and expected treatment effects on the treated)  </strong></span>The Treatment on the Treated parameters for outcome <span class="math inline">\(Y\)</span> are:
</div>

<ul>
<li><p>The average Treatment effect on the Treated in the sample:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{TT_s} &amp; = \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^N(Y_i^1-Y_i^0)D_i,
\end{align*}\]</span></p></li>
<li><p>The expected Treatment effect on the Treated in the population:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{TT} &amp; = \esp{Y_i^1-Y_i^0|D_i=1}.
\end{align*}\]</span></p></li>
</ul>
<p>The TT parameters measure the average effect of the treatment on those who actually take it, either in the sample at hand or in the popluation.
It is generally considered to be the most policy-relevant parameter since it measures the effect of the treatment as it has actually been allocated.
For example, the expected causal effect on the overall population is only relevant if policymakers are considering implementing the treatment even on those who have not been selected to receive it.
For a drug or an anti-poverty program, it would mean giving the treatment to healthy or rich people, which would make little sense.</p>
<p>TT does not say anything about how the effect of the treatment is distributed in the population or in the sample.
TT does not account for the heterogneity of treatment effects.
In Lecture 7, we will look at other parameters of interest that look more closely into how the effect of the treatment is distributed.</p>

<div class="example">
<span id="exm:unnamed-chunk-9" class="example"><strong>Example 1.7  </strong></span>The value of TT in our sample is:
</div>

<p><span class="math display">\[
\Delta^y_{TT_s}=0.168.
\]</span></p>
<p>Computing the population value of <span class="math inline">\(TT\)</span> is slightly more involved: we have to use the formula for the conditional expectation of a censored bivariate normal random variable:</p>
<p><span class="math display">\[\begin{align*}
\Delta^y_{TT} &amp; = \esp{\alpha_i|D_i=1}\\
              &amp; = \bar{\alpha}+\theta\esp{\mu_i|\mu_i+U_i^B\leq\bar{y}}\\
              &amp; = \bar{\alpha}+\theta\left(\bar{\mu} - \frac{\sigma^2_{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right)\\
              &amp; = \bar{\alpha}+\theta\bar{\mu}-\theta\left(\frac{\sigma^2_{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\Phi\)</span> are respectively the density and the cumulative distribution functions of the standard normal.
The second equality follows from the definition of <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(D_i\)</span> and from the fact that <span class="math inline">\(\eta_i\)</span> is independent from <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(U_i^B\)</span>.
The third equality comes from the formula for the expectation of a censored bivariate normal random variable.
In order to compute the population value of TT easily for different sets of parameter values, let’s write a function in R:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">delta.y.tt &lt;-<span class="st"> </span><span class="cf">function</span>(param){<span class="kw">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;barmu&quot;</span>]</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">                                     <span class="op">-</span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>((param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">                                                      <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">                                                        <span class="op">*</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))}</a></code></pre></div>
<p>The population value of TT computed using this function is: <span class="math inline">\(\Delta^y_{TT}=\)</span> 0.172.
We can see that the values of TT in the sample and in the population differ slightly.
This is because of sampling noise: the units in the sample are not perfectly representative of the units in the population.</p>
</div>
</div>
<div id="fundamental-problem-of-causal-inference" class="section level2">
<h2><span class="header-section-number">1.3</span> Fundamental problem of causal inference</h2>
<p>At least in this lecture, causal inference is about trying to infer TT, either in the sample or in the population.
The FPCI states that it is impossible to directly observe TT because one part of it remains fundamentally unobserved.</p>

<div class="theorem">
<span id="thm:FPCI" class="theorem"><strong>Theorem 1.1  (Fundamental problem of causal inference)  </strong></span>It is impossible to observe TT, either in the population or in the sample.
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> The proof of the FPCI is rather straightforward.
Let me start with the sample TT:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT_s} &amp; = \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^N(Y_i^1-Y_i^0)D_i \\
                  &amp; = \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_i^1D_i- \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_i^0D_i \\
                  &amp; = \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_iD_i- \frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_i^0D_i.
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(Y_i^0\)</span> is unobserved whenever <span class="math inline">\(D_i=1\)</span>, <span class="math inline">\(\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_i^0D_i\)</span> is unobserved, and so is <span class="math inline">\(\Delta^Y_{TT_s}\)</span>.
The same is true for the population TT:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{TT} &amp; = \esp{Y_i^1-Y_i^0|D_i=1} \\
                &amp; = \esp{Y_i^1|D_i=1}-\esp{Y_i^0|D_i=1}\\
                &amp; = \esp{Y_i|D_i=1}-\esp{Y_i^0|D_i=1}.
\end{align*}\]</span></p>
<span class="math inline">\(\esp{Y_i^0|D_i=1}\)</span> is unobserved, and so is <span class="math inline">\(\Delta^Y_{TT}\)</span>.
</div>

<p>The key insight in order to understand the FPCI is to see that the outcomes of the treated units had they not been treated are unobservable, and so is their average or expectation.
We say that they are counterfactual, contrary to what has happened.</p>

<div class="definition">
<span id="def:counter" class="definition"><strong>Definition 1.4  (Couterfactual)  </strong></span>Both <span class="math inline">\(\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^NY_i^0D_i\)</span> and <span class="math inline">\(\esp{Y_i^0|D_i=1}\)</span> are counterfactual quantities that we will never get to observe.
</div>


<div class="example">
<span id="exm:unnamed-chunk-11" class="example"><strong>Example 1.8  </strong></span>The average counterfactual outcome of the treated is the mean of the red circles in the <span class="math inline">\(y\)</span> axis on Figure <a href="FPCI.html#fig:ploty1y0yB">1.3</a>:
</div>

<p><span class="math display">\[
\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^Ny_i^0D_i= 6.91.
\]</span>
Remember that we can estimate this quantity only because we have generated the data ourselves.
In real life, this quantity is hopelessly unobserved.</p>
<p><span class="math inline">\(\esp{y_i^0|D_i=1}\)</span> can be computed using the formula for the expectation of a censored normal random variable:</p>
<p><span class="math display">\[\begin{align*}
\esp{y_i^0|D_i=1} &amp; = \esp{\mu_i+\delta+U_i^0|D_i=1}\\
                  &amp; = \esp{\mu_i+\delta+\rho U_i^B+\epsilon_i|D_i=1}\\
                  &amp; = \delta + \esp{\mu_i+\rho U_i^B|y_i^B\leq\bar{y}}\\
                  &amp; = \delta + \bar{\mu} - \frac{\sigma^2_{\mu}+\rho\sigma^2_U}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}.
\end{align*}\]</span></p>
<p>We can write a function in R to compute this value:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">esp.y0.D1 &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">  <span class="kw">return</span>(param[<span class="st">&quot;delta&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;barmu&quot;</span>]</a>
<a class="sourceLine" id="cb15-3" data-line-number="3">         <span class="op">-</span>((param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;sigma2U&quot;</span>])</a>
<a class="sourceLine" id="cb15-4" data-line-number="4">           <span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">         <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])<span class="op">*</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])</a>
<a class="sourceLine" id="cb15-6" data-line-number="6">                                                          <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))))</a>
<a class="sourceLine" id="cb15-7" data-line-number="7">}</a></code></pre></div>
<p>The population value of TT computed using this function is: <span class="math inline">\(\esp{y_i^0|D_i=1}=\)</span> 6.9.</p>
</div>
<div id="intuitive-estimators-confounding-factors-and-selection-bias" class="section level2">
<h2><span class="header-section-number">1.4</span> Intuitive estimators, confounding factors and selection bias</h2>
<p>In this section, we are going to examine the properties of two intuitive comparisons that laypeople, policymakers but also ourselves make in order to estimate causal effects: the with/wihtout comparison (<span class="math inline">\(WW\)</span>) and the before/after comparison (<span class="math inline">\(BA\)</span>).
<span class="math inline">\(WW\)</span> compares the average outcomes of the treated individuals with those of the untreated individuals.
<span class="math inline">\(BA\)</span> compares the average outcomes of the treated after taking the treatment to their average outcomes before they took the treatment.
These comparisons try to proxy for the expected counterfactual outcome in the treated group by using an observed quantity.
<span class="math inline">\(WW\)</span> uses the expected outcome of the untreated individuals as a proxy.
<span class="math inline">\(BA\)</span> uses the expected outcome of the treated before they take the treatment as a proxy.</p>
<p>Unfortunately, both of these proxies are generally poor and provide biased estimates of <span class="math inline">\(TT\)</span>.
The reason that these proxies are poor is that the treatment is not the only factor that differentiates the treated group from the groups used to form the proxy.
The intuitive comparisons are biased because factors, other than the treatment, are correlated to its allocation.
The factors that bias the intuitive comparisons are generally called confouding factors or confounders.</p>
<p>The treatment effect measures the effect of a ceteris paribus change in treatment status, while the intuitive comparisons capture both the effect of this change and that of other correlated changes that spuriously contaminate the comparison.
Intuitive comparisons measure correlations while treatment effects measure causality.
The old motto “correlation is not causation” applies vehemently here.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> A funny anecdote about this expression “correlation is not causation”.
This expression is due to Karl Pearson, the father of modern statistics.
He coined the phrase in his famous book “The Grammar of Science.”
Pearson is famous for inventing the correlation coefficient.
He actually thought that correlation was a much superior, much more rigorous term, than causation.
In his book, he actually used the sentence to argue in favor of abandoning causation altogether and focusing on the much better-defined and measurable concept of correlation.
Interesting turn of events that his sentence is now used to mean that correlation is weaker than causation, totally reverting the original intended meaning.
</div>

<p>In this section, we are going to define both comparisons, study their biases and state the conditions under which they identify <span class="math inline">\(TT\)</span>.
This will prove to be a very useful introduction to the notion of identification.
It is also very important to be able to understand the sources of bias of comparisons that we use every day and that come very naturally to policy makers and lay people.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> In this section, we state the definitions and formulae in the population.
This is for two reasons.
First, it is simpler, and lighter in terms of notation.
Second, it emphasizes that the problems with intuitive comparisons are independent of sampling noise.
Most of the results stated here for the population extend to the sample, replacing the expectation operator by the average operator.
I will nevertheless give examples in the sample, since it is so much simpler to compute.
I will denote sample equivalents of population estimators with a hat.
</div>

<div id="withwithout-comparison-selection-bias-and-cross-sectional-confounders" class="section level3">
<h3><span class="header-section-number">1.4.1</span> With/Without comparison, selection bias and cross-sectional confounders</h3>
<p>The with/without comparison (<span class="math inline">\(WW\)</span>) is very intuitive: just compare the outcomes of the treated and untreated individuals in order to estimate the causal effect.
This approach is nevertheless generally biased.
We call the bias of <span class="math inline">\(WW\)</span> selection bias (<span class="math inline">\(SB\)</span>).
Selection bias is due to unobserved confounders that are distributed differently in the treatment and control group and that generate differences in outcomes even in the absence of the treatment.
In this section, I define the <span class="math inline">\(WW\)</span> estimator, derives its bias, introduces the confounders and states conditions under which it is unbiased.</p>
<div id="withwithout-comparison" class="section level4">
<h4><span class="header-section-number">1.4.1.1</span> With/Without comparison</h4>
<p>The with/without comparison (<span class="math inline">\(WW\)</span>) is very intuitive: just compare the outcomes of the treated and untreated individuals in order to estimate the causal effect.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-14" class="definition"><strong>Definition 1.5  (With/without comparison)  </strong></span>The with/without comparison is the difference between the expected outcomes of the treated and the expected outcomes of the untreated:</p>
<span class="math display">\[\begin{align*}
\Delta^Y_{WW} &amp; =  \esp{Y_i|D_i=1}-\esp{Y_i|D_i=0}.
\end{align*}\]</span>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-15" class="example"><strong>Example 1.9  </strong></span>In the population, <span class="math inline">\(WW\)</span> can be computed using the traditional formula for the expectation of a truncated normal distribution:</p>
<span class="math display">\[\begin{align*}
\Delta^y_{WW} &amp; = \esp{y_i|D_i=1}-\esp{y_i|D_i=0} \\
              &amp; = \esp{y_i^1|D_i=1}-\esp{y^0_i|D_i=0} \\
              &amp; = \esp{\alpha_i|D_i=1}+\esp{\mu_i+\rho U_i^B|\mu_i+U_i^B\leq\bar{y}}-\esp{\mu_i+\rho U_i^B|\mu_i+U_i^B&gt;\bar{y}} \\
              &amp; = \bar{\alpha}+\theta\left(\bar{\mu}-\frac{\sigma^2_{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right)  
              -\frac{\sigma^2_{\mu}+\rho\sigma^2_{U}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\left(\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}+\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{1-\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right).
\end{align*}\]</span>
</div>

<p>In order to compute this parameter, we are going to set up a R function.
For reasons that will become clearer later, we will define two separate functions to compute the first and second part of the formula.
In the first part, you should have recognised <span class="math inline">\(TT\)</span>, that we have already computed in Lecture 1.
We are going to call the second part <span class="math inline">\(SB\)</span>, for reasons that will become explicit in a bit.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">delta.y.tt &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">  <span class="kw">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;barmu&quot;</span>]<span class="op">-</span>param[<span class="st">&quot;theta&quot;</span>]</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">         <span class="op">*</span>((param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">                                    <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">           <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])<span class="op">*</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])</a>
<a class="sourceLine" id="cb16-6" data-line-number="6">                                                            <span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))</a>
<a class="sourceLine" id="cb16-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb16-8" data-line-number="8">delta.y.sb &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb16-9" data-line-number="9">  <span class="kw">return</span>(<span class="op">-</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;sigma2U&quot;</span>])<span class="op">/</span><span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])</a>
<a class="sourceLine" id="cb16-10" data-line-number="10">         <span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb16-11" data-line-number="11">         <span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb16-12" data-line-number="12">           <span class="op">+</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))</a>
<a class="sourceLine" id="cb16-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb16-14" data-line-number="14">delta.y.ww &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb16-15" data-line-number="15">  <span class="kw">return</span>(<span class="kw">delta.y.tt</span>(param)<span class="op">+</span><span class="kw">delta.y.sb</span>(param))</a>
<a class="sourceLine" id="cb16-16" data-line-number="16">}</a></code></pre></div>
<p>As a conclusion of all these derivations, <span class="math inline">\(WW\)</span> in the population is equal to -1.298.
Remember that the value of <span class="math inline">\(TT\)</span> in the population is 0.172.</p>
<p>In order to compute the <span class="math inline">\(WW\)</span> estimator in a sample, I’m going to generate a brand new sample and I’m going to choose a seed for the pseudo-random number generator so that we obtain the same result each time we run the code.
I use <code>set.seed(1234)</code> in the code chunk below.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">param &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">8</span>,.<span class="dv">5</span>,.<span class="dv">28</span>,<span class="dv">1500</span>)</a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="kw">names</span>(param) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb17-4" data-line-number="4">N &lt;-<span class="dv">1000</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb17-6" data-line-number="6">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb17-7" data-line-number="7">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB</a>
<a class="sourceLine" id="cb17-8" data-line-number="8">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb17-9" data-line-number="9">Ds &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,N)</a>
<a class="sourceLine" id="cb17-10" data-line-number="10">Ds[YB<span class="op">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb17-11" data-line-number="11">l &lt;-<span class="st"> </span><span class="kw">length</span>(param)</a>
<a class="sourceLine" id="cb17-12" data-line-number="12">param &lt;-<span class="st"> </span><span class="kw">c</span>(param,<span class="fl">0.9</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb17-13" data-line-number="13"><span class="kw">names</span>(param)[(l<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span><span class="kw">length</span>(param)] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</a>
<a class="sourceLine" id="cb17-14" data-line-number="14">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb17-15" data-line-number="15">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb17-16" data-line-number="16">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb17-17" data-line-number="17">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb17-18" data-line-number="18">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb17-19" data-line-number="19">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb17-20" data-line-number="20">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb17-21" data-line-number="21">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a>
<a class="sourceLine" id="cb17-22" data-line-number="22">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb17-23" data-line-number="23">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<p>In this sample, the average outcome of the treated in the presence of the treatment is
<span class="math display">\[
\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^ND_iy_i= 7.074.
\]</span>
It is materialized by a circle on Figure <a href="FPCI.html#fig:ploty0y1yBD">1.6</a>.
The average outcome of the untreated is
<span class="math display">\[
\frac{1}{\sum_{i=1}^N(1-D_i)}\sum_{i=1}^N(1-D_i)y_i= 8.383.
\]</span>
It is materialized by a plus sign on Figure <a href="FPCI.html#fig:ploty0y1yBD">1.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:ploty0y1yBD"></span>
<img src="STCI_files/figure-html/ploty0y1yBD-1.png" alt="Evolution of average outcomes in the treated and control group before (Time =1) and after (Time=2) the treatment" width="60%" />
<p class="caption">
Figure 1.6: Evolution of average outcomes in the treated and control group before (Time =1) and after (Time=2) the treatment
</p>
</div>
<p>The estimate of the <span class="math inline">\(WW\)</span> comparison in the sample is thus:</p>
<p><span class="math display">\[\begin{align*}
\hat{\Delta^Y_{WW}} &amp; = \frac{1}{\sum_{i=1}^N D_i}\sum_{i=1}^N Y_iD_i-\frac{1}{\sum_{i=1}^N (1-D_i)}\sum_{i=1}^N Y_i(1-D_i).
\end{align*}\]</span></p>
<p>We have <span class="math inline">\(\hat{\Delta^y_{WW}}=\)</span> -1.308.
Remember that the value of <span class="math inline">\(TT\)</span> in the sample is <span class="math inline">\(\Delta^y_{TT_s}=\)</span> 0.168.</p>
<p>Overall, <span class="math inline">\(WW\)</span> severely underestimates the effect of the treatment in our example.
<span class="math inline">\(WW\)</span> suggests that the treatment has a negative effect on outcomes whereas we know by construction that it has a positive one.</p>
</div>
<div id="selection-bias" class="section level4">
<h4><span class="header-section-number">1.4.1.2</span> Selection bias</h4>
<p>When we form the with/without comparison, we do not recover the <span class="math inline">\(TT\)</span> parameter.
Instead, we recover <span class="math inline">\(TT\)</span> plus a bias term, called <strong>selection bias</strong>:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{WW} &amp; =\Delta^Y_{TT}+\Delta^Y_{SB}.
\end{align*}\]</span></p>

<div class="definition">
<span id="def:SB" class="definition"><strong>Definition 1.6  (Selection bias)  </strong></span>Selection bias is the difference between the with/without comparison and the treatment on the treated parameter:
<span class="math display">\[\begin{align*}
\Delta^Y_{SB} &amp; = \Delta^Y_{WW}-\Delta^Y_{TT}.
\end{align*}\]</span>
</div>

<p><span class="math inline">\(WW\)</span> tries to approximate the counterfactual expected outcome in the treated group by using <span class="math inline">\(\esp{Y_i^0|D_i=0}\)</span>, the expected outcome in the untreated group .
Selection bias appears because this proxy is generally poor.
It is very easy to see that selection bias is indeed directly due to this bad proxy problem:</p>

<div class="theorem">
<p><span id="thm:SBth" class="theorem"><strong>Theorem 1.2  (Selection bias and counterfactual)  </strong></span>Selection bias is the difference between the counterfactual expected potential outcome in the absence of the treatment among the treated and the expected potential outcome in the absence of the treatment among the untreated.</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{SB} &amp; = \esp{Y_i^0|D_i=1}-\esp{Y_i^0|D_i=0}.
\end{align*}\]</span></p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> <span class="math display">\[\begin{align*}
\Delta^Y_{SB} &amp; = \Delta^Y_{WW}-\Delta^Y_{TT} \\
              &amp; = \esp{Y_i|D_i=1}-\esp{Y_i|D_i=0}-\esp{Y_i^1-Y_i^0|D_i=1}\\
              &amp; = \esp{Y_i^0|D_i=1}-\esp{Y_i^0|D_i=0}.
\end{align*}\]</span></p>
The first and second equalities stem only from the definition of both parameters.
The third equality stems from using the switching equation: <span class="math inline">\(Y_i=Y_i^1D_i+Y_i^0(1-D_i)\)</span>, so that <span class="math inline">\(\esp{Y_i|D_i=1}=\esp{Y^1_i|D_i=1}\)</span> and <span class="math inline">\(\esp{Y_i|D_i=0}=\esp{Y_i^0|D_i=0}\)</span>.
</div>


<div class="example">
<span id="exm:unnamed-chunk-17" class="example"><strong>Example 1.10  </strong></span>In the population, <span class="math inline">\(SB\)</span> is equal to
</div>

<p><span class="math display">\[\begin{align*}
  \Delta^y_{SB} &amp; = \Delta^y_{WW}-\Delta^y_{TT} \\
                &amp; = -1.298 - 0.172 \\
                &amp; = -1.471
\end{align*}\]</span></p>
<p>We could have computed <span class="math inline">\(SB\)</span> directly using the formula from Theorem <a href="FPCI.html#thm:SBth">1.2</a>:</p>
<p><span class="math display">\[\begin{align*}
\Delta^y_{SB} &amp; = \esp{y_i^0|D_i=1}-\esp{y_i^0|D_i=0}\\
              &amp; = -\frac{\sigma^2_{\mu}+\rho\sigma^2_{U}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\left(\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}+\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{1-\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right).
\end{align*}\]</span></p>
<p>When using the R function for <span class="math inline">\(SB\)</span> that we have defined earlier, we indeed find: <span class="math inline">\(\Delta^y_{SB}=\)</span> -1.471.</p>
<p>In the sample, <span class="math inline">\(\hat{\Delta^y_{SB}}=\)</span>-1.308-0.168 <span class="math inline">\(=\)</span> -1.476.
Selection bias emerges because we are using a bad proxy for the counterfactual.
The average outcome for the untreated is equal to <span class="math inline">\(\frac{1}{\sum_{i=1}^N(1-D_i)}\sum_{i=1}^N(1-D_i)y_i=\)</span> 8.383 while the counterfactual average outcome for the treated is <span class="math inline">\(\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^ND_iy^0_i=\)</span> 6.906.
Their difference is as expected equal to <span class="math inline">\(SB\)</span>:
<span class="math inline">\(\hat{\Delta^y_{SB}}=\)</span> 6.906 <span class="math inline">\(-\)</span> 8.383 <span class="math inline">\(=\)</span> -1.476.
The counterfactual average outcome of the treated is much smaller than the average outcome of the untreated.
On Figure <a href="FPCI.html#fig:ploty0y1yBD">1.6</a>, this is materialized by the fact that the plus sign is located much above the triangle.</p>

<div class="remark">
<p> <span class="remark"><em>Remark. </em></span> The concept of selection bias is related to but different from the concept of sample selection bias.
With sample selection bias, we worry that selection into the sample might bias the estimated effect of a treatment on outcomes.
With selection bias, we worry that selection into the treatment itself might bias the effect of the treatment on outcomes.
Both biases are due to unbserved covariates, but they do not play out in the same way.</p>
<p>For example, estimating the effect of education on women’s wages raises both selection bias and sample selection bias issues.
Selection bias stems from the fact that more educated women are more likely to be more dynamic and thus to have higher earnings even when less educated.
Selection bias would be positive in that case, overestimating the effect of education on earnings.</p>
Sample selection bias stems from the fact that we can only use a sample of working women in order to estimate the effect of education on wages, since we do not observe the wages on non working women.
But, selection into the labor force might generate sample selection bias.
More educated women participate more in the labor market, while less educated women participate less.
As a consequence, less educated women that work are different from the overall sample of less educated women.
They might be more dynamic and work-focused.
As a consequence, their wages are higher than the average wages of the less educated women.
Comparing the wages of less educated women that work to those of more educated women that work might understate the effect of education on earnings.
Sample selection bias would generate a negative bias on the education coefficient.
</div>

</div>
<div id="confounding-factors" class="section level4">
<h4><span class="header-section-number">1.4.1.3</span> Confounding factors</h4>
<p>Confounding factors are the factors that generate differences between treated and untreated individuals even in the absence of the treatment.
The confounding factors are thus responsible for selection bias.
In general, the mere fact of being selected for receiving the treatment means that you have a host of characteristics that would differentiate you from the unselected individuals, even if you were not to receive the treatment eventually.</p>
<p>For example, if a drug is given to initially sicker individuals, then, we expect that they will be sicker that the untreated in the absence of the treatment.
Comparing sick individuals to healthy ones is not a sound way to estimate the effect of a treatment.
Obviously, even if our treatment performs well, healthier individuals will be healthier after the treatment has been allocated to the sicker patients.
The best we can expect is that the treated patients have recovered, and that their health after the treatment is comparable to that of the untreated patients.
In that case, the with/without comparison is going to be null, whereas the true effect of the treatment is positive.
Selection bias is negative in that case: in the absence of the treatment, the average health status of the treated individuals would have been smaller than that of the untreated individuals.
The confounding factor is the health status of individuals when the decision to allocate the drug has been taken.
It is correlated to both the allocation of the treatment (negatively) and to health in the absence of the treatment (positively).</p>

<div class="example">
<span id="exm:unnamed-chunk-19" class="example"><strong>Example 1.11  </strong></span>In our example, <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(U_i^B\)</span> are the confounding factors.
Because the treatment is only given to individuals with pre-treament outcomes smaller than a threshold (<span class="math inline">\(y_i^B\leq\bar{y}\)</span>), participants tend to have smaller <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(U_i^B\)</span> than non participants, as we can see on Figure <a href="FPCI.html#fig:histmuD">1.7</a>.
</div>

<div class="figure" style="text-align: center"><span id="fig:histmuD"></span>
<img src="STCI_files/figure-html/histmuD-1.png" alt="Distribution of confounders in the treated and control group" width="60%" />
<p class="caption">
Figure 1.7: Distribution of confounders in the treated and control group
</p>
</div>
<p>Since confounding factors are persistent, they affect the outcomes of participants and non participants after the treatment date.
<span class="math inline">\(\mu_i\)</span> persists entirely over time, and <span class="math inline">\(U_i^B\)</span> persists at a rate <span class="math inline">\(\rho\)</span>.
As a consequence, even in the absence of the treatment, participants have lower outcomes than non participants, as we can see on Figure <a href="FPCI.html#fig:histmuD">1.7</a>.</p>
<p>We can derive the contributions of both confouding factors to overall SB:</p>
<p><span class="math display">\[\begin{align*}
\esp{Y_i^0|D_i=1} &amp; = \esp{\mu_i+\delta+U_i^0|\mu_i+U_i^B\leq\bar{y}}\\
                  &amp; = \delta + \esp{\mu_i|\mu_i+U_i^B\leq\bar{y}} + \rho\esp{U_i^B|\mu_i+U_i^B\leq\bar{y}}\\
\Delta^y_{SB}     &amp; = \esp{\mu_i|\mu_i+U_i^B\leq\bar{y}}-\esp{\mu_i|\mu_i+U_i^B&gt;\bar{y}} \\
                  &amp; \phantom{=} + \rho\left(\esp{U_i^B|\mu_i+U_i^B\leq\bar{y}}-\esp{U_i^B|\mu_i+U_i^B&gt;\bar{y}}\right)\\
                  &amp; = -\frac{\sigma^2_{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\left(\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}+\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{1-\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right) \\
                  &amp; \phantom{=} -\frac{\rho\sigma^2_{U}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\left(\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}+\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{1-\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right)
\end{align*}\]</span></p>
<p>In order to evaluate these quantities, let’s build two R functions:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">delta.y.sb.mu &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb18-2" data-line-number="2">  <span class="kw">return</span>(<span class="op">-</span>(param[<span class="st">&quot;sigma2mu&quot;</span>])<span class="op">/</span><span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])</a>
<a class="sourceLine" id="cb18-3" data-line-number="3">         <span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb18-4" data-line-number="4">         <span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb18-5" data-line-number="5">           <span class="op">+</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))</a>
<a class="sourceLine" id="cb18-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb18-7" data-line-number="7">delta.y.sb.U &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb18-8" data-line-number="8">  <span class="kw">return</span>(<span class="op">-</span>(param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;sigma2U&quot;</span>])<span class="op">/</span><span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])</a>
<a class="sourceLine" id="cb18-9" data-line-number="9">         <span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb18-10" data-line-number="10">         <span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb18-11" data-line-number="11">           <span class="op">+</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))</a>
<a class="sourceLine" id="cb18-12" data-line-number="12">}</a></code></pre></div>
<p>The contribution of <span class="math inline">\(\mu_i\)</span> to selection bias is -0.978 while that of <span class="math inline">\(U_i^0\)</span> is of -0.493.</p>
</div>
<div id="when-does-ww-identify-tt" class="section level4">
<h4><span class="header-section-number">1.4.1.4</span> When does <span class="math inline">\(WW\)</span> identify <span class="math inline">\(TT\)</span>?</h4>
<p>Are there conditions under which <span class="math inline">\(WW\)</span> identify <span class="math inline">\(TT\)</span>?
The answer is yes: when there is no selection bias, the proxy used by <span class="math inline">\(WW\)</span> for the counterfactual quantity is actually valid.
Formally, <span class="math inline">\(WW\)</span> identifies <span class="math inline">\(TT\)</span> when the following assumption holds:</p>

<div class="definition">
<span id="def:noselb" class="definition"><strong>Definition 1.7  (No selection bias)  </strong></span>We assume the following:
<span class="math display">\[\begin{align*}
\esp{Y_i^0|D_i=1} &amp; = \esp{Y_i^0|D_i=0}.
\end{align*}\]</span>
</div>

<p>Under Assumption <a href="FPCI.html#def:noselb">1.7</a>, the expected counterfactual outcome of the treated is equal to the expected potential outcome of the untreated in the absence of the treatment.
This yields to the following result:</p>

<div class="theorem">
<span id="thm:wwtt" class="theorem"><strong>Theorem 1.3  </strong></span>Under Assumption <a href="FPCI.html#def:noselb">1.7</a>, <span class="math inline">\(WW\)</span> identifies the <span class="math inline">\(TT\)</span> parameter:
<span class="math display">\[\begin{align*}
\Delta^Y_{WW} &amp; = \Delta^Y_{TT}.
\end{align*}\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <span class="math display">\[\begin{align*}
\Delta^Y_{WW} &amp; = \esp{Y_i|D_i=1}-\esp{Y_i|D_i=0}\\
              &amp; = \esp{Y_i^1|D_i=1}-\esp{Y_i^0|D_i=0}\\
              &amp; = \esp{Y_i^1|D_i=1}-\esp{Y_i^0|D_i=1} \\
              &amp; = \Delta^Y_{TT},
\end{align*}\]</span>
where the second equation uses the switching equation and the third uses Assumption <a href="FPCI.html#def:noselb">1.7</a>.
</div>

<p>So, under Assumption <a href="FPCI.html#def:noselb">1.7</a>, the <span class="math inline">\(WW\)</span> comparison actually identifies the <span class="math inline">\(TT\)</span> parameter.
We say that Assumption <a href="FPCI.html#def:noselb">1.7</a> is an <strong>identification assumption</strong>: it serves to identify the parameter of interest using observed data.
The intuition for this result is simply that, under Assumption <a href="FPCI.html#def:noselb">1.7</a>, there are no confounding factors and thus no selection bias.
under Assumption <a href="FPCI.html#def:noselb">1.7</a>, the factors that yield individuals to receive or not the treatment are mean-independent of the potential outcomes in the absence of the treatment.
In this case, the expected outcome in the untreated group actually is a perfect proxy for the counterfactual expected outcome of the treated group.</p>
<p>Obviously, Assumption <a href="FPCI.html#def:noselb">1.7</a> is extremely unlikely to hold in real life.
For Assumption <a href="FPCI.html#def:noselb">1.7</a> to hold, it has to be that <strong>all</strong> the determinants of <span class="math inline">\(D_i\)</span> are actually unrelated to <span class="math inline">\(Y_i^0\)</span>.
One way to enforce Assumption <a href="FPCI.html#def:noselb">1.7</a> is to randomize treatment intake.
We will see this in the Lecture on RCTs.
It might also be possible that Assumption <a href="FPCI.html#def:noselb">1.7</a> holds in the data in the absence of an RCT.
But this is not very likely, and should be checked by every mean possible.</p>
<p>One way to test for the validity of Assumption <a href="FPCI.html#def:noselb">1.7</a> is to compare the values of observed covariates in the treated and untreated group.
For Assumption <a href="FPCI.html#def:noselb">1.7</a> to be credible, observed covariates should be distributed in the same way.</p>
<p>Another nice way to test for the validity of Assumption <a href="FPCI.html#def:noselb">1.7</a> with observed data is to implement a <strong>placebo test</strong>.
A placebo test looks for an effect where there should be none, if we believe the identification assumptions.
For example, under Assumption <a href="FPCI.html#def:noselb">1.7</a> it should be (even though it is not rigorously implied) that outcomes before the treatment are also mean-independent of the treatment allocation.
And actually, since a future treatment cannot have an effect today (unless people anticipate the treatment, which we assume away here), the <span class="math inline">\(WW\)</span> comparison before the treatment should be null, therefore giving a zero effect of the placebo treatment “will receive the treatment in the future.”</p>

<div class="example">
<span id="exm:unnamed-chunk-21" class="example"><strong>Example 1.12  </strong></span>When the allocation rule defining <span class="math inline">\(D_i\)</span> is the eligibility rule that we have used so far, we have already seen that Assumption <a href="FPCI.html#def:noselb">1.7</a> does not hold and the placebo test should not pass either.
</div>

<p>One way of generating Assumption <a href="FPCI.html#def:noselb">1.7</a> from the eligibility rule that we are using is to mute the persistence in outcome dynamics.
For example, one could set <span class="math inline">\(\rho=0\)</span> and <span class="math inline">\(\sigma^2_{\mu}=0\)</span>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">param &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">0</span>,.<span class="dv">28</span>,<span class="dv">1500</span>,<span class="dv">0</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="kw">names</span>(param) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>,<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3">param</a></code></pre></div>
<pre><code>##         barmu      sigma2mu       sigma2U          barY           rho 
##          8.00          0.00          0.28       1500.00          0.00 
##         theta sigma2epsilon     sigma2eta         delta      baralpha 
##          0.01          0.05          0.05          0.05          0.10</code></pre>
<p>In that case, outcomes are not persistent and Assumption <a href="FPCI.html#def:noselb">1.7</a> holds:</p>
<p><span class="math display">\[\begin{align*}
\esp{y_i^0|D_i=1} &amp; = \esp{\mu_i+\delta+U_i^0|y_i^B\leq\bar{y}}\\
                  &amp; = \esp{\bar{\mu}+\delta+\epsilon_i|\bar{\mu}+U_i^B\leq\bar{y}}\\
                  &amp; = \bar{\mu} + \delta + \esp{\epsilon_i|\bar{\mu}+U_i^B\leq\bar{y}}\\
                  &amp; = \bar{\mu} + \delta + \esp{\epsilon_i|\bar{\mu}+U_i^B&gt;\bar{y}}\\
                  &amp; = \esp{\mu_i+\delta+U_i^0|y_i^B&gt;\bar{y}}\\
                  &amp; = \esp{y_i^0|D_i=0},                  
\end{align*}\]</span></p>
<p>where the second equality follows from <span class="math inline">\(\sigma^2_{\mu}=0\)</span> and <span class="math inline">\(\rho=0\)</span> and the fourth from <span class="math inline">\(\epsilon_i \Ind U_i^B\)</span>.
Another direct way to see this is to use the formula for selection bias that we have derived above.
It is easy to see that with <span class="math inline">\(\rho=0\)</span> and <span class="math inline">\(\sigma^2_{\mu}=0\)</span>, <span class="math inline">\(\Delta^y_{SB}=0\)</span>.
To be sure, we can compute <span class="math inline">\(\Delta^y_{SB}\)</span> with the new parameter values: <span class="math inline">\(\Delta^y_{SB}=\)</span> 0.
As a consequence, <span class="math inline">\(\Delta^y_{TT}=\)</span> 0.18 <span class="math inline">\(=\)</span> 0.18 <span class="math inline">\(=\Delta^y_{WW}\)</span>.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> You might have noticed that the value of <span class="math inline">\(\Delta^y_{TT}\)</span> is different than before.
It is normal, since it depends on the values of parameters, and especially on <span class="math inline">\(\sigma_{\mu}^2\)</span> and <span class="math inline">\(\rho\)</span>.
</div>

<p>Let’s see how these quantities behave in the sample.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb21-3" data-line-number="3">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb21-4" data-line-number="4">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB </a>
<a class="sourceLine" id="cb21-5" data-line-number="5">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb21-6" data-line-number="6">Ds &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,N)</a>
<a class="sourceLine" id="cb21-7" data-line-number="7">Ds[YB<span class="op">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] &lt;-<span class="st"> </span><span class="dv">1</span> </a>
<a class="sourceLine" id="cb21-8" data-line-number="8">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb21-9" data-line-number="9">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb21-10" data-line-number="10">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb21-11" data-line-number="11">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb21-12" data-line-number="12">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb21-13" data-line-number="13">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb21-14" data-line-number="14">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb21-15" data-line-number="15">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a>
<a class="sourceLine" id="cb21-16" data-line-number="16">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb21-17" data-line-number="17">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<p>We can see that <span class="math inline">\(\hat{\esp{Y_i^0|D_i=1}}=\)</span> 8.038 <span class="math inline">\(\approx\)</span> 8.055 <span class="math inline">\(=\hat{\esp{Y_i^0|D_i=0}}\)</span>.
This means that <span class="math inline">\(WW\)</span> should be close to <span class="math inline">\(TT\)</span>: <span class="math inline">\(\hat{\Delta^y_{TT}}=\)</span> 0.198 <span class="math inline">\(\approx\)</span> 0.182 <span class="math inline">\(=\hat{\Delta^y_{WW}}\)</span>.
Note that <span class="math inline">\(\hat{WW}\)</span> in the sample is not exactly, but only approximately, equal to <span class="math inline">\(TT\)</span> in the population and in the sample.
This is an instance of the Fundamental Problem of Statistical Inference that we will study in the next chapter.</p>
<p>Under these restrictions, the placebo test would unfortunately conclude against Assumption <a href="FPCI.html#def:noselb">1.7</a> even though it is valid:</p>
<p><span class="math display">\[\begin{align*}
\esp{y_i^B|D_i=1} &amp; = \esp{\mu_i+ U_i^B|y_i^B\leq\bar{y}}\\
                  &amp; = \esp{\bar{\mu}+U_i^B|\bar{\mu}+U_i^B\leq\bar{y}}\\
                  &amp; = \bar{\mu}  + \esp{U_i^B|\bar{\mu}+U_i^B\leq\bar{y}}\\
                  &amp; \neq \bar{\mu}  + \esp{U_i^B|\bar{\mu}+U_i^B&gt;\bar{y}}\\
                  &amp; = \esp{\mu_i+U_i^0|y_i^B&gt;\bar{y}}\\
                  &amp; = \esp{y_i^B|D_i=0}.                  
\end{align*}\]</span></p>
<p>In the sample, we indeed have that <span class="math inline">\(\hat{\esp{Y_i^B|D_i=1}}=\)</span> 7.004 <span class="math inline">\(\neq\)</span> 8.072 <span class="math inline">\(=\hat{\esp{Y_i^B|D_i=0}}\)</span>.
The reason for the failure of the placebo test to conclude that <span class="math inline">\(Ww\)</span> is actually correct is that the <span class="math inline">\(U_i^B\)</span> shock enters both into the selection equation and the outcome equation for <span class="math inline">\(y_i^B\)</span>, generating a wage at period <span class="math inline">\(B\)</span> between the outcomes of the treated and of the untreated.
Since it is not persistent, this wedge does not generate selection bias.
This wedge would not be detected if we could perform it further back in time, before the selection period.</p>
<p>Another way to make Assumption <a href="FPCI.html#def:noselb">1.7</a> work is to generate a new allocation rule where all the determinants of treatment intake are indeed orthogonal to potential outcomes and to outcomes before the treatment.
Let’s assume for example that <span class="math inline">\(D_i=\uns{V_i\leq\bar{y}}\)</span>, with <span class="math inline">\(V_i\sim\mathcal{N}(\bar{\mu},\sigma^2_{\mu}+\sigma^2_{U})\)</span> and <span class="math inline">\(V_i\Ind(Y_i^0,Y_i^1,Y_i^B,\mu_i,\eta_i)\)</span>.
In that case, Assumption <a href="FPCI.html#def:noselb">1.7</a> holds and the placebo test does work.
Indeed, we have:</p>
<p><span class="math display">\[\begin{align*}
\Delta^y_{TT} &amp; = \esp{Y_i^1-Y_i^0|D_i=1} \\
              &amp; = \esp{\alpha_i|D_i=1} \\
              &amp; = \esp{\bar{\alpha}+\theta\mu_i+\eta_i|V_i\leq\bar{y}}\\
              &amp; = \bar{\alpha}+\theta\bar{\mu} \\
              &amp; = \Delta^y_{ATE} \\
\Delta^y_{WW} &amp; = \esp{Y_i|D_i=1} - \esp{Y_i|D_i=0} \\
              &amp; = \esp{Y^1_i|D_i=1} - \esp{Y^0_i|D_i=0} \\
              &amp; = \esp{Y^1_i|V_i\leq\bar{y}} - \esp{Y^0_i|V_i&gt;\bar{y}} \\
              &amp; = \esp{Y^1_i} - \esp{Y^0_i} \\
              &amp; = \Delta^y_{ATE}
\end{align*}\]</span></p>
<p><span class="math inline">\(ATE\)</span> is the Average Treatment Effect in the population.
It is the expected effect of the treatment on all the members of the population, not only on the treated.
When the treatment is randomly allocated, both <span class="math inline">\(TT\)</span> and <span class="math inline">\(ATE\)</span> are equal, since the treated are a random subset of the overall population.
I prefer to use <span class="math inline">\(ATE\)</span> for my definition of the <span class="math inline">\(R\)</span> function in order not to erase the definition of the <span class="math inline">\(TT\)</span> function:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">delta.y.ate &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">  <span class="kw">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>param[<span class="st">&quot;barmu&quot;</span>])</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">}</a></code></pre></div>
<p>In the population, <span class="math inline">\(WW\)</span> identifies <span class="math inline">\(TT\)</span>: <span class="math inline">\(\Delta^y_{TT}=\)</span> 0.18 <span class="math inline">\(=\Delta^y_{WW}\)</span>.
Let’s see how these quantities behave in the sample:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb23-2" data-line-number="2">N &lt;-<span class="dv">1000</span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb23-4" data-line-number="4">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb23-5" data-line-number="5">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB </a>
<a class="sourceLine" id="cb23-6" data-line-number="6">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb23-7" data-line-number="7">Ds &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,N)</a>
<a class="sourceLine" id="cb23-8" data-line-number="8">V &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb23-9" data-line-number="9">Ds[V<span class="op">&lt;=</span><span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])] &lt;-<span class="st"> </span><span class="dv">1</span> </a>
<a class="sourceLine" id="cb23-10" data-line-number="10">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb23-11" data-line-number="11">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb23-12" data-line-number="12">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb23-13" data-line-number="13">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb23-14" data-line-number="14">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb23-15" data-line-number="15">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb23-16" data-line-number="16">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb23-17" data-line-number="17">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a>
<a class="sourceLine" id="cb23-18" data-line-number="18">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb23-19" data-line-number="19">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<p>In the sample, the counterfactual is well approximated by the outcomes of the untreated: <span class="math inline">\(\hat{\esp{Y_i^0|D_i=1}}=\)</span> 8.085 <span class="math inline">\(\approx\)</span> 8.054 <span class="math inline">\(=\hat{\esp{Y_i^0|D_i=0}}\)</span>.
As a consequence, <span class="math inline">\(WW\)</span> should be close to <span class="math inline">\(TT\)</span>: <span class="math inline">\(\hat{\Delta^y_{TT}}=\)</span> 0.168 <span class="math inline">\(\approx\)</span> 0.199 <span class="math inline">\(=\hat{\Delta^y_{WW}}\)</span>.
The placebo test is also valid in that case: <span class="math inline">\(\hat{\esp{Y_i^B|D_i=1}}=\)</span> 7.95 <span class="math inline">\(\approx\)</span> 7.99 <span class="math inline">\(=\hat{\esp{Y_i^B|D_i=0}}\)</span>.</p>
</div>
</div>
<div id="the-beforeafter-comparison-temporal-confounders-and-time-trend-bias" class="section level3">
<h3><span class="header-section-number">1.4.2</span> The before/after comparison, temporal confounders and time trend bias</h3>
<p>The before/after comparison (<span class="math inline">\(BA\)</span>) is also very intuitive: it consists in looking at how the outcomes of the treated have changed over time and to attribute this change to the effect of the treatment.
The problem is that other changes might have affected outcomes in the absence of the treatment, thereby biasing <span class="math inline">\(BA\)</span>.
The bias of <span class="math inline">\(BA\)</span> is called time-trend bias.
It is due to confounders that affect the outcomes of the treated over time.
This section defines the <span class="math inline">\(BA\)</span> estimator, derives its bias, describes the role of the confounders and states conditions under which <span class="math inline">\(BA\)</span> identifies <span class="math inline">\(TT\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-23" class="example"><strong>Example 1.13  </strong></span>Before computing any estimates, we need to reset all our parameter values and generated sample it their usual values:
</div>

<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">param &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">8</span>,.<span class="dv">5</span>,.<span class="dv">28</span>,<span class="dv">1500</span>)</a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="kw">names</span>(param) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb24-4" data-line-number="4">N &lt;-<span class="dv">1000</span></a>
<a class="sourceLine" id="cb24-5" data-line-number="5">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb24-6" data-line-number="6">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb24-7" data-line-number="7">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB </a>
<a class="sourceLine" id="cb24-8" data-line-number="8">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb24-9" data-line-number="9">Ds &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,N)</a>
<a class="sourceLine" id="cb24-10" data-line-number="10">Ds[YB<span class="op">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] &lt;-<span class="st"> </span><span class="dv">1</span> </a>
<a class="sourceLine" id="cb24-11" data-line-number="11">l &lt;-<span class="st"> </span><span class="kw">length</span>(param)</a>
<a class="sourceLine" id="cb24-12" data-line-number="12">param &lt;-<span class="st"> </span><span class="kw">c</span>(param,<span class="fl">0.9</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb24-13" data-line-number="13"><span class="kw">names</span>(param)[(l<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span><span class="kw">length</span>(param)] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</a>
<a class="sourceLine" id="cb24-14" data-line-number="14">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb24-15" data-line-number="15">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb24-16" data-line-number="16">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb24-17" data-line-number="17">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb24-18" data-line-number="18">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb24-19" data-line-number="19">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb24-20" data-line-number="20">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb24-21" data-line-number="21">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a>
<a class="sourceLine" id="cb24-22" data-line-number="22">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb24-23" data-line-number="23">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<div id="the-beforeafter-comparison" class="section level4">
<h4><span class="header-section-number">1.4.2.1</span> The before/after comparison</h4>
<p>The before/after estimator (<span class="math inline">\(BA\)</span>) compares the outcomes of the treated after taking the treatment to the outcomes of the treated before taking the treatment.
It is also sometimes called a “pre-post comparison.”</p>

<div class="definition">
<span id="def:unnamed-chunk-24" class="definition"><strong>Definition 1.8  (Before/after comparison)  </strong></span>The before/after comparison is the difference between the expected outcomes in the treated group after the treatment and the expected outcomes in the same group before the treatment:
<span class="math display">\[\begin{align*}
\Delta^Y_{BA} &amp; =  \esp{Y_i|D_i=1}-\esp{Y^B_i|D_i=1}.
\end{align*}\]</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-25" class="example"><strong>Example 1.14  </strong></span>In the population, the <span class="math inline">\(BA\)</span> estimator has the following shape:
<span class="math display">\[\begin{align*}
  \Delta^y_{BA} &amp; = \esp{y_i|D_i=1}-\esp{y^B_i|D_i=1}\\
                &amp; = \esp{y^1_i-y^B_i|D_i=1}\\
                &amp; = \esp{\alpha_i|D_i=1} + \delta + (\rho-1)\esp{U_i^B|\mu_i+U_i^B\leq\bar{y}}\\
                &amp; = \Delta^y_{TT} + \delta + (1-\rho)\left(\frac{\sigma^2_{U}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right).
\end{align*}\]</span>
</div>

<p>In order to compute <span class="math inline">\(BA\)</span> in the population, we can again use a R function, combining the value of <span class="math inline">\(TT\)</span> and that of the second part of the formula, that we are going to denote <span class="math inline">\(TB\)</span> for reasons that are going to become clear in a bit.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">delta.y.tb &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">  <span class="kw">return</span>(param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">          <span class="op">+</span>(<span class="dv">1</span><span class="op">-</span>param[<span class="st">&quot;rho&quot;</span>])<span class="op">*</span>((param[<span class="st">&quot;sigma2U&quot;</span>])<span class="op">/</span><span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">         <span class="op">*</span><span class="kw">dnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))</a>
<a class="sourceLine" id="cb25-5" data-line-number="5">         <span class="op">/</span><span class="kw">pnorm</span>((<span class="kw">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="op">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="op">/</span>(<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="op">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))</a>
<a class="sourceLine" id="cb25-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb25-7" data-line-number="7">delta.y.ba &lt;-<span class="st"> </span><span class="cf">function</span>(param){</a>
<a class="sourceLine" id="cb25-8" data-line-number="8">  <span class="kw">return</span>(<span class="kw">delta.y.tt</span>(param)<span class="op">+</span><span class="st"> </span><span class="kw">delta.y.tb</span>(param))</a>
<a class="sourceLine" id="cb25-9" data-line-number="9">}</a></code></pre></div>
<p>The value of <span class="math inline">\(BA\)</span> in the population is thus <span class="math inline">\(\Delta^y_{BA}=\)</span> 0.265.
Remember that the true value of <span class="math inline">\(TT\)</span> in the population is 0.172.
In the sample, the value of <span class="math inline">\(BA\)</span> is <span class="math inline">\(\hat{\Delta^y_{BA}}=\)</span> 0.267.
Remember that the value of <span class="math inline">\(TT\)</span> in the sample is <span class="math inline">\(\Delta^y_{TT_s}=\)</span> 0.168.</p>
</div>
<div id="time-trend-bias" class="section level4">
<h4><span class="header-section-number">1.4.2.2</span> Time trend bias</h4>
<p>When we form the before/after comparison, we do not recover the <span class="math inline">\(TT\)</span> parameter.
Instead, we recover <span class="math inline">\(TT\)</span> plus a bias term, called <strong>time trend bias</strong>:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{BA} &amp; =\Delta^Y_{TT}+\Delta^Y_{TB}.
\end{align*}\]</span></p>

<div class="definition">
<span id="def:unnamed-chunk-26" class="definition"><strong>Definition 1.9  (Time trend bias)  </strong></span>Time trend bias is the difference between the before/after comparison and the treatment on the treated parameter:
<span class="math display">\[\begin{align*}
\Delta^Y_{TB} &amp; = \Delta^Y_{BA}-\Delta^Y_{TT} .
\end{align*}\]</span>
</div>

<p><span class="math inline">\(BA\)</span> uses the expected outcome in the treated group before the treatment as a proxy for the expected counterfactual outcome in the absence of the treatment in the same group.
<span class="math inline">\(TB\)</span> is due to the fact that <span class="math inline">\(BA\)</span> uses an imperfect proxy for the counterfactual expected outcome of the treated:</p>

<div class="theorem">
<span id="thm:TB" class="theorem"><strong>Theorem 1.4  </strong></span>Time trend bias is the difference between the counterfactual expected potential outcome in the absence of the treatment among the treated and the expected outcome before the treatment in the same group.
<span class="math display">\[\begin{align*}
\Delta^Y_{TB} &amp; = \esp{Y_i^0|D_i=1}-\esp{Y_i^B|D_i=1}.
\end{align*}\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <span class="math display">\[\begin{align*}
\Delta^Y_{TB} &amp; = \Delta^Y_{BA}-\Delta^Y_{TT} \\
              &amp; = \esp{Y_i|D_i=1}-\esp{Y^B_i|D_i=1}-\esp{Y_i^1-Y_i^0|D_i=1}\\
              &amp; = \esp{Y_i^0|D_i=1}-\esp{Y_i^B|D_i=1}.
\end{align*}\]</span>
The first and second equalities stem from the definition of both parameters.
The third equality stems from using the switching equation: <span class="math inline">\(Y_i=Y_i^1D_i+Y_i^0(1-D_i)\)</span>, so that <span class="math inline">\(\esp{Y_i|D_i=1}=\esp{Y^1_i|D_i=1}\)</span>.
</div>


<div class="example">
<span id="exm:unnamed-chunk-28" class="example"><strong>Example 1.15  </strong></span>In the population, <span class="math inline">\(TB\)</span> is equal to
</div>

<p><span class="math inline">\(\Delta^y_{TB}=\Delta^y_{BA}-\Delta^y_{TT}=\)</span> 0.265 <span class="math inline">\(-\)</span> 0.172 <span class="math inline">\(=\)</span> 0.093.
We could have computed this result using Theorem<a href="FPCI.html#thm:TB">1.4</a>:</p>
<p><span class="math display">\[\begin{align*}
\Delta^y_{TB} &amp; = \esp{y_i^0|D_i=1}-\esp{y_i^B|D_i=1} \\
              &amp; = \delta + (1-\rho)\left(\frac{\sigma^2_{U}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{\sigma^2_{\mu}+\sigma^2_{U}}}\right)}\right).
\end{align*}\]</span></p>
<p>Using the R function that we have defined previously, this approach gives <span class="math inline">\(\Delta^y_{TB}=\)</span> 0.093.</p>
<p>In the sample <span class="math inline">\(\hat{\Delta^y_{BA}}=\)</span> 0.267 while <span class="math inline">\(\hat{\Delta^y_{TT}}=\)</span> 0.168, so that <span class="math inline">\(\hat{\Delta^y_{TB}}=\)</span> 0.099.
Time trend bias emerges because we are using a bad proxy for the counterfactual average outcomes of the treated.
The average outcome of the treated before the treatment takes place is <span class="math inline">\(\hat{\esp{y_i^B|D_i=1}}=\)</span> 6.807 while the true counterfactual average outcome for the treated after the treatment is <span class="math inline">\(\hat{\esp{y_i^0|D_i=1}}=\)</span> 6.906.
Outcomes would have increased in the treatment group even in the absence of the treatment.
As a consequence, the <span class="math inline">\(BA\)</span> comparison overestimates the true effect of the treatment.
<span class="math inline">\(TB\)</span> estimated using Theorem <a href="FPCI.html#thm:TB">1.4</a> is equal to: <span class="math inline">\(\hat{\Delta^y_{TB}}=\)</span> 6.906 <span class="math inline">\(-\)</span> 6.807 <span class="math inline">\(=\)</span> 0.099.
This can be seen on Figure <a href="FPCI.html#fig:ploty0y1yBD">1.6</a>: the triangle in period 2 is higher than in period 1.</p>
</div>
<div id="temporal-confounders" class="section level4">
<h4><span class="header-section-number">1.4.2.3</span> Temporal confounders</h4>
<p>Temporal confounders make the outcomes of the treated change at the same time as the treatment status changes, thereby confounding the effect of the treatment.
Temporal confounders are responsible for time trend bias.</p>
<p>Over time, there are other things that change than the treatment status.
For example, maybe sick individuals naturally recover, and thus their counterfactual health status is better than ther health status before taking the treatment.
As a results, <span class="math inline">\(BA\)</span> might overstimate the effect of the treatment.
It might also be that the overall level of health in the country has increased, because of increasing GDP, for example.</p>

<div class="example">
<span id="exm:unnamed-chunk-29" class="example"><strong>Example 1.16  </strong></span>In our example, <span class="math inline">\(\delta\)</span> and <span class="math inline">\(U_i^B\)</span> are the confounders.
<span class="math inline">\(\delta\)</span> captures the overall changes in outcomes over time (business cycle, general improvement of health status).
<span class="math inline">\(U^B_i\)</span> captures the fact that transitorily sicker individuals tend at the same time to receive the treatment and also to recover naturally.
The <span class="math inline">\(BA\)</span> comparison incorrectly attributes both of these changes to the effect of the treatment.
We can compute the relative contributions of both sources to the overall time-trend bias in the population.
</div>

<p><span class="math inline">\(\delta\)</span> contributes for 0.05 while <span class="math inline">\(U^B_i\)</span> contributes for 0.043.</p>
</div>
<div id="when-does-ba-identify-tt" class="section level4">
<h4><span class="header-section-number">1.4.2.4</span> When does <span class="math inline">\(BA\)</span> identify <span class="math inline">\(TT\)</span>?</h4>
<p>Are there conditions under which <span class="math inline">\(BA\)</span> actually identifies <span class="math inline">\(TT\)</span>?
The answer is yes, when there are no temporal confounders.
When that is the case, the variation of outcomes over time is only due to the treatment and it identifies the treatment effect.</p>
<p>More formally, we make the following assumption:</p>

<div class="definition">
<span id="def:notb" class="definition"><strong>Definition 1.10  (No time trend bias)  </strong></span>We assume the following:
<span class="math display">\[\begin{align*}
\esp{Y_i^0|D_i=1} &amp; = \esp{Y_i^B|D_i=1}.
\end{align*}\]</span>
</div>

<p>Under Assumption <a href="FPCI.html#def:notb">1.10</a>, the expected counterfactual outcome of the treated is equal to the expected potential outcome of the untreated in the absence of the treatment.
This yields to the following result:</p>

<div class="theorem">
<span id="thm:batt" class="theorem"><strong>Theorem 1.5  </strong></span>Under Assumption <a href="FPCI.html#def:notb">1.10</a>, <span class="math inline">\(BA\)</span> identifies the <span class="math inline">\(TT\)</span> parameter:
<span class="math display">\[\begin{align*}
\Delta^Y_{BA} &amp; = \Delta^Y_{TT}.
\end{align*}\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <span class="math display">\[\begin{align*}
\Delta^Y_{BA} &amp; = \esp{Y_i|D_i=1}-\esp{Y_i^B|D_i=1}\\
              &amp; = \esp{Y_i^1|D_i=1}-\esp{Y_i^B|D_i=1}\\
              &amp; = \esp{Y_i^1|D_i=1}-\esp{Y_i^0|D_i=1} \\
              &amp; = \Delta^Y_{TT},
\end{align*}\]</span>
where the second equation uses the switching equation and the third uses Assumption <a href="FPCI.html#def:notb">1.10</a>.
</div>

<p>Under Assumption <a href="FPCI.html#def:notb">1.10</a> the outcomes of the treated before the treatment takes place are a good proxy for the counterfactual.
As a consequence, <span class="math inline">\(BA\)</span> identifies <span class="math inline">\(TT\)</span>.
Under Assumption <a href="FPCI.html#def:notb">1.10</a>is very unlikely to hold in real life.
Indeed, it requires tha nothing happens to the outcomes of the treated in the absence of the treatment.
Assumption <a href="FPCI.html#def:notb">1.10</a> rules out economy-wide shocks but also mean-reversion, such as when sick people naturally recover from an illness.</p>
<p>A good way to test for the validity of Assumption <a href="FPCI.html#def:notb">1.10</a> is to perform a placebo test.
Two of these tests are possible.
One placebo test would be to apply the <span class="math inline">\(BA\)</span> estimator between two pre-treatment periods where nothing should happen since the treatment status does not vary and, by assumption, nothing else should vary.
A second placebo test would be to apply the <span class="math inline">\(BA\)</span> estimator to a group that does not receive the treatment.
The untreated group is a perfectly suitable candidate for that.
Assumption <a href="FPCI.html#def:notb">1.10</a> does not imply that there should be no change in the untreated outcomes, but detecting such a change would cast a serious doubt on the validity of Assumption <a href="FPCI.html#def:notb">1.10</a>.</p>

<div class="example">
<span id="exm:unnamed-chunk-31" class="example"><strong>Example 1.17  </strong></span>One way to generate a population in which Assumption <a href="FPCI.html#def:notb">1.10</a> holds is to shut down the two sources of confounders in our original model by setting both <span class="math inline">\(\delta=0\)</span> and <span class="math inline">\(\rho=1\)</span>.
</div>

<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">param &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">8</span>,<span class="fl">0.5</span>,.<span class="dv">28</span>,<span class="dv">1500</span>,<span class="dv">1</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2"><span class="kw">names</span>(param) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>,<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">param</a></code></pre></div>
<pre><code>##         barmu      sigma2mu       sigma2U          barY           rho 
##          8.00          0.50          0.28       1500.00          1.00 
##         theta sigma2epsilon     sigma2eta         delta      baralpha 
##          0.01          0.05          0.05          0.00          0.10</code></pre>
<p>In that case, according to the formula we have derived for <span class="math inline">\(TB\)</span>, we have: <span class="math inline">\(\Delta^y_{TB}=\)</span> 0.
Let’s see how these quantities behave in the sample:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb28-2" data-line-number="2">mu &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</a>
<a class="sourceLine" id="cb28-3" data-line-number="3">UB &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</a>
<a class="sourceLine" id="cb28-4" data-line-number="4">yB &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>UB </a>
<a class="sourceLine" id="cb28-5" data-line-number="5">YB &lt;-<span class="st"> </span><span class="kw">exp</span>(yB)</a>
<a class="sourceLine" id="cb28-6" data-line-number="6">Ds &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,N)</a>
<a class="sourceLine" id="cb28-7" data-line-number="7">Ds[YB<span class="op">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] &lt;-<span class="st"> </span><span class="dv">1</span> </a>
<a class="sourceLine" id="cb28-8" data-line-number="8">epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</a>
<a class="sourceLine" id="cb28-9" data-line-number="9">eta&lt;-<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="kw">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</a>
<a class="sourceLine" id="cb28-10" data-line-number="10">U0 &lt;-<span class="st"> </span>param[<span class="st">&quot;rho&quot;</span>]<span class="op">*</span>UB <span class="op">+</span><span class="st"> </span>epsilon</a>
<a class="sourceLine" id="cb28-11" data-line-number="11">y0 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st">  </span>U0 <span class="op">+</span><span class="st"> </span>param[<span class="st">&quot;delta&quot;</span>]</a>
<a class="sourceLine" id="cb28-12" data-line-number="12">alpha &lt;-<span class="st"> </span>param[<span class="st">&quot;baralpha&quot;</span>]<span class="op">+</span><span class="st">  </span>param[<span class="st">&quot;theta&quot;</span>]<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>eta</a>
<a class="sourceLine" id="cb28-13" data-line-number="13">y1 &lt;-<span class="st"> </span>y0<span class="op">+</span>alpha</a>
<a class="sourceLine" id="cb28-14" data-line-number="14">Y0 &lt;-<span class="st"> </span><span class="kw">exp</span>(y0)</a>
<a class="sourceLine" id="cb28-15" data-line-number="15">Y1 &lt;-<span class="st"> </span><span class="kw">exp</span>(y1)</a>
<a class="sourceLine" id="cb28-16" data-line-number="16">y &lt;-<span class="st"> </span>y1<span class="op">*</span>Ds<span class="op">+</span>y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a>
<a class="sourceLine" id="cb28-17" data-line-number="17">Y &lt;-<span class="st"> </span>Y1<span class="op">*</span>Ds<span class="op">+</span>Y0<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>Ds)</a></code></pre></div>
<p>In the sample, the value of <span class="math inline">\(BA\)</span> is <span class="math inline">\(\hat{\Delta^y_{BA}}=\)</span> 0.173 while the value of <span class="math inline">\(TT\)</span> in the sample is <span class="math inline">\(\Delta^y_{TT_s}=\)</span> 0.168.
We cannot perform a placebo test using two periods of pre-treatment outcomes for the treated since we have generated only one period of pre-treatment outcome.
We will be able to perform this test later in the DID lecture.
We can perfom the placebo test that applies the <span class="math inline">\(BA\)</span> estimator to the untreated.
The value of <span class="math inline">\(BA\)</span> for the untreated is <span class="math inline">\(\hat{\Delta^y_{BA|D=0}}=\)</span> 0.007, which is reasonably close to zero.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-the-two-fundamental-problems-of-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="FPSI.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/chabefer/STCI/blob/master/01_FPI.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["STCI.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 1
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
