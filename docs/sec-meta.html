<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 12 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference</title>
  <meta name="description" content="This is an open source collaborative book.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 12 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source collaborative book." />
  <meta name="github-repo" content="chabefer/STCI" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Meta-analysis and Publication Bias | Statistical Tools for Causal Inference" />
  
  <meta name="twitter:description" content="This is an open source collaborative book." />
  

<meta name="author" content="The SKY Community">


<meta name="date" content="2019-10-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="Distribution.html">
<link rel="next" href="Bounds.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







$$
\newcommand{\uns}[1]{\mathbf{1}[#1]}
\newcommand{\esp}[1]{\mathbf{E}[#1]}
\newcommand{\Ind}{\perp\kern-5pt\perp}
\newcommand{\var}[1]{\mathbf{V}[ #1 ]}
\newcommand{\cov}[1]{\mathbf{C}[ #1 ]}
\newcommand{\plim}[1]{\text{plim}_{ #1 \rightarrow \infty}}
\newcommand{\plims}{\text{plim}}
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\DeclareMathOperator{\diag}{diag}
$$


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Tools for Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Fundamental Problems of Inference</b></span></li>
<li class="chapter" data-level="" data-path="introduction-the-two-fundamental-problems-of-inference.html"><a href="introduction-the-two-fundamental-problems-of-inference.html"><i class="fa fa-check"></i>Introduction: the Two Fundamental Problems of Inference</a></li>
<li class="chapter" data-level="1" data-path="FPCI.html"><a href="FPCI.html"><i class="fa fa-check"></i><b>1</b> Fundamental Problem of Causal Inference</a><ul>
<li class="chapter" data-level="1.1" data-path="FPCI.html"><a href="FPCI.html#rubin-causal-model"><i class="fa fa-check"></i><b>1.1</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="1.1.1" data-path="FPCI.html"><a href="FPCI.html#treatment-allocation-rule"><i class="fa fa-check"></i><b>1.1.1</b> Treatment allocation rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="FPCI.html"><a href="FPCI.html#potential-outcomes"><i class="fa fa-check"></i><b>1.1.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="1.1.3" data-path="FPCI.html"><a href="FPCI.html#switching-equation"><i class="fa fa-check"></i><b>1.1.3</b> Switching equation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="FPCI.html"><a href="FPCI.html#treatment-effects"><i class="fa fa-check"></i><b>1.2</b> Treatment effects</a><ul>
<li class="chapter" data-level="1.2.1" data-path="FPCI.html"><a href="FPCI.html#individual-level-treatment-effects"><i class="fa fa-check"></i><b>1.2.1</b> Individual level treatment effects</a></li>
<li class="chapter" data-level="1.2.2" data-path="FPCI.html"><a href="FPCI.html#average-treatment-effect-on-the-treated"><i class="fa fa-check"></i><b>1.2.2</b> Average treatment effect on the treated</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="FPCI.html"><a href="FPCI.html#fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Fundamental problem of causal inference</a></li>
<li class="chapter" data-level="1.4" data-path="FPCI.html"><a href="FPCI.html#intuitive-estimators-confounding-factors-and-selection-bias"><i class="fa fa-check"></i><b>1.4</b> Intuitive estimators, confounding factors and selection bias</a><ul>
<li class="chapter" data-level="1.4.1" data-path="FPCI.html"><a href="FPCI.html#withwithout-comparison-selection-bias-and-cross-sectional-confounders"><i class="fa fa-check"></i><b>1.4.1</b> With/Without comparison, selection bias and cross-sectional confounders</a></li>
<li class="chapter" data-level="1.4.2" data-path="FPCI.html"><a href="FPCI.html#the-beforeafter-comparison-temporal-confounders-and-time-trend-bias"><i class="fa fa-check"></i><b>1.4.2</b> The before/after comparison, temporal confounders and time trend bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FPSI.html"><a href="FPSI.html"><i class="fa fa-check"></i><b>2</b> Fundamental Problem of Statistical Inference</a><ul>
<li class="chapter" data-level="2.1" data-path="FPSI.html"><a href="FPSI.html#sec:sampnoise"><i class="fa fa-check"></i><b>2.1</b> What is sampling noise? Definition and illustration</a><ul>
<li class="chapter" data-level="2.1.1" data-path="FPSI.html"><a href="FPSI.html#sec:definitionnoise"><i class="fa fa-check"></i><b>2.1.1</b> Sampling noise, a definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisepop"><i class="fa fa-check"></i><b>2.1.2</b> Sampling noise for the population treatment effect</a></li>
<li class="chapter" data-level="2.1.3" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisesamp"><i class="fa fa-check"></i><b>2.1.3</b> Sampling noise for the sample treatment effect</a></li>
<li class="chapter" data-level="2.1.4" data-path="FPSI.html"><a href="FPSI.html#sec:confinterv"><i class="fa fa-check"></i><b>2.1.4</b> Building confidence intervals from estimates of sampling noise</a></li>
<li class="chapter" data-level="2.1.5" data-path="FPSI.html"><a href="FPSI.html#reporting-sampling-noise-a-proposal"><i class="fa fa-check"></i><b>2.1.5</b> Reporting sampling noise: a proposal</a></li>
<li class="chapter" data-level="2.1.6" data-path="FPSI.html"><a href="FPSI.html#sec:effectsize"><i class="fa fa-check"></i><b>2.1.6</b> Using effect sizes to normalize the reporting of treatment effects and their precision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FPSI.html"><a href="FPSI.html#sec:estimsampnoise"><i class="fa fa-check"></i><b>2.2</b> Estimating sampling noise</a><ul>
<li class="chapter" data-level="2.2.1" data-path="FPSI.html"><a href="FPSI.html#sec:assumptions"><i class="fa fa-check"></i><b>2.2.1</b> Assumptions</a></li>
<li class="chapter" data-level="2.2.2" data-path="FPSI.html"><a href="FPSI.html#sec:cheb"><i class="fa fa-check"></i><b>2.2.2</b> Using Chebyshev’s inequality</a></li>
<li class="chapter" data-level="2.2.3" data-path="FPSI.html"><a href="FPSI.html#sec:CLT"><i class="fa fa-check"></i><b>2.2.3</b> Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.4" data-path="FPSI.html"><a href="FPSI.html#sec:resamp"><i class="fa fa-check"></i><b>2.2.4</b> Using resampling methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Methods of Causal Inference</b></span></li>
<li class="chapter" data-level="3" data-path="RCT.html"><a href="RCT.html"><i class="fa fa-check"></i><b>3</b> Randomized Controlled Trials</a><ul>
<li class="chapter" data-level="3.1" data-path="RCT.html"><a href="RCT.html#sec:design1"><i class="fa fa-check"></i><b>3.1</b> Brute Force Design</a><ul>
<li class="chapter" data-level="3.1.1" data-path="RCT.html"><a href="RCT.html#identification"><i class="fa fa-check"></i><b>3.1.1</b> Identification</a></li>
<li class="chapter" data-level="3.1.2" data-path="RCT.html"><a href="RCT.html#estimating-ate"><i class="fa fa-check"></i><b>3.1.2</b> Estimating ATE</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="RCT.html"><a href="RCT.html#sec:design2"><i class="fa fa-check"></i><b>3.2</b> Randomization After Self-Selection</a><ul>
<li class="chapter" data-level="3.2.1" data-path="RCT.html"><a href="RCT.html#identification-1"><i class="fa fa-check"></i><b>3.2.1</b> Identification</a></li>
<li class="chapter" data-level="3.2.2" data-path="RCT.html"><a href="RCT.html#estimating-tt"><i class="fa fa-check"></i><b>3.2.2</b> Estimating TT</a></li>
<li class="chapter" data-level="3.2.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="RCT.html"><a href="RCT.html#sec:design3"><i class="fa fa-check"></i><b>3.3</b> Randomization After Eligibility</a><ul>
<li class="chapter" data-level="3.3.1" data-path="RCT.html"><a href="RCT.html#identification-2"><i class="fa fa-check"></i><b>3.3.1</b> Identification</a></li>
<li class="chapter" data-level="3.3.2" data-path="RCT.html"><a href="RCT.html#estimating-the-ite-and-the-tt"><i class="fa fa-check"></i><b>3.3.2</b> Estimating the ITE and the TT</a></li>
<li class="chapter" data-level="3.3.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-2"><i class="fa fa-check"></i><b>3.3.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="RCT.html"><a href="RCT.html#sec:design4"><i class="fa fa-check"></i><b>3.4</b> Encouragement Design</a><ul>
<li class="chapter" data-level="3.4.1" data-path="RCT.html"><a href="RCT.html#identification-3"><i class="fa fa-check"></i><b>3.4.1</b> Identification</a></li>
<li class="chapter" data-level="3.4.2" data-path="RCT.html"><a href="RCT.html#estimating-the-local-average-treatment-effect-and-the-intention-to-treat-effect"><i class="fa fa-check"></i><b>3.4.2</b> Estimating the Local Average Treatment Effect and the Intention to Treat Effect</a></li>
<li class="chapter" data-level="3.4.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-3"><i class="fa fa-check"></i><b>3.4.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="RCT.html"><a href="RCT.html#sec:threats"><i class="fa fa-check"></i><b>3.5</b> Threats to the validity of RCTs</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="NE.html"><a href="NE.html"><i class="fa fa-check"></i><b>4</b> Natural Experiments</a></li>
<li class="chapter" data-level="5" data-path="sec-OM.html"><a href="sec-OM.html"><i class="fa fa-check"></i><b>5</b> Observational Methods</a></li>
<li class="part"><span><b>III Additional Topics</b></span></li>
<li class="chapter" data-level="6" data-path="Power.html"><a href="Power.html"><i class="fa fa-check"></i><b>6</b> Power Analysis</a></li>
<li class="chapter" data-level="7" data-path="Placebo.html"><a href="Placebo.html"><i class="fa fa-check"></i><b>7</b> Placebo Tests</a></li>
<li class="chapter" data-level="8" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>8</b> Clustering</a></li>
<li class="chapter" data-level="9" data-path="LaLonde.html"><a href="LaLonde.html"><i class="fa fa-check"></i><b>9</b> LaLonde Tests</a></li>
<li class="chapter" data-level="10" data-path="Diffusion.html"><a href="Diffusion.html"><i class="fa fa-check"></i><b>10</b> Diffusion effects</a></li>
<li class="chapter" data-level="11" data-path="Distribution.html"><a href="Distribution.html"><i class="fa fa-check"></i><b>11</b> Distributional effects</a></li>
<li class="chapter" data-level="12" data-path="sec-meta.html"><a href="sec-meta.html"><i class="fa fa-check"></i><b>12</b> Meta-analysis and Publication Bias</a><ul>
<li class="chapter" data-level="12.1" data-path="sec-meta.html"><a href="sec-meta.html#meta-analysis"><i class="fa fa-check"></i><b>12.1</b> Meta-analysis</a><ul>
<li class="chapter" data-level="12.1.1" data-path="sec-meta.html"><a href="sec-meta.html#basic-setting"><i class="fa fa-check"></i><b>12.1.1</b> Basic setting</a></li>
<li class="chapter" data-level="12.1.2" data-path="sec-meta.html"><a href="sec-meta.html#meta-analysis-as-a-weighted-average"><i class="fa fa-check"></i><b>12.1.2</b> Meta-analysis as a weighted average</a></li>
<li class="chapter" data-level="12.1.3" data-path="sec-meta.html"><a href="sec-meta.html#constantly-updated-meta-analysis"><i class="fa fa-check"></i><b>12.1.3</b> Constantly updated meta-analysis</a></li>
<li class="chapter" data-level="12.1.4" data-path="sec-meta.html"><a href="sec-meta.html#testing-for-the-homogeneity-of-treatment-effects"><i class="fa fa-check"></i><b>12.1.4</b> Testing for the homogeneity of treatment effects</a></li>
<li class="chapter" data-level="12.1.5" data-path="sec-meta.html"><a href="sec-meta.html#meta-analysis-when-treatment-effects-are-heterogeneous"><i class="fa fa-check"></i><b>12.1.5</b> Meta-analysis when treatment effects are heterogeneous</a></li>
<li class="chapter" data-level="12.1.6" data-path="sec-meta.html"><a href="sec-meta.html#meta-regression"><i class="fa fa-check"></i><b>12.1.6</b> Meta-regression</a></li>
<li class="chapter" data-level="12.1.7" data-path="sec-meta.html"><a href="sec-meta.html#why-vote-counting-does-not-work"><i class="fa fa-check"></i><b>12.1.7</b> Why vote-counting does not work</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="sec-meta.html"><a href="sec-meta.html#publication-bias"><i class="fa fa-check"></i><b>12.2</b> Publication bias</a><ul>
<li class="chapter" data-level="12.2.1" data-path="sec-meta.html"><a href="sec-meta.html#sources-of-publication-bias"><i class="fa fa-check"></i><b>12.2.1</b> Sources of publication bias</a></li>
<li class="chapter" data-level="12.2.2" data-path="sec-meta.html"><a href="sec-meta.html#detecting-and-correcting-for-publication-bias"><i class="fa fa-check"></i><b>12.2.2</b> Detecting and correcting for publication bias</a></li>
<li class="chapter" data-level="12.2.3" data-path="sec-meta.html"><a href="sec-meta.html#vote-counting-and-publication-bias"><i class="fa fa-check"></i><b>12.2.3</b> Vote counting and publication bias</a></li>
<li class="chapter" data-level="12.2.4" data-path="sec-meta.html"><a href="sec-meta.html#the-value-of-a-statistically-significant-result"><i class="fa fa-check"></i><b>12.2.4</b> The value of a statistically significant result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Bounds.html"><a href="Bounds.html"><i class="fa fa-check"></i><b>13</b> Bounds</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="proofs.html"><a href="proofs.html"><i class="fa fa-check"></i><b>A</b> Proofs</a><ul>
<li class="chapter" data-level="A.1" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-reffpsi"><i class="fa fa-check"></i><b>A.1</b> Proofs of results in Chapter @ref(FPSI)</a><ul>
<li class="chapter" data-level="A.1.1" data-path="proofs.html"><a href="proofs.html#proofcheb"><i class="fa fa-check"></i><b>A.1.1</b> Proof of Theorem @ref(thm:uppsampnoise)</a></li>
<li class="chapter" data-level="A.1.2" data-path="proofs.html"><a href="proofs.html#proofCLT"><i class="fa fa-check"></i><b>A.1.2</b> Proof of Theorem @ref(thm:asympnoiseWW)</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refrct"><i class="fa fa-check"></i><b>A.2</b> Proofs of results in Chapter @ref(RCT)</a><ul>
<li class="chapter" data-level="A.2.1" data-path="proofs.html"><a href="proofs.html#proofIdentLATE"><i class="fa fa-check"></i><b>A.2.1</b> Proof of Theorem @ref(thm:IdentLATE)</a></li>
<li class="chapter" data-level="A.2.2" data-path="proofs.html"><a href="proofs.html#proofWaldIV"><i class="fa fa-check"></i><b>A.2.2</b> Proof of Lemma @ref(lem:WaldIV)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Tools for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec:meta" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Meta-analysis and Publication Bias</h1>
<p>When several research teams work on a similar topic, they obtain and publish several estimates for the same program of for similar programs. For example, teams of doctors regularly test the same treatment on different samples or populations in order to refine the estimated effect. Similarly, economists report on the effects of similar types of programs (Conditional and Unconditional Cash Transfers, Job Training Programs, microcredit, etc) implemented in different countries.</p>
<p>Meta-analysis aims at summarizing and synthetizing the available evidence with two main goals in mind:</p>
<ol style="list-style-type: decimal">
<li>Increasing precision by providing an average estimated effect combining several estimates</li>
<li>Explaining variations in treatment effectiveness by relating changes in effect size to changes in sample characteristics.</li>
</ol>
<p>One key issue that meta-analysis has to face – actually, we all have to face it, meta-analysis simply makes it more apparent – is that of publication bias. Publication bias is due to the fact that referees and editors have a marked preference for publishing statistically significant results. The problem with this approach is that the distribution of published results is going to be censored on the left: we will have more statistically significant results in the published record, and as a consequence, the average published result will be an upward biased estimate of the true treatment effect in the population. This is potentially a very severe problem if the amount of censoring due to publication bias is large. Eventually, this hinges on the true distribution of treatment effects: if it is centered on zero or close to zero, we run the risk of having very large publication bias.</p>
<p>In this chapter, I present first the tools for meta-analysis, and I then move on to testing and correcting for publication bias.</p>
<div id="meta-analysis" class="section level2">
<h2><span class="header-section-number">12.1</span> Meta-analysis</h2>
<p>There are several approaches and refinements to meta-analysis. In this section, I am going to present only the most important ones. I’ll defer the reader to other more specialized publications if needed.</p>
<p>I first present the basics of meta-analysis: the constitution and structure of the sample. Second, I present the simplest method to aggregate effects: the weighted average. Third, I present tests for deciding whether the effects are from a homogeneous or a heterogeneous population. Fourth, I explain how to conduct a meta-analysis when effects are heterogeneous. Fifth, I cover the meta-regression that we use to account for heterogeneity in treatment effects. Finally, I explain why usual intuitive methods such as vote-counting are biased.</p>
<div id="basic-setting" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Basic setting</h3>
<p>The basic setting for a meta-analysis is that you have access to a list of estimates for the effect of a given program and for their precision. These estimates come from the literature, searching published and unpublished sources alike. This data is usually collected after an extensive search of bibliographic databases. Then, one has to select among all the studies selected by the search the ones that are actualy relevant. This is the most excruciating part of a meta-analysis, since a lot of the studies selected by hte search algorithm are actually irrelevant. Finally, one has to extract from each relevant paper an estimate of the effect of the treatment and of its precision. In general, one tries to choose standardized estimates such as the effect size (see Section <a href="FPSI.html#sec:effectsize">2.1.6</a> for a definition) and its standard error. After all this process, we should end up with a dataset like: <span class="math inline">\(\left\{(\hat{\theta}_k,\hat{\sigma}_k)\right\}_{k=1}^N\)</span>, with <span class="math inline">\(\hat{\theta}_k\)</span> the estimated effect size, <span class="math inline">\(\hat{\sigma}_k\)</span> its estimated standard error, and <span class="math inline">\(N\)</span> the number of included studies.</p>

<div class="example">
<span id="exm:unnamed-chunk-122" class="example"><strong>Example 12.1  </strong></span>Let’s see how such a dataset would look like? Let’s build one from our simulations.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N.sample &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>,<span class="dv">10000</span>,<span class="dv">100000</span>)
N.plot.ES.CLT &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">7</span>,<span class="dv">2</span>,<span class="dv">1</span>)
data.meta &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">ES=</span><span class="kw">numeric</span>(),
                          <span class="dt">se=</span><span class="kw">numeric</span>())

se.ww.CLT.ES &lt;-<span class="st"> </span><span class="cf">function</span>(N,v1,v0,p){
  <span class="kw">return</span>(<span class="kw">sqrt</span>((v1<span class="op">/</span>p<span class="op">+</span>v0<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p))<span class="op">/</span>N)<span class="op">/</span>v0)
}

<span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(N.sample)){
  <span class="kw">set.seed</span>(<span class="dv">1234</span>)
  simuls.ww[[k]]<span class="op">$</span>se.ES &lt;-<span class="st"> </span><span class="kw">se.ww.CLT.ES</span>(N.sample[[k]],simuls.ww[[k]][,<span class="st">&#39;V1&#39;</span>],simuls.ww[[k]][,<span class="st">&#39;V0&#39;</span>],simuls.ww[[k]][,<span class="st">&#39;p&#39;</span>])
  test.ES &lt;-<span class="st"> </span>simuls.ww[[k]][<span class="kw">sample</span>(N.plot.ES.CLT[[k]]),<span class="kw">c</span>(<span class="st">&#39;ES&#39;</span>,<span class="st">&#39;se.ES&#39;</span>)]
  test.ES<span class="op">$</span>N &lt;-<span class="st"> </span><span class="kw">rep</span>(N.sample[[k]],N.plot.ES.CLT[[k]])
  data.meta &lt;-<span class="st"> </span><span class="kw">rbind</span>(data.meta,test.ES)
  }

data.meta<span class="op">$</span>id &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data.meta)
<span class="co">#data.meta$N &lt;- factor(data.meta$N,levels(N.sample))</span>

  <span class="kw">ggplot</span>(data.meta, <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(id), <span class="dt">y=</span>ES)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>ES<span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES, <span class="dt">ymax=</span>ES<span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:confintervalESCLT"></span>
<img src="STCI_files/figure-html/confintervalESCLT-1.png" alt="Example data set: effect sizes and confidence intervals with $\delta=$ 0.95" width="60%" />
<p class="caption">
Figure 12.1: Example data set: effect sizes and confidence intervals with <span class="math inline">\(\delta=\)</span> 0.95
</p>
</div>
<p>Figure <a href="sec-meta.html#fig:confintervalESCLT">12.1</a> shows the resulting sample. I’ve selected 10 studies with <span class="math inline">\(N=\)</span> 100, 7 studies with <span class="math inline">\(N=\)</span> 1000, 2 studies with <span class="math inline">\(N=\)</span> 10^{4}, and 1 study with <span class="math inline">\(N=\)</span> 10^{5}. The studies are represented in that order, mimicking the increasing sample size of studies that accumulate evidence on a treatment, probably with studies with a small sample size at first, and only large studies at the end for the most promising treatments.</p>
</div>
<div id="meta-analysis-as-a-weighted-average" class="section level3">
<h3><span class="header-section-number">12.1.2</span> Meta-analysis as a weighted average</h3>
<p>The key idea of meta-analysis is to combine the effect size estimates stemming from different studies, weighing them by their relative precision.</p>

<div class="definition">
<span id="def:metaweights" class="definition"><strong>Definition 12.1  (Weighted Meta-Analytic Estimator)  </strong></span>The weighted meta-analytic estimator is <span class="math display">\[
\bar{\theta} = \sum_{k=1}^Nw_k\hat{\theta}_k \text{ with } w_k=\frac{\frac{1}{\hat{\sigma}^2_k}}{\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k}}.
\]</span>
</div>

<p>Under some assumptions, the estimator <span class="math inline">\(\bar{\theta}\)</span> converges to the true effect of the treatment. Let’s delineate these assumptions.</p>

<div class="definition">
<span id="def:metahomo" class="definition"><strong>Definition 12.2  (Homogeneous Treatment Effect)  </strong></span>Each <span class="math inline">\(\hat{\theta}_k\)</span> converges to the same treatment effect <span class="math inline">\(\theta\)</span>.
</div>

<p>Assumption <a href="sec-meta.html#def:metahomo">12.2</a> imposes that all the studies have been drawn from the same population, where the treatment effect is a constant.</p>

<div class="definition">
<span id="def:metaind" class="definition"><strong>Definition 12.3  (Independence of Estimates)  </strong></span>The <span class="math inline">\(\hat{\theta}_k\)</span> are independent from each other.
</div>

<p>Assumption <a href="sec-meta.html#def:metaind">12.3</a> imposes that all the studies estimates are independent from each other. That means that they do not share sampling units and that they are not affected by common shocks.</p>
<p>Under these assumptions, we can show two important results.</p>

<div class="theorem">
<span id="thm:metafixedcons" class="theorem"><strong>Theorem 12.1  (Consistency of the Weighted Meta-Analytic Estimator)  </strong></span>Under Assumptions <a href="sec-meta.html#def:metahomo">12.2</a> and <a href="sec-meta.html#def:metaind">12.3</a>, when the sample size of each study goes to infinity, <span class="math inline">\(\bar{\theta}\approx\theta\)</span>.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> The Law of Large Number applied to each sample gives the fact that the estimator is a weighted sum of <span class="math inline">\(\theta\)</span> with weights summing to one. Hence the result.
</div>

<p>Theorem <a href="sec-meta.html#thm:metafixedcons">12.1</a> says that the error we are making around the true effect of the treatment goes to zero as the sample size in each study decrease. This is great: aggregating the studies is thus going to get us to the truth.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> One interesting question is whether Theorem <a href="sec-meta.html#thm:metafixedcons">12.1</a> also holds when the size of the individual studies remains fixed and the number of studies goes to infinity, which seems a more natural way to do asymptotics in a meta-analysis. I’m pretty sure that is the case. Indeed, the studies constitute an enormous sample in which we take the average outcomes of the treated on the one hand and of the untreated on the other. These averages differ from the usual ones in the Law of Large Numbers only by the fact that the weights are not equal to one. But they (i) are independent from the outcomes and (ii) sum to one. As a consequence, I’m pretty sure the Law of Large Numbers also apply in this dimension.
</div>

<p><strong><span style="font-variant: small-caps;">Check if this is a consequence of Kolmogorov’s Law of Large Numbers.</span></strong></p>

<div class="theorem">
<span id="thm:metafixeddis" class="theorem"><strong>Theorem 12.2  (Asymptotic Distribution of the Weighted Meta-Analytic Estimator)  </strong></span>Under Assumptions <a href="sec-meta.html#def:metahomo">12.2</a> and <a href="sec-meta.html#def:metaind">12.3</a>, when the sample size of each study goes to infinity, <span class="math inline">\(\bar{\theta}\stackrel{d}{\rightarrow}\mathcal{N}(\theta,\sigma^2)\)</span>, with <span class="math display">\[
\sigma^2 = \frac{1}{\sum_{k=1}^N\frac{1}{\sigma^2_k}}.
\]</span>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> <strong><span style="font-variant: small-caps;">To do using the Lindenberg-Levy version of the Central Limit Theorem.</span></strong>
</div>

<p>Theorem <a href="sec-meta.html#thm:metafixeddis">12.2</a> shows that the distribution of the weighted meta-analytic estimator converges to a normal, which is very convenient in order to compute sampling noise. In order to obtain an estimator <span class="math inline">\(\hat{\sigma}^2\)</span> of the variance of the meta-analytic estimator, we can simply replace the individual variance terms by their estimates: <span class="math inline">\(\hat{\sigma}_k^2\)</span>.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> I’ve taken Theorem <a href="sec-meta.html#thm:metafixeddis">12.2</a> from Hedges and Olkin, but I think it is much more interesting and correct when the asymptotics goes in the number of studies.
</div>


<div class="remark">
 <span class="remark"><em>Remark. </em></span> According to Hedges and Olkin, the weighted meta-analytic estimator is the most efficient estimator available.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wmae &lt;-<span class="st"> </span><span class="cf">function</span>(theta,sigma2){
  <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">weighted.mean</span>(theta,(<span class="dv">1</span><span class="op">/</span>sigma2)<span class="op">/</span>(<span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>sigma2))),<span class="dv">1</span><span class="op">/</span><span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>sigma2)))
}</code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-128" class="example"><strong>Example 12.2  </strong></span>Let’s use our meta-analytic estimator to estimate the effect size of our treatment.
</div>
<p> The estimated treatment effect size with our sample is 0.19 <span class="math inline">\(\pm\)</span> 0.02. A very simple way to implement such an estimator in R is to use the <code>rma</code> command of the <code>metafor</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data.meta<span class="op">$</span>var.ES &lt;-<span class="st"> </span>data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>
meta.example.FE &lt;-<span class="st"> </span><span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>ES,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span><span class="st">&quot;FE&quot;</span>)
<span class="kw">summary</span>(meta.example.FE)</code></pre></div>
<pre><code>## 
## Fixed-Effects Model (k = 20)
## 
##   logLik  deviance       AIC       BIC      AICc  
##  16.1375   12.7060  -30.2751  -29.2793  -30.0529  
## 
## Test for Heterogeneity: 
## Q(df = 19) = 12.7060, p-val = 0.8533
## 
## Model Results:
## 
## estimate      se     zval    pval   ci.lb   ci.ub     
##   0.1950  0.0079  24.6975  &lt;.0001  0.1795  0.2104  ***
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As seen above, the <code>metafor</code> package yields a meta-analytic estimate of 0.19 <span class="math inline">\(\pm\)</span> 0.02, as we have found using the weighted meta-analytic estimator.</p>
<p>It is customary to present the results of a meta-analysis using a forest plot. A forest plows all the individual estimates along with the aggregated estimate. Figure <a href="sec-meta.html#fig:FEforestplot">12.2</a> presents the forest plot for our example using the very convenient <code>forest</code> function in the <code>metafor</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">forest</span>(meta.example.FE,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:FEforestplot"></span>
<img src="STCI_files/figure-html/FEforestplot-1.png" alt="Example data set: forest plot" width="60%" />
<p class="caption">
Figure 12.2: Example data set: forest plot
</p>
</div>
</div>
<div id="constantly-updated-meta-analysis" class="section level3">
<h3><span class="header-section-number">12.1.3</span> Constantly updated meta-analysis</h3>
<p>Constantly updated meta-analysis performs the meta-analysis in a progressive manner, as the results keep arriving. This is a very important tool that enables us to aggregate constantly the information coming from different studies. Moreover, restrospectively, it helps us to assess when we would have reached enough precision so that we could have foregone an additional study. The way constantly updated meta-analysis works is simply by performing a new meta-analysis each time a new results pops up.</p>

<div class="example">
<span id="exm:unnamed-chunk-129" class="example"><strong>Example 12.3  </strong></span>Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a> shows how constantly updated meta-analysis works in our example.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cum.wmae.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="cf">function</span>(k,theta,sigma2){
  <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">weighted.mean</span>(theta[<span class="dv">1</span><span class="op">:</span>k],(<span class="dv">1</span><span class="op">/</span>sigma2[<span class="dv">1</span><span class="op">:</span>k])<span class="op">/</span>(<span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>sigma2[<span class="dv">1</span><span class="op">:</span>k]))),<span class="dv">1</span><span class="op">/</span><span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>sigma2[<span class="dv">1</span><span class="op">:</span>k])))
}

cum.wmae &lt;-<span class="st"> </span><span class="cf">function</span>(theta,sigma2){
  <span class="kw">return</span>(<span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(theta),cum.wmae.<span class="dv">1</span>,<span class="dt">theta=</span>theta,<span class="dt">sigma2=</span>sigma2))
}

cum.test &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(<span class="kw">cum.wmae</span>(data.meta<span class="op">$</span>ES,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>)))
<span class="kw">colnames</span>(cum.test) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;cum.ES&#39;</span>,<span class="st">&#39;cum.var&#39;</span>)
cum.test<span class="op">$</span>id &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(cum.test)
cum.test<span class="op">$</span>cum.se.ES &lt;-<span class="st"> </span><span class="kw">sqrt</span>(cum.test<span class="op">$</span>cum.var)

  <span class="kw">ggplot</span>(data.meta, <span class="kw">aes</span>(<span class="dt">x=</span>forcats<span class="op">::</span><span class="kw">fct_rev</span>(<span class="kw">as.factor</span>(id)), <span class="dt">y=</span>ES)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>ES<span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES, <span class="dt">ymax=</span>ES<span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Initial effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()<span class="op">+</span>
<span class="st">      </span><span class="kw">coord_flip</span>()

  <span class="kw">ggplot</span>(cum.test, <span class="kw">aes</span>(<span class="dt">x=</span>forcats<span class="op">::</span><span class="kw">fct_rev</span>(<span class="kw">as.factor</span>(id)), <span class="dt">y=</span>cum.ES)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>cum.ES<span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>cum.se.ES, <span class="dt">ymax=</span>cum.ES<span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>cum.se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="st">&quot;Studies&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Cumulative effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()<span class="op">+</span>
<span class="st">      </span><span class="kw">coord_flip</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cumWMAE"></span>
<img src="STCI_files/figure-html/cumWMAE-1.png" alt="Constantly updated meta-analysis" width="50%" /><img src="STCI_files/figure-html/cumWMAE-2.png" alt="Constantly updated meta-analysis" width="50%" />
<p class="caption">
Figure 12.3: Constantly updated meta-analysis
</p>
</div>
<p>Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a> shows that combining several imprecise estimates might help you reach the same precision as running a larger experiment.<br />
For instance, cumulating the first 10 studies with a small sample size (<span class="math inline">\(N=\)</span> 100), the meta-analytic effect is estimated at 0.2 <span class="math inline">\(\pm\)</span> 0.18. This is very close to the individual estimate obtained from the first estimate with a larger sample size (sample 11 on Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a>, with <span class="math inline">\(N=\)</span> 1000): 0.17 <span class="math inline">\(\pm\)</span> 0.18. Both estimates actually have the exact same precision (because they actually have the same sample size). The same is true when combining the first 17 studies. The meta-analytic effect is estimated at 0.24 <span class="math inline">\(\pm\)</span> 0.06, while the effect estimated using one unique RCT with a larger sample size (sample 18 on Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a>, with <span class="math inline">\(N=\)</span> 10^{4}) is 0.21 <span class="math inline">\(\pm\)</span> 0.05. Finally, the same result occurs when combining the first 19 studies. The meta-analytic effect is estimated at 0.21 <span class="math inline">\(\pm\)</span> 0.03, while the effect estimated using one unique RCT with a larger sample size (sample 20 on Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a>, with <span class="math inline">\(N=\)</span> 10^{5}) is 0.19 <span class="math inline">\(\pm\)</span> 0.02.</p>
<p>As a conclusion, constantly updated meta-analysis would have each time delivered the same result than the one found with a much larger study, rendering this additional study almost irrelevant. This is a very important result: beyond the apparent messiness of the first noisy estimates in Figures <a href="sec-meta.html#fig:confintervalESCLT">12.1</a> and <a href="sec-meta.html#fig:FEforestplot">12.2</a> lies an order that can be retrieved and made apparent using constantly updated meta-analysis. Sometimes, the answer is right there in front of our eyes, we just lack the ability to see it. Constantly updated meta-analysis serves as a binocular to magnify what is there. Think about how costly it woud be to run a very large study, just to find out that the we did not really need it because we had known the result all along.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Something pretty cool is that I can reproduce Figure <a href="sec-meta.html#fig:cumWMAE">12.3</a> using the <code>metafor</code> package with much less lines of code.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">forest</span>(meta.example.FE,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)
cumul.meta.example.FE &lt;-<span class="st"> </span><span class="kw">cumul</span>(meta.example.FE, <span class="dt">order=</span>data.meta<span class="op">$</span>id)
<span class="kw">forest</span>(cumul.meta.example.FE,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="st">&#39;Estimated Meta-analytic Cumulated Parameter&#39;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cumWMAEmetafor"></span>
<img src="STCI_files/figure-html/cumWMAEmetafor-1.png" alt="Constantly updated meta-analysis with the `metafor` package" width="50%" /><img src="STCI_files/figure-html/cumWMAEmetafor-2.png" alt="Constantly updated meta-analysis with the `metafor` package" width="50%" />
<p class="caption">
Figure 12.4: Constantly updated meta-analysis with the <code>metafor</code> package
</p>
</div>
<p>You can also call each of the individual results of the cumulative meta-analysis using <code>cumul.meta.example.FE$estimate</code>. For example, the cumulated effect size after the 10 first studies is equal to 0.2 <span class="math inline">\(\pm\)</span> 0.18.</p>
</div>
<div id="testing-for-the-homogeneity-of-treatment-effects" class="section level3">
<h3><span class="header-section-number">12.1.4</span> Testing for the homogeneity of treatment effects</h3>
<p>One key assumption that we have just made so far is that of homogeneous treatment effect. We have worked under the assumption that each study was drawn from the same population, where the treatment effect is a constant. Why would the treatment effects differ in each study?</p>
<ol style="list-style-type: decimal">
<li>We do not study exactly the same treatment, but a family of similar treatments. Each individual study covers a particular iteration of the treatment, each with its idiosyncratic parameterization. The particular value of the transfer in a Cash Transfer program, or of the conditions to receive it, or the length of payment, whether it is in one time or over some period, might make a difference, for example. The same is true for Job Training Programs, Payments for Environmental Services, microcredit, graduation programs, nudges, etc. Actually, most programs that economists study differ from one implementation to the next. In psychology and medecine, most treatments are accompanied by a rigorous protocol that makes them much more homogeneous.</li>
<li>The population on which the treatment is applied varies. For example, similar Job Training Programs or microcredit initiatives might have very different outcomes depending on the business cycle. Education interventions might have very different effects depending on the background of the students on which they are tested. A drug might interact with patients’ phenotype and genotype to generate different effects, and the populations from which the experimental samples are drawn do not have to be similar. As an extreme example, think of a vaccine tested in a population where the prevalence of a disease is null. The treatment effect is zero. Now, test the vaccine in a population where the disease is endemic: the treatment effect might be huge.</li>
</ol>
<p>We can also think that the treatment effect differs in each sample because the composition of the sample changes. But this is normal variation due to sampling noise and is to be expected. It is not the same thing as assuming that the population effect differs.</p>
<p>What can we do in order to test whether there is heterogeneity in treatment effects? One way is to build an index comparing the usual variation in treatment effects stemming from sampling noise to the one stemming from variation between studies. If we find that the variation between studies dwarves the variation due to sampling noise in each study, then there is some heterogeneity for sure. One statistics that does that is the <span class="math inline">\(Q\)</span> statistic where the variation in treatment effects between studies is estimated using the difference between the individual effect size and the average one squared:</p>
<span class="math display">\[\begin{align*}
  Q &amp; = \sum_{k=1}^N\frac{(\hat{\theta}_k-\bar{\theta})^2}{\hat{\sigma}^2_k}.
\end{align*}\]</span>
<p>What is great with the <span class="math inline">\(Q\)</span> statistic is that, under the Null hypothesis that all the treatment effects are equal to the same constant, it is distributed asymptotically as a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(N-1\)</span> degrees of freedom, and thus it can directly be used to test for the hypothesis of homogeneous treatment effects.</p>

<div class="example">
<span id="exm:unnamed-chunk-131" class="example"><strong>Example 12.4  </strong></span>In our example, we have already computed the <span class="math inline">\(Q\)</span> statistic when we have used the <code>rma</code> function in the <code>metafor</code> package. In order to access it, we just need to extract it using <code>meta.example.FE$QE</code> for the <span class="math inline">\(Q\)</span> statistic and <code>meta.example.FE$QEp</code> for its p-value.
</div>
<p> The <span class="math inline">\(Q\)</span> statistic in our example has value 12.71, with associated p-value 0.85. We end up not rejecting homogeneity, which is correct.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The problem with using test statistics for testing for treatment effect homogeneity is that, when precision increases, we might end up rejecting homogeneity despite the fact that it is there.
</div>

<p><strong><span style="font-variant: small-caps;">Test with <span class="math inline">\(N=10^5\)</span>.</span></strong></p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(k\)</span> degrees of freedom is asymptotically distributed as a normal with mean <span class="math inline">\(k\)</span> and variance <span class="math inline">\(2k\)</span>. So, when <span class="math inline">\(k\)</span> is large, a good rule of thumb for assessing the homogeneity of the treatment effect estimates is to compare the <span class="math inline">\(Q\)</span> statistic to the number of studies. If it is much larger, homogeneity is probably not guaranteed.
</div>

</div>
<div id="meta-analysis-when-treatment-effects-are-heterogeneous" class="section level3">
<h3><span class="header-section-number">12.1.5</span> Meta-analysis when treatment effects are heterogeneous</h3>
<p>When each study draws a treatment effect from a distinct population, meta-analysis has to take into account that treatment effects are heterogeneous. The main consequence of treatment effect heterogeneity is that the weighting approach we have used so far underestimates the uncertainty around the true effect, since it does not acknowledge that there is additional variation within each study.</p>
<p>There are two main ways to account for heterogeneity in meta-analysis:</p>
<ol style="list-style-type: decimal">
<li><strong>Meta-regression</strong> trying to capture the heterogeneity in treatment effects with observed covariates.</li>
<li><strong>Random effects</strong> allowing for additional random noise in each study.</li>
</ol>
<p>In this section, we are going to study the random effects approach, and we’ll defer the meta-regression for the next section.</p>
<div id="estimating-the-variance-of-the-treatment-effect-across-sites" class="section level4">
<h4><span class="header-section-number">12.1.5.1</span> Estimating the variance of the treatment effect across sites</h4>
<p>The key component of the random effects approach is the estimation of the size of the variance of the treatment effect in the population. Indeed, the observed effect size estimate for a given study <span class="math inline">\(k\)</span> is modelled as follows in the random effects approach:</p>
<span class="math display">\[\begin{align*}
\hat{\theta}_k &amp; = \alpha + \epsilon_k + \nu_k,
\end{align*}\]</span>
<p>where <span class="math inline">\(\epsilon_k\)</span> is due to sampling noise and <span class="math inline">\(\nu_k\)</span> is due to the heterogeneity in effect sizes across sites, while <span class="math inline">\(\alpha\)</span> is the average of the effect size accross all populations. We denote the variance of <span class="math inline">\(\nu_k\)</span> as <span class="math inline">\(\tau^2\)</span>.</p>
<p>Since Hedges, <span class="math inline">\(\tau^2\)</span> is estimated as the residual variance in effect sizes that is not explained by sampling noise. In order to compute this estimator, first estimate the overall variance in <span class="math inline">\(\hat{\theta}_k\)</span>, then estimate the component of the variance due to sampling noise and finally take the difference between the two. Hedges’ estimator of the overall variance in effect sizes is:</p>
<span class="math display">\[\begin{align*}
\hat{\tau}^2 &amp; = \hat{\sigma}^2_{tot}-\hat{\sigma}^2_{\epsilon},
\end{align*}\]</span>
<p>with</p>
<span class="math display">\[\begin{align*}
\hat{\sigma^2_{tot}} &amp; = \frac{1}{N}\sum_{k=1}^N(\hat{\theta}_k-\bar{\theta}_u)^2\\
\bar{\theta}_u &amp; = \frac{1}{N}\sum_{k=1}^N\hat{\theta}_k \\
\hat{\sigma^2_{\epsilon}} &amp; = \frac{1}{N}\sum_{k=1}^N\hat{\sigma}_k^2.
\end{align*}\]</span>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Hedges actually uses the unbiased estimator adapted to small samples and thus replaces <span class="math inline">\(N\)</span> by <span class="math inline">\(N-1\)</span> in the first equation.
</div>


<div class="example">
<span id="exm:unnamed-chunk-135" class="example"><strong>Example 12.5  </strong></span>Let’s compute Hedges’ esimator for <span class="math inline">\(\tau^2\)</span> in our numerical example.
</div>

<p>Let’s first define a few functions to compute each part:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="cf">function</span>(theta,vartheta){
  <span class="kw">return</span>(<span class="kw">var</span>(theta)<span class="op">-</span><span class="kw">mean</span>(vartheta))
}
tau.<span class="fl">2.</span>theta &lt;-<span class="st"> </span><span class="kw">tau.2</span>(data.meta<span class="op">$</span>ES,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>)</code></pre></div>
<p>Our estimate of <span class="math inline">\(\tau^2\)</span> in our example is thus -0.03. This estimate is small, suggesting that there is no additional variance in the treatment effects on top of sammling variation, as we know is the case and has already been suggested by the results of the <span class="math inline">\(Q\)</span> statistic. Let’s now create a new sample of effect sizes where we add noise to each estimate stemming not from sampling, but from heterogeneity in treatment effects across sites and studies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
data.meta<span class="op">$</span>theta.<span class="dv">1</span> &lt;-<span class="st"> </span>data.meta<span class="op">$</span>ES <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(data.meta),<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span>tau[[<span class="dv">1</span>]])
data.meta<span class="op">$</span>theta.<span class="dv">2</span> &lt;-<span class="st"> </span>data.meta<span class="op">$</span>ES <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(data.meta),<span class="dt">mean=</span><span class="dv">0</span>,<span class="dt">sd=</span>tau[[<span class="dv">2</span>]])</code></pre></div>
<p>I’ve simulated two new vectors of estimates for <span class="math inline">\(\theta\)</span>, both obtained adding a mean-zero normally distributed noise to the initial estimates of <span class="math inline">\(\theta\)</span>, one with a standard deviation of 0.5 and the other of 1. Let’s visualize our two new datasets:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">ggplot</span>(data.meta, <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(id), <span class="dt">y=</span>ES)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>ES<span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES, <span class="dt">ymax=</span>ES<span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="dv">0</span>,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()<span class="op">+</span>
<span class="st">      </span><span class="kw">ylim</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>)

  <span class="kw">ggplot</span>(data.meta, <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(id), <span class="dt">y=</span>theta.<span class="dv">1</span>)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>theta.<span class="dv">1</span><span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES, <span class="dt">ymax=</span>theta.<span class="dv">1</span><span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,tau[[<span class="dv">1</span>]],<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()<span class="op">+</span>
<span class="st">      </span><span class="kw">ylim</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>)

  <span class="kw">ggplot</span>(data.meta, <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">as.factor</span>(id), <span class="dt">y=</span>theta.<span class="dv">2</span>)) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_bar</span>(<span class="dt">position=</span><span class="kw">position_dodge</span>(), <span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">colour=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>theta.<span class="dv">2</span><span class="op">-</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES, <span class="dt">ymax=</span>theta.<span class="dv">2</span><span class="op">+</span><span class="kw">qnorm</span>((delta.<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>se.ES), <span class="dt">width=</span>.<span class="dv">2</span>,<span class="dt">position=</span><span class="kw">position_dodge</span>(.<span class="dv">9</span>),<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="kw">ES</span>(param)), <span class="dt">colour=</span><span class="st">&quot;#990000&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Studies&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,tau[[<span class="dv">2</span>]],<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))<span class="op">+</span>
<span class="st">      </span><span class="kw">ylab</span>(<span class="st">&quot;Effect size&quot;</span>)<span class="op">+</span>
<span class="st">      </span><span class="kw">theme_bw</span>()<span class="op">+</span>
<span class="st">      </span><span class="kw">ylim</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:metanoiseplot"></span>
<img src="STCI_files/figure-html/metanoiseplot-1.png" alt="Datasets with treatment effect heterogeneity" width="33%" /><img src="STCI_files/figure-html/metanoiseplot-2.png" alt="Datasets with treatment effect heterogeneity" width="33%" /><img src="STCI_files/figure-html/metanoiseplot-3.png" alt="Datasets with treatment effect heterogeneity" width="33%" />
<p class="caption">
Figure 12.5: Datasets with treatment effect heterogeneity
</p>
</div>
<p>Let’s see now how Hedge’s estimator performs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau.<span class="fl">2.</span>theta.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">tau.2</span>(data.meta<span class="op">$</span>theta.<span class="dv">1</span>,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>)
tau.<span class="fl">2.</span>theta.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">tau.2</span>(data.meta<span class="op">$</span>theta.<span class="dv">2</span>,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>)</code></pre></div>
<p>Hedges’ estimates of <span class="math inline">\(\tau^2\)</span> in our examples are thus 0.2 and 0.73 respectively, while the true values are, respectively 0.25 and 1.</p>
</div>
<div id="estimating-the-average-effect-of-the-treatment-taking-heterogeneity-into-account" class="section level4">
<h4><span class="header-section-number">12.1.5.2</span> Estimating the average effect of the treatment taking heterogeneity into account</h4>
<p>Hedges proposes a new estimator for the average effect of the treatment, an estimator that accounts for the additional noise due to heterogeneous treatment effects accross sites.</p>

<div class="definition">
<span id="def:Hmetaweights" class="definition"><strong>Definition 12.4  (Hedges Weighted Meta-Analytic Estimator)  </strong></span>Hedges weighted meta-analytic estimator for in the presence of random effects is <span class="math display">\[
\bar{\theta}_H = \sum_{k=1}^Nv_k\hat{\theta}_k \text{ with } v_k=\frac{\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}}{\sum_{k=1}^N\frac{1}{\hat{\sigma}^2_k+\hat{\tau}^2}}.
\]</span>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hwmae &lt;-<span class="st"> </span><span class="cf">function</span>(theta,sigma2,tau2){
  <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">weighted.mean</span>(theta,(<span class="dv">1</span><span class="op">/</span>sigma2)<span class="op">/</span>(<span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>(sigma2<span class="op">+</span>tau2))),<span class="dv">1</span><span class="op">/</span><span class="kw">sum</span>(<span class="dv">1</span><span class="op">/</span>sigma2<span class="op">+</span>tau2))))
}
ES.H.theta.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">Hwmae</span>(data.meta<span class="op">$</span>theta.<span class="dv">1</span>,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>,tau.<span class="fl">2.</span>theta.<span class="dv">1</span>)
ES.H.theta.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">Hwmae</span>(data.meta<span class="op">$</span>theta.<span class="dv">2</span>,data.meta<span class="op">$</span>se.ES<span class="op">^</span><span class="dv">2</span>,tau.<span class="fl">2.</span>theta.<span class="dv">2</span>)</code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-136" class="example"><strong>Example 12.6  </strong></span>Let’s see how Hedges estimator performs in our example.
</div>
<p> Hedges’ estimates of the average effect size is equal to 0.3 and 0.65 respectively, while the true value is 0.2. The main problem with Hedges’ estimator when treatment effects are heterogeneous is that very large effects for the more precise estimators dramatically affect the estimate.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Hedges’ estimate of <span class="math inline">\(\tau^2\)</span> is slightly negative, which is problem, since a variance is always positive. Other estimators of <span class="math inline">\(\tau^2\)</span> have been proposed in the literature to account for this fact and to respond to various shortcomings of Hedges’ approach. We will present them succinctly since they are part of the <code>metafor</code> package. These other estimators have bames such as . They are very well described in this <a href="http://www.edii.uclm.es/~useR-2013/Tutorials/kovalchik/kovalchik_meta_tutorial.pdf">amazing set of slides</a>. Besides Hedges’ (denoted ‘HE’ in R), the other estimators are named:
</div>

<ul>
<li>DerSimonian-Laird (‘DL’)</li>
<li>Hunter-Schmidt (‘HS’)</li>
<li>Sidik-Jonkman (‘SJ’)</li>
<li>Maximum-likelihood (‘ML’)</li>
<li>Restricted maximum-likelihood (‘REML’)</li>
<li>Empirical Bayes (‘EB’)</li>
</ul>
<p>I’ll detail how they work later.</p>
<p><strong><span style="font-variant: small-caps;">Detail other estimators of tau.</span></strong></p>

<div class="example">
<span id="exm:unnamed-chunk-138" class="example"><strong>Example 12.7  </strong></span>For the moment, let’s see how they perform in our numerical example.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimators &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;DL&quot;</span>, <span class="st">&quot;REML&quot;</span>, <span class="st">&quot;HE&quot;</span>, <span class="st">&quot;HS&quot;</span>, <span class="st">&quot;SJ&quot;</span>, <span class="st">&quot;ML&quot;</span>, <span class="st">&quot;EB&quot;</span>)
meta.example.RE.theta.<span class="fl">1.</span>tau2 &lt;-<span class="st"> </span><span class="kw">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="kw">return</span>(<span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">1</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span>method)<span class="op">$</span>tau2)})
meta.example.RE.theta.<span class="fl">2.</span>tau2 &lt;-<span class="st"> </span><span class="kw">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="kw">return</span>(<span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">2</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span>method)<span class="op">$</span>tau2)})
<span class="co">#meta.example.RE &lt;- sapply(estimators,function(method){return(rma(yi = data.meta$theta.1,vi=data.meta$var.ES,method=method))})</span>
<span class="co">#meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;))</span>

result.RE &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Method=</span><span class="kw">rep</span>(estimators,<span class="dv">2</span>),<span class="dt">tau2hat=</span><span class="kw">c</span>(meta.example.RE.theta.<span class="fl">1.</span>tau2,meta.example.RE.theta.<span class="fl">2.</span>tau2),<span class="dt">tau2=</span><span class="kw">c</span>(<span class="kw">rep</span>(tau[[<span class="dv">1</span>]]<span class="op">^</span><span class="dv">2</span>,<span class="kw">length</span>(estimators)),<span class="kw">rep</span>(tau[[<span class="dv">2</span>]]<span class="op">^</span><span class="dv">2</span>,<span class="kw">length</span>(estimators))))

<span class="kw">ggplot</span>(<span class="dt">data=</span>result.RE, <span class="kw">aes</span>(<span class="dt">x=</span>Method, <span class="dt">y=</span>tau2hat, <span class="dt">fill=</span><span class="kw">as.factor</span>(tau2))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">position=</span><span class="kw">position_dodge</span>())<span class="op">+</span>
<span class="st">    </span><span class="kw">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:RandomOthersTau"></span>
<img src="STCI_files/figure-html/RandomOthersTau-1.png" alt="Various estimators of $\tau^2$" width="60%" />
<p class="caption">
Figure 12.6: Various estimators of <span class="math inline">\(\tau^2\)</span>
</p>
</div>
<p>We are ready to estimate the overall treatment effect using random effects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimators &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;DL&quot;</span>, <span class="st">&quot;REML&quot;</span>, <span class="st">&quot;HE&quot;</span>, <span class="st">&quot;HS&quot;</span>, <span class="st">&quot;SJ&quot;</span>, <span class="st">&quot;ML&quot;</span>, <span class="st">&quot;EB&quot;</span>)
meta.example.RE.theta.<span class="fl">1.</span>ES &lt;-<span class="st"> </span><span class="kw">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="kw">return</span>(<span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">1</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span>method)<span class="op">$</span>beta)})
meta.example.RE.theta.<span class="fl">2.</span>ES &lt;-<span class="st"> </span><span class="kw">sapply</span>(estimators,<span class="cf">function</span>(method){<span class="kw">return</span>(<span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">2</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span>method)<span class="op">$</span>beta)})
<span class="co">#meta.example.RE.tau2.test &lt;- unlist(lapply(meta.example.RE,&#39;[[&#39;,&#39;tau2&#39;))</span>

result.RE<span class="op">$</span>ES.RE &lt;-<span class="st"> </span><span class="kw">c</span>(meta.example.RE.theta.<span class="fl">1.</span>ES,meta.example.RE.theta.<span class="fl">2.</span>ES)

<span class="kw">ggplot</span>(<span class="dt">data=</span>result.RE, <span class="kw">aes</span>(<span class="dt">x=</span>Method, <span class="dt">y=</span>ES.RE, <span class="dt">fill=</span><span class="kw">as.factor</span>(tau2))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">position=</span><span class="kw">position_dodge</span>())</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:RandomOthersES"></span>
<img src="STCI_files/figure-html/RandomOthersES-1.png" alt="Various estimators of the treatment effect with random effects" width="60%" />
<p class="caption">
Figure 12.7: Various estimators of the treatment effect with random effects
</p>
</div>
</div>
<div id="other-estimators-of-inter-site-variability" class="section level4">
<h4><span class="header-section-number">12.1.5.3</span> Other estimators of inter-site variability</h4>
<p><span class="math inline">\(\tau^2\)</span> is a pretty difficult measure of treatment effect heterogeneity to interpret. That’s why other indicators have been built that are easier to interpret. We are going to review several of them in this section.</p>
<p>The first alternative or complement to <span class="math inline">\(\tau^2\)</span> is Higgin’s <span class="math inline">\(I^2\)</span>:</p>
<span class="math display">\[\begin{align*}
  I^2 &amp; = \frac{Q-(N-1)}{Q}*100
\end{align*}\]</span>
<p>The interpretation of <span class="math inline">\(I^2\)</span> is pretty straightforward: it is the distance between the actual value of the <span class="math inline">\(Q\)</span> statistic and its value under the null of treatment effect homogeneity (it is equal to the number of studies <span class="math inline">\(N\)</span>, with a correction for degress of freedom). It can also be interpreted as the fraction of the overall variance (remember that <span class="math inline">\(Q\)</span> is the sum of variance ratios) that is not explained by within study sampling noise.</p>
<p>Another complement to <span class="math inline">\(\tau^2\)</span> is <span class="math inline">\(H^2\)</span>:</p>
<span class="math display">\[\begin{align*}
  H^2 &amp; = \frac{Q}{N-1}
\end{align*}\]</span>
<p>If <span class="math inline">\(H^2\)</span> is above one, then there is unexplained heterogeneity, again by the fact that <span class="math inline">\(Q\)</span> has mean <span class="math inline">\(N-1\)</span> under the null of treatment effect homogeneity.</p>
<p>Finally, we can also define the Intra Class Correlation (<span class="math inline">\(ICC\)</span>), which precisely measures the share of total variance attributable to treatment effect heterogeneity:</p>
<span class="math display">\[\begin{align*}
  ICC &amp; = \frac{\tau^2}{\tau^2+S^2}
\end{align*}\]</span>
<p>Where <span class="math inline">\(S^2\)</span> is the amount of variance due to sampling noise. An estimator for <span class="math inline">\(S^2\)</span> is:</p>
<span class="math display">\[\begin{align*}
  S^2 &amp; = \frac{(N-1)\sum_{k=1}^N\frac{1}{\sigma^2_k}}{(\sum_{k=1}^N\frac{1}{\sigma^2_k})^2-\sum_{k=1}^N(\frac{1}{\sigma^2_k})^2}.
\end{align*}\]</span>
<p><strong><span style="font-variant: small-caps;">I do not understand the formula for <span class="math inline">\(S^2\)</span>. Why does it estimate what we want? I’d take the average variance.</span></strong></p>
<p><span class="math inline">\(ICC\)</span> and <span class="math inline">\(I^2\)</span> are related by the following very simple relation: <span class="math inline">\(I^2=ICC*100\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-139" class="example"><strong>Example 12.8  </strong></span>Let’s see how these three estimators look like in our example. The cool thing is that <code>rma</code> computes these estimators by default, so that a simple call to <code>summary()</code> is going to show them. The default random effects estimator is <code>REML</code>, which is deemed to be the best of them all according to simulations <a href="https://journals.sagepub.com/doi/abs/10.3102/10769986030003261">(Viechtbauer, 2002)</a>.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meta.example.RE.ES &lt;-<span class="st"> </span><span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>ES,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES)
meta.example.RE.theta.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">1</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES)
meta.example.RE.theta.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">2</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES)

tau2.hat &lt;-<span class="st"> </span><span class="kw">c</span>(meta.example.RE.ES<span class="op">$</span>tau2,meta.example.RE.theta.<span class="dv">1</span><span class="op">$</span>tau2,meta.example.RE.theta.<span class="dv">2</span><span class="op">$</span>tau2)
I2 &lt;-<span class="st">  </span><span class="kw">c</span>(meta.example.RE.theta.<span class="dv">1</span><span class="op">$</span>I2,meta.example.RE.theta.<span class="dv">2</span><span class="op">$</span>I2,meta.example.RE.ES<span class="op">$</span>I2)
H2 &lt;-<span class="st">  </span><span class="kw">c</span>(meta.example.RE.theta.<span class="dv">1</span><span class="op">$</span>H2,meta.example.RE.theta.<span class="dv">2</span><span class="op">$</span>H2,meta.example.RE.ES<span class="op">$</span>H2)

<span class="co"># illustration of results returned by summary</span>
<span class="kw">summary</span>(meta.example.RE.theta.<span class="dv">2</span>)</code></pre></div>
<pre><code>## 
## Random-Effects Model (k = 20; tau^2 estimator: REML)
## 
##   logLik  deviance       AIC       BIC      AICc  
## -24.7208   49.4417   53.4417   55.3305   54.1917  
## 
## tau^2 (estimated amount of total heterogeneity): 0.7507 (SE = 0.2583)
## tau (square root of estimated tau^2 value):      0.8664
## I^2 (total heterogeneity / total variability):   99.59%
## H^2 (total variability / sampling variability):  241.82
## 
## Test for Heterogeneity: 
## Q(df = 19) = 1927.7020, p-val &lt; .0001
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub    
##   0.6015  0.1997  3.0127  0.0026  0.2102  0.9929  **
## 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The estimate of <span class="math inline">\(I^2\)</span> in our example is of 0 when <span class="math inline">\(\tau^2\)</span> is equal to 0, of 98.71 when <span class="math inline">\(\tau^2\)</span> is equal to 0.25 and of 99.59 when <span class="math inline">\(\tau^2\)</span> is equal to 1. The estimate of <span class="math inline">\(H^2\)</span> in our example is of 1 when <span class="math inline">\(\tau^2\)</span> is equal to 0, of 77.4 when <span class="math inline">\(\tau^2\)</span> is equal to 0.25 and of 241.82 when <span class="math inline">\(\tau^2\)</span> is equal to 1.</p>
</div>
<div id="presenting-the-results-of-a-random-effects-meta-analysis" class="section level4">
<h4><span class="header-section-number">12.1.5.4</span> Presenting the results of a random effects meta-analysis</h4>
<p>In order to illustrate the results of a random effects meta-analysis, you can first show the forest plot. Let’s see how it works in our example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">forest</span>(meta.example.RE.ES,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))
<span class="kw">forest</span>(meta.example.RE.theta.<span class="dv">1</span>,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="st">&#39;0.25&#39;</span>,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))
<span class="kw">forest</span>(meta.example.RE.theta.<span class="dv">2</span>,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Estimated Meta-analytic Parameter,&#39;</span>,tau<span class="op">^</span><span class="dv">2</span>,<span class="st">&#39;=&#39;</span>,<span class="st">&#39;1&#39;</span>,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>)))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:RERMAmetafor"></span>
<img src="STCI_files/figure-html/RERMAmetafor-1.png" alt="Forest plots with random effects" width="33%" /><img src="STCI_files/figure-html/RERMAmetafor-2.png" alt="Forest plots with random effects" width="33%" /><img src="STCI_files/figure-html/RERMAmetafor-3.png" alt="Forest plots with random effects" width="33%" />
<p class="caption">
Figure 12.8: Forest plots with random effects
</p>
</div>
<p>Another very nice and useful graphical presentation device is a radial (or Galbraith) plot. It relates the invserse of the standard errors to the effect sizes normalized by their standard errors. Each data point is also related a radius by the line passing through the origin. The Radial plot enables to visualize the noise in the dataset, and is especially useful when comparing a fixed and a random effects estimator for the same study.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meta.example.FE.theta.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rma</span>(<span class="dt">yi =</span> data.meta<span class="op">$</span>theta.<span class="dv">1</span>,<span class="dt">vi=</span>data.meta<span class="op">$</span>var.ES,<span class="dt">method=</span><span class="st">&quot;FE&quot;</span>)
<span class="kw">radial</span>(meta.example.FE.theta.<span class="dv">1</span>)
<span class="kw">radial</span>(meta.example.RE.theta.<span class="dv">1</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:Radial"></span>
<img src="STCI_files/figure-html/Radial-1.png" alt="Radial plots with fixed and random effects $\tau^2=$ 0.25" width="50%" /><img src="STCI_files/figure-html/Radial-2.png" alt="Radial plots with fixed and random effects $\tau^2=$ 0.25" width="50%" />
<p class="caption">
Figure 12.9: Radial plots with fixed and random effects <span class="math inline">\(\tau^2=\)</span> 0.25
</p>
</div>
<p>Figure <a href="sec-meta.html#fig:Radial">12.9</a> shows how the mechanics of the fixed effects estimator differs from the mechanics of the random effects one. In the presence of treatment effect heterogeneity, the fixed effect estimator faces two issues:</p>
<ol style="list-style-type: decimal">
<li>It gives too much weight to very precise estimators. The random effects estimator undoes part of this importance by adding <span class="math inline">\(\tau^2\)</span> to the weights of each observation.</li>
<li>It overestimates overall precision by ignoring the sampling variance stemming from treatment effect heterogeneity across sites. The random effects estimator corrects for that by estimating <span class="math inline">\(\tau^2\)</span> and adding it to the estimate of the total variance of the treatment effect.</li>
</ol>

<div class="example">
<span id="exm:unnamed-chunk-140" class="example"><strong>Example 12.9  </strong></span>Let’s see how big a difference using random versus fixed effects does to the estimation of treatment effects. Let’s plot the two forest plots for the example with <span class="math inline">\(\tau=\)</span> <code>r tau[[1]]^2</code>.
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">forest</span>(meta.example.FE.theta.<span class="dv">1</span>,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)
<span class="kw">forest</span>(meta.example.RE.theta.<span class="dv">1</span>,<span class="dt">slab =</span> <span class="kw">paste</span>(<span class="st">&#39;Study&#39;</span>,data.meta<span class="op">$</span>id,<span class="dt">sep=</span><span class="st">&#39; &#39;</span>),<span class="dt">xlab=</span><span class="st">&#39;Estimated Meta-analytic Parameter&#39;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:FEvsRE"></span>
<img src="STCI_files/figure-html/FEvsRE-1.png" alt="Fixed vs random effects with $\tau^2=$ 0.25" width="50%" /><img src="STCI_files/figure-html/FEvsRE-2.png" alt="Fixed vs random effects with $\tau^2=$ 0.25" width="50%" />
<p class="caption">
Figure 12.10: Fixed vs random effects with <span class="math inline">\(\tau^2=\)</span> 0.25
</p>
</div>
<p>Figure <a href="sec-meta.html#fig:FEvsRE">12.10</a> clearly shows that the inclusion of <span class="math inline">\(\tau^2\)</span> in the weights and precision estimates makes a huge difference to the meta-analytic estimate. The fixed effects estimator yields an estimate of our treatment effect of 0.3 <span class="math inline">\(\pm\)</span> 0.02. The random effects estimator yields an estimate of our treatment effect of 0.13 <span class="math inline">\(\pm\)</span> 0.23. With <span class="math inline">\(\tau^2=\)</span> 1, the random effects estimator yields an estimate of our treatment effect of 0.6 <span class="math inline">\(\pm\)</span> 0.39. Remember that the true effect size of our treatment is 0.2. With <span class="math inline">\(\tau^2=\)</span> 1, the random effects estimator barely contains the truth in its 95 <span class="math inline">\(\%\)</span> confidence interval.</p>
</div>
</div>
<div id="meta-regression" class="section level3">
<h3><span class="header-section-number">12.1.6</span> Meta-regression</h3>
</div>
<div id="why-vote-counting-does-not-work" class="section level3">
<h3><span class="header-section-number">12.1.7</span> Why vote-counting does not work</h3>
</div>
</div>
<div id="publication-bias" class="section level2">
<h2><span class="header-section-number">12.2</span> Publication bias</h2>
<div id="sources-of-publication-bias" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Sources of publication bias</h3>
</div>
<div id="detecting-and-correcting-for-publication-bias" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Detecting and correcting for publication bias</h3>
<div id="p-curving" class="section level4">
<h4><span class="header-section-number">12.2.2.1</span> P-curving</h4>
</div>
<div id="pet-peese" class="section level4">
<h4><span class="header-section-number">12.2.2.2</span> PET-PEESE</h4>
</div>
<div id="kasy-and-andrews-approach" class="section level4">
<h4><span class="header-section-number">12.2.2.3</span> Kasy and Andrews approach</h4>
</div>
<div id="last-approach" class="section level4">
<h4><span class="header-section-number">12.2.2.4</span> Last approach</h4>
</div>
</div>
<div id="vote-counting-and-publication-bias" class="section level3">
<h3><span class="header-section-number">12.2.3</span> Vote counting and publication bias</h3>
</div>
<div id="the-value-of-a-statistically-significant-result" class="section level3">
<h3><span class="header-section-number">12.2.4</span> The value of a statistically significant result</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Distribution.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Bounds.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/chabefer/STCI/blob/master/12_Meta.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["STCI.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 1
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
