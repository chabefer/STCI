<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Observational Methods | Statistical Tools for Causal Inference</title>
  <meta name="description" content="This is an open source collaborative book." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Observational Methods | Statistical Tools for Causal Inference" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an open source collaborative book." />
  <meta name="github-repo" content="chabefer/STCI" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Observational Methods | Statistical Tools for Causal Inference" />
  
  <meta name="twitter:description" content="This is an open source collaborative book." />
  

<meta name="author" content="Sylvain Chabé-Ferret" />


<meta name="date" content="2023-12-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="NE.html"/>
<link rel="next" href="threats.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
$$
\newcommand{\uns}[1]{\mathbf{1}[#1]}
\newcommand{\esp}[1]{\mathbf{E}[#1]}
\newcommand{\hatesp}[1]{\hat{\mathbf{E}}[ #1 ]}
\newcommand{\espE}{\mathbf{E}}
\newcommand{\Ind}{\perp\kern-5pt\perp}
\newcommand{\var}[1]{\mathbf{V}[ #1 ]}
\newcommand{\hatvar}[1]{\hat{\mathbf{V}}[ #1 ]}
\newcommand{\cov}[1]{\mathbf{C}[ #1 ]}
\newcommand{\plim}[1]{\text{plim}_{ #1 \rightarrow \infty}}
\newcommand{\plims}{\text{plim}}
\newcommand{\distr}{\stackrel{d}{\rightarrow}}
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\partdersq}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\asym}{Asym}
$$


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Tools for Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Fundamental Problems of Inference</b></span></li>
<li class="chapter" data-level="" data-path="introduction-the-two-fundamental-problems-of-inference.html"><a href="introduction-the-two-fundamental-problems-of-inference.html"><i class="fa fa-check"></i>Introduction: the Two Fundamental Problems of Inference</a></li>
<li class="chapter" data-level="1" data-path="FPCI.html"><a href="FPCI.html"><i class="fa fa-check"></i><b>1</b> Fundamental Problem of Causal Inference</a>
<ul>
<li class="chapter" data-level="1.1" data-path="FPCI.html"><a href="FPCI.html#rubin-causal-model"><i class="fa fa-check"></i><b>1.1</b> Rubin Causal Model</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="FPCI.html"><a href="FPCI.html#treatment-allocation-rule"><i class="fa fa-check"></i><b>1.1.1</b> Treatment allocation rule</a></li>
<li class="chapter" data-level="1.1.2" data-path="FPCI.html"><a href="FPCI.html#potential-outcomes"><i class="fa fa-check"></i><b>1.1.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="1.1.3" data-path="FPCI.html"><a href="FPCI.html#switching-equation"><i class="fa fa-check"></i><b>1.1.3</b> Switching equation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="FPCI.html"><a href="FPCI.html#treatment-effects"><i class="fa fa-check"></i><b>1.2</b> Treatment effects</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="FPCI.html"><a href="FPCI.html#individual-level-treatment-effects"><i class="fa fa-check"></i><b>1.2.1</b> Individual level treatment effects</a></li>
<li class="chapter" data-level="1.2.2" data-path="FPCI.html"><a href="FPCI.html#average-treatment-effect-on-the-treated"><i class="fa fa-check"></i><b>1.2.2</b> Average treatment effect on the treated</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="FPCI.html"><a href="FPCI.html#fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>1.3</b> Fundamental problem of causal inference</a></li>
<li class="chapter" data-level="1.4" data-path="FPCI.html"><a href="FPCI.html#intuitive-estimators-confounding-factors-and-selection-bias"><i class="fa fa-check"></i><b>1.4</b> Intuitive estimators, confounding factors and selection bias</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="FPCI.html"><a href="FPCI.html#withwithout-comparison-selection-bias-and-cross-sectional-confounders"><i class="fa fa-check"></i><b>1.4.1</b> With/Without comparison, selection bias and cross-sectional confounders</a></li>
<li class="chapter" data-level="1.4.2" data-path="FPCI.html"><a href="FPCI.html#the-beforeafter-comparison-temporal-confounders-and-time-trend-bias"><i class="fa fa-check"></i><b>1.4.2</b> The before/after comparison, temporal confounders and time trend bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FPSI.html"><a href="FPSI.html"><i class="fa fa-check"></i><b>2</b> Fundamental Problem of Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="FPSI.html"><a href="FPSI.html#sec:sampnoise"><i class="fa fa-check"></i><b>2.1</b> What is sampling noise? Definition and illustration</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="FPSI.html"><a href="FPSI.html#sec:definitionnoise"><i class="fa fa-check"></i><b>2.1.1</b> Sampling noise, a definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisepop"><i class="fa fa-check"></i><b>2.1.2</b> Sampling noise for the population treatment effect</a></li>
<li class="chapter" data-level="2.1.3" data-path="FPSI.html"><a href="FPSI.html#sec:illusnoisesamp"><i class="fa fa-check"></i><b>2.1.3</b> Sampling noise for the sample treatment effect</a></li>
<li class="chapter" data-level="2.1.4" data-path="FPSI.html"><a href="FPSI.html#sec:confinterv"><i class="fa fa-check"></i><b>2.1.4</b> Building confidence intervals from estimates of sampling noise</a></li>
<li class="chapter" data-level="2.1.5" data-path="FPSI.html"><a href="FPSI.html#reporting-sampling-noise-a-proposal"><i class="fa fa-check"></i><b>2.1.5</b> Reporting sampling noise: a proposal</a></li>
<li class="chapter" data-level="2.1.6" data-path="FPSI.html"><a href="FPSI.html#sec:effectsize"><i class="fa fa-check"></i><b>2.1.6</b> Using effect sizes to normalize the reporting of treatment effects and their precision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FPSI.html"><a href="FPSI.html#sec:estimsampnoise"><i class="fa fa-check"></i><b>2.2</b> Estimating sampling noise</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="FPSI.html"><a href="FPSI.html#sec:assumptions"><i class="fa fa-check"></i><b>2.2.1</b> Assumptions</a></li>
<li class="chapter" data-level="2.2.2" data-path="FPSI.html"><a href="FPSI.html#sec:cheb"><i class="fa fa-check"></i><b>2.2.2</b> Using Chebyshev’s inequality</a></li>
<li class="chapter" data-level="2.2.3" data-path="FPSI.html"><a href="FPSI.html#sec:CLT"><i class="fa fa-check"></i><b>2.2.3</b> Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.4" data-path="FPSI.html"><a href="FPSI.html#sec:resamp"><i class="fa fa-check"></i><b>2.2.4</b> Using resampling methods</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Methods of Causal Inference</b></span></li>
<li class="chapter" data-level="3" data-path="RCT.html"><a href="RCT.html"><i class="fa fa-check"></i><b>3</b> Randomized Controlled Trials</a>
<ul>
<li class="chapter" data-level="3.1" data-path="RCT.html"><a href="RCT.html#sec:design1"><i class="fa fa-check"></i><b>3.1</b> Brute Force Design</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="RCT.html"><a href="RCT.html#identification"><i class="fa fa-check"></i><b>3.1.1</b> Identification</a></li>
<li class="chapter" data-level="3.1.2" data-path="RCT.html"><a href="RCT.html#estimating-ate"><i class="fa fa-check"></i><b>3.1.2</b> Estimating ATE</a></li>
<li class="chapter" data-level="3.1.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise"><i class="fa fa-check"></i><b>3.1.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="RCT.html"><a href="RCT.html#sec:design2"><i class="fa fa-check"></i><b>3.2</b> Self-Selection design</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="RCT.html"><a href="RCT.html#identification-1"><i class="fa fa-check"></i><b>3.2.1</b> Identification</a></li>
<li class="chapter" data-level="3.2.2" data-path="RCT.html"><a href="RCT.html#estimating-tt"><i class="fa fa-check"></i><b>3.2.2</b> Estimating TT</a></li>
<li class="chapter" data-level="3.2.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimating Sampling Noise</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="RCT.html"><a href="RCT.html#sec:design3"><i class="fa fa-check"></i><b>3.3</b> Eligibility design</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="RCT.html"><a href="RCT.html#identification-2"><i class="fa fa-check"></i><b>3.3.1</b> Identification</a></li>
<li class="chapter" data-level="3.3.2" data-path="RCT.html"><a href="RCT.html#estimating-the-ite-and-the-tt"><i class="fa fa-check"></i><b>3.3.2</b> Estimating the ITE and the TT</a></li>
<li class="chapter" data-level="3.3.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-2"><i class="fa fa-check"></i><b>3.3.3</b> Estimating sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="RCT.html"><a href="RCT.html#sec:design4"><i class="fa fa-check"></i><b>3.4</b> Encouragement Design</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="RCT.html"><a href="RCT.html#identification-3"><i class="fa fa-check"></i><b>3.4.1</b> Identification</a></li>
<li class="chapter" data-level="3.4.2" data-path="RCT.html"><a href="RCT.html#IVRCT"><i class="fa fa-check"></i><b>3.4.2</b> Estimating the Local Average Treatment Effect and the Intention to Treat Effect</a></li>
<li class="chapter" data-level="3.4.3" data-path="RCT.html"><a href="RCT.html#estimating-sampling-noise-3"><i class="fa fa-check"></i><b>3.4.3</b> Estimating sampling noise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="NE.html"><a href="NE.html"><i class="fa fa-check"></i><b>4</b> Natural Experiments</a>
<ul>
<li class="chapter" data-level="4.1" data-path="NE.html"><a href="NE.html#instrumental-variables"><i class="fa fa-check"></i><b>4.1</b> Instrumental Variables</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="NE.html"><a href="NE.html#an-example-where-monotonicity-does-not-hold"><i class="fa fa-check"></i><b>4.1.1</b> An example where Monotonicity does not hold</a></li>
<li class="chapter" data-level="4.1.2" data-path="NE.html"><a href="NE.html#identification-4"><i class="fa fa-check"></i><b>4.1.2</b> Identification</a></li>
<li class="chapter" data-level="4.1.3" data-path="NE.html"><a href="NE.html#estimation"><i class="fa fa-check"></i><b>4.1.3</b> Estimation</a></li>
<li class="chapter" data-level="4.1.4" data-path="NE.html"><a href="NE.html#estimation-of-sampling-noise"><i class="fa fa-check"></i><b>4.1.4</b> Estimation of sampling noise</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="NE.html"><a href="NE.html#regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2</b> Regression Discontinuity Designs</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="NE.html"><a href="NE.html#sharp-regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2.1</b> Sharp Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="4.2.2" data-path="NE.html"><a href="NE.html#fuzzy-regression-discontinuity-designs"><i class="fa fa-check"></i><b>4.2.2</b> Fuzzy Regression Discontinuity Designs</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="NE.html"><a href="NE.html#DID"><i class="fa fa-check"></i><b>4.3</b> Difference In Differences</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="NE.html"><a href="NE.html#sec:DIDbasic"><i class="fa fa-check"></i><b>4.3.1</b> Difference In Differences with two time periods</a></li>
<li class="chapter" data-level="4.3.2" data-path="NE.html"><a href="NE.html#sec:DIDr"><i class="fa fa-check"></i><b>4.3.2</b> Reverse Difference In Differences designs with two time periods</a></li>
<li class="chapter" data-level="4.3.3" data-path="NE.html"><a href="NE.html#DIDStaggered"><i class="fa fa-check"></i><b>4.3.3</b> Difference In Differences with multiple time periods</a></li>
<li class="chapter" data-level="4.3.4" data-path="NE.html"><a href="NE.html#difference-in-differences-with-instrumental-variables"><i class="fa fa-check"></i><b>4.3.4</b> Difference In Differences with Instrumental Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="OM.html"><a href="OM.html"><i class="fa fa-check"></i><b>5</b> Observational Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="OM.html"><a href="OM.html#parametric-methods"><i class="fa fa-check"></i><b>5.1</b> Parametric methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="OM.html"><a href="OM.html#assuming-espy_i0x_i-is-known"><i class="fa fa-check"></i><b>5.1.1</b> Assuming <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known</a></li>
<li class="chapter" data-level="5.1.2" data-path="OM.html"><a href="OM.html#assuming-espy_i1x_i-is-known"><i class="fa fa-check"></i><b>5.1.2</b> Assuming <span class="math inline">\(\esp{Y_i^1|X_i}\)</span> is known</a></li>
<li class="chapter" data-level="5.1.3" data-path="OM.html"><a href="OM.html#BiasOLS"><i class="fa fa-check"></i><b>5.1.3</b> Properties of the OLS estimator under Conditional Independence</a></li>
<li class="chapter" data-level="5.1.4" data-path="OM.html"><a href="OM.html#problems-with-parametric-methods"><i class="fa fa-check"></i><b>5.1.4</b> Problems with parametric methods</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="OM.html"><a href="OM.html#nonparametric-methods"><i class="fa fa-check"></i><b>5.2</b> Nonparametric methods</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="OM.html"><a href="OM.html#identification-12"><i class="fa fa-check"></i><b>5.2.1</b> Identification</a></li>
<li class="chapter" data-level="5.2.2" data-path="OM.html"><a href="OM.html#estimation-8"><i class="fa fa-check"></i><b>5.2.2</b> Estimation</a></li>
<li class="chapter" data-level="5.2.3" data-path="OM.html"><a href="OM.html#estimating-precision-2"><i class="fa fa-check"></i><b>5.2.3</b> Estimating precision</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="OM.html"><a href="OM.html#imputation-methods"><i class="fa fa-check"></i><b>5.3</b> Imputation methods</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="threats.html"><a href="threats.html"><i class="fa fa-check"></i><b>6</b> Threats to the validity of Causal Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="threats.html"><a href="threats.html#threats-to-internal-validity"><i class="fa fa-check"></i><b>6.1</b> Threats to internal validity</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="threats.html"><a href="threats.html#survey-bias"><i class="fa fa-check"></i><b>6.1.1</b> Survey bias</a></li>
<li class="chapter" data-level="6.1.2" data-path="threats.html"><a href="threats.html#experimenter-bias"><i class="fa fa-check"></i><b>6.1.2</b> Experimenter bias</a></li>
<li class="chapter" data-level="6.1.3" data-path="threats.html"><a href="threats.html#substitution-bias"><i class="fa fa-check"></i><b>6.1.3</b> Substitution bias</a></li>
<li class="chapter" data-level="6.1.4" data-path="threats.html"><a href="threats.html#diffusion-bias"><i class="fa fa-check"></i><b>6.1.4</b> Diffusion bias</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="threats.html"><a href="threats.html#threats-to-the-measurement-of-precision"><i class="fa fa-check"></i><b>6.2</b> Threats to the measurement of precision</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="threats.html"><a href="threats.html#insufficient-precision"><i class="fa fa-check"></i><b>6.2.1</b> Insufficient precision</a></li>
<li class="chapter" data-level="6.2.2" data-path="threats.html"><a href="threats.html#clustering"><i class="fa fa-check"></i><b>6.2.2</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="threats.html"><a href="threats.html#threats-to-external-validity"><i class="fa fa-check"></i><b>6.3</b> Threats to external validity</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="threats.html"><a href="threats.html#randomization-bias"><i class="fa fa-check"></i><b>6.3.1</b> Randomization bias</a></li>
<li class="chapter" data-level="6.3.2" data-path="threats.html"><a href="threats.html#equilibrium-effects"><i class="fa fa-check"></i><b>6.3.2</b> Equilibrium effects</a></li>
<li class="chapter" data-level="6.3.3" data-path="threats.html"><a href="threats.html#context-effects"><i class="fa fa-check"></i><b>6.3.3</b> Context effects</a></li>
<li class="chapter" data-level="6.3.4" data-path="threats.html"><a href="threats.html#site-selection-bias"><i class="fa fa-check"></i><b>6.3.4</b> Site selection bias</a></li>
<li class="chapter" data-level="6.3.5" data-path="threats.html"><a href="threats.html#publication-bias"><i class="fa fa-check"></i><b>6.3.5</b> Publication bias</a></li>
<li class="chapter" data-level="6.3.6" data-path="threats.html"><a href="threats.html#ethical-and-political-issues"><i class="fa fa-check"></i><b>6.3.6</b> Ethical and political issues</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Additional Topics</b></span></li>
<li class="chapter" data-level="7" data-path="Power.html"><a href="Power.html"><i class="fa fa-check"></i><b>7</b> Power Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="Power.html"><a href="Power.html#basics-of-traditional-power-analysis-using-test-statistics"><i class="fa fa-check"></i><b>7.1</b> Basics of traditional power analysis using test statistics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="Power.html"><a href="Power.html#power"><i class="fa fa-check"></i><b>7.1.1</b> Power</a></li>
<li class="chapter" data-level="7.1.2" data-path="Power.html"><a href="Power.html#minimum-detectable-effect"><i class="fa fa-check"></i><b>7.1.2</b> Minimum Detectable Effect</a></li>
<li class="chapter" data-level="7.1.3" data-path="Power.html"><a href="Power.html#minimum-required-sample-size"><i class="fa fa-check"></i><b>7.1.3</b> Minimum Required Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Power.html"><a href="Power.html#traditional-power-analysis-in-practice"><i class="fa fa-check"></i><b>7.2</b> Traditional power analysis in practice</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="Power.html"><a href="Power.html#power-analysis-for-randomized-controlled-trials"><i class="fa fa-check"></i><b>7.2.1</b> Power Analysis for Randomized Controlled Trials</a></li>
<li class="chapter" data-level="7.2.2" data-path="Power.html"><a href="Power.html#power-analysis-for-natural-experiments"><i class="fa fa-check"></i><b>7.2.2</b> Power Analysis for Natural Experiments</a></li>
<li class="chapter" data-level="7.2.3" data-path="Power.html"><a href="Power.html#power-analysis-for-observational-methods"><i class="fa fa-check"></i><b>7.2.3</b> Power Analysis for Observational Methods</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Power.html"><a href="Power.html#limitations-of-and-alternatives-to-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3</b> Limitations of and alternatives to traditional power analysis</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="Power.html"><a href="Power.html#limitations-of-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3.1</b> Limitations of traditional power analysis</a></li>
<li class="chapter" data-level="7.3.2" data-path="Power.html"><a href="Power.html#an-alternative-to-traditional-power-analysis"><i class="fa fa-check"></i><b>7.3.2</b> An alternative to traditional power analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sec:placebo.html"><a href="sec:placebo.html"><i class="fa fa-check"></i><b>8</b> Placebo Tests</a></li>
<li class="chapter" data-level="9" data-path="cluster.html"><a href="cluster.html"><i class="fa fa-check"></i><b>9</b> Clustering</a>
<ul>
<li class="chapter" data-level="9.1" data-path="cluster.html"><a href="cluster.html#ClusterRCT"><i class="fa fa-check"></i><b>9.1</b> Clustering in Randomized Controlled Trials</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="cluster.html"><a href="cluster.html#an-example"><i class="fa fa-check"></i><b>9.1.1</b> An example</a></li>
<li class="chapter" data-level="9.1.2" data-path="cluster.html"><a href="cluster.html#design-effect"><i class="fa fa-check"></i><b>9.1.2</b> Design effect</a></li>
<li class="chapter" data-level="9.1.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-accounting-for-clustering"><i class="fa fa-check"></i><b>9.1.3</b> Estimating sampling noise accounting for clustering</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="cluster.html"><a href="cluster.html#clustering-in-panel-data"><i class="fa fa-check"></i><b>9.2</b> Clustering in panel data</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="cluster.html"><a href="cluster.html#an-example-1"><i class="fa fa-check"></i><b>9.2.1</b> An example</a></li>
<li class="chapter" data-level="9.2.2" data-path="cluster.html"><a href="cluster.html#design-effect-in-panel-data"><i class="fa fa-check"></i><b>9.2.2</b> Design effect in panel data</a></li>
<li class="chapter" data-level="9.2.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-in-panel-data-with-autocorrelated-error-terms"><i class="fa fa-check"></i><b>9.2.3</b> Estimating sampling noise in panel data with autocorrelated error terms</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="cluster.html"><a href="cluster.html#spatial-correlation"><i class="fa fa-check"></i><b>9.3</b> Spatial correlation</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="cluster.html"><a href="cluster.html#an-example-2"><i class="fa fa-check"></i><b>9.3.1</b> An example</a></li>
<li class="chapter" data-level="9.3.2" data-path="cluster.html"><a href="cluster.html#design-effect-in-spatially-autocorrelated-data"><i class="fa fa-check"></i><b>9.3.2</b> Design effect in spatially autocorrelated data</a></li>
<li class="chapter" data-level="9.3.3" data-path="cluster.html"><a href="cluster.html#estimating-sampling-noise-with-spatially-autocorrelated-data"><i class="fa fa-check"></i><b>9.3.3</b> Estimating sampling noise with spatially autocorrelated data</a></li>
<li class="chapter" data-level="9.3.4" data-path="cluster.html"><a href="cluster.html#testing-for-spatial-autocorrelation"><i class="fa fa-check"></i><b>9.3.4</b> Testing for spatial autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="cluster.html"><a href="cluster.html#clustering-on-a-network"><i class="fa fa-check"></i><b>9.4</b> Clustering on a network</a></li>
<li class="chapter" data-level="9.5" data-path="cluster.html"><a href="cluster.html#multi-way-clustering"><i class="fa fa-check"></i><b>9.5</b> Multi-way clustering</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="cluster.html"><a href="cluster.html#at-which-level-should-we-cluster"><i class="fa fa-check"></i><b>9.5.1</b> At which level should we cluster?</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="cluster.html"><a href="cluster.html#what-to-do-when-there-are-few-clusters"><i class="fa fa-check"></i><b>9.6</b> What to do when there are few clusters?</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="cluster.html"><a href="cluster.html#aggregation"><i class="fa fa-check"></i><b>9.6.1</b> Aggregation</a></li>
<li class="chapter" data-level="9.6.2" data-path="cluster.html"><a href="cluster.html#permutation-tests"><i class="fa fa-check"></i><b>9.6.2</b> Permutation tests</a></li>
<li class="chapter" data-level="9.6.3" data-path="cluster.html"><a href="cluster.html#wild-bootstrap"><i class="fa fa-check"></i><b>9.6.3</b> Wild bootstrap</a></li>
<li class="chapter" data-level="9.6.4" data-path="cluster.html"><a href="cluster.html#ibragimov-and-muller-2010-group-based-inference"><i class="fa fa-check"></i><b>9.6.4</b> Ibragimov and Muller (2010) group-based inference</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="cluster.html"><a href="cluster.html#CLTDD"><i class="fa fa-check"></i><b>9.7</b> Central Limit Theorems for Dependent Data</a></li>
<li class="chapter" data-level="9.8" data-path="cluster.html"><a href="cluster.html#DesignBasedClusters"><i class="fa fa-check"></i><b>9.8</b> Sampling-based and design-based approaches to clustering</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LaLonde.html"><a href="LaLonde.html"><i class="fa fa-check"></i><b>10</b> LaLonde Tests</a></li>
<li class="chapter" data-level="11" data-path="Diffusion.html"><a href="Diffusion.html"><i class="fa fa-check"></i><b>11</b> Diffusion effects</a></li>
<li class="chapter" data-level="12" data-path="Distribution.html"><a href="Distribution.html"><i class="fa fa-check"></i><b>12</b> Distributional effects</a></li>
<li class="chapter" data-level="13" data-path="meta.html"><a href="meta.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and Publication Bias</a>
<ul>
<li class="chapter" data-level="13.1" data-path="meta.html"><a href="meta.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="meta.html"><a href="meta.html#basic-setting"><i class="fa fa-check"></i><b>13.1.1</b> Basic setting</a></li>
<li class="chapter" data-level="13.1.2" data-path="meta.html"><a href="meta.html#why-vote-counting-does-not-work"><i class="fa fa-check"></i><b>13.1.2</b> Why vote-counting does not work</a></li>
<li class="chapter" data-level="13.1.3" data-path="meta.html"><a href="meta.html#MetaWA"><i class="fa fa-check"></i><b>13.1.3</b> Meta-analysis when treatment effects are homogeneous: the fixed effects approach</a></li>
<li class="chapter" data-level="13.1.4" data-path="meta.html"><a href="meta.html#meta-analysis-when-treatment-effects-are-heterogeneous-the-random-effects-approach"><i class="fa fa-check"></i><b>13.1.4</b> Meta-analysis when treatment effects are heterogeneous: the random effects approach</a></li>
<li class="chapter" data-level="13.1.5" data-path="meta.html"><a href="meta.html#meta-regression"><i class="fa fa-check"></i><b>13.1.5</b> Meta-regression</a></li>
<li class="chapter" data-level="13.1.6" data-path="meta.html"><a href="meta.html#constantly-updated-meta-analysis"><i class="fa fa-check"></i><b>13.1.6</b> Constantly updated meta-analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="meta.html"><a href="meta.html#publication-bias-and-site-selection-bias"><i class="fa fa-check"></i><b>13.2</b> Publication bias and site selection bias</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="meta.html"><a href="meta.html#sources-of-publication-bias-and-of-site-selection-bias-and-questionable-research-practices"><i class="fa fa-check"></i><b>13.2.1</b> Sources of publication bias and of site selection bias and Questionable Research Practices</a></li>
<li class="chapter" data-level="13.2.2" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-publication-bias"><i class="fa fa-check"></i><b>13.2.2</b> Detection of and correction for publication bias</a></li>
<li class="chapter" data-level="13.2.3" data-path="meta.html"><a href="meta.html#getting-rid-of-publication-bias-registered-reports-and-pre-analysis-plans"><i class="fa fa-check"></i><b>13.2.3</b> Getting rid of publication bias: registered reports and pre-analysis plans</a></li>
<li class="chapter" data-level="13.2.4" data-path="meta.html"><a href="meta.html#detection-of-and-correction-for-site-selection-bias"><i class="fa fa-check"></i><b>13.2.4</b> Detection of and correction for site selection bias</a></li>
<li class="chapter" data-level="13.2.5" data-path="meta.html"><a href="meta.html#vote-counting-and-publication-bias"><i class="fa fa-check"></i><b>13.2.5</b> Vote counting and publication bias</a></li>
<li class="chapter" data-level="13.2.6" data-path="meta.html"><a href="meta.html#the-value-of-a-statistically-significant-result"><i class="fa fa-check"></i><b>13.2.6</b> The value of a statistically significant result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Bounds.html"><a href="Bounds.html"><i class="fa fa-check"></i><b>14</b> Bounds</a></li>
<li class="chapter" data-level="15" data-path="mediation-analysis.html"><a href="mediation-analysis.html"><i class="fa fa-check"></i><b>15</b> Mediation Analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-a-framework"><i class="fa fa-check"></i><b>15.1</b> Mediation analysis: a framework</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#defining-mediated-and-unmediated-treatment-effects"><i class="fa fa-check"></i><b>15.1.1</b> Defining mediated and unmediated treatment effects</a></li>
<li class="chapter" data-level="15.1.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#decomposing-mediated-and-unmediated-effects"><i class="fa fa-check"></i><b>15.1.2</b> Decomposing mediated and unmediated effects</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#the-fundamental-problem-of-mediation-analysis"><i class="fa fa-check"></i><b>15.2</b> The Fundamental Problem of Mediation Analysis</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#the-fundamental-problem-of-mediation-analysis-1"><i class="fa fa-check"></i><b>15.2.1</b> The Fundamental Problem of Mediation Analysis</a></li>
<li class="chapter" data-level="15.2.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#biases-of-intuitive-comparisons"><i class="fa fa-check"></i><b>15.2.2</b> Biases of Intuitive Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-experimental-data"><i class="fa fa-check"></i><b>15.3</b> Mediation analysis with experimental data</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-parallel-design"><i class="fa fa-check"></i><b>15.3.1</b> Mediation analysis in the Parallel design</a></li>
<li class="chapter" data-level="15.3.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-sequential-self-selection-design"><i class="fa fa-check"></i><b>15.3.2</b> Mediation analysis in the Sequential Self-Selection design</a></li>
<li class="chapter" data-level="15.3.3" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-in-the-crossover-design"><i class="fa fa-check"></i><b>15.3.3</b> Mediation analysis in the Crossover design</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-under-unconfoundedness"><i class="fa fa-check"></i><b>15.4</b> Mediation analysis under unconfoundedness</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="mediation-analysis.html"><a href="mediation-analysis.html#non-parametric-identification-under-sequential-ignorability"><i class="fa fa-check"></i><b>15.4.1</b> Non-parametric identification under sequential ignorability</a></li>
<li class="chapter" data-level="15.4.2" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-under-sequential-ignorability-in-linear-models"><i class="fa fa-check"></i><b>15.4.2</b> Mediation analysis under sequential ignorability in linear models</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-panel-data"><i class="fa fa-check"></i><b>15.5</b> Mediation analysis with panel data</a></li>
<li class="chapter" data-level="15.6" data-path="mediation-analysis.html"><a href="mediation-analysis.html#mediation-analysis-with-instruments"><i class="fa fa-check"></i><b>15.6</b> Mediation analysis with instruments</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="stratification.html"><a href="stratification.html"><i class="fa fa-check"></i><b>16</b> Stratification</a>
<ul>
<li class="chapter" data-level="16.1" data-path="stratification.html"><a href="stratification.html#ClassicalStratification"><i class="fa fa-check"></i><b>16.1</b> Analysis of classical stratified experiments</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="stratification.html"><a href="stratification.html#an-example-3"><i class="fa fa-check"></i><b>16.1.1</b> An example</a></li>
<li class="chapter" data-level="16.1.2" data-path="stratification.html"><a href="stratification.html#estimating-treatment-effects-with-stratified-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.1.2</b> Estimating treatment effects with stratified randomized controlled trials</a></li>
<li class="chapter" data-level="16.1.3" data-path="stratification.html"><a href="stratification.html#estimating-sampling-noise-in-stratified-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.1.3</b> Estimating sampling noise in stratified randomized controlled trials</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="stratification.html"><a href="stratification.html#analysis-of-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2</b> Analysis of pairwise randomized controlled trials</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="stratification.html"><a href="stratification.html#building-a-sample-of-pairs"><i class="fa fa-check"></i><b>16.2.1</b> Building a sample of pairs</a></li>
<li class="chapter" data-level="16.2.2" data-path="stratification.html"><a href="stratification.html#estimating-treatment-effects-in-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2.2</b> Estimating treatment effects in pairwise randomized controlled trials</a></li>
<li class="chapter" data-level="16.2.3" data-path="stratification.html"><a href="stratification.html#estimating-sampling-noise-in-pairwise-randomized-controlled-trials"><i class="fa fa-check"></i><b>16.2.3</b> Estimating sampling noise in pairwise randomized controlled trials</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="proofs.html"><a href="proofs.html"><i class="fa fa-check"></i><b>A</b> Proofs</a>
<ul>
<li class="chapter" data-level="A.1" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-reffpsi"><i class="fa fa-check"></i><b>A.1</b> Proofs of results in Chapter @ref(FPSI)</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="proofs.html"><a href="proofs.html#proofcheb"><i class="fa fa-check"></i><b>A.1.1</b> Proof of Theorem @ref(thm:uppsampnoise)</a></li>
<li class="chapter" data-level="A.1.2" data-path="proofs.html"><a href="proofs.html#proofCLT"><i class="fa fa-check"></i><b>A.1.2</b> Proof of Theorem @ref(thm:asympnoiseWW)</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refrct"><i class="fa fa-check"></i><b>A.2</b> Proofs of results in Chapter @ref(RCT)</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="proofs.html"><a href="proofs.html#proofIdentLATE"><i class="fa fa-check"></i><b>A.2.1</b> Proof of Theorem @ref(thm:IdentLATE)</a></li>
<li class="chapter" data-level="A.2.2" data-path="proofs.html"><a href="proofs.html#proofWaldIV"><i class="fa fa-check"></i><b>A.2.2</b> Proof of Theorem @ref(thm:WaldIV)</a></li>
<li class="chapter" data-level="A.2.3" data-path="proofs.html"><a href="proofs.html#ProofAsymWald"><i class="fa fa-check"></i><b>A.2.3</b> Proof of Theorem @ref(thm:asymWald)</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refne"><i class="fa fa-check"></i><b>A.3</b> Proofs of results in Chapter @ref(NE)</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="proofs.html"><a href="proofs.html#proofEstimDID"><i class="fa fa-check"></i><b>A.3.1</b> Proof of Theorem @ref(thm:EstimDID)</a></li>
<li class="chapter" data-level="A.3.2" data-path="proofs.html"><a href="proofs.html#proofasympnoiseDIDCross"><i class="fa fa-check"></i><b>A.3.2</b> Proof of Theorem @ref(thm:asympnoiseDIDCross)</a></li>
<li class="chapter" data-level="A.3.3" data-path="proofs.html"><a href="proofs.html#proofEquivDIDSApop"><i class="fa fa-check"></i><b>A.3.3</b> Proof of Theorem @ref(thm:EquivDIDSApop)</a></li>
<li class="chapter" data-level="A.3.4" data-path="proofs.html"><a href="proofs.html#proofEquivDIDSAsamp"><i class="fa fa-check"></i><b>A.3.4</b> Proof of Theorem @ref(thm:EquivDIDSAsamp)</a></li>
<li class="chapter" data-level="A.3.5" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSACross"><i class="fa fa-check"></i><b>A.3.5</b> Proof of Theorem @ref(thm:asympnoiseSACross)</a></li>
<li class="chapter" data-level="A.3.6" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTCross"><i class="fa fa-check"></i><b>A.3.6</b> Proof of Theorem @ref(thm:asympnoiseSATTCross)</a></li>
<li class="chapter" data-level="A.3.7" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSAPanel"><i class="fa fa-check"></i><b>A.3.7</b> Proof of Theorem @ref(thm:asympnoiseSAPanel)</a></li>
<li class="chapter" data-level="A.3.8" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTPanel"><i class="fa fa-check"></i><b>A.3.8</b> Proof of Theorem @ref(thm:asympnoiseSATTPanel)</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refom"><i class="fa fa-check"></i><b>A.4</b> Proofs of results in Chapter @ref(OM)</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="proofs.html"><a href="proofs.html#proofAsympWWOLS10"><i class="fa fa-check"></i><b>A.4.1</b> Proof of Theorem @ref(thm:AsympWWOLS10)</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refcluster"><i class="fa fa-check"></i><b>A.5</b> Proofs of results in Chapter @ref(cluster)</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="proofs.html"><a href="proofs.html#proofVarWWClus"><i class="fa fa-check"></i><b>A.5.1</b> Proof of Theorem @ref(thm:VarWWClus)</a></li>
<li class="chapter" data-level="A.5.2" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATTPanelAR1"><i class="fa fa-check"></i><b>A.5.2</b> Proof of Theorem @ref(thm:asympnoiseSATTPanelAR1)</a></li>
<li class="chapter" data-level="A.5.3" data-path="proofs.html"><a href="proofs.html#proofVarWWSpatial"><i class="fa fa-check"></i><b>A.5.3</b> Proof of Theorem @ref(thm:VarWWSpatial)</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="proofs.html"><a href="proofs.html#proofs-of-results-in-chapter-refstratification"><i class="fa fa-check"></i><b>A.6</b> Proofs of results in Chapter @ref(stratification)</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="proofs.html"><a href="proofs.html#proofSFEdecomp"><i class="fa fa-check"></i><b>A.6.1</b> Proof of Theorem @ref(thm:SFEdecomp)</a></li>
<li class="chapter" data-level="A.6.2" data-path="proofs.html"><a href="proofs.html#proofSFEconsistent"><i class="fa fa-check"></i><b>A.6.2</b> Proof of Theorem @ref(thm:SFEconsistent)</a></li>
<li class="chapter" data-level="A.6.3" data-path="proofs.html"><a href="proofs.html#proofSATUnbiasedConsistent"><i class="fa fa-check"></i><b>A.6.3</b> Proof of Theorem @ref(thm:SATUnbiasedConsistent)</a></li>
<li class="chapter" data-level="A.6.4" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSATStrata"><i class="fa fa-check"></i><b>A.6.4</b> Proof of Theorem @ref(thm:asympnoiseSATStrata)</a></li>
<li class="chapter" data-level="A.6.5" data-path="proofs.html"><a href="proofs.html#proofasympnoiseSFEStrata"><i class="fa fa-check"></i><b>A.6.5</b> Proof of Theorem @ref(thm:asympnoiseSFEStrata)</a></li>
<li class="chapter" data-level="A.6.6" data-path="proofs.html"><a href="proofs.html#proofPairUnbiasedConsistent"><i class="fa fa-check"></i><b>A.6.6</b> Proof of Theorem @ref(thm:PairUnbiasedConsistent)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Tools for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="OM" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Observational Methods<a href="OM.html#OM" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this lecture, we are going to study how to estimate the effect of an intervention on an outcome using observational methods, that is methods which try to correct for selection bias by accounting for as many observed confounders as possible.
The key assumption that we are going to make is that of conditional independence:</p>
<div class="hypothesis">
<p><span id="hyp:CIAExp" class="hypothesis"><strong>Hypothesis 5.1  (Conditional Independence (in Expectation)) </strong></span>We assume that there exists a known set of observable covariates <span class="math inline">\(X_i\)</span> such that:</p>
<p><span class="math display">\[\begin{align*}
\esp{Y_i^0|X_i,D_i=1} &amp; = \esp{Y_i^0|X_i,D_i=0}.
\end{align*}\]</span></p>
</div>
<p>Under Assumption <a href="OM.html#hyp:CIAExp">5.1</a>, the expected potential outcomes of the treated in the absence of the treatment are independent of the treatment conditional on a set of observed covariates <span class="math inline">\(X_i\)</span>.
As a consequence, selection bias is zero after conditioning on <span class="math inline">\(X_i\)</span>, and we can recover the treatment on the treated parameter by using the With/Without comparison conditional on <span class="math inline">\(X_i\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  \Delta^Y_{WW}(X_i) &amp; = \esp{Y_i|X_i,D_i=1} - \esp{Y_i|X_i,D_i=0} \\
                    &amp; = \esp{Y^1_i|X_i,D_i=1} - \esp{Y^0_i|X_i,D_i=0} \\
                    &amp; = \esp{Y^1_i|X_i,D_i=1} - \esp{Y^0_i|X_i,D_i=1} \\
                    &amp; = \esp{Y^1_i-Y_i^0|X_i,D_i=1}\\
                    &amp; = \Delta^Y_{TT}(X_i),
\end{align*}\]</span></p>
<p>where the third equality uses Assumption <a href="OM.html#hyp:CIAExp">5.1</a>.</p>
<p>There are several ways to use Assumption <a href="OM.html#hyp:CIAExp">5.1</a> (and thus Assumption <a href="OM.html#hyp:CIA">5.2</a>) to build estimators of the treatment effect.
Let’s start with the parametric approaches and then we’ll study the non-parametric approaches.</p>
<div class="remark">
<p><span id="unlabeled-div-168" class="remark"><em>Remark</em>. </span>Assumption <a href="OM.html#hyp:CIAExp">5.1</a> is the minimal assumption needed to indentify the average effect of the treatment on the treated.
Researchers often use a stronger version of that assumption:</p>
</div>
<div class="hypothesis">
<p><span id="hyp:CIA" class="hypothesis"><strong>Hypothesis 5.2  (Conditional Independence) </strong></span>We assume that there exists a known set of observable covariates <span class="math inline">\(X_i\)</span> such that:</p>
<p><span class="math display">\[\begin{align*}
(Y_i^1,Y_i^0)\Ind D_i|X_i.
\end{align*}\]</span></p>
</div>
<p>Assumption <a href="OM.html#hyp:CIA">5.2</a> is stronger than Assumption <a href="OM.html#hyp:CIAExp">5.1</a> because it imposes conditional independence of all the distribution of <span class="math inline">\(Y_i^0\)</span>, not only of its mean, and also because it imposes conditional independence of <span class="math inline">\(Y_i^1\)</span> and moreover that this independence is jointly holding for <span class="math inline">\((Y_i^1,Y_i^0)\)</span>.</p>
<div class="remark">
<p><span id="unlabeled-div-169" class="remark"><em>Remark</em>. </span>Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> and <a href="OM.html#hyp:CIA">5.2</a> are sometimes called Ignorability, Unconfoundedness or Selection on Observables.</p>
</div>
<div id="parametric-methods" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Parametric methods<a href="OM.html#parametric-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We are going to study two approaches uses increasingly strong parametric assumptions.
The first assumes the functional form of <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known.
The second assumes furthermore that the functional form of <span class="math inline">\(\esp{Y_i^1|X_i}\)</span> is known.
We finaly are going to discuss the conditions under which a simple OLS regressions identifies the treatment effect on the treated.</p>
<div id="assuming-espy_i0x_i-is-known" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Assuming <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known<a href="OM.html#assuming-espy_i0x_i-is-known" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s study identification, estimation and inference when <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known</p>
<div id="identification-10" class="section level4 hasAnchor" number="5.1.1.1">
<h4><span class="header-section-number">5.1.1.1</span> Identification<a href="OM.html#identification-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The most simple assumption that we can make in order to identify the treatment on the treated parameter under Conditional Indepedence is that the functional form of <span class="math inline">\(\esp{Y_i^0|X_i}\)</span> is known (and for example is linear):</p>
<div class="hypothesis">
<p><span id="hyp:paramff0" class="hypothesis"><strong>Hypothesis 5.3  </strong></span>We assume that there exists a known set of observable covariates <span class="math inline">\(X_i\)</span> such that:</p>
<p><span class="math display">\[\begin{align*}
\esp{Y_i^0|X_i} &amp; = \alpha_0+\beta_0&#39;X_i.
\end{align*}\]</span></p>
</div>
<p>One way to use this assumption to identify the effect of the treatment on the treated is to follow the following steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\beta_0\)</span> on the population of untreated individuals.</li>
<li>Use these estimates to predict potential outcomes for the treated.</li>
<li>Compute the difference between the observed potential outcomes and the simulated ones for the treated observations.</li>
</ol>
<p>In practice, this estimator, which I call <span class="math inline">\(\Delta^Y_{WWOLS(X)}\)</span>, is equal to:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{WWOLS(X)} &amp; = \esp{Y_i-\alpha_0-\beta_0&#39;X_i|D_i=1}.
\end{align*}\]</span></p>
<p>Under the assumptions we’ve made so far, <span class="math inline">\(\Delta^Y_{WWOLS(X)}\)</span> identifies <span class="math inline">\(TT\)</span>:</p>
<div class="theorem">
<p><span id="thm:olsid" class="theorem"><strong>Theorem 5.1  (Identification of TT using OLS) </strong></span>Under Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> and (hyp:paramff0), TT is identified using the WW comparison adjusted by the OLS projection.</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{WWOLS(X)} &amp; = \Delta^Y_{TT}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-170" class="proof"><em>Proof</em>. </span>Under Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> and (hyp:paramff0), we have:</p>
<p><span class="math display">\[\begin{align*}
  \esp{Y_i^0|D_i=0,X_i} &amp; = \esp{Y_i^0|X_i} = \alpha_0+\beta_0&#39;X_i.
\end{align*}\]</span></p>
<p>As a consequence, <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\beta_0\)</span> are identified by using the untreated population, as long as the components of <span class="math inline">\(X\)</span> are not colinear.
Then, we have:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{WWOLS(X)} &amp; = \esp{Y_i-\alpha_0-\beta_0&#39;X_i|D_i=1}\\
                  &amp; = \esp{Y_i-\esp{Y_i^0|D_i=1,X_i}|D_i=1}\\
                  &amp; = \esp{Y_i|D_i=1}-\esp{\esp{Y_i^0|D_i=1,X_i}|D_i=1}\\
                  &amp; = \esp{Y^1_i|D_i=1}-\esp{Y^0_i|D_i=1}\\
                  &amp; = \Delta^Y_{TT},
\end{align*}\]</span></p>
<p>where the first equality is the definition of the second step of the OLS projection procedure, the second equality is a consequence of Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> and (hyp:paramff0), the third and fifth equalities use the linearity of conditional expectations and the fourth equality uses the Law of Iterated Expectations.</p>
</div>
</div>
<div id="estimation-6" class="section level4 hasAnchor" number="5.1.1.2">
<h4><span class="header-section-number">5.1.1.2</span> Estimation<a href="OM.html#estimation-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Estimation can follow in the sample steps similar to the ones taken in the population:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(\hat{\alpha_0}\)</span> and <span class="math inline">\(\hat{\beta_0}\)</span> using an OLS regression of <span class="math inline">\(Y_i\)</span> on <span class="math inline">\(X_i\)</span> on the sample of untreated individuals.</li>
<li>Predict the counterfactual values for each treated using <span class="math inline">\(\hat{Y_i^0}=\hat{\alpha_0}+\hat{\beta_0}&#39;X_i\)</span>.</li>
<li>Compute <span class="math inline">\(\hat{\Delta}^Y_{WWOLS(X)}=\frac{1}{\sum_{i=1}^ND_i}\sum_{i=1}^ND_i(Y_i^1-\hat{Y_i^0})\)</span>.</li>
</ol>
<div class="example">
<p><span id="exm:unnamed-chunk-296" class="example"><strong>Example 5.1  </strong></span>Let’s see how this works in our example.</p>
</div>
<p>Let’s first choose some parameter values:</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="OM.html#cb261-1" aria-hidden="true" tabindex="-1"></a>param <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">8</span>,.<span class="dv">5</span>,.<span class="dv">28</span>,<span class="dv">1500</span>,<span class="fl">0.9</span>,<span class="fl">0.01</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.05</span>,<span class="fl">0.1</span>)</span>
<span id="cb261-2"><a href="OM.html#cb261-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(param) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>,<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>)</span></code></pre></div>
<p>Let us now simulate the data:</p>
<p><span class="math display">\[\begin{align*}
y_i^1 &amp; = y_i^0+\bar{\alpha}+\theta\mu_i+\eta_i \\
y_i^0 &amp; = \mu_i+\delta+U_i^0  \\
U_i^0 &amp; = \rho U_i^B+\epsilon_i \\
y_i^B &amp; =\mu_i+U_i^B \\
U_i^B &amp; \sim\mathcal{N}(0,\sigma^2_{U}) \\
D_i   &amp; = \uns{y_i^B\leq\bar{y}} \\
(\eta_i,\mu_i,\epsilon_i) &amp; \sim\mathcal{N}(0,0,0,\sigma^2_{\eta},\sigma^2_{\mu},\sigma^2_{\epsilon},0,0,0).
\end{align*}\]</span></p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="OM.html#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb262-2"><a href="OM.html#cb262-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span><span class="dv">1000</span></span>
<span id="cb262-3"><a href="OM.html#cb262-3" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb262-4"><a href="OM.html#cb262-4" aria-hidden="true" tabindex="-1"></a>UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb262-5"><a href="OM.html#cb262-5" aria-hidden="true" tabindex="-1"></a>yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb262-6"><a href="OM.html#cb262-6" aria-hidden="true" tabindex="-1"></a>YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb262-7"><a href="OM.html#cb262-7" aria-hidden="true" tabindex="-1"></a>Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb262-8"><a href="OM.html#cb262-8" aria-hidden="true" tabindex="-1"></a>Ds[YB<span class="sc">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb262-9"><a href="OM.html#cb262-9" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb262-10"><a href="OM.html#cb262-10" aria-hidden="true" tabindex="-1"></a>eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb262-11"><a href="OM.html#cb262-11" aria-hidden="true" tabindex="-1"></a>U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb262-12"><a href="OM.html#cb262-12" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>]</span>
<span id="cb262-13"><a href="OM.html#cb262-13" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb262-14"><a href="OM.html#cb262-14" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb262-15"><a href="OM.html#cb262-15" aria-hidden="true" tabindex="-1"></a>Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb262-16"><a href="OM.html#cb262-16" aria-hidden="true" tabindex="-1"></a>Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb262-17"><a href="OM.html#cb262-17" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb262-18"><a href="OM.html#cb262-18" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span></code></pre></div>
<p>Let us now plot the sample and the procedure to estimate <span class="math inline">\(\hat{\Delta}^Y_{WWOLS(X)}\)</span>:</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="OM.html#cb263-1" aria-hidden="true" tabindex="-1"></a>col.obs <span class="ot">&lt;-</span> <span class="st">&#39;black&#39;</span></span>
<span id="cb263-2"><a href="OM.html#cb263-2" aria-hidden="true" tabindex="-1"></a>col.unobs <span class="ot">&lt;-</span> <span class="st">&#39;red&#39;</span></span>
<span id="cb263-3"><a href="OM.html#cb263-3" aria-hidden="true" tabindex="-1"></a>lty.obs <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb263-4"><a href="OM.html#cb263-4" aria-hidden="true" tabindex="-1"></a>lty.unobs <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb263-5"><a href="OM.html#cb263-5" aria-hidden="true" tabindex="-1"></a>xlim.big <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>,<span class="fl">0.5</span>)</span>
<span id="cb263-6"><a href="OM.html#cb263-6" aria-hidden="true" tabindex="-1"></a>xlim.small <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.15</span>,<span class="fl">0.55</span>)</span>
<span id="cb263-7"><a href="OM.html#cb263-7" aria-hidden="true" tabindex="-1"></a>adj <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb263-8"><a href="OM.html#cb263-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-9"><a href="OM.html#cb263-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample</span></span>
<span id="cb263-10"><a href="OM.html#cb263-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-11"><a href="OM.html#cb263-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb263-12"><a href="OM.html#cb263-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span>col.unobs)</span>
<span id="cb263-13"><a href="OM.html#cb263-13" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span>col.unobs)</span>
<span id="cb263-14"><a href="OM.html#cb263-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),<span class="at">col=</span><span class="fu">c</span>(col.obs,col.unobs),<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb263-15"><a href="OM.html#cb263-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-16"><a href="OM.html#cb263-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1</span></span>
<span id="cb263-17"><a href="OM.html#cb263-17" aria-hidden="true" tabindex="-1"></a>ols.reg<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>]<span class="sc">~</span>yB[Ds<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb263-18"><a href="OM.html#cb263-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-19"><a href="OM.html#cb263-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb263-20"><a href="OM.html#cb263-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span>col.unobs)</span>
<span id="cb263-21"><a href="OM.html#cb263-21" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],ols.reg<span class="fl">.0</span><span class="sc">$</span>fitted.values,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb263-22"><a href="OM.html#cb263-22" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span>col.unobs)</span>
<span id="cb263-23"><a href="OM.html#cb263-23" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=0&#39;</span>))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>),<span class="at">col=</span><span class="fu">c</span>(col.obs,col.unobs,<span class="st">&#39;blue&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb263-24"><a href="OM.html#cb263-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-25"><a href="OM.html#cb263-25" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2</span></span>
<span id="cb263-26"><a href="OM.html#cb263-26" aria-hidden="true" tabindex="-1"></a>y.pred <span class="ot">&lt;-</span> ols.reg<span class="fl">.0</span><span class="sc">$</span>coef[[<span class="dv">1</span>]]<span class="sc">+</span>ols.reg<span class="fl">.0</span><span class="sc">$</span>coef[[<span class="dv">2</span>]]<span class="sc">*</span>yB[Ds<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb263-27"><a href="OM.html#cb263-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-28"><a href="OM.html#cb263-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb263-29"><a href="OM.html#cb263-29" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span>col.unobs)</span>
<span id="cb263-30"><a href="OM.html#cb263-30" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],ols.reg<span class="fl">.0</span><span class="sc">$</span>fitted.values,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb263-31"><a href="OM.html#cb263-31" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y.pred,<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb263-32"><a href="OM.html#cb263-32" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span>col.unobs)</span>
<span id="cb263-33"><a href="OM.html#cb263-33" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=0&#39;</span>)),<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=1&#39;</span>))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>),<span class="at">col=</span><span class="fu">c</span>(col.obs,col.unobs,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb263-34"><a href="OM.html#cb263-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-35"><a href="OM.html#cb263-35" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3</span></span>
<span id="cb263-36"><a href="OM.html#cb263-36" aria-hidden="true" tabindex="-1"></a>ww.ols <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y.pred)</span>
<span id="cb263-37"><a href="OM.html#cb263-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-38"><a href="OM.html#cb263-38" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb263-39"><a href="OM.html#cb263-39" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span>col.unobs)</span>
<span id="cb263-40"><a href="OM.html#cb263-40" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],ols.reg<span class="fl">.0</span><span class="sc">$</span>fitted.values,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb263-41"><a href="OM.html#cb263-41" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y.pred,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb263-42"><a href="OM.html#cb263-42" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb263-43"><a href="OM.html#cb263-43" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span>col.unobs)</span>
<span id="cb263-44"><a href="OM.html#cb263-44" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=0&#39;</span>)),<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=1&#39;</span>))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">3</span>),<span class="at">col=</span><span class="fu">c</span>(col.obs,col.unobs,col.obs,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plotOLSEstimSteps"></span>
<img src="STCI_files/figure-html/plotOLSEstimSteps-1.png" alt="Estimating treatment effects using WWOLS(X)" width="45%" /><img src="STCI_files/figure-html/plotOLSEstimSteps-2.png" alt="Estimating treatment effects using WWOLS(X)" width="45%" /><img src="STCI_files/figure-html/plotOLSEstimSteps-3.png" alt="Estimating treatment effects using WWOLS(X)" width="45%" /><img src="STCI_files/figure-html/plotOLSEstimSteps-4.png" alt="Estimating treatment effects using WWOLS(X)" width="45%" />
<p class="caption">
Figure 5.1: Estimating treatment effects using WWOLS(X)
</p>
</div>
<p>Let’s also compute the true values of the treatment effects in the population:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="OM.html#cb264-1" aria-hidden="true" tabindex="-1"></a>delta.y.tt <span class="ot">&lt;-</span> <span class="cf">function</span>(param){</span>
<span id="cb264-2"><a href="OM.html#cb264-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>param[<span class="st">&quot;barmu&quot;</span>]<span class="sc">-</span>param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>((param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">*</span><span class="fu">dnorm</span>((<span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="sc">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="sc">/</span>(<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))<span class="sc">/</span>(<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])<span class="sc">*</span><span class="fu">pnorm</span>((<span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="sc">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="sc">/</span>(<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))))))</span>
<span id="cb264-3"><a href="OM.html#cb264-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb264-4"><a href="OM.html#cb264-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb264-5"><a href="OM.html#cb264-5" aria-hidden="true" tabindex="-1"></a>delta.y.ate <span class="ot">&lt;-</span> <span class="cf">function</span>(param){</span>
<span id="cb264-6"><a href="OM.html#cb264-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>param[<span class="st">&quot;barmu&quot;</span>])</span>
<span id="cb264-7"><a href="OM.html#cb264-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The true effect of the treatment on the treated in the population is equal to 0.17 and our estimator, <span class="math inline">\(\hat{\Delta}^Y_{WWOLS(X)}\)</span>, is equal to 0.18.</p>
</div>
<div id="estimating-precision" class="section level4 hasAnchor" number="5.1.1.3">
<h4><span class="header-section-number">5.1.1.3</span> Estimating precision<a href="OM.html#estimating-precision" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Estimating the precision of this estimator can be done using the bootstrap.
Or we could derive its distribution using the CLT.</p>
<p><strong>TO DO</strong></p>
</div>
</div>
<div id="assuming-espy_i1x_i-is-known" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Assuming <span class="math inline">\(\esp{Y_i^1|X_i}\)</span> is known<a href="OM.html#assuming-espy_i1x_i-is-known" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to make our estimation procedure even simpler than using the <span class="math inline">\(WWOLS(X)\)</span> estimator is to assume that <span class="math inline">\(\esp{Y_i^1|X_i}\)</span> is also linear.
In that case, we are going to be able to use the OLS estimator conditioning on <span class="math inline">\(X_i\)</span> to estimate the average treatment effect on the treated.
We are going to see that this estimator will have a peculiar shape.
We’ll understand better why in Section <a href="OM.html#BiasOLS">5.1.3</a>.
Let’s start with how to use OLS under linearity of conditional expectations.</p>
<div id="identification-11" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> Identification<a href="OM.html#identification-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s assume that we also know the functional form of <span class="math inline">\(\esp{Y_i^1|X_i}\)</span>:</p>
<div class="hypothesis">
<p><span id="hyp:paramff1" class="hypothesis"><strong>Hypothesis 5.4  </strong></span>We assume that there exists a known set of observable covariates <span class="math inline">\(X_i\)</span> such that:</p>
<p><span class="math display">\[\begin{align*}
\esp{Y_i^1|X_i} &amp; = \alpha_1+\beta_1&#39;X_i.
\end{align*}\]</span></p>
</div>
<p>The first thing we can show is that we now have a parametric formula for our target parameter <span class="math inline">\(TT\)</span> (using the slighlty stronger version of the Conditional Indepedence Assumption):</p>
<div class="theorem">
<p><span id="thm:TTff" class="theorem"><strong>Theorem 5.2  (TT under Linearity of Conditional Expectations) </strong></span>Under Assumptions <a href="OM.html#hyp:CIA">5.2</a>, <a href="OM.html#hyp:paramff0">5.3</a> and <a href="OM.html#hyp:paramff1">5.4</a>, the Treatment on the Treated parameter simplifies to:</p>
<p><span class="math display">\[\begin{align*}
    \Delta^Y_{TT} &amp; = \alpha_1-\alpha_0+(\beta_1-\beta_0)&#39;\esp{X_i|D_i=1}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-171" class="proof"><em>Proof</em>. </span><span class="math display">\[\begin{align*}
    \Delta^Y_{TT} &amp; = \esp{Y_i^1-Y_i^0|D_i=1} \\
                 &amp; =  \esp{\esp{Y_i^1-Y_i^0|X_i,D_i=1}|D_i=1} \\
                 &amp; =  \esp{\esp{Y_i^1|X_i,D_i=1}-\esp{Y_i^0|X_i,D_i=1}|D_i=1} \\
                 &amp; =  \esp{\esp{Y_i^1|X_i}-\esp{Y_i^0|X_i}|D_i=1} \\
                 &amp; =  \esp{\alpha_1+\beta_1&#39;X_i-(\alpha_0+\beta_0&#39;X_i)|D_i=1} \\
                 &amp; =  \alpha_1-\alpha_0+(\beta_1-\beta_0)&#39;\esp{X_i|D_i=1},
\end{align*}\]</span></p>
<p>where the second equality follows from the Law of Iterated Exppectations, the third equality from Assumption <a href="OM.html#hyp:CIA">5.2</a> and the fourth equality from Assumptions <a href="OM.html#hyp:paramff0">5.3</a> and <a href="OM.html#hyp:paramff1">5.4</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-172" class="remark"><em>Remark</em>. </span>Theorem <a href="OM.html#thm:TTff">5.2</a> shows that under our assumptions, treatment effects are heterogenous in a way that is correlated with the treatment only because of differences in <span class="math inline">\(X_i\)</span>.</p>
</div>
<p>Equipped with this result, we can now state the identification result of this section:</p>
<div class="theorem">
<p><span id="thm:WWOLS10" class="theorem"><strong>Theorem 5.3  (OLS Identifies TT under Linearity and Conditional Independence) </strong></span>Under Assumptions <a href="OM.html#hyp:CIA">5.2</a>, <a href="OM.html#hyp:paramff0">5.3</a> and <a href="OM.html#hyp:paramff1">5.4</a>, the OLS coefficient <span class="math inline">\(\delta\)</span> in the following regression:</p>
<p><span class="math display">\[\begin{align*}
    Y_i &amp;  = \alpha_0 + \beta_0&#39;X_i + (\beta_1-\beta_0)&#39;\left(X_i-\esp{X_i|D_i=1}\right)D_i + \delta D_i + U_i
    \end{align*}\]</span></p>
<p>identifies the effect of the treatment on the treated.</p>
<p>We denote: <span class="math inline">\(\delta=\Delta^Y_{OLS(X)}\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-173" class="proof"><em>Proof</em>. </span>Under Assumptions <a href="OM.html#hyp:paramff0">5.3</a> and <a href="OM.html#hyp:paramff1">5.4</a>, we have <span class="math inline">\(Y_i^d=\alpha_d + \beta_d&#39;X_i +Y_i^d-\esp{Y_i^d|X_i}\)</span>, for <span class="math inline">\(d\in\left\{0,1\right\}\)</span>.
As a consequence, we have:</p>
<p><span class="math display">\[\begin{align*}
    Y_i &amp; = Y_i^0+D_i(Y_i^1-Y_i^0) \\
        &amp; = \alpha_0 + \beta_0&#39;X_i +D_i(\alpha_1-\alpha_0 + (\beta_1-\beta_0)&#39;X_i)\\
        &amp; \phantom{=}+Y_i^0-\esp{Y_i^0|X_i}+D_i(Y_i^1-Y_i^0-(\esp{Y_i^1|X_i}-\esp{Y_i^0|X_i}))\\
        &amp;  = \alpha_0 + \beta_0&#39;X_i + (\beta_1-\beta_0)&#39;\left(X_i-\esp{X_i|D_i=1}\right)D_i + (\alpha_1-\alpha_0 + (\beta_1-\beta_0)&#39;\esp{X_i|D_i=1})D_i\\
        &amp; \phantom{=}+\underbrace{Y_i^0-\esp{Y_i^0|X_i}+D(Y_i^1-Y_i^0-\esp{Y_i^1-Y_i^0|X_i})}_{U_i}\\
        &amp; = \alpha_0 + \beta_0&#39;X_i + (\beta_1-\beta_0)&#39;\left(X_i-\esp{X_i|D_i=1}\right)D_i + \Delta^Y_{TT}D_i +U_i,
\end{align*}\]</span></p>
<p>where the first equation uses the Switching Equation, the second equation uses Assumptions <a href="OM.html#hyp:paramff0">5.3</a> and <a href="OM.html#hyp:paramff1">5.4</a> and the last equation uses Theorem <a href="OM.html#thm:TTff">5.2</a>.</p>
<p>We are now going to show that <span class="math inline">\(\esp{U_i|X_i,D_i}=0\)</span>.</p>
<p><span class="math display">\[\begin{align*}
    \esp{U_i|X_i,D_i=0} &amp; = \esp{Y_i^0-\esp{Y_i^0|X_i}|X_i,D_i=0}\\
                        &amp; =\esp{Y_i^0|X_i,D_i=0}-\esp{\esp{Y_i^0|X_i}|X_i,D_i=0}\\
                        &amp; =\esp{Y_i^0|X_i,D_i=0}-\esp{\esp{Y_i^0|X_i,D_i=0}|X_i,D_i=0}\\
                        &amp; =\esp{Y_i^0|X_i,D_i=0}-\esp{Y_i^0|X_i,D_i=0}\\
                        &amp; = 0\\
    \esp{U_i|X_i,D_i=1} &amp; = \esp{Y_i^0-\esp{Y_i^0|X_i}|X_i,D_i=1}+\esp{Y_i^1-Y_i^0-\esp{Y_i^1-Y_i^0|X_i}|X_i,D_i=1}\\
                        &amp; =\esp{Y_i^1-Y_i^0|X_i,D_i=1}-\esp{\esp{Y_i^1-Y_i^0|X_i}|X_i,D_i=1} \\
                        &amp; =\esp{Y_i^1-Y_i^0|X_i,D_i=1}-\esp{\esp{Y_i^1-Y_i^0|X_i,D_i=1}|X_i,D_i=1} \\
                        &amp; = 0,
\end{align*}\]</span></p>
<p>where the third and eighth equalities follow from Assumption <a href="OM.html#hyp:CIA">5.2</a>.</p>
<p>We thus have <span class="math inline">\(\esp{Y_i|X_i,D_i}=\alpha_0 + \beta_0&#39;X_i + (\beta_1-\beta_0)&#39;\left(X_i-\esp{X_i|D_i=1}\right)D_i + \Delta^Y_{TT}D_i\)</span>.
Theorem <a href="proofs.html#thm:LinearCEF">A.2</a> ensures that the OLS estimator identifies the parameters of this model.
As a consequence, <span class="math inline">\(\Delta^Y_{TT}\)</span> is identified by the OLS estimator of <span class="math inline">\(\delta\)</span> in the model.
This completes the proof.</p>
</div>
</div>
<div id="estimation-7" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> Estimation<a href="OM.html#estimation-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>What is pretty nice with Theorem <a href="OM.html#thm:WWOLS10">5.3</a> is that it suggests directly an estimation strategy.
Let’s estimate <span class="math inline">\(\hat\delta^{OLS}\)</span> in the following regression:</p>
<p><span class="math display">\[\begin{align*}
    Y_i &amp;  = \alpha_0 + \beta_0&#39;X_i + (\beta_1-\beta_0)&#39;\left(X_i-\esp{X_i|D_i=1}\right)D_i + \delta D_i + U_i.
\end{align*}\]</span></p>
<div class="example">
<p><span id="exm:unnamed-chunk-300" class="example"><strong>Example 5.2  </strong></span>Let’s see what happens in our example when doing that.</p>
</div>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="OM.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="co"># deameaning the control variable</span></span>
<span id="cb265-2"><a href="OM.html#cb265-2" aria-hidden="true" tabindex="-1"></a>yB.Ds <span class="ot">&lt;-</span>(yB<span class="sc">-</span><span class="fu">mean</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>]))<span class="sc">*</span>Ds</span>
<span id="cb265-3"><a href="OM.html#cb265-3" aria-hidden="true" tabindex="-1"></a><span class="co"># running the OLS estimator with interactions between treatment and demeaned covariate</span></span>
<span id="cb265-4"><a href="OM.html#cb265-4" aria-hidden="true" tabindex="-1"></a>ols.direct <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>yB<span class="sc">+</span>Ds<span class="sc">+</span>yB.Ds)</span>
<span id="cb265-5"><a href="OM.html#cb265-5" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate of TT</span></span>
<span id="cb265-6"><a href="OM.html#cb265-6" aria-hidden="true" tabindex="-1"></a>ww.ols.direct <span class="ot">&lt;-</span> ols.direct<span class="sc">$</span>coef[[<span class="dv">3</span>]]</span></code></pre></div>
<p>Our estimator is equal to 0.18, while the true effect of the treatment on the treated in the population is equal to 0.17.</p>
<p><strong>Monte Carlo simulations</strong></p>
</div>
<div id="estimating-precision-1" class="section level4 hasAnchor" number="5.1.2.3">
<h4><span class="header-section-number">5.1.2.3</span> Estimating precision<a href="OM.html#estimating-precision-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Estimating precision is pretty straightforward in our case.
What is going to happen with respect to a simple WW estimator that does not condition on covariates is that the asymptotic variance of the estimated treatment effect is going to depend on the variance of outcomes conditional on observed covariates <span class="math inline">\(X_i\)</span>.
As a consequence, and as we have already seen in Chapter <a href="RCT.html#RCT">3</a>, precision will increase as long as the covariates we control for explain part of the variance of the outcome.
The main issue that we have to deal with is that of heteroskedasticity: <span class="math inline">\(U_i\)</span> is correlated with both <span class="math inline">\(X_i\)</span> and <span class="math inline">\(D_i\)</span>.
So we need to use a heteroskedasticity-robust estimator for the variance of the treatment effect.
Let us first state the main result.
For that, we need to reformulate the classical assumptions so that they cover the case with covariates:</p>
<div class="hypothesis">
<p><span id="hyp:iidX" class="hypothesis"><strong>Hypothesis 5.5  (i.i.d. sampling with covariates) </strong></span>We assume that the observations in the sample are identically and independently distributed:</p>
<p><span class="math display">\[\begin{align*}
\forall i,j\leq N\text{, }i\neq j\text{, } &amp; (Y_i,D_i,X_i)\Ind(Y_j,D_j,X_j),\\
                                           &amp; (Y_i,D_i,X_i)\&amp;(Y_j,D_j,X_j)\sim F_{Y,D,X}.
\end{align*}\]</span></p>
</div>
<div class="hypothesis">
<p><span id="hyp:finitevarX" class="hypothesis"><strong>Hypothesis 5.6  (Finite variances of potential outcomes conditional on covariates) </strong></span>We assume that <span class="math inline">\(\var{Y_i^1|X_i,D_i=1}\)</span> and <span class="math inline">\(\var{Y_i^0|X_i,D_i=0}\)</span> are finite.</p>
</div>
<p>We can now state our main result:</p>
<div class="theorem">
<p><span id="thm:AsympWWOLS10" class="theorem"><strong>Theorem 5.4  (Distribution of the OLS Estimator of TT under Conditional Independence) </strong></span>Under Assumptions <a href="OM.html#hyp:CIA">5.2</a>, <a href="OM.html#hyp:paramff0">5.3</a>, <a href="OM.html#hyp:paramff1">5.4</a>, <a href="FPSI.html#hyp:fullrank">2.1</a>, <a href="OM.html#hyp:iidX">5.5</a> and <a href="OM.html#hyp:finitevarX">5.6</a>, we have:</p>
<p><span class="math display">\[\begin{align*}
    \sqrt{N}(\hat\Delta^Y_{OLS(X)}-\Delta^Y_{TT}) &amp; \stackrel{d}{\rightarrow}
  \mathcal{N}\left(0,\frac{\var{Y^0_i|X_i,D_i=0}}{1-p}+\frac{\var{Y^1_i|X_i,D_i=1}}{p}\right),
    \end{align*}\]</span></p>
<p>with <span class="math inline">\(p=\Pr(D_i=1)\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-174" class="proof"><em>Proof</em>. </span>See Section <a href="proofs.html#proofAsympWWOLS10">A.4.1</a> in the Appendix.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-175" class="remark"><em>Remark</em>. </span>Theorem <a href="OM.html#thm:AsympWWOLS10">5.4</a> is super powerful: it tells us that conditioning on observed covariates yields an improvement in precision equivalent to the part of the variance of <span class="math inline">\(Y_i\)</span> explained by the observed covariates.
What is nice as well is that the distribution of the OLS estimator with controls has the same flavor as the distribution of the silpler With/Without estimator derived in Theorem <a href="FPSI.html#thm:asympnoiseWW">2.5</a> (and in Lemma <a href="proofs.html#lem:asymWW">A.5</a>).</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-176" class="remark"><em>Remark</em>. </span>In order to operationalize Theorem <a href="OM.html#thm:AsympWWOLS10">5.4</a>, one can either use the formula or simply use the heteroskedasticity-robust variance-covariance matrix proposed for the OLS estimator.
Both estimators should be similar.
Let <span class="math inline">\(\Theta=(\alpha_0,\beta_0,\beta_1,\delta)\)</span> and <span class="math inline">\(X\)</span> be the matrix of all regressors, with a first column of ones and the last column of <span class="math inline">\(D_i\)</span>.
Most available heteroskedasticity robust estimators based on the CLT can be written in the following way:</p>
<p><span class="math display">\[\begin{align*}
  \var{\hat{\Theta}_{OLS}} &amp; \approx (X&#39;X)^{-1}X&#39;\hat{\Omega}X(X&#39;X)^{-1},
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\hat{\Omega}=\diag(\hat{\sigma}^2_{U_1},\dots,\hat{\sigma}^2_{U_N})\)</span> is an estimate the covariance matrix of the residuals <span class="math inline">\(U_i\)</span>.</p>
<p>Here are various classical estimators for <span class="math inline">\(\hat{\Omega}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  \text{HC0:} &amp; &amp; \hat{\sigma_{U_i}}^2 &amp; = \hat{U_i}^2 \\
  \text{HC1:} &amp; &amp; \hat{\sigma_{U_i}}^2 &amp; = \frac{N}{N-K}\hat{U_i}^2 \\
  \text{HC2:} &amp; &amp; \hat{\sigma_{U_i}}^2 &amp; = \frac{\hat{U_i}^2}{1-h_i} \\
  \text{HC3:} &amp; &amp; \hat{\sigma_{U_i}}^2 &amp; = \frac{\hat{U_i}^2}{(1-h_i)^2}, 
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\hat{U}_i\)</span> is the residual from the OLS regression, <span class="math inline">\(K\)</span> is the number of regressors, <span class="math inline">\(h_i\)</span> is the leverage of observation <span class="math inline">\(i\)</span>, and is the <span class="math inline">\(i^{\text{th}}\)</span> diagonal element of <span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;\)</span>.
HC1 is the one reported by Stata when using the ‘robust’ option.
All of these estimators are programmed in the <a href="https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf">sandwich</a> package.</p>
</div>
<div class="example">
<p><span id="exm:unnamed-chunk-304" class="example"><strong>Example 5.3  </strong></span>Let’s see how our estimator works to estimate precision.</p>
</div>
<p>We can first try to implement the formula.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="OM.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="co"># regs on X in both smaples</span></span>
<span id="cb266-2"><a href="OM.html#cb266-2" aria-hidden="true" tabindex="-1"></a>ols.reg<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>]<span class="sc">~</span>yB[Ds<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb266-3"><a href="OM.html#cb266-3" aria-hidden="true" tabindex="-1"></a>ols.reg<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>]<span class="sc">~</span>yB[Ds<span class="sc">==</span><span class="dv">1</span>])</span>
<span id="cb266-4"><a href="OM.html#cb266-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb266-5"><a href="OM.html#cb266-5" aria-hidden="true" tabindex="-1"></a><span class="co"># variance</span></span>
<span id="cb266-6"><a href="OM.html#cb266-6" aria-hidden="true" tabindex="-1"></a>var.delta.ols <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>N<span class="sc">*</span>(<span class="fu">var</span>(ols.reg<span class="fl">.0</span><span class="sc">$</span>residuals)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>(Ds))<span class="sc">+</span><span class="fu">var</span>(ols.reg<span class="fl">.1</span><span class="sc">$</span>residuals)<span class="sc">/</span>(<span class="fu">mean</span>(Ds)))</span></code></pre></div>
<p>We can now try to see what the heteroskedasticity-robust variance estimator gives.</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="OM.html#cb267-1" aria-hidden="true" tabindex="-1"></a>ols.direct.HC1 <span class="ot">&lt;-</span> <span class="fu">vcovHC</span>(ols.direct,<span class="at">type=</span><span class="st">&#39;HC1&#39;</span>)</span></code></pre></div>
<p>The robust standard error using HC1 is thus 0.03, while the default standard error assuming homoskedasticity is 0.03.
The estimate obtained using Theorem <a href="OM.html#thm:AsympWWOLS10">5.4</a> directly is equal to 0.02.</p>
</div>
</div>
<div id="BiasOLS" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Properties of the OLS estimator under Conditional Independence<a href="OM.html#BiasOLS" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we have seen in Chapter <a href="RCT.html#RCT">3</a>, we could also have estimated <span class="math inline">\(TT\)</span> using a regression omitting the interaction between the treatment indicator and control variables.
With RCTs, this did not matter for the final result.
With Observational Methods, this might make a huge difference.
The reason is that the distribution of the observed covariates in the treatment and control group are the same in expectation in an RCT, while they are by essence different under Conditional Independence.
As a consequence, when we estimate a model by OLS which does not insert interactions of the covariates, we might end up with a different parameter than the one we are after.</p>
<p><a href="https://doi.org/10.1162/rest_a_00953">Sloczynski (2020)</a> studies this issue in great detail (<a href="http://arxiv.org/abs/2106.05024">Goldsmith-Pinkham, Hull and Kolesar (2022)</a> make also progress on this front, but in a more general way.)
In order to derive his result, <a href="https://doi.org/10.1162/rest_a_00953">Sloczynski (2020)</a> slightly strengthens the assumptions we have made so far, especially by making potential outcomes dependent on <span class="math inline">\(X_i\)</span> only through the propensity score: <span class="math inline">\(p(X_i)=\Pr(D_i=1|X_i)\)</span>.
<a href="https://doi.org/10.1162/rest_a_00953">Sloczynski (2020)</a>’s main result concerns <span class="math inline">\(\delta\)</span> estimated by OLS in the following regression:</p>
<p><span class="math display">\[\begin{align*}
        Y_i &amp;  = \alpha +  \beta&#39; X_i + \delta D_i + U_i.
\end{align*}\]</span></p>
<div class="theorem">
<p><span id="thm:OLSWeights" class="theorem"><strong>Theorem 5.5  (Weighted Average Interpretation of OLS) </strong></span>Under Assumptions <a href="OM.html#hyp:CIAExp">5.1</a>, <a href="OM.html#hyp:paramff0">5.3</a>, <a href="OM.html#hyp:paramff1">5.4</a>, <a href="OM.html#hyp:finitevarX">5.6</a> (modified to hold with <span class="math inline">\(p(X_i)\)</span> replacing <span class="math inline">\(X_i\)</span>) and assuming that <span class="math inline">\(\esp{Y_i^2}\)</span> and <span class="math inline">\(\esp{\lVert X_i^2 \rVert}\)</span> are finite and that the covariance matrix of <span class="math inline">\((D_i,X_i)\)</span> is non singular, we have <span class="math inline">\(\delta\)</span> in the previous equation when estimated by OLS equal to:</p>
<p><span class="math display">\[\begin{align*}
  \delta^{OLS} &amp; = w_1\Delta^Y_{TT}+w_0\Delta^Y_{TUT},
\end{align*}\]</span></p>
<p>with:</p>
<p><span class="math display">\[\begin{align*}
  w_1 &amp; = \frac{(1-p)\var{p(X_i)|D_i=0}}{p\var{p(X_i)|D_i=1}+(1-p)\var{p(X_i)|D_i=0}}\\
  w_0 &amp; = \frac{p\var{p(X_i)|D_i=1}}{p\var{p(X_i)|D_i=1}+(1-p)\var{p(X_i)|D_i=0}} = 1-w_1.
\end{align*}\]</span></p>
<p>and <span class="math inline">\(p=\Pr(D_i=1)\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-177" class="proof"><em>Proof</em>. </span>See <a href="https://doi.org/10.1162/rest_a_00953">Sloczynski (2020)</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-178" class="remark"><em>Remark</em>. </span>Theorem <a href="OM.html#thm:OLSWeights">5.5</a> shows that OLS without interactions between the treatment and the covariates is a weighted average of the effect of the treatment on the treated (<span class="math inline">\(TT\)</span>) and of the effect of the treatment on the untreated (<span class="math inline">\(TUT\)</span>).
This is thus not the parameter we are after.
Fortunately, the weights are positive and sum to one, so that we still find a weighted average of treatment effects with positive weights
Unfortunately, the weigths do not behave as we would like.
For example, <span class="math inline">\(w_1\)</span>, the weight on <span class="math inline">\(TT\)</span>, becomes larger as the proportion of the UNtreated increases.
This is inconvenient for estimating the <span class="math inline">\(ATE\)</span>.
It is also inco,venient for estimating <span class="math inline">\(TT\)</span>, since how close <span class="math inline">\(\delta^{OLS}\)</span> is to <span class="math inline">\(TT\)</span> depends on whether there are a lot of treated units in the population (in which case <span class="math inline">\(\delta^{OLS}\)</span> will be closer to <span class="math inline">\(TUT\)</span>) or not (in which case, <span class="math inline">\(\delta^{OLS}\)</span> will be closer to <span class="math inline">\(TT\)</span>).</p>
</div>
<div class="example">
<p><span id="exm:unnamed-chunk-307" class="example"><strong>Example 5.4  </strong></span>Let’s see how this result plays out in our example.
Note however than treatment effect heterogeneity might not be enough to alter our estimates strongly.</p>
</div>
<p>Let’s estimate a model without interactions:</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="OM.html#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="co"># running the OLS estimator without interactions</span></span>
<span id="cb268-2"><a href="OM.html#cb268-2" aria-hidden="true" tabindex="-1"></a>ols.simp <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>yB<span class="sc">+</span>Ds)</span>
<span id="cb268-3"><a href="OM.html#cb268-3" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate of TT</span></span>
<span id="cb268-4"><a href="OM.html#cb268-4" aria-hidden="true" tabindex="-1"></a>ww.ols.simp <span class="ot">&lt;-</span> ols.simp<span class="sc">$</span>coef[[<span class="dv">3</span>]]</span></code></pre></div>
<p>The estimate of <span class="math inline">\(TT\)</span> using the OLS regression without interactions is equal to 0.182, while our estimate obtained with the added interaction term is equal to 0.184.</p>
</div>
<div id="problems-with-parametric-methods" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Problems with parametric methods<a href="OM.html#problems-with-parametric-methods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When the conditional expectation of outcomes given the covariates is not linear, parametric methods which make this assumption will be erroneous.
We will talk of specification bias.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-308" class="example"><strong>Example 5.5  </strong></span>Let’s see why in our example:</p>
</div>
<p>We write outcomes as a non linear function of the pre-treatment covariate <span class="math inline">\(y_i^B\)</span>:</p>
<p><span class="math display">\[\begin{align*}
y^0_i &amp; =\mu_i+\delta+\gamma (y_i^B - \bar{y^B})^2 + U_i^0.
\end{align*}\]</span></p>
<p>Let’s choose some parameters:</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="OM.html#cb269-1" aria-hidden="true" tabindex="-1"></a>param <span class="ot">&lt;-</span> <span class="fu">c</span>(param,<span class="fl">0.1</span>,<span class="fl">7.98</span>)</span>
<span id="cb269-2"><a href="OM.html#cb269-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(param) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;barmu&quot;</span>,<span class="st">&quot;sigma2mu&quot;</span>,<span class="st">&quot;sigma2U&quot;</span>,<span class="st">&quot;barY&quot;</span>,<span class="st">&quot;rho&quot;</span>,<span class="st">&quot;theta&quot;</span>,<span class="st">&quot;sigma2epsilon&quot;</span>,<span class="st">&quot;sigma2eta&quot;</span>,<span class="st">&quot;delta&quot;</span>,<span class="st">&quot;baralpha&quot;</span>,<span class="st">&quot;gamma&quot;</span>,<span class="st">&quot;baryB&quot;</span>)</span></code></pre></div>
<p>and then simulate a dataset:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="OM.html#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb270-2"><a href="OM.html#cb270-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span><span class="dv">1000</span></span>
<span id="cb270-3"><a href="OM.html#cb270-3" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb270-4"><a href="OM.html#cb270-4" aria-hidden="true" tabindex="-1"></a>UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb270-5"><a href="OM.html#cb270-5" aria-hidden="true" tabindex="-1"></a>yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb270-6"><a href="OM.html#cb270-6" aria-hidden="true" tabindex="-1"></a>YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb270-7"><a href="OM.html#cb270-7" aria-hidden="true" tabindex="-1"></a>Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb270-8"><a href="OM.html#cb270-8" aria-hidden="true" tabindex="-1"></a>Ds[YB<span class="sc">&lt;=</span>param[<span class="st">&quot;barY&quot;</span>]] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb270-9"><a href="OM.html#cb270-9" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb270-10"><a href="OM.html#cb270-10" aria-hidden="true" tabindex="-1"></a>eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb270-11"><a href="OM.html#cb270-11" aria-hidden="true" tabindex="-1"></a>U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb270-12"><a href="OM.html#cb270-12" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb270-13"><a href="OM.html#cb270-13" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb270-14"><a href="OM.html#cb270-14" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb270-15"><a href="OM.html#cb270-15" aria-hidden="true" tabindex="-1"></a>Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb270-16"><a href="OM.html#cb270-16" aria-hidden="true" tabindex="-1"></a>Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb270-17"><a href="OM.html#cb270-17" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb270-18"><a href="OM.html#cb270-18" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span></code></pre></div>
<p>If we estimate the conditional expectation on the untreated population using a linear model, we are going to have biased predictions of the truth.
Let’s first estimate the regression function:</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="OM.html#cb271-1" aria-hidden="true" tabindex="-1"></a>ols.reg<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>]<span class="sc">~</span>yB[Ds<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb271-2"><a href="OM.html#cb271-2" aria-hidden="true" tabindex="-1"></a><span class="co"># predicted values for the treated</span></span>
<span id="cb271-3"><a href="OM.html#cb271-3" aria-hidden="true" tabindex="-1"></a>y.pred <span class="ot">&lt;-</span> ols.reg<span class="fl">.0</span><span class="sc">$</span>coef[[<span class="dv">1</span>]]<span class="sc">+</span>ols.reg<span class="fl">.0</span><span class="sc">$</span>coef[[<span class="dv">2</span>]]<span class="sc">*</span>yB[Ds<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb271-4"><a href="OM.html#cb271-4" aria-hidden="true" tabindex="-1"></a><span class="co"># estimated treatment effect by WWOLSX</span></span>
<span id="cb271-5"><a href="OM.html#cb271-5" aria-hidden="true" tabindex="-1"></a>ww.ols <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y.pred)</span>
<span id="cb271-6"><a href="OM.html#cb271-6" aria-hidden="true" tabindex="-1"></a><span class="co"># true value of TT in the sample</span></span>
<span id="cb271-7"><a href="OM.html#cb271-7" aria-hidden="true" tabindex="-1"></a>tt.sample <span class="ot">&lt;-</span> <span class="fu">mean</span>(alpha[Ds<span class="sc">==</span><span class="dv">1</span>])</span></code></pre></div>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="OM.html#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb272-2"><a href="OM.html#cb272-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb272-3"><a href="OM.html#cb272-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],ols.reg<span class="fl">.0</span><span class="sc">$</span>fitted.values,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb272-4"><a href="OM.html#cb272-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y.pred,<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb272-5"><a href="OM.html#cb272-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb272-6"><a href="OM.html#cb272-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb272-7"><a href="OM.html#cb272-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=0&#39;</span>)),<span class="fu">expression</span>(<span class="fu">hat</span>(<span class="st">&#39;y0|D=1&#39;</span>))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">3</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;black&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;blue&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotOLSNonLin"></span>
<img src="STCI_files/figure-html/PlotOLSNonLin-1.png" alt="Biased parametric estimator" width="65%" />
<p class="caption">
Figure 5.2: Biased parametric estimator
</p>
</div>
<p>We can see on Figure <a href="OM.html#fig:PlotOLSNonLin">5.2</a> that the predicted values for the potential outcomes of the treated in the absence of the treatment (<span class="math inline">\(\hatesp{y_i^0|D_i=1,y_i^B}\)</span>) based on the regression estimated on the untreated observations (in blue) are too low compared with the true values (in red).
As a consequence, the OLS estimator is going to over estimate the true effect of the treatment.
Indeed, the OLS estimate of the effect of the treatment is equal to 0.45 while the true value of the treatment effect in the sample is equal to 0.16.</p>
</div>
</div>
<div id="nonparametric-methods" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Nonparametric methods<a href="OM.html#nonparametric-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nonparametric observational methods enable to avoid (or at least mitigate) the issue of specification bias.
In exchange, they have stronger requirements than parametric methods in terms of comparability between treated and control observations.
The idea is that nonparametric methods rely on local comparisons to avoid specification bias.
For that, we need that treated and untreated observations overlap.
We call this assumption the Common Support Assumption, and it is required for nonparametric methods to solve the issue of specification bias.</p>
<div class="hypothesis">
<p><span id="hyp:comsupp" class="hypothesis"><strong>Hypothesis 5.7  (Common Support) </strong></span>We assume that, for the known set of observable covariates <span class="math inline">\(X_i\)</span> for which the Selection on Observables Assumption holds, we have:</p>
<p><span class="math display">\[\begin{align*}
0&lt;\Pr(D_i=1|X_i)&lt;1.
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unnamed-chunk-309" class="example"><strong>Example 5.6  </strong></span>Assumption <a href="OM.html#hyp:comsupp">5.7</a> does not hold on Figure <a href="OM.html#fig:PlotOLSNonLin">5.2</a>.
The probability of receiving treatment jumps discontinuously at <span class="math inline">\(y_i^B=\bar{y}\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(0\)</span>.</p>
</div>
<p>Let’s generate some data with common support.
For that, we are going to modify the selection equation to add some noise so that units with similar <span class="math inline">\(y_i^B\)</span> might end up treated or untreated:</p>
<p><span class="math display">\[\begin{align*}
D_i &amp; = \uns{y_i^B+V_i\leq\bar{y}} \\
V_i &amp; \Ind Y_i^0 \\
V_i &amp; \sim\mathcal{N}(0,\sigma^2_{\mu}+\sigma^2_{U})
\end{align*}\]</span></p>
<p>Let’s now generate some data following this new selection equation:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="OM.html#cb273-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb273-2"><a href="OM.html#cb273-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb273-3"><a href="OM.html#cb273-3" aria-hidden="true" tabindex="-1"></a>UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb273-4"><a href="OM.html#cb273-4" aria-hidden="true" tabindex="-1"></a>yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb273-5"><a href="OM.html#cb273-5" aria-hidden="true" tabindex="-1"></a>YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb273-6"><a href="OM.html#cb273-6" aria-hidden="true" tabindex="-1"></a>Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb273-7"><a href="OM.html#cb273-7" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb273-8"><a href="OM.html#cb273-8" aria-hidden="true" tabindex="-1"></a>Ds[yB<span class="sc">+</span>V<span class="sc">&lt;=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb273-9"><a href="OM.html#cb273-9" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb273-10"><a href="OM.html#cb273-10" aria-hidden="true" tabindex="-1"></a>eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb273-11"><a href="OM.html#cb273-11" aria-hidden="true" tabindex="-1"></a>U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb273-12"><a href="OM.html#cb273-12" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb273-13"><a href="OM.html#cb273-13" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb273-14"><a href="OM.html#cb273-14" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb273-15"><a href="OM.html#cb273-15" aria-hidden="true" tabindex="-1"></a>Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb273-16"><a href="OM.html#cb273-16" aria-hidden="true" tabindex="-1"></a>Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb273-17"><a href="OM.html#cb273-17" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb273-18"><a href="OM.html#cb273-18" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span></code></pre></div>
<p>Let’s plot this new dataset and examine it for common support:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="OM.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">5</span>))</span>
<span id="cb274-2"><a href="OM.html#cb274-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb274-3"><a href="OM.html#cb274-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb274-4"><a href="OM.html#cb274-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>]),<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb274-5"><a href="OM.html#cb274-5" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="fl">10.5</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="st">&#39;D&#39;</span>),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>),<span class="at">col=</span><span class="fu">c</span>(col.obs,<span class="st">&#39;blue&#39;</span>,col.unobs),<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb274-6"><a href="OM.html#cb274-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">new=</span><span class="cn">TRUE</span>)</span>
<span id="cb274-7"><a href="OM.html#cb274-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB,Ds,<span class="at">pch=</span><span class="dv">2</span>,<span class="at">col=</span>col.unobs,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb274-8"><a href="OM.html#cb274-8" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>)</span>
<span id="cb274-9"><a href="OM.html#cb274-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;D&quot;</span>,<span class="at">side=</span><span class="dv">4</span>,<span class="at">line=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotComSupp"></span>
<img src="STCI_files/figure-html/PlotComSupp-1.png" alt="Common Support Holds" width="65%" />
<p class="caption">
Figure 5.3: Common Support Holds
</p>
</div>
<p>Figure <a href="OM.html#fig:PlotComSupp">5.3</a> shows that we now have treated and untreated units on both sides of <span class="math inline">\(y_i^B=\bar{y}\)</span>.
Before we move to the identification of <span class="math inline">\(TT\)</span> under Assumption <a href="OM.html#hyp:comsupp">5.7</a>, we need to compute the true value of the <span class="math inline">\(TT\)</span> parameter in the population in our new example:
Because we have changed the selection rule, the value of <span class="math inline">\(TT\)</span> in the population has changed also:</p>
<p><span class="math display">\[\begin{align*}
\Delta_{TT}^y &amp; =\bar{\alpha}+\theta\bar{\mu} -\theta\frac{\sigma^2_{\mu}}{\sqrt{2(\sigma^2_{\mu}+\sigma^2_{U})}}\frac{\phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{2(\sigma^2_{\mu}+\sigma^2_{U})}}\right)}{\Phi\left(\frac{\bar{y}-\bar{\mu}}{\sqrt{2(\sigma^2_{\mu}+\sigma^2_{U})}}\right)}.
\end{align*}\]</span></p>
<p>Let’s write a fiunction to compute this parameter:</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="OM.html#cb275-1" aria-hidden="true" tabindex="-1"></a>delta.y.tt.com.supp <span class="ot">&lt;-</span> <span class="cf">function</span>(param){</span>
<span id="cb275-2"><a href="OM.html#cb275-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>param[<span class="st">&quot;barmu&quot;</span>]<span class="sc">-</span>param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>((param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">*</span><span class="fu">dnorm</span>((<span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="sc">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="sc">/</span>(<span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))))<span class="sc">/</span>(<span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))<span class="sc">*</span><span class="fu">pnorm</span>((<span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])<span class="sc">-</span>param[<span class="st">&quot;barmu&quot;</span>])<span class="sc">/</span>(<span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>])))))))</span>
<span id="cb275-3"><a href="OM.html#cb275-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb275-4"><a href="OM.html#cb275-4" aria-hidden="true" tabindex="-1"></a>delta.y.tt.CS.pop <span class="ot">&lt;-</span> <span class="fu">delta.y.tt.com.supp</span>(param)</span></code></pre></div>
<p>The value of <span class="math inline">\(TT\)</span> in the population in our new example is 0.18.</p>
<div id="identification-12" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Identification<a href="OM.html#identification-12" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s now derive identification of <span class="math inline">\(TT\)</span>:</p>
<div class="theorem">
<p><span id="thm:socsid" class="theorem"><strong>Theorem 5.6  (Identification of TT Under Conditional Independence and Common Support) </strong></span>Under Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> (or the stronger <a href="OM.html#hyp:CIA">5.2</a>) and <a href="OM.html#hyp:comsupp">5.7</a>, <span class="math inline">\(TT\)</span> is identified using either a nonparametric regression approach or a reweighting approach:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{TT} &amp; = \Delta^Y_{NPR(X)}  = \Delta^Y_{RW(X)}, 
\end{align*}\]</span></p>
<p>with:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{NPR(X)} &amp; = \esp{Y_i-\esp{Y_i|X_i,D_i=0}|D_i=1} \\
\Delta^Y_{RW(X)}  &amp; = \esp{Y_i|D_i=1} \\
                  &amp; \phantom{=} -\esp{Y_i\frac{\Pr(D_i=1|X_i)}{1-\Pr(D_i=1|X_i)}\frac{1-\Pr(D_i=1)}{\Pr(D_i=1)}|D_i=0}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-179" class="proof"><em>Proof</em>. </span>Let us start with the first equality:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{NPR(X)} &amp; = \esp{Y_i-\esp{Y_i|X_i,D_i=0}|D_i=1} \\
                  &amp; = \esp{Y_i|D_i=1}-\esp{\esp{Y_i|X_i,D_i=0}|D_i=1}\\
                  &amp; = \esp{Y^1_i|D_i=1}- \esp{\esp{Y^0_i|X_i,D_i=0}|D_i=1} \\
                  &amp; = \esp{Y^1_i|D_i=1}- \esp{\esp{Y^0_i|X_i,D_i=1}|D_i=1} \\
                  &amp; = \esp{Y^1_i|D_i=1}- \esp{Y^0_i|D_i=1} \\
                  &amp; = \Delta^Y_{TT},
\end{align*}\]</span></p>
<p>where the second equality follows from the linearity of linear expectations, the fourth equality follows from Assumptions <a href="OM.html#hyp:CIAExp">5.1</a> and <a href="OM.html#hyp:comsupp">5.7</a> and the fifth equality follows from the Law of Iterated Expectations.</p>
<p>Let us now examine the second equality:</p>
<p><span class="math display">\[\begin{align*}
\Delta^Y_{RW(X)}-\esp{Y_i|D_i=1}  &amp; = \esp{Y_i\frac{\Pr(D_i=1|X_i)}{1-\Pr(D_i=1|X_i)}\frac{1-\Pr(D_i=1)}{\Pr(D_i=1)}|D_i=0} \\
                 &amp; = \frac{1}{\Pr(D_i=1)}\esp{Y^0_i(1-D_i)\frac{\Pr(D_i=1|X_i)}{1-\Pr(D_i=1|X_i)}} \\
                             &amp; = \frac{1}{\Pr(D_i=1)}\esp{\esp{Y^0_i(1-D_i)\frac{\Pr(D_i=1|X_i)}{1-\Pr(D_i=1|X_i)}|X_i}}\\
                                &amp; = \frac{1}{\Pr(D_i=1)}\esp{\esp{Y_i^0|X_i}(1-\Pr(D_i=1|X_i))\frac{\Pr(D_i=1|X_i)}{1-\Pr(D_i=1|X_i)}} \\
                                &amp; = \frac{1}{\Pr(D_i=1)}\esp{\esp{Y_i^0|X_i}\Pr(D_i=1|X_i)}\\
                                &amp; = \frac{1}{\Pr(D_i=1)}\esp{\esp{Y_i^0D_i|X_i}}\\
                                &amp; =\frac{1}{\Pr(D_i=1)}\esp{Y_i^0D_i} \\
                                &amp; =\frac{1}{\Pr(D_i=1)}\esp{Y_i^0|D_i=1}\Pr(D_i=1)\\
                                &amp; = \esp{Y_i^0|D_i=1},
\end{align*}\]</span></p>
<p>where Assumption <a href="OM.html#hyp:comsupp">5.7</a> ensures that <span class="math inline">\(\Delta^Y_{RW(X)}\)</span> is well-defined, the third and seven equalities follow from the Law of Iterated Expectations, and the fourth and sixth equalities use Assumption <a href="OM.html#hyp:CIAExp">5.1</a>.</p>
</div>
<p>Theorem <a href="OM.html#thm:socsid">5.6</a> shows that we can identify the effect of the treatment on the treated in the population under Conditional Independence (and Common Support) by adopting one of two approaches.
With the regression-based approach, untreated observations help us estimate the predicted value of the treated with the same values of the observed covariates <span class="math inline">\(X_i\)</span>.
This is very similar to what we did with the <span class="math inline">\(OLS(X)\)</span> estimator above.
The only exception is that we do not use a parametric model to predict the counterfactual value of the outcome of the untreated.</p>
<p>With the reweighting approach, we use the propensity score <span class="math inline">\(\Pr(D_i=1|X_i)\)</span> to reweight all untreated observations so that the weighted expectation is equal to those that the treated would have had absent the treatment.
Reweighting puts more weight on the untreated observations that have a large probability of being treated: they resemble the treated a lot in terms of their observed covariates and thus inform us on what would have happened to the treated in the absence of the treatment.</p>
</div>
<div id="estimation-8" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Estimation<a href="OM.html#estimation-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do we implement matching estimators in practice?
There are almost zillions of way to implement them.
What’s nice is that mosst (all?) of them can be written as a reweighting estimator:</p>
<p><span class="math display">\[\begin{align*}
\hat{\Delta}^Y_{M} &amp; = \frac{1}{N_1^S}\sum_{i\in\mathcal{I}^1\cap S}\left(Y_i-\sum_{j\in\mathcal{I}^0}w_{i,j}Y_j\right)
\end{align*}\]</span></p>
<p>with <span class="math inline">\(\mathcal{I}^1\)</span> is the set of treated individuals, <span class="math inline">\(\mathcal{I}^0\)</span> the set of untreated individuals, <span class="math inline">\(S\)</span> the set of individuals lying on the common support and <span class="math inline">\(N_1^S\)</span> the number of treated on the common support.
Each specific estimator differs on how it computes the weights <span class="math inline">\(w_{i,j}\)</span> and how it chooses the set of observations in the common support <span class="math inline">\(S\)</span>.</p>
<p>Here are the methods we are going to detail in this section:</p>
<ul>
<li>Local Regression Matching (on the propensity score)</li>
<li>Local Averaging Matching</li>
<li>Nearest Neighbor Matching</li>
<li>Reweighting Matching</li>
<li>Doubly Robust Matching</li>
</ul>
<div id="local-regression-matching-on-the-propensity-score" class="section level4 hasAnchor" number="5.2.2.1">
<h4><span class="header-section-number">5.2.2.1</span> Local Regression Matching (on the Propensity Score)<a href="OM.html#local-regression-matching-on-the-propensity-score" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The idea of Local Regression Matching is very simple: run a separate regression for each treated observation using only untreated observations that are close enough to it.
Closeness is defined by a bandwidth, or a window around the treated observation of interest.
In order to be more efficient, more weight is given to untreated observations that lie closer to the treated observation.
Weights are given using a kernel function.</p>
<p>The key difficulty is what to do when the number of covariates is more than one (as it will very likely happen).
How do you define close observations then?
There are several possible approaches to that issue.
One is to use multivariate kernel functions (generally after standardizing covariates so that bandwidth choice is similar for all covariates).
Another approach more heavily used in practice is to summarize the influence of observed covariates on selection by using the propensity score.
A very nice result shows that conditioning on the propensity score is similar for estimating the <span class="math inline">\(TT\)</span> as conditioning on all the covariates.
The propensity score is also very useful to build the set of observations that lie on the common support.</p>
<p>Let’s first study the Local Regression Matching and then add the propensity score to the mix.</p>
<div id="local-regression-matching" class="section level5 hasAnchor" number="5.2.2.1.1">
<h5><span class="header-section-number">5.2.2.1.1</span> Local Regression Matching<a href="OM.html#local-regression-matching" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In practice, with LLR, <span class="math inline">\(\sum_{j\in\mathcal{I}^0}w_{i,j}Y_j=\hatesp{Y_i|X_i,D_i=0}\)</span> is equal to <span class="math inline">\(\hat{\theta_0}\)</span> estimated by weighted OLS in the following regression on the sample of untreated individuals</p>
<p><span class="math display">\[\begin{align*}
Y_j  = \theta_0 + (X_i-X_j)\theta_1 + \epsilon_j,
\end{align*}\]</span></p>
<p>with weights <span class="math inline">\(K\left(\frac{X_i-X_j}{h}\right)\)</span>, where <span class="math inline">\(h\)</span> is the bandwidth and <span class="math inline">\(K\)</span> is a kernel function.
Using some algebra, on can show, in the case of one-dimensional covariate <span class="math inline">\(X_i\)</span>, that the weights of LLR are as follows (<a href="https://www.jstor.org/stable/2290637">Fan (1992)</a> and <a href="https://doi.org/10.1016/j.jeconom.2004.04.011">Smith and Todd (2005)</a>):</p>
<p><span class="math display">\[\begin{align*}
w_{i,j} &amp; =\frac{K_{i,j}\sum^{}_{k\in \mathcal{I}_0}K_{i,k}(X_k-X_i)^2-[K_{i,j}(X_j-X_i)][\sum_{k\in \mathcal{I}_0}^{}K_{i,k}(X_k-X_i)]}{\sum_{j\in \mathcal{I}_0}^{}K_{i,j}\sum_{k\in \mathcal{I}_0}^{}K_{i,k}(X_k-X_i)^2-[\sum_{k\in \mathcal{I}_0}^{}K_{i,k}(X_k-X_i)]^2}
\end{align*}\]</span></p>
<p>with <span class="math inline">\(K_{i,j}=K\left(\frac{X_i-X_j}{h}\right)\)</span>.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-311" class="example"><strong>Example 5.7  </strong></span>Let us see how this works in our example.</p>
</div>
<p>Let us now run the LLR regression on the untreated sample, using as grid points all the observations in the treated sample, and let us then compute the estimated <span class="math inline">\(TT\)</span>, with two candidates for the bandwidth:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="OM.html#cb276-1" aria-hidden="true" tabindex="-1"></a>kernel <span class="ot">&lt;-</span> <span class="st">&#39;gaussian&#39;</span></span>
<span id="cb276-2"><a href="OM.html#cb276-2" aria-hidden="true" tabindex="-1"></a>bw <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb276-3"><a href="OM.html#cb276-3" aria-hidden="true" tabindex="-1"></a><span class="co"># run LLR on the untreated sample using treated points as grid points</span></span>
<span id="cb276-4"><a href="OM.html#cb276-4" aria-hidden="true" tabindex="-1"></a>y0.llr<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">llr</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>],yB[Ds<span class="sc">==</span><span class="dv">0</span>],yB[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)    </span>
<span id="cb276-5"><a href="OM.html#cb276-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compute TT</span></span>
<span id="cb276-6"><a href="OM.html#cb276-6" aria-hidden="true" tabindex="-1"></a>ww.llr<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y0.llr<span class="fl">.1</span>)</span>
<span id="cb276-7"><a href="OM.html#cb276-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-8"><a href="OM.html#cb276-8" aria-hidden="true" tabindex="-1"></a>bw <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb276-9"><a href="OM.html#cb276-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run LLR on the untreated sample using treated points as grid points</span></span>
<span id="cb276-10"><a href="OM.html#cb276-10" aria-hidden="true" tabindex="-1"></a>y0.llr.<span class="fl">0.5</span> <span class="ot">&lt;-</span> <span class="fu">llr</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>],yB[Ds<span class="sc">==</span><span class="dv">0</span>],yB[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)    </span>
<span id="cb276-11"><a href="OM.html#cb276-11" aria-hidden="true" tabindex="-1"></a><span class="co"># compute TT</span></span>
<span id="cb276-12"><a href="OM.html#cb276-12" aria-hidden="true" tabindex="-1"></a>ww.llr.<span class="fl">0.5</span> <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y0.llr.<span class="fl">0.5</span>)</span></code></pre></div>
<p>Let us now visualize how these estimates look like:</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="OM.html#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB[Ds<span class="sc">==</span><span class="dv">0</span>],y0[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">11</span>),<span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>)</span>
<span id="cb277-2"><a href="OM.html#cb277-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb277-3"><a href="OM.html#cb277-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0.llr<span class="fl">.1</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb277-4"><a href="OM.html#cb277-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y0.llr.<span class="fl">0.5</span>,<span class="at">col=</span><span class="st">&#39;green&#39;</span>)</span>
<span id="cb277-5"><a href="OM.html#cb277-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(yB[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>)</span>
<span id="cb277-6"><a href="OM.html#cb277-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">5</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(y0<span class="fl">.1</span>)),<span class="fu">expression</span>(<span class="fu">hat</span>(y0.<span class="fl">0.5</span>)),<span class="st">&#39;y|D=1&#39;</span>),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;green&#39;</span>,<span class="st">&#39;black&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotLLRStep2"></span>
<img src="STCI_files/figure-html/PlotLLRStep2-1.png" alt="LLR Matching estimates" width="65%" />
<p class="caption">
Figure 5.4: LLR Matching estimates
</p>
</div>
<p>The LLR Matching estimate is equal to 0.192 with a bandwidth of <span class="math inline">\(1\)</span> and to 0.164 with a bandwidth of <span class="math inline">\(0.5\)</span>, while the true value of the parameter in the population is equal to 0.175.</p>
<p>Let us see how this estimator behaves over sample replications:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="OM.html#cb278-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LLR matching fnciton</span></span>
<span id="cb278-2"><a href="OM.html#cb278-2" aria-hidden="true" tabindex="-1"></a>llr.match <span class="ot">&lt;-</span> <span class="cf">function</span>(y,D,x,bw,kernel){</span>
<span id="cb278-3"><a href="OM.html#cb278-3" aria-hidden="true" tabindex="-1"></a>  y0.llr <span class="ot">&lt;-</span> <span class="fu">llr</span>(y[D<span class="sc">==</span><span class="dv">0</span>],x[D<span class="sc">==</span><span class="dv">0</span>],x[D<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb278-4"><a href="OM.html#cb278-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(y[D<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y0.llr))</span>
<span id="cb278-5"><a href="OM.html#cb278-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb278-6"><a href="OM.html#cb278-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-7"><a href="OM.html#cb278-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Monte Carlos</span></span>
<span id="cb278-8"><a href="OM.html#cb278-8" aria-hidden="true" tabindex="-1"></a>monte.carlo.llr <span class="ot">&lt;-</span> <span class="cf">function</span>(s,N,param,bw,kernel){</span>
<span id="cb278-9"><a href="OM.html#cb278-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb278-10"><a href="OM.html#cb278-10" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb278-11"><a href="OM.html#cb278-11" aria-hidden="true" tabindex="-1"></a>  UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb278-12"><a href="OM.html#cb278-12" aria-hidden="true" tabindex="-1"></a>  yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb278-13"><a href="OM.html#cb278-13" aria-hidden="true" tabindex="-1"></a>  YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb278-14"><a href="OM.html#cb278-14" aria-hidden="true" tabindex="-1"></a>  Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb278-15"><a href="OM.html#cb278-15" aria-hidden="true" tabindex="-1"></a>  V <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb278-16"><a href="OM.html#cb278-16" aria-hidden="true" tabindex="-1"></a>  Ds[yB<span class="sc">+</span>V<span class="sc">&lt;=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb278-17"><a href="OM.html#cb278-17" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb278-18"><a href="OM.html#cb278-18" aria-hidden="true" tabindex="-1"></a>  eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb278-19"><a href="OM.html#cb278-19" aria-hidden="true" tabindex="-1"></a>  U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb278-20"><a href="OM.html#cb278-20" aria-hidden="true" tabindex="-1"></a>  y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb278-21"><a href="OM.html#cb278-21" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb278-22"><a href="OM.html#cb278-22" aria-hidden="true" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb278-23"><a href="OM.html#cb278-23" aria-hidden="true" tabindex="-1"></a>  Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb278-24"><a href="OM.html#cb278-24" aria-hidden="true" tabindex="-1"></a>  Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb278-25"><a href="OM.html#cb278-25" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb278-26"><a href="OM.html#cb278-26" aria-hidden="true" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb278-27"><a href="OM.html#cb278-27" aria-hidden="true" tabindex="-1"></a>  ww.llr <span class="ot">&lt;-</span> <span class="fu">llr.match</span>(y,Ds,yB,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb278-28"><a href="OM.html#cb278-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ww.llr)</span>
<span id="cb278-29"><a href="OM.html#cb278-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb278-30"><a href="OM.html#cb278-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-31"><a href="OM.html#cb278-31" aria-hidden="true" tabindex="-1"></a>simuls.llr.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,bw,kernel){</span>
<span id="cb278-32"><a href="OM.html#cb278-32" aria-hidden="true" tabindex="-1"></a>  simuls.llr <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.llr,<span class="at">N=</span>N,<span class="at">param=</span>param,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb278-33"><a href="OM.html#cb278-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(simuls.llr) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;LLR&#39;</span>)</span>
<span id="cb278-34"><a href="OM.html#cb278-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(simuls.llr)</span>
<span id="cb278-35"><a href="OM.html#cb278-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb278-36"><a href="OM.html#cb278-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-37"><a href="OM.html#cb278-37" aria-hidden="true" tabindex="-1"></a>sf.simuls.llr.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,bw,kernel){</span>
<span id="cb278-38"><a href="OM.html#cb278-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb278-39"><a href="OM.html#cb278-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfExport</span>(<span class="st">&#39;llr.match&#39;</span>,<span class="st">&#39;llr&#39;</span>)</span>
<span id="cb278-40"><a href="OM.html#cb278-40" aria-hidden="true" tabindex="-1"></a>  sim.llr <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.llr,<span class="at">N=</span>N,<span class="at">param=</span>param,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb278-41"><a href="OM.html#cb278-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb278-42"><a href="OM.html#cb278-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.llr) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;LLR&#39;</span>)</span>
<span id="cb278-43"><a href="OM.html#cb278-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.llr)</span>
<span id="cb278-44"><a href="OM.html#cb278-44" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb278-45"><a href="OM.html#cb278-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-46"><a href="OM.html#cb278-46" aria-hidden="true" tabindex="-1"></a>Nsim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb278-47"><a href="OM.html#cb278-47" aria-hidden="true" tabindex="-1"></a><span class="co">#Nsim &lt;- 10</span></span>
<span id="cb278-48"><a href="OM.html#cb278-48" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000,100000)</span></span>
<span id="cb278-49"><a href="OM.html#cb278-49" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000)</span></span>
<span id="cb278-50"><a href="OM.html#cb278-50" aria-hidden="true" tabindex="-1"></a>N.sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>)</span>
<span id="cb278-51"><a href="OM.html#cb278-51" aria-hidden="true" tabindex="-1"></a><span class="co">#simuls.llr &lt;- lapply(N.sample,simuls.llr.N,Nsim=Nsim,param=param,bw=bw,kernel=kernel)</span></span>
<span id="cb278-52"><a href="OM.html#cb278-52" aria-hidden="true" tabindex="-1"></a>simuls.llr <span class="ot">&lt;-</span> <span class="fu">lapply</span>(N.sample,sf.simuls.llr.N,<span class="at">Nsim=</span>Nsim,<span class="at">param=</span>param,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb278-53"><a href="OM.html#cb278-53" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(simuls.llr) <span class="ot">&lt;-</span> N.sample</span></code></pre></div>
<p>Let us now plot the resulting estimates:</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="OM.html#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb279-2"><a href="OM.html#cb279-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(simuls.llr)){</span>
<span id="cb279-3"><a href="OM.html#cb279-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(simuls.llr[[i]][,<span class="st">&#39;LLR&#39;</span>],<span class="at">main=</span><span class="fu">paste</span>(<span class="st">&#39;N=&#39;</span>,<span class="fu">as.character</span>(N.sample[i])),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">hat</span>(Delta<span class="sc">^</span>yLLR)),<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.15</span>,<span class="fl">0.55</span>))</span>
<span id="cb279-4"><a href="OM.html#cb279-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v=</span><span class="fu">delta.y.tt.com.supp</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb279-5"><a href="OM.html#cb279-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:HistMCLLRMatch"></span>
<img src="STCI_files/figure-html/HistMCLLRMatch-1.png" alt="Distribution of the $LLR$ estimator over replications of samples of different sizes" width="65%" />
<p class="caption">
Figure 5.5: Distribution of the <span class="math inline">\(LLR\)</span> estimator over replications of samples of different sizes
</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-180" class="remark"><em>Remark</em>. </span>On key limitation of the LLR Matching estimator that we have studies so far is the fact that it requires the use on only one covariate.
What to do when there is more than one covariate?
There are basically two solutions.
One is to use multidimensional kernels, which are simply products of unidimensionnal kernel functions.
In order to make things simpler, we generally standardize variables so that their dimensions are similar.
Another approach is to use the propensity score as a dimension reduction device.</p>
</div>
</div>
<div id="local-regression-matching-on-the-propensity-score-1" class="section level5 hasAnchor" number="5.2.2.1.2">
<h5><span class="header-section-number">5.2.2.1.2</span> Local Regression Matching on the Propensity Score<a href="OM.html#local-regression-matching-on-the-propensity-score-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The propensity score, which we denote <span class="math inline">\(P(X_i)\)</span>, is the probability that a unit is treated given its observed covariates: <span class="math inline">\(P(X_i)=\Pr(D_i=1|X_i)\)</span>.
The key results that enables us to use the propensity score as dimension reduction device has been introduced by <a href="">Rosenbaum and Rubin (1983)</a>:</p>
<div class="theorem">
<p><span id="thm:PScoreSuff" class="theorem"><strong>Theorem 5.7  (Sufficiency of Propensity Score) </strong></span><span class="math inline">\((Y_i^1,Y_i^0)\Ind D_i|X_i \Rightarrow (Y_i^1,Y_i^0)\Ind D_i|P(X_i)\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-181" class="proof"><em>Proof</em>. </span><span class="math display">\[\begin{align*}
\Pr(D_i=1|Y_i^1,Y_i^0,P(X_i)) &amp; = \esp{\Pr(D_i=1|Y_i^1,Y_i^0,X_i)|Y_i^1,Y_i^0,P(X_i)} \\
                                                            &amp; = \esp{\Pr(D_i=1|X_i)|Y_i^1,Y_i^0,P(X_i)} \\
                                                            &amp; = P(X_i) = \Pr(D_i=1|X_i),
\end{align*}\]</span></p>
<p>where the first equality uses the Law of Iterated Expectations and the second one uses <span class="math inline">\((Y_i^1,Y_i^0)\Ind D_i|X_i\)</span>.</p>
</div>
<p>In practice, in order to estimate LLR Matching using the propensity score, you can follow the following steps:</p>
<ul>
<li>Estimate a logit or probit regression: <span class="math inline">\(D_i = \uns{\gamma_0 + \gamma_1&#39;X_i + \zeta_i&gt;0}\)</span> (you might use series or splines to be more non-parametric here)</li>
<li>Compute the predicted values (which are estimates of the propensity score): <span class="math inline">\(\hat{P}(X_i)\)</span> (you could also directly use multivariate non-parametric regression at this stage)</li>
<li>Use <span class="math inline">\(\hat{P}(X_i)\)</span> as control variable in LLR Matching.</li>
</ul>
<div class="example">
<p><span id="exm:unnamed-chunk-314" class="example"><strong>Example 5.8  </strong></span>Let’s see how this works in our example.</p>
</div>
<p>First, we need to estimate the propensity score.
We are going to use a probit estimator, but things would be much similar with a logit.
The most important assumption is the linearity of the link function.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="OM.html#cb280-1" aria-hidden="true" tabindex="-1"></a>probit.Ds <span class="ot">&lt;-</span> <span class="fu">glm</span>(Ds<span class="sc">~</span>yB, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;probit&quot;</span>))</span>
<span id="cb280-2"><a href="OM.html#cb280-2" aria-hidden="true" tabindex="-1"></a>pscore <span class="ot">&lt;-</span> <span class="fu">predict</span>(probit.Ds,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<p>Let us now see how the propensity score looks like as a function of <span class="math inline">\(y_i^B\)</span>:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="OM.html#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yB,pscore, <span class="at">xlab=</span><span class="st">&quot;yB&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Propensity score&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotPscore"></span>
<img src="STCI_files/figure-html/PlotPscore-1.png" alt="Propensity score as a function of $y_i^B$" width="65%" />
<p class="caption">
Figure 5.6: Propensity score as a function of <span class="math inline">\(y_i^B\)</span>
</p>
</div>
<p>Let us now compute the LLR Matching estimator using the propensity score.</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="OM.html#cb282-1" aria-hidden="true" tabindex="-1"></a>bw <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb282-2"><a href="OM.html#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="co"># run LLR on the untreated sample using treated points as grid points</span></span>
<span id="cb282-3"><a href="OM.html#cb282-3" aria-hidden="true" tabindex="-1"></a>y0.llr.pscore.<span class="fl">0.1</span> <span class="ot">&lt;-</span> <span class="fu">llr</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>],pscore[Ds<span class="sc">==</span><span class="dv">0</span>],pscore[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)    </span>
<span id="cb282-4"><a href="OM.html#cb282-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute TT</span></span>
<span id="cb282-5"><a href="OM.html#cb282-5" aria-hidden="true" tabindex="-1"></a>ww.llr.pscore.<span class="fl">0.1</span> <span class="ot">&lt;-</span> <span class="fu">llr.match</span>(y,Ds,pscore,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span></code></pre></div>
<p>Let’s see how the LLR estimator using the propensity score works:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="OM.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>],y[Ds<span class="sc">==</span><span class="dv">0</span>], <span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Propensity score&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">12</span>))</span>
<span id="cb283-2"><a href="OM.html#cb283-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb283-3"><a href="OM.html#cb283-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb283-4"><a href="OM.html#cb283-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y0.llr.pscore.<span class="fl">0.1</span>,<span class="at">col=</span><span class="st">&#39;green&#39;</span>)</span>
<span id="cb283-5"><a href="OM.html#cb283-5" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="fl">0.7</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(y0.<span class="fl">0.1</span>))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;green&#39;</span>),<span class="at">ncol=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotPscorePO"></span>
<img src="STCI_files/figure-html/PlotPscorePO-1.png" alt="Propensity score and potential outcomes" width="65%" />
<p class="caption">
Figure 5.7: Propensity score and potential outcomes
</p>
</div>
<p>The estimated value of the <span class="math inline">\(TT\)</span> parameter using LLR Matching on the propensity score is equal to 0.139.
Remember that the LLR Matching estimate using <span class="math inline">\(y_i^B\)</span> directly is equal to 0.192 with a bandwidth of <span class="math inline">\(1\)</span> and to 0.164 with a bandwidth of <span class="math inline">\(0.5\)</span>, while the true value of the parameter in the population is equal to 0.175.</p>
<div class="remark">
<p><span id="unlabeled-div-182" class="remark"><em>Remark</em>. </span>We have not seen how to choose the bandwidth optimally.
A second thing we are missing is what to do when the density of the pscore is too low and the common support assumption almost does not hold.</p>
</div>
</div>
<div id="bandwidth-choice" class="section level5 hasAnchor" number="5.2.2.1.3">
<h5><span class="header-section-number">5.2.2.1.3</span> Bandwidth choice<a href="OM.html#bandwidth-choice" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Choosing a bandwidth can be done using one of two approaches.
The smaller the bandwidth, the less biased the estimate is, but also the more noisy.
With a larger bandwidth, bias increases, but noise decreases.
This is the usual Bias/Variance trade-off in nonparametric estimation.
<a href="https://link.springer.com/article/10.1007/s11222-005-1309-6">Frolich (2005)</a> derives formulae based on the asymptotic distribution of the LLR Matching estimator to help choose the optimal bandwidth.
The problem is that these formulae are complex and they are not very precise (the criteria is flat in the bandwidth).</p>
<p>In general, we thus prefer to use use Cross-Validation.
Cross validation estimates the MSE using leave-one out estimation and searches for the bandwidth having the lower MSE.
<a href="https://www.jstor.org/stable/27917245">Galdo, Smith and Black (2008)</a> suggest to weighted the MSE search by importance of the treated.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-316" class="example"><strong>Example 5.9  </strong></span>Let’s see how this works in our example.</p>
</div>
<p>Let us first (re)define a function to compute the MSE and then compute is:</p>
<p>Let us now plot the link between bandwidth and MSE and what the prediction looks like:</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="OM.html#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(MSE.grid.pscore[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>],MSE.pscore[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">xlab=</span><span class="st">&quot;Bandwidth&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;MSE&quot;</span>)</span>
<span id="cb284-2"><a href="OM.html#cb284-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb284-3"><a href="OM.html#cb284-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>],y[Ds<span class="sc">==</span><span class="dv">0</span>], <span class="at">ylab=</span><span class="st">&quot;Outcomes&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Propensity score&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">12</span>))</span>
<span id="cb284-4"><a href="OM.html#cb284-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb284-5"><a href="OM.html#cb284-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y0[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">pch=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb284-6"><a href="OM.html#cb284-6" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y0.llr.pscore.<span class="fl">0.1</span>,<span class="at">col=</span><span class="st">&#39;green&#39;</span>)</span>
<span id="cb284-7"><a href="OM.html#cb284-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],y0.llr.pscore.bw,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb284-8"><a href="OM.html#cb284-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="fl">0.7</span>,<span class="dv">11</span>,<span class="fu">c</span>(<span class="st">&#39;y0|D=0&#39;</span>,<span class="st">&#39;y1|D=1&#39;</span>,<span class="st">&#39;y0|D=1&#39;</span>,<span class="fu">expression</span>(<span class="fu">hat</span>(y0.<span class="fl">0.1</span>)),<span class="fu">expression</span>(<span class="fu">hat</span>(y0.bw))),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;red&#39;</span>,<span class="st">&#39;green&#39;</span>,<span class="st">&#39;blue&#39;</span>),<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotLLRCV"></span>
<img src="STCI_files/figure-html/PlotLLRCV-1.png" alt="LLR Matching on the propensity score with an optimal bandwidth" width="45%" /><img src="STCI_files/figure-html/PlotLLRCV-2.png" alt="LLR Matching on the propensity score with an optimal bandwidth" width="45%" />
<p class="caption">
Figure 5.8: LLR Matching on the propensity score with an optimal bandwidth
</p>
</div>
<p>With the optimal bandwidth, the estimated value of the <span class="math inline">\(TT\)</span> parameter using LLR Matching on the propensity score is equal to 0.17.
Remember that the LLR Matching on the propensity score estimate using a bandwidth of <span class="math inline">\(0.1\)</span> is equal to 0.139.
Using LLR Matching on <span class="math inline">\(y_i^B\)</span> directly, the estimated <span class="math inline">\(TT\)</span> is equal to 0.192 with a bandwidth of <span class="math inline">\(1\)</span> and to 0.164 with a bandwidth of <span class="math inline">\(0.5\)</span>, while the true value of the parameter in the population is equal to 0.175.</p>
</div>
<div id="trimming" class="section level5 hasAnchor" number="5.2.2.1.4">
<h5><span class="header-section-number">5.2.2.1.4</span> Trimming<a href="OM.html#trimming" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Trimming is done to prevent areas where the density of the propensity score is low (where there are very few untreated observations) to blow up our estimates.
This is a way to enforce the common support assumption.
Note that at the same time we are changing the parameter estimate from <span class="math inline">\(TT\)</span> to <span class="math inline">\(TT\)</span> on the trimmed common support.</p>
<p>Trimming, as done for example by <a href="https://doi.org/10.1016/j.jeconom.2004.04.011">Smith and Todd (2005)</a>), goes as follows:</p>
<ol style="list-style-type: decimal">
<li>Estimate conditional density <span class="math inline">\(\hat{f}_{P(X)|D=0}\)</span>, for <span class="math inline">\(i\in\mathcal{I}_1\)</span></li>
<li>Get rid of observations with density lower than the <span class="math inline">\(t^{\text{th}}\)</span> percentile of <span class="math inline">\(\hat{f}_{P(X)|D=0}\)</span>, where <span class="math inline">\(t\)</span> is the trimming level (5% in general).</li>
</ol>
<p>In order to estimate the density of the propensity score, we use a kernel estimator:</p>
<p><span class="math display">\[\begin{align*}
  \hat{f}_{P(X)|D=d}(P(X_i)) &amp;= \frac{1}{N_dh}\sum^{N_d}_{j=1}K\left(\frac{P(X_i)-P(X_j)}{h}\right) \\
\hat{S} &amp; = 
  \begin{cases}
  1 &amp; \text{ if } \hat{f}_{P(X)|D=0}(P(X_i))&gt;\text{quantile}_{t}(\hat{f}_{P(X)|D=1}(P(X_i))) \\
  0 &amp; \text{ if } \hat{f}_{P(X)|D=0}(P(X_i))\leq\text{quantile}_{t}(\hat{f}_{P(X)|D=1}(P(X_i))),
  \end{cases}
\end{align*}\]</span></p>
<p>where <span class="math inline">\(h\)</span> is a different bandwidth that the one chosen for LLR.
It can be choosen by using Silverman’s rule of thumb, for example.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-317" class="example"><strong>Example 5.10  </strong></span>Let us illustrate how this works in our numerical example.</p>
</div>
<p>First, let’s define a function to estimate the density and then compute the common support.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="OM.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="co"># density function estimated at one point</span></span>
<span id="cb285-2"><a href="OM.html#cb285-2" aria-hidden="true" tabindex="-1"></a>dens.fun.point <span class="ot">&lt;-</span> <span class="cf">function</span>(n,x,gridx,bw,kernel){</span>
<span id="cb285-3"><a href="OM.html#cb285-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">density</span>(x,<span class="at">n=</span><span class="dv">1</span>,<span class="at">from=</span>gridx[n],<span class="at">to=</span>gridx[n],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)[[<span class="dv">2</span>]])</span>
<span id="cb285-4"><a href="OM.html#cb285-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb285-5"><a href="OM.html#cb285-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-6"><a href="OM.html#cb285-6" aria-hidden="true" tabindex="-1"></a>dens.fun <span class="ot">&lt;-</span> <span class="cf">function</span>(x,gridx,bw,kernel){</span>
<span id="cb285-7"><a href="OM.html#cb285-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(gridx), dens.fun.point, <span class="at">x=</span>x, <span class="at">gridx=</span>gridx, <span class="at">bw=</span>bw, <span class="at">kernel=</span>kernel))</span>
<span id="cb285-8"><a href="OM.html#cb285-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb285-9"><a href="OM.html#cb285-9" aria-hidden="true" tabindex="-1"></a>dens.pscore.D0 <span class="ot">&lt;-</span> <span class="fu">dens.fun</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>],pscore[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span><span class="fu">bw.nrd</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>]),<span class="at">kernel=</span><span class="st">&#39;b&#39;</span>)</span>
<span id="cb285-10"><a href="OM.html#cb285-10" aria-hidden="true" tabindex="-1"></a>dens.pscore.D1 <span class="ot">&lt;-</span> <span class="fu">dens.fun</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],pscore[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span><span class="fu">bw.nrd</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>]),<span class="at">kernel=</span><span class="st">&#39;b&#39;</span>)</span>
<span id="cb285-11"><a href="OM.html#cb285-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-12"><a href="OM.html#cb285-12" aria-hidden="true" tabindex="-1"></a>com.supp <span class="ot">&lt;-</span> <span class="cf">function</span>(x,gridx,t,bw,kernel){</span>
<span id="cb285-13"><a href="OM.html#cb285-13" aria-hidden="true" tabindex="-1"></a>  dens.x <span class="ot">&lt;-</span> <span class="fu">dens.fun</span>(<span class="at">x=</span>x,<span class="at">gridx=</span>gridx,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb285-14"><a href="OM.html#cb285-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">ifelse</span>(dens.x<span class="sc">&lt;=</span><span class="fu">quantile</span>(dens.x,t),<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb285-15"><a href="OM.html#cb285-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb285-16"><a href="OM.html#cb285-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-17"><a href="OM.html#cb285-17" aria-hidden="true" tabindex="-1"></a>t<span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb285-18"><a href="OM.html#cb285-18" aria-hidden="true" tabindex="-1"></a>com.supp.pscore <span class="ot">&lt;-</span> <span class="fu">com.supp</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>],pscore[Ds<span class="sc">==</span><span class="dv">1</span>],<span class="at">t=</span>t,<span class="at">bw=</span><span class="fu">bw.nrd</span>(pscore[Ds<span class="sc">==</span><span class="dv">0</span>]),<span class="at">kernel=</span><span class="st">&#39;b&#39;</span>)</span>
<span id="cb285-19"><a href="OM.html#cb285-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb285-20"><a href="OM.html#cb285-20" aria-hidden="true" tabindex="-1"></a><span class="co"># estimation using common support and trimming</span></span>
<span id="cb285-21"><a href="OM.html#cb285-21" aria-hidden="true" tabindex="-1"></a>llr.match.trim <span class="ot">&lt;-</span> <span class="cf">function</span>(y,D,x,t,bw,kernel){</span>
<span id="cb285-22"><a href="OM.html#cb285-22" aria-hidden="true" tabindex="-1"></a>  com.supp.x <span class="ot">&lt;-</span> <span class="fu">com.supp</span>(x[D<span class="sc">==</span><span class="dv">0</span>],x[D<span class="sc">==</span><span class="dv">1</span>],<span class="at">t=</span>t,<span class="at">bw=</span><span class="fu">bw.nrd</span>(x[D<span class="sc">==</span><span class="dv">0</span>]),<span class="at">kernel=</span><span class="st">&#39;b&#39;</span>)</span>
<span id="cb285-23"><a href="OM.html#cb285-23" aria-hidden="true" tabindex="-1"></a>  y0.llr <span class="ot">&lt;-</span> <span class="fu">llr</span>(y[D<span class="sc">==</span><span class="dv">0</span>],x[D<span class="sc">==</span><span class="dv">0</span>],x[D<span class="sc">==</span><span class="dv">1</span>][com.supp.x<span class="sc">==</span><span class="dv">1</span>],<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb285-24"><a href="OM.html#cb285-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(y[D<span class="sc">==</span><span class="dv">1</span>][com.supp.x<span class="sc">==</span><span class="dv">1</span>]<span class="sc">-</span>y0.llr))</span>
<span id="cb285-25"><a href="OM.html#cb285-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb285-26"><a href="OM.html#cb285-26" aria-hidden="true" tabindex="-1"></a>ww.llr.pscore.trim <span class="ot">&lt;-</span> <span class="fu">llr.match.trim</span>(y,Ds,pscore,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span></code></pre></div>
<p>Let us now plot what the common support looks like:</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="OM.html#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">5</span>))</span>
<span id="cb286-2"><a href="OM.html#cb286-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],dens.pscore.D0,<span class="at">pch=</span><span class="dv">1</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">xlab=</span><span class="st">&quot;Propensity score&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;density&quot;</span>)</span>
<span id="cb286-3"><a href="OM.html#cb286-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],dens.pscore.D1,<span class="at">pch=</span><span class="dv">3</span>)</span>
<span id="cb286-4"><a href="OM.html#cb286-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="fl">0.65</span>,<span class="fl">2.5</span>,<span class="fu">c</span>(<span class="st">&#39;fP(yB)|D=0&#39;</span>,<span class="st">&#39;fP(yB)|D=1&#39;</span>,<span class="st">&#39;Common Support&#39;</span>),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;black&#39;</span>,<span class="st">&#39;black&#39;</span>,<span class="st">&#39;red&#39;</span>),<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb286-5"><a href="OM.html#cb286-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">new=</span><span class="cn">TRUE</span>)</span>
<span id="cb286-6"><a href="OM.html#cb286-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pscore[Ds<span class="sc">==</span><span class="dv">1</span>],com.supp.pscore,<span class="at">pch=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&#39;red&#39;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb286-7"><a href="OM.html#cb286-7" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>)</span>
<span id="cb286-8"><a href="OM.html#cb286-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Common Support&quot;</span>,<span class="at">side=</span><span class="dv">4</span>,<span class="at">line=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotCommonSupport"></span>
<img src="STCI_files/figure-html/PlotCommonSupport-1.png" alt="Trimming and Common Support" width="65%" />
<p class="caption">
Figure 5.9: Trimming and Common Support
</p>
</div>
<p>With trimming and the optimal bandwidth, the estimated value of the <span class="math inline">\(TT\)</span> parameter using LLR Matching on the propensity score is equal to 0.168.
Remember that the LLR Matching on the propensity score estimate using the optimal bandwidth but no trimming is equal to 0.17.
Using LLR Matching on <span class="math inline">\(y_i^B\)</span> directly, the estimated <span class="math inline">\(TT\)</span> is equal to 0.192 with a bandwidth of <span class="math inline">\(1\)</span> and to 0.164 with a bandwidth of <span class="math inline">\(0.5\)</span>, while the true value of the parameter in the population is equal to 0.175.</p>
<p>Let us run Monte Carlo simulations for this estimator:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="OM.html#cb287-1" aria-hidden="true" tabindex="-1"></a>monte.carlo.llr.trim <span class="ot">&lt;-</span> <span class="cf">function</span>(s,N,param,t,bw,kernel){</span>
<span id="cb287-2"><a href="OM.html#cb287-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb287-3"><a href="OM.html#cb287-3" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb287-4"><a href="OM.html#cb287-4" aria-hidden="true" tabindex="-1"></a>  UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb287-5"><a href="OM.html#cb287-5" aria-hidden="true" tabindex="-1"></a>  yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb287-6"><a href="OM.html#cb287-6" aria-hidden="true" tabindex="-1"></a>  YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb287-7"><a href="OM.html#cb287-7" aria-hidden="true" tabindex="-1"></a>  Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb287-8"><a href="OM.html#cb287-8" aria-hidden="true" tabindex="-1"></a>  V <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb287-9"><a href="OM.html#cb287-9" aria-hidden="true" tabindex="-1"></a>  Ds[yB<span class="sc">+</span>V<span class="sc">&lt;=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb287-10"><a href="OM.html#cb287-10" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb287-11"><a href="OM.html#cb287-11" aria-hidden="true" tabindex="-1"></a>  eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb287-12"><a href="OM.html#cb287-12" aria-hidden="true" tabindex="-1"></a>  U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb287-13"><a href="OM.html#cb287-13" aria-hidden="true" tabindex="-1"></a>  y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb287-14"><a href="OM.html#cb287-14" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb287-15"><a href="OM.html#cb287-15" aria-hidden="true" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb287-16"><a href="OM.html#cb287-16" aria-hidden="true" tabindex="-1"></a>  Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb287-17"><a href="OM.html#cb287-17" aria-hidden="true" tabindex="-1"></a>  Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb287-18"><a href="OM.html#cb287-18" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb287-19"><a href="OM.html#cb287-19" aria-hidden="true" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb287-20"><a href="OM.html#cb287-20" aria-hidden="true" tabindex="-1"></a>  probit.Ds <span class="ot">&lt;-</span> <span class="fu">glm</span>(Ds<span class="sc">~</span>yB, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;probit&quot;</span>))</span>
<span id="cb287-21"><a href="OM.html#cb287-21" aria-hidden="true" tabindex="-1"></a>  pscore <span class="ot">&lt;-</span> <span class="fu">predict</span>(probit.Ds,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb287-22"><a href="OM.html#cb287-22" aria-hidden="true" tabindex="-1"></a>  ww.llr <span class="ot">&lt;-</span> <span class="fu">llr.match.trim</span>(y,Ds,pscore,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb287-23"><a href="OM.html#cb287-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ww.llr)</span>
<span id="cb287-24"><a href="OM.html#cb287-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb287-25"><a href="OM.html#cb287-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-26"><a href="OM.html#cb287-26" aria-hidden="true" tabindex="-1"></a>simuls.llr.trim.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,t,bw,kernel){</span>
<span id="cb287-27"><a href="OM.html#cb287-27" aria-hidden="true" tabindex="-1"></a>  simuls.llr.trim <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.llr.trim,<span class="at">N=</span>N,<span class="at">param=</span>param,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb287-28"><a href="OM.html#cb287-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(simuls.llr.trim) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;LLR Trim&#39;</span>)</span>
<span id="cb287-29"><a href="OM.html#cb287-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(simuls.llr.trim)</span>
<span id="cb287-30"><a href="OM.html#cb287-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb287-31"><a href="OM.html#cb287-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-32"><a href="OM.html#cb287-32" aria-hidden="true" tabindex="-1"></a>sf.simuls.llr.trim.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,t,bw,kernel){</span>
<span id="cb287-33"><a href="OM.html#cb287-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb287-34"><a href="OM.html#cb287-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfExport</span>(<span class="st">&#39;llr.match.trim&#39;</span>,<span class="st">&#39;llr&#39;</span>,<span class="st">&#39;dens.fun.point&#39;</span>,<span class="st">&#39;dens.fun&#39;</span>,<span class="st">&#39;com.supp&#39;</span>)</span>
<span id="cb287-35"><a href="OM.html#cb287-35" aria-hidden="true" tabindex="-1"></a>  sim.llr.trim <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.llr.trim,<span class="at">N=</span>N,<span class="at">param=</span>param,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb287-36"><a href="OM.html#cb287-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb287-37"><a href="OM.html#cb287-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.llr.trim) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;LLR Trim&#39;</span>)</span>
<span id="cb287-38"><a href="OM.html#cb287-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.llr.trim)</span>
<span id="cb287-39"><a href="OM.html#cb287-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb287-40"><a href="OM.html#cb287-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-41"><a href="OM.html#cb287-41" aria-hidden="true" tabindex="-1"></a>Nsim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb287-42"><a href="OM.html#cb287-42" aria-hidden="true" tabindex="-1"></a><span class="co">#Nsim &lt;- 10</span></span>
<span id="cb287-43"><a href="OM.html#cb287-43" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000,100000)</span></span>
<span id="cb287-44"><a href="OM.html#cb287-44" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000)</span></span>
<span id="cb287-45"><a href="OM.html#cb287-45" aria-hidden="true" tabindex="-1"></a>N.sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>)</span>
<span id="cb287-46"><a href="OM.html#cb287-46" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100)</span></span>
<span id="cb287-47"><a href="OM.html#cb287-47" aria-hidden="true" tabindex="-1"></a><span class="co">#simuls.llr.trim &lt;- lapply(N.sample,simuls.llr.trim.N,Nsim=Nsim,param=param,t=t,bw=bw,kernel=kernel)</span></span>
<span id="cb287-48"><a href="OM.html#cb287-48" aria-hidden="true" tabindex="-1"></a>simuls.llr.trim <span class="ot">&lt;-</span> <span class="fu">lapply</span>(N.sample,sf.simuls.llr.trim.N,<span class="at">Nsim=</span>Nsim,<span class="at">param=</span>param,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb287-49"><a href="OM.html#cb287-49" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(simuls.llr.trim) <span class="ot">&lt;-</span> N.sample</span></code></pre></div>
<p>Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations):</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="OM.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb288-2"><a href="OM.html#cb288-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(simuls.llr.trim)){</span>
<span id="cb288-3"><a href="OM.html#cb288-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(simuls.llr.trim[[i]][,<span class="st">&#39;LLR Trim&#39;</span>],<span class="at">main=</span><span class="fu">paste</span>(<span class="st">&#39;N=&#39;</span>,<span class="fu">as.character</span>(N.sample[i])),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">hat</span>(Delta<span class="sc">^</span>yLLRTrim)),<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.15</span>,<span class="fl">0.55</span>))</span>
<span id="cb288-4"><a href="OM.html#cb288-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v=</span><span class="fu">delta.y.tt.com.supp</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb288-5"><a href="OM.html#cb288-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MonteCarloHistLLRTrim"></span>
<img src="STCI_files/figure-html/MonteCarloHistLLRTrim-1.png" alt="Distribution of the trimmed $LLR$ estimator over replications of samples of different sizes" width="65%" />
<p class="caption">
Figure 5.10: Distribution of the trimmed <span class="math inline">\(LLR\)</span> estimator over replications of samples of different sizes
</p>
</div>
</div>
</div>
<div id="nearest-neighbor-matching" class="section level4 hasAnchor" number="5.2.2.2">
<h4><span class="header-section-number">5.2.2.2</span> Nearest neighbor matching<a href="OM.html#nearest-neighbor-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>With Nearest Neighbor Matching (NNM), we choose the <span class="math inline">\(M\)</span> closest untreated units for each treated observation <span class="math inline">\(i\)</span> on the common support, we compute the average outcome of the <span class="math inline">\(M\)</span> twins to be the imputed counterfactual mean for unit <span class="math inline">\(i\)</span>, take the difference with the observed outcome for <span class="math inline">\(i\)</span>, <span class="math inline">\(Y_i\)</span>, and we take the average of this difference over all treated <span class="math inline">\(i\)</span> on the common support to obtain the treatment effect estimate:</p>
<ol style="list-style-type: decimal">
<li>The <span class="math inline">\(m^{\text{th}}\)</span> closest neighbor is defined as follows:
<span class="math display">\[
    j_m(i) = \left\{j:D_j=1-D_i \text{ } \&amp;\sum_{k:D_k=1-D_i}\uns{d(i,k)\leq d(i,j)}=m\right\}
    \]</span>
2. The set of <span class="math inline">\(M\)</span> closest neighbors is thus:
<span class="math display">\[
    \mathcal{J}_M(i) = \left\{j_1(i),\dots,j_M(i)\right\}
    \]</span>
3. The number of times observation <span class="math inline">\(j\)</span> is used as a neighbor (when matching is with replacement) is:
<span class="math display">\[
    \mathcal{K}_M(j) = \sum_{i=1}^N\uns{j\in\mathcal{J}_M(i)}.
    \]</span></li>
<li><span class="math inline">\(M\)</span> nearest-neighbors pair matching with replacement has the following weights:
<span class="math display">\[
    w_{i,j} = \begin{cases}
    \frac{1}{M} &amp; \text{ if } j\in\mathcal{J}_M(i)\\
    0                   &amp; \text{ if } j\notin\mathcal{J}_M(i)
    \end{cases}
    \]</span>
5. We can rewrite the estimator of <span class="math inline">\(M\)</span> nearest-neighbors matching with replacement as follows:</li>
</ol>
<p><span class="math display">\[\begin{align*}
\hat{\Delta}^Y_{NNM} &amp;  = \frac{1}{N_1^S}\sum_{i\in\mathcal{I}^1\cap S}\left(Y_i-\sum_{j\in\mathcal{I}^0}w_{i,j}Y_j\right)\\
                                        &amp;  = \frac{1}{N_1^S}\sum_{i\in S}\left(D_i-(1-D_i)\frac{\mathcal{K}_M(i)}{M}\right)Y_i
\end{align*}\]</span></p>
<p>A key issue with how we have implemented NNM is the choice of the metric <span class="math inline">\(d(i,j)\)</span>.
Several can be used among the following:</p>
<ol style="list-style-type: decimal">
<li>Euclidean distance
<span class="math display">\[
    d(i,j) = \sqrt{\sum_k(X^k_i-X^k_j)^2}
    \]</span>
2. Normalized Euclidean distance
<span class="math display">\[
    d(i,j) = \sqrt{\sum_k\frac{(X^k_i-X^k_j)^2}{\var{X^k}}}
    \]</span>
3. Mahalanobis distance
<span class="math display">\[
    d(i,j) = \sqrt{(X-\bar{X})&#39;S^{-1}(X-\bar{X})}
    \]</span>
with <span class="math inline">\(S\)</span> the covariance matrix of <span class="math inline">\(X\)</span>
4. Propensity score distance
<span class="math display">\[
    d(i,j) = \sqrt{(P(X_i)-P(X_j))^2}= \left|P(X_i)-P(X_j)\right|
    \]</span>
5. Genetic distance (Sekhon)</li>
</ol>
<div class="remark">
<p><span id="unlabeled-div-183" class="remark"><em>Remark</em>. </span>When <span class="math inline">\(d(i,k)\leq d(i,j)\)</span> we break ties at random to maintain the integrity of NNM definition.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-184" class="remark"><em>Remark</em>. </span>Euclidean distance is a bad choice for matching since it gives mucg more weight to covariates observed on a large scale.
You are much better off using Normalized Euclidean distance or Mahalanobis distance.</p>
</div>
<div class="example">
<p><span id="exm:unnamed-chunk-320" class="example"><strong>Example 5.11  </strong></span>Let’s see how Nearest Neighbor Matching can be implemented in our example.</p>
</div>
<p>The two <code>R</code> packages that can be used for implementing NNM estimators are <code>Matching</code> by Jasjeet Sekhon and <code>MatchIt</code> by Ho, Imai, King and Stuart.
As <code>MatchIt</code> is more general and includes most <code>Matching</code> options, I’ll focus on <code>MatchIt</code>.</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="OM.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="co"># building a dataset with treatment, control and outcome</span></span>
<span id="cb289-2"><a href="OM.html#cb289-2" aria-hidden="true" tabindex="-1"></a>match.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y=</span>y,<span class="at">Ds=</span>Ds,<span class="at">yB=</span>yB)</span>
<span id="cb289-3"><a href="OM.html#cb289-3" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with euclidean distance and 1 to 1 matching with replacement</span></span>
<span id="cb289-4"><a href="OM.html#cb289-4" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-5"><a href="OM.html#cb289-5" aria-hidden="true" tabindex="-1"></a>nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">1</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;euclidean&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-6"><a href="OM.html#cb289-6" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-7"><a href="OM.html#cb289-7" aria-hidden="true" tabindex="-1"></a>data.nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.euclid.<span class="fl">1.1</span>)</span>
<span id="cb289-8"><a href="OM.html#cb289-8" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-9"><a href="OM.html#cb289-9" aria-hidden="true" tabindex="-1"></a>tt.nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.euclid.<span class="fl">1.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb289-10"><a href="OM.html#cb289-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-11"><a href="OM.html#cb289-11" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with euclidean distance and 5 to 1 matching with replacement</span></span>
<span id="cb289-12"><a href="OM.html#cb289-12" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-13"><a href="OM.html#cb289-13" aria-hidden="true" tabindex="-1"></a>nnm.euclid.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">5</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;euclidean&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-14"><a href="OM.html#cb289-14" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-15"><a href="OM.html#cb289-15" aria-hidden="true" tabindex="-1"></a>data.nnm.euclid.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.euclid.<span class="fl">5.1</span>)</span>
<span id="cb289-16"><a href="OM.html#cb289-16" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-17"><a href="OM.html#cb289-17" aria-hidden="true" tabindex="-1"></a>tt.nnm.euclid.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.euclid.<span class="fl">5.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb289-18"><a href="OM.html#cb289-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-19"><a href="OM.html#cb289-19" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with propensity score distance and 1 to 1 matching with replacement</span></span>
<span id="cb289-20"><a href="OM.html#cb289-20" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-21"><a href="OM.html#cb289-21" aria-hidden="true" tabindex="-1"></a>nnm.pscore.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">1</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;glm&#39;</span>,<span class="at">link=</span><span class="st">&#39;probit&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-22"><a href="OM.html#cb289-22" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-23"><a href="OM.html#cb289-23" aria-hidden="true" tabindex="-1"></a>data.nnm.pscore.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.pscore.<span class="fl">1.1</span>)</span>
<span id="cb289-24"><a href="OM.html#cb289-24" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-25"><a href="OM.html#cb289-25" aria-hidden="true" tabindex="-1"></a>tt.nnm.pscore.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.pscore.<span class="fl">1.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb289-26"><a href="OM.html#cb289-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-27"><a href="OM.html#cb289-27" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with propensity score distance and 5 to 1 matching with replacement</span></span>
<span id="cb289-28"><a href="OM.html#cb289-28" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-29"><a href="OM.html#cb289-29" aria-hidden="true" tabindex="-1"></a>nnm.pscore.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">5</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;glm&#39;</span>,<span class="at">link=</span><span class="st">&#39;probit&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-30"><a href="OM.html#cb289-30" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-31"><a href="OM.html#cb289-31" aria-hidden="true" tabindex="-1"></a>data.nnm.pscore.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.pscore.<span class="fl">5.1</span>)</span>
<span id="cb289-32"><a href="OM.html#cb289-32" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-33"><a href="OM.html#cb289-33" aria-hidden="true" tabindex="-1"></a>tt.nnm.pscore.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.pscore.<span class="fl">5.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb289-34"><a href="OM.html#cb289-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-35"><a href="OM.html#cb289-35" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with Mahalanobis distance and 1 to 1 matching with replacement</span></span>
<span id="cb289-36"><a href="OM.html#cb289-36" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-37"><a href="OM.html#cb289-37" aria-hidden="true" tabindex="-1"></a>nnm.maha.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">1</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;mahalanobis&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-38"><a href="OM.html#cb289-38" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-39"><a href="OM.html#cb289-39" aria-hidden="true" tabindex="-1"></a>data.nnm.maha.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.maha.<span class="fl">1.1</span>)</span>
<span id="cb289-40"><a href="OM.html#cb289-40" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-41"><a href="OM.html#cb289-41" aria-hidden="true" tabindex="-1"></a>tt.nnm.maha.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.maha.<span class="fl">1.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb289-42"><a href="OM.html#cb289-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-43"><a href="OM.html#cb289-43" aria-hidden="true" tabindex="-1"></a><span class="co"># NNM with Mahalanobis distance and 5 to 1 matching with replacement</span></span>
<span id="cb289-44"><a href="OM.html#cb289-44" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting the neighbors</span></span>
<span id="cb289-45"><a href="OM.html#cb289-45" aria-hidden="true" tabindex="-1"></a>nnm.maha.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">ratio=</span><span class="dv">5</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;mahalanobis&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">data=</span>match.data)</span>
<span id="cb289-46"><a href="OM.html#cb289-46" aria-hidden="true" tabindex="-1"></a><span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb289-47"><a href="OM.html#cb289-47" aria-hidden="true" tabindex="-1"></a>data.nnm.maha.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.maha.<span class="fl">5.1</span>)</span>
<span id="cb289-48"><a href="OM.html#cb289-48" aria-hidden="true" tabindex="-1"></a><span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb289-49"><a href="OM.html#cb289-49" aria-hidden="true" tabindex="-1"></a>tt.nnm.maha.<span class="fl">5.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.maha.<span class="fl">5.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span></code></pre></div>
<p>The estimates are going to be pretty similar among all the methods in our example.
For example, 5 to 1 NNM with the Mahalanobis distance yields an estimate of <span class="math inline">\(TT\)</span> of 0.147.</p>
<p>The <code>MatchIt</code> package offers some pretty cool visualization tools.
For example, we can visualize the standardized distance (mean difference in units of standard deviation) between the treated and control units before and after matching, and the distribution of covariates before and after matching:</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="OM.html#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot of standardized distance</span></span>
<span id="cb290-2"><a href="OM.html#cb290-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">summary</span>(nnm.euclid.<span class="fl">1.1</span>),<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))</span>
<span id="cb290-3"><a href="OM.html#cb290-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-4"><a href="OM.html#cb290-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot of distribution of covariates</span></span>
<span id="cb290-5"><a href="OM.html#cb290-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nnm.euclid.<span class="fl">1.1</span>, <span class="at">type =</span> <span class="st">&quot;density&quot;</span>, <span class="at">interactive =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PlotNNM"></span>
<img src="STCI_files/figure-html/PlotNNM-1.png" alt="Trimming and Common Support" width="50%" /><img src="STCI_files/figure-html/PlotNNM-2.png" alt="Trimming and Common Support" width="50%" />
<p class="caption">
Figure 5.11: Trimming and Common Support
</p>
</div>
<p>As Figure <a href="OM.html#fig:PlotNNM">5.11</a> shows, the Matching procedure is pretty effective in that it completely aligns treated and control units in terms of the pre-treatment covariate.
<code>MatchIt</code> is much reacher than I can do it justice here.
See its <a href="https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html">amazing documentation</a> for inspiration and guidance.</p>
<p>Let us run Monte Carlo simulations for this estimator:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="OM.html#cb291-1" aria-hidden="true" tabindex="-1"></a>monte.carlo.nnm <span class="ot">&lt;-</span> <span class="cf">function</span>(s,N,param,...){</span>
<span id="cb291-2"><a href="OM.html#cb291-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb291-3"><a href="OM.html#cb291-3" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb291-4"><a href="OM.html#cb291-4" aria-hidden="true" tabindex="-1"></a>  UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb291-5"><a href="OM.html#cb291-5" aria-hidden="true" tabindex="-1"></a>  yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb291-6"><a href="OM.html#cb291-6" aria-hidden="true" tabindex="-1"></a>  YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb291-7"><a href="OM.html#cb291-7" aria-hidden="true" tabindex="-1"></a>  Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb291-8"><a href="OM.html#cb291-8" aria-hidden="true" tabindex="-1"></a>  V <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb291-9"><a href="OM.html#cb291-9" aria-hidden="true" tabindex="-1"></a>  Ds[yB<span class="sc">+</span>V<span class="sc">&lt;=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb291-10"><a href="OM.html#cb291-10" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb291-11"><a href="OM.html#cb291-11" aria-hidden="true" tabindex="-1"></a>  eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb291-12"><a href="OM.html#cb291-12" aria-hidden="true" tabindex="-1"></a>  U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb291-13"><a href="OM.html#cb291-13" aria-hidden="true" tabindex="-1"></a>  y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb291-14"><a href="OM.html#cb291-14" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb291-15"><a href="OM.html#cb291-15" aria-hidden="true" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb291-16"><a href="OM.html#cb291-16" aria-hidden="true" tabindex="-1"></a>  Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb291-17"><a href="OM.html#cb291-17" aria-hidden="true" tabindex="-1"></a>  Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb291-18"><a href="OM.html#cb291-18" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb291-19"><a href="OM.html#cb291-19" aria-hidden="true" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb291-20"><a href="OM.html#cb291-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># building a dataset with treatment, control and outcome</span></span>
<span id="cb291-21"><a href="OM.html#cb291-21" aria-hidden="true" tabindex="-1"></a>  match.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y=</span>y,<span class="at">Ds=</span>Ds,<span class="at">yB=</span>yB)</span>
<span id="cb291-22"><a href="OM.html#cb291-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># NNM with euclidean distance and 1 to 1 matching with replacement</span></span>
<span id="cb291-23"><a href="OM.html#cb291-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># selecting the neighbors</span></span>
<span id="cb291-24"><a href="OM.html#cb291-24" aria-hidden="true" tabindex="-1"></a>  nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">matchit</span>(Ds<span class="sc">~</span>yB,<span class="at">data=</span>match.data,...)</span>
<span id="cb291-25"><a href="OM.html#cb291-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># generating the data with neighbors and weights</span></span>
<span id="cb291-26"><a href="OM.html#cb291-26" aria-hidden="true" tabindex="-1"></a>  data.nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">match.data</span>(nnm.euclid.<span class="fl">1.1</span>)</span>
<span id="cb291-27"><a href="OM.html#cb291-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># estimating tt on the matched data using the weights</span></span>
<span id="cb291-28"><a href="OM.html#cb291-28" aria-hidden="true" tabindex="-1"></a>  tt.nnm.euclid.<span class="fl">1.1</span> <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y<span class="sc">~</span>Ds,<span class="at">data=</span>data.nnm.euclid.<span class="fl">1.1</span>,<span class="at">weights=</span>weights))[[<span class="dv">2</span>]]</span>
<span id="cb291-29"><a href="OM.html#cb291-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(tt.nnm.euclid.<span class="fl">1.1</span>)</span>
<span id="cb291-30"><a href="OM.html#cb291-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb291-31"><a href="OM.html#cb291-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-32"><a href="OM.html#cb291-32" aria-hidden="true" tabindex="-1"></a>simuls.nnm.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,...){</span>
<span id="cb291-33"><a href="OM.html#cb291-33" aria-hidden="true" tabindex="-1"></a>  simuls.nnm <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.nnm,<span class="at">N=</span>N,<span class="at">param=</span>param,...)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb291-34"><a href="OM.html#cb291-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(simuls.nnm) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;NNM&#39;</span>)</span>
<span id="cb291-35"><a href="OM.html#cb291-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(simuls.nnm)</span>
<span id="cb291-36"><a href="OM.html#cb291-36" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb291-37"><a href="OM.html#cb291-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-38"><a href="OM.html#cb291-38" aria-hidden="true" tabindex="-1"></a>sf.simuls.nnm.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param,...){</span>
<span id="cb291-39"><a href="OM.html#cb291-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb291-40"><a href="OM.html#cb291-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfLibrary</span>(MatchIt)</span>
<span id="cb291-41"><a href="OM.html#cb291-41" aria-hidden="true" tabindex="-1"></a>  sim.nnm <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.nnm,<span class="at">N=</span>N,<span class="at">param=</span>param,...)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb291-42"><a href="OM.html#cb291-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb291-43"><a href="OM.html#cb291-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.nnm) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;NNM&#39;</span>)</span>
<span id="cb291-44"><a href="OM.html#cb291-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.nnm)</span>
<span id="cb291-45"><a href="OM.html#cb291-45" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb291-46"><a href="OM.html#cb291-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-47"><a href="OM.html#cb291-47" aria-hidden="true" tabindex="-1"></a>Nsim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb291-48"><a href="OM.html#cb291-48" aria-hidden="true" tabindex="-1"></a><span class="co">#Nsim &lt;- 10</span></span>
<span id="cb291-49"><a href="OM.html#cb291-49" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000,100000)</span></span>
<span id="cb291-50"><a href="OM.html#cb291-50" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000)</span></span>
<span id="cb291-51"><a href="OM.html#cb291-51" aria-hidden="true" tabindex="-1"></a>N.sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>)</span>
<span id="cb291-52"><a href="OM.html#cb291-52" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100)</span></span>
<span id="cb291-53"><a href="OM.html#cb291-53" aria-hidden="true" tabindex="-1"></a><span class="co">#simuls.nnm &lt;- lapply(N.sample,simuls.nnm.N,Nsim=Nsim,param=param,ratio=1,method=&quot;nearest&quot;,distance=&#39;euclidean&#39;,replace=TRUE)</span></span>
<span id="cb291-54"><a href="OM.html#cb291-54" aria-hidden="true" tabindex="-1"></a>simuls.nnm <span class="ot">&lt;-</span> <span class="fu">lapply</span>(N.sample,sf.simuls.nnm.N,<span class="at">Nsim=</span>Nsim,<span class="at">param=</span>param,<span class="at">ratio=</span><span class="dv">1</span>,<span class="at">method=</span><span class="st">&quot;nearest&quot;</span>,<span class="at">distance=</span><span class="st">&#39;euclidean&#39;</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb291-55"><a href="OM.html#cb291-55" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(simuls.nnm) <span class="ot">&lt;-</span> N.sample</span></code></pre></div>
<p>Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations):</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="OM.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb292-2"><a href="OM.html#cb292-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(simuls.nnm)){</span>
<span id="cb292-3"><a href="OM.html#cb292-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(simuls.nnm[[i]][,<span class="st">&#39;NNM&#39;</span>],<span class="at">main=</span><span class="fu">paste</span>(<span class="st">&#39;N=&#39;</span>,<span class="fu">as.character</span>(N.sample[i])),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">hat</span>(Delta<span class="sc">^</span>yNNM)),<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.15</span>,<span class="fl">0.55</span>))</span>
<span id="cb292-4"><a href="OM.html#cb292-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v=</span><span class="fu">delta.y.tt.com.supp</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb292-5"><a href="OM.html#cb292-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MonteCarloHistNNM"></span>
<img src="STCI_files/figure-html/MonteCarloHistNNM-1.png" alt="Distribution of the NNM estimator over replications of samples of different sizes" width="65%" />
<p class="caption">
Figure 5.12: Distribution of the NNM estimator over replications of samples of different sizes
</p>
</div>
</div>
<div id="reweighting-matching" class="section level4 hasAnchor" number="5.2.2.3">
<h4><span class="header-section-number">5.2.2.3</span> Reweighting matching<a href="OM.html#reweighting-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Reweighting matching uses the following set of weigths:</p>
<p><span class="math display">\[\begin{align*}
w_{i,j} &amp; = \frac{\frac{\hat{P}(X_j)}{1-\hat{P}(X_j)}}{\sum_{j\in\mathcal{I}_0}\frac{\hat{P}(X_j)}{1-\hat{P}(X_j)}} = w_j.
\end{align*}\]</span></p>
<p>Since these weights do not depend on <span class="math inline">\(i\)</span>, we can thus write:</p>
<p><span class="math display">\[\begin{align*}
\hat{\Delta}^Y_{TT} &amp;  = \frac{1}{N_1}\sum_{i\in\mathcal{I}_1}\left(Y_i-\sum_{j\in\mathcal{I}_0}w_{i,j}Y_j\right)\\
                                        &amp;  = \frac{1}{N_1}\sum_{i\in\mathcal{I}_1}Y_i - \sum_{j\in\mathcal{I}_0}w_{j}Y_j
\end{align*}\]</span></p>
<p>The Reweighting estimator is thus very simple and quick: it only needs two separate summations instead of two nested summations.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-321" class="example"><strong>Example 5.12  </strong></span>Let’s see how the reweighting estimator works in practice.</p>
</div>
<p>The main object that we have to build are the weights.
They stem directly from the propensity score estimates.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="OM.html#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="co"># computing weights</span></span>
<span id="cb293-2"><a href="OM.html#cb293-2" aria-hidden="true" tabindex="-1"></a>pscore.weights <span class="ot">&lt;-</span> (pscore<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>pscore))<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>(Ds))<span class="sc">/</span><span class="fu">mean</span>(Ds)</span>
<span id="cb293-3"><a href="OM.html#cb293-3" aria-hidden="true" tabindex="-1"></a><span class="co"># get rid of weights for the treated</span></span>
<span id="cb293-4"><a href="OM.html#cb293-4" aria-hidden="true" tabindex="-1"></a>pscore.weights[Ds<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb293-5"><a href="OM.html#cb293-5" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize by sum of weights for the untreated</span></span>
<span id="cb293-6"><a href="OM.html#cb293-6" aria-hidden="true" tabindex="-1"></a>pscore.weights <span class="ot">&lt;-</span> pscore.weights<span class="sc">/</span><span class="fu">sum</span>(pscore.weights)</span>
<span id="cb293-7"><a href="OM.html#cb293-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb293-8"><a href="OM.html#cb293-8" aria-hidden="true" tabindex="-1"></a><span class="co"># counterfactual estimation using reweighting:</span></span>
<span id="cb293-9"><a href="OM.html#cb293-9" aria-hidden="true" tabindex="-1"></a>y0.D1.reweighting <span class="ot">&lt;-</span> <span class="fu">weighted.mean</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">w=</span>pscore.weights[Ds<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb293-10"><a href="OM.html#cb293-10" aria-hidden="true" tabindex="-1"></a><span class="co"># TT estimation</span></span>
<span id="cb293-11"><a href="OM.html#cb293-11" aria-hidden="true" tabindex="-1"></a>TT.reweighting <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>])<span class="sc">-</span>y0.D1.reweighting</span></code></pre></div>
<p>The <span class="math inline">\(TT\)</span> estimated by the reweighting estimator is equal to 0.297.
Remember that the true value of the parameter in the population is equal to 0.175.</p>
<p>Let us run Monte Carlo simulations for this estimator:</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="OM.html#cb294-1" aria-hidden="true" tabindex="-1"></a>monte.carlo.reweight <span class="ot">&lt;-</span> <span class="cf">function</span>(s,N,param){</span>
<span id="cb294-2"><a href="OM.html#cb294-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb294-3"><a href="OM.html#cb294-3" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,param[<span class="st">&quot;barmu&quot;</span>],<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]))</span>
<span id="cb294-4"><a href="OM.html#cb294-4" aria-hidden="true" tabindex="-1"></a>  UB <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb294-5"><a href="OM.html#cb294-5" aria-hidden="true" tabindex="-1"></a>  yB <span class="ot">&lt;-</span> mu <span class="sc">+</span> UB </span>
<span id="cb294-6"><a href="OM.html#cb294-6" aria-hidden="true" tabindex="-1"></a>  YB <span class="ot">&lt;-</span> <span class="fu">exp</span>(yB)</span>
<span id="cb294-7"><a href="OM.html#cb294-7" aria-hidden="true" tabindex="-1"></a>  Ds <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,N)</span>
<span id="cb294-8"><a href="OM.html#cb294-8" aria-hidden="true" tabindex="-1"></a>  V <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2mu&quot;</span>]<span class="sc">+</span>param[<span class="st">&quot;sigma2U&quot;</span>]))</span>
<span id="cb294-9"><a href="OM.html#cb294-9" aria-hidden="true" tabindex="-1"></a>  Ds[yB<span class="sc">+</span>V<span class="sc">&lt;=</span><span class="fu">log</span>(param[<span class="st">&quot;barY&quot;</span>])] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb294-10"><a href="OM.html#cb294-10" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2epsilon&quot;</span>]))</span>
<span id="cb294-11"><a href="OM.html#cb294-11" aria-hidden="true" tabindex="-1"></a>  eta<span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fu">sqrt</span>(param[<span class="st">&quot;sigma2eta&quot;</span>]))</span>
<span id="cb294-12"><a href="OM.html#cb294-12" aria-hidden="true" tabindex="-1"></a>  U0 <span class="ot">&lt;-</span> param[<span class="st">&quot;rho&quot;</span>]<span class="sc">*</span>UB <span class="sc">+</span> epsilon</span>
<span id="cb294-13"><a href="OM.html#cb294-13" aria-hidden="true" tabindex="-1"></a>  y0 <span class="ot">&lt;-</span> mu <span class="sc">+</span>  U0 <span class="sc">+</span> param[<span class="st">&quot;delta&quot;</span>] <span class="sc">+</span> param[<span class="st">&quot;gamma&quot;</span>]<span class="sc">*</span>(yB<span class="sc">-</span>param[<span class="st">&quot;baryB&quot;</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb294-14"><a href="OM.html#cb294-14" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> param[<span class="st">&quot;baralpha&quot;</span>]<span class="sc">+</span>  param[<span class="st">&quot;theta&quot;</span>]<span class="sc">*</span>mu <span class="sc">+</span> eta</span>
<span id="cb294-15"><a href="OM.html#cb294-15" aria-hidden="true" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> y0<span class="sc">+</span>alpha</span>
<span id="cb294-16"><a href="OM.html#cb294-16" aria-hidden="true" tabindex="-1"></a>  Y0 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y0)</span>
<span id="cb294-17"><a href="OM.html#cb294-17" aria-hidden="true" tabindex="-1"></a>  Y1 <span class="ot">&lt;-</span> <span class="fu">exp</span>(y1)</span>
<span id="cb294-18"><a href="OM.html#cb294-18" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> y1<span class="sc">*</span>Ds<span class="sc">+</span>y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb294-19"><a href="OM.html#cb294-19" aria-hidden="true" tabindex="-1"></a>  Y <span class="ot">&lt;-</span> Y1<span class="sc">*</span>Ds<span class="sc">+</span>Y0<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Ds)</span>
<span id="cb294-20"><a href="OM.html#cb294-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># pscore estimation</span></span>
<span id="cb294-21"><a href="OM.html#cb294-21" aria-hidden="true" tabindex="-1"></a>  probit.Ds <span class="ot">&lt;-</span> <span class="fu">glm</span>(Ds<span class="sc">~</span>yB, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;probit&quot;</span>))</span>
<span id="cb294-22"><a href="OM.html#cb294-22" aria-hidden="true" tabindex="-1"></a>  pscore <span class="ot">&lt;-</span> <span class="fu">predict</span>(probit.Ds,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb294-23"><a href="OM.html#cb294-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># computing weights</span></span>
<span id="cb294-24"><a href="OM.html#cb294-24" aria-hidden="true" tabindex="-1"></a>  pscore.weights <span class="ot">&lt;-</span> pscore<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>pscore)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>(Ds))<span class="sc">/</span><span class="fu">mean</span>(Ds)</span>
<span id="cb294-25"><a href="OM.html#cb294-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get rid of weights for the treated</span></span>
<span id="cb294-26"><a href="OM.html#cb294-26" aria-hidden="true" tabindex="-1"></a>  pscore.weights[Ds<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb294-27"><a href="OM.html#cb294-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normalize by sum of weights for the untreated</span></span>
<span id="cb294-28"><a href="OM.html#cb294-28" aria-hidden="true" tabindex="-1"></a>  pscore.weights <span class="ot">&lt;-</span> pscore.weights<span class="sc">/</span><span class="fu">sum</span>(pscore.weights)</span>
<span id="cb294-29"><a href="OM.html#cb294-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># counterfactual estimation using reweighting:</span></span>
<span id="cb294-30"><a href="OM.html#cb294-30" aria-hidden="true" tabindex="-1"></a>  y0.D1.reweighting <span class="ot">&lt;-</span> <span class="fu">weighted.mean</span>(y[Ds<span class="sc">==</span><span class="dv">0</span>],<span class="at">w=</span>pscore.weights[Ds<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb294-31"><a href="OM.html#cb294-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># TT estimation</span></span>
<span id="cb294-32"><a href="OM.html#cb294-32" aria-hidden="true" tabindex="-1"></a>  TT.reweighting <span class="ot">&lt;-</span> <span class="fu">mean</span>(y[Ds<span class="sc">==</span><span class="dv">1</span>])<span class="sc">-</span>y0.D1.reweighting</span>
<span id="cb294-33"><a href="OM.html#cb294-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(TT.reweighting)</span>
<span id="cb294-34"><a href="OM.html#cb294-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb294-35"><a href="OM.html#cb294-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb294-36"><a href="OM.html#cb294-36" aria-hidden="true" tabindex="-1"></a>simuls.reweight.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param){</span>
<span id="cb294-37"><a href="OM.html#cb294-37" aria-hidden="true" tabindex="-1"></a>  simuls.reweight <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.reweight,<span class="at">N=</span>N,<span class="at">param=</span>param)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb294-38"><a href="OM.html#cb294-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(simuls.reweight) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Reweighting Matching&#39;</span>)</span>
<span id="cb294-39"><a href="OM.html#cb294-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(simuls.reweight)</span>
<span id="cb294-40"><a href="OM.html#cb294-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb294-41"><a href="OM.html#cb294-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb294-42"><a href="OM.html#cb294-42" aria-hidden="true" tabindex="-1"></a>sf.simuls.reweight.N <span class="ot">&lt;-</span> <span class="cf">function</span>(N,Nsim,param){</span>
<span id="cb294-43"><a href="OM.html#cb294-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb294-44"><a href="OM.html#cb294-44" aria-hidden="true" tabindex="-1"></a>  sim.reweight <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,monte.carlo.reweight,<span class="at">N=</span>N,<span class="at">param=</span>param)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb294-45"><a href="OM.html#cb294-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb294-46"><a href="OM.html#cb294-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.reweight) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Reweighting Matching&#39;</span>)</span>
<span id="cb294-47"><a href="OM.html#cb294-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.reweight)</span>
<span id="cb294-48"><a href="OM.html#cb294-48" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb294-49"><a href="OM.html#cb294-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb294-50"><a href="OM.html#cb294-50" aria-hidden="true" tabindex="-1"></a>Nsim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb294-51"><a href="OM.html#cb294-51" aria-hidden="true" tabindex="-1"></a><span class="co">#Nsim &lt;- 10</span></span>
<span id="cb294-52"><a href="OM.html#cb294-52" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000,100000)</span></span>
<span id="cb294-53"><a href="OM.html#cb294-53" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100,1000,10000)</span></span>
<span id="cb294-54"><a href="OM.html#cb294-54" aria-hidden="true" tabindex="-1"></a>N.sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">1000</span>)</span>
<span id="cb294-55"><a href="OM.html#cb294-55" aria-hidden="true" tabindex="-1"></a><span class="co">#N.sample &lt;- c(100)</span></span>
<span id="cb294-56"><a href="OM.html#cb294-56" aria-hidden="true" tabindex="-1"></a><span class="co">#simuls.reweight &lt;- lapply(N.sample,simuls.reweight.N,Nsim=Nsim,param=param)</span></span>
<span id="cb294-57"><a href="OM.html#cb294-57" aria-hidden="true" tabindex="-1"></a>simuls.reweight<span class="ot">&lt;-</span> <span class="fu">lapply</span>(N.sample,sf.simuls.reweight.N,<span class="at">Nsim=</span>Nsim,<span class="at">param=</span>param)</span>
<span id="cb294-58"><a href="OM.html#cb294-58" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(simuls.reweight) <span class="ot">&lt;-</span> N.sample</span></code></pre></div>
<p>Let’s plot the resulting distribution (note that we have not chosen the bandwidth optimally in these simulations):</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="OM.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb295-2"><a href="OM.html#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(simuls.reweight)){</span>
<span id="cb295-3"><a href="OM.html#cb295-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(simuls.reweight[[i]][,<span class="st">&#39;Reweighting Matching&#39;</span>],<span class="at">main=</span><span class="fu">paste</span>(<span class="st">&#39;N=&#39;</span>,<span class="fu">as.character</span>(N.sample[i])),<span class="at">xlab=</span><span class="fu">expression</span>(<span class="fu">hat</span>(Delta<span class="sc">^</span>yReweight)),<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.15</span>,<span class="fl">0.55</span>))</span>
<span id="cb295-4"><a href="OM.html#cb295-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v=</span><span class="fu">delta.y.tt.com.supp</span>(param),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb295-5"><a href="OM.html#cb295-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MonteCarloHistReweight"></span>
<img src="STCI_files/figure-html/MonteCarloHistReweight-1.png" alt="Distribution of the Reweighting Matching estimator over replications of samples of different sizes" width="65%" />
<p class="caption">
Figure 5.13: Distribution of the Reweighting Matching estimator over replications of samples of different sizes
</p>
</div>
</div>
<div id="doubly-robust-matching" class="section level4 hasAnchor" number="5.2.2.4">
<h4><span class="header-section-number">5.2.2.4</span> Doubly robust matching<a href="OM.html#doubly-robust-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Doubly robust matching combines regression adjusted matching and weighting matching.
Its main property is that it is robust to misspecification of the regression functions for the outcomes or for the treatment: even if one of these functions is misspecified, the doubly robust matching estimator will be consistent as long as the other one is correctly specified.</p>
<p><strong>TO DO</strong></p>
</div>
</div>
<div id="estimating-precision-2" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Estimating precision<a href="OM.html#estimating-precision-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several ways to estimate of the precision of matching estimators.
In practice, we end up using the bootstrap for LLR, reweighting and doubly robust matching and to use CLT-based approximations for NNM.
This is because of the combination of several factors:</p>
<ul>
<li>The bootstrap is inconsistent for NNM: <a href="https://www.jstor.org/stable/40056514">Abadie and Imbens (2008)</a> show that the bootstrap fails to approximate the distribution of the NNM estimator.</li>
<li>The CLT-based formulae for LLR and reweighting matching are in general difficult to compute or take too much time to run, or are attached to specific estimators.</li>
<li>The CLT-based formula developped by <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> for NNM are simple to compute.</li>
</ul>
<p>Here, we are going to first give a sense of the maximum possible precision of matching estimators.
Then we will see how this result applies to teh CLT-based formulae for LLR and reweighting matching.
We will then describe the CLT-based formulae for NNM.</p>
<div id="maxium-precision-of-matching-estimators" class="section level4 hasAnchor" number="5.2.3.1">
<h4><span class="header-section-number">5.2.3.1</span> Maxium precision of matching estimators<a href="OM.html#maxium-precision-of-matching-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The maximum level of precision that any estimator relying on the matching assumptions can hope to reach is the minimum asymptotic variance that any such estimator cannot get under.
The derivation of this bound (called the semiparametric efficiency bound of matching estimators) is due to <a href="https://www.jstor.org/stable/2998560">Hahn (1998)</a>.</p>
<div class="theorem">
<p><span id="thm:effbound" class="theorem"><strong>Theorem 5.8  (Efficiency Bound under Conditional Independence) </strong></span>Under Assumption <a href="OM.html#hyp:CIA">5.2</a>, we have, for all consistent estimators <span class="math inline">\(\hat{\Delta^Y_{ATE}}\)</span> and <span class="math inline">\(\hat{\Delta^Y_{TT}}\)</span> of <span class="math inline">\(\Delta^Y_{ATE}\)</span> and <span class="math inline">\(\Delta^Y_{TT}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\asym\var{\hat{\Delta^Y_{ATE}}} &amp; \geq \frac{1}{N}\esp{\frac{\var{Y_i^1|X_i}}{\Pr(D_i=1|X_i)}+\frac{\var{Y_i^0|X_i}}{1-\Pr(D_i=1|X_i)}+(\Delta^Y_{ATE}(X_i)-\Delta^Y_{ATE})^2} \\
\asym\var{\hat{\Delta^Y_{TT}}} &amp; \geq \frac{1}{N}\esp{\frac{\Pr(D_i=1|X_i)\var{Y_i^1|X_i}}{\Pr(D_i=1)}+\frac{\Pr(D_i=1|X_i)^2\var{Y_i^0|X_i}}{\Pr(D_i=1)(1-\Pr(D_i=1|X_i))}}\\
                                &amp; \phantom{\geq} +\frac{1}{N}\esp{\frac{(\Delta^Y_{TT}(X_i)-\Delta^Y_{TT})^2\Pr(D_i=1|X_i)}{\Pr(D_i=1)}}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-185" class="proof"><em>Proof</em>. </span>See <a href="https://www.jstor.org/stable/2998560">Hahn (1998)</a>.</p>
</div>
<p>Theorem <a href="OM.html#thm:effbound">5.8</a> enables to compute a lower bound on the variance of any matching estimator.
Moreover, if it can be shown that a given estimator reaches the semi-parametric efficiency bound (<em>i.e.</em> is efficient), then Theorem <a href="OM.html#thm:effbound">5.8</a> enables to compute its precision using a CLT-based approximation (and not only a lower bound).</p>
<p>There are thus two key issues with using Theorem <a href="OM.html#thm:effbound">5.8</a> in practice:</p>
<ol style="list-style-type: decimal">
<li>Is it the case that our candidate matching estimator is efficient?</li>
<li>How can we operationalize the formula in Theorem <a href="OM.html#thm:effbound">5.8</a>?</li>
</ol>
<p>Question 1 is a theoretical question about properties of estimators while question 2 is a practical question.
Theorem <a href="OM.html#thm:effbound">5.8</a> shows that estimating the variance of efficient matching estimators requires to estimate the propensity score, but also two conditional variance terms and the conditional treatment on the treated parameter.
Thus Theorem <a href="OM.html#thm:effbound">5.8</a> requires the estimation of multiple nonparametric functions.
It might sometimes be preferable to rey on the bootstrap, if the bootstrap is consistent (which it is when the estimator is efficient, hence the relevance of question 1).</p>
</div>
<div id="estimating-precision-of-llr-and-reweighting-matching" class="section level4 hasAnchor" number="5.2.3.2">
<h4><span class="header-section-number">5.2.3.2</span> Estimating precision of LLR and reweighting matching<a href="OM.html#estimating-precision-of-llr-and-reweighting-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is in general believed that LLR and Reweighting Matching estimators are efficient, and thus that they reach the semi-parametric efficiency bound derived by Hahn (1998).
The devil is in the details though, since the particular form of the estimators and the conditions imposed on the d.g.p. are crucial for these results to hold.
Let’s state the results that hold for the reweighting and LLR matching estimators.</p>
<div class="theorem">
<p><span id="thm:ReweightLLRMatchEff" class="theorem"><strong>Theorem 5.9  (Asymptotic Distribution of Reweighting and LLR Matching) </strong></span>Under Assumption <a href="OM.html#hyp:CIA">5.2</a> and technical conditions made clear in <a href="https://www.jstor.org/stable/2998560">Hahn (1998)</a> and <a href="https://www.jstor.org/stable/43948009">Mammen et al (2016)</a>, the Reweighting matching estimator and the LLR matching estimator based on the propensity score of the Average Effect of the Treatment on the Treated are consistent, asymptotically normally distributed and reach the nonparametric efficiency bound.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-186" class="proof"><em>Proof</em>. </span>See <a href="https://www.jstor.org/stable/2998560">Hahn (1998)</a> and <a href="https://www.jstor.org/stable/43948009">Mammen et al (2016)</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-187" class="remark"><em>Remark</em>. </span><a href="https://www.jstor.org/stable/43948009">Mammen et al (2016)</a> only prove the consistency and efficiency of the LLR matching estimator using the propensity score for the ATE.
Extension to the TT is assumed here but should be checked rigorously.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-188" class="remark"><em>Remark</em>. </span><a href="https://www.jstor.org/stable/2566973">Heckman et al (1998)</a> derive the distribution of the LLR Matching estimator based on the propensity score, but their derivation does not seem to reach the semiparametric efficiency bound.
More investigation is needed to reconcile this result with the one in <a href="https://www.jstor.org/stable/43948009">Mammen et al (2016)</a>.</p>
</div>
<p>In practice, we do not use CLT-based approximations to estimate the precision of LLR Matching on the propensity score, since these estimators require rather complex computations.
We rather rely on the nonparametric bootstrap, we is justified by the existence of the CLT-based results.</p>
<div class="remark">
<p><span id="unlabeled-div-189" class="remark"><em>Remark</em>. </span><a href="https://www.jstor.org/stable/43948009">Mammen et al (2016)</a> show that the nonparametric bootstrap can be used to estimate the distribution of LLR matching on the propensity score under technical conditions.</p>
</div>
<div class="example">
<p><span id="exm:unnamed-chunk-327" class="example"><strong>Example 5.13  </strong></span>Let us see how we can use the bootstrap in our example.</p>
</div>
<p>Let’s first write a function to generate a bootstrap estimate:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="OM.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function for the bootstrap of LLR</span></span>
<span id="cb296-2"><a href="OM.html#cb296-2" aria-hidden="true" tabindex="-1"></a>bootstrap.llr.trim <span class="ot">&lt;-</span> <span class="cf">function</span>(s,y,D,x,t,bw,kernel){</span>
<span id="cb296-3"><a href="OM.html#cb296-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb296-4"><a href="OM.html#cb296-4" aria-hidden="true" tabindex="-1"></a>  boot.samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(N,<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb296-5"><a href="OM.html#cb296-5" aria-hidden="true" tabindex="-1"></a>  y.boot <span class="ot">&lt;-</span> y[boot.samp]</span>
<span id="cb296-6"><a href="OM.html#cb296-6" aria-hidden="true" tabindex="-1"></a>  D.boot <span class="ot">&lt;-</span> D[boot.samp]</span>
<span id="cb296-7"><a href="OM.html#cb296-7" aria-hidden="true" tabindex="-1"></a>  x.boot <span class="ot">&lt;-</span> x[boot.samp]</span>
<span id="cb296-8"><a href="OM.html#cb296-8" aria-hidden="true" tabindex="-1"></a>  llr.match.trim.boot <span class="ot">&lt;-</span> <span class="fu">llr.match.trim</span>(y.boot,D.boot,x.boot,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb296-9"><a href="OM.html#cb296-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(llr.match.trim.boot)</span>
<span id="cb296-10"><a href="OM.html#cb296-10" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb296-11"><a href="OM.html#cb296-11" aria-hidden="true" tabindex="-1"></a><span class="co"># function for the bootstrap of Reweighting</span></span>
<span id="cb296-12"><a href="OM.html#cb296-12" aria-hidden="true" tabindex="-1"></a>bootstrap.reweigthing <span class="ot">&lt;-</span> <span class="cf">function</span>(s,y,D,x){</span>
<span id="cb296-13"><a href="OM.html#cb296-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(s)</span>
<span id="cb296-14"><a href="OM.html#cb296-14" aria-hidden="true" tabindex="-1"></a>  boot.samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(N,<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb296-15"><a href="OM.html#cb296-15" aria-hidden="true" tabindex="-1"></a>  y.boot <span class="ot">&lt;-</span> y[boot.samp]</span>
<span id="cb296-16"><a href="OM.html#cb296-16" aria-hidden="true" tabindex="-1"></a>  D.boot <span class="ot">&lt;-</span> D[boot.samp]</span>
<span id="cb296-17"><a href="OM.html#cb296-17" aria-hidden="true" tabindex="-1"></a>  x.boot <span class="ot">&lt;-</span> x[boot.samp]</span>
<span id="cb296-18"><a href="OM.html#cb296-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># pscore estimation</span></span>
<span id="cb296-19"><a href="OM.html#cb296-19" aria-hidden="true" tabindex="-1"></a>  probit.Ds <span class="ot">&lt;-</span> <span class="fu">glm</span>(D.boot<span class="sc">~</span>x.boot, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span><span class="st">&quot;probit&quot;</span>))</span>
<span id="cb296-20"><a href="OM.html#cb296-20" aria-hidden="true" tabindex="-1"></a>  pscore <span class="ot">&lt;-</span> <span class="fu">predict</span>(probit.Ds,<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb296-21"><a href="OM.html#cb296-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># computing weights</span></span>
<span id="cb296-22"><a href="OM.html#cb296-22" aria-hidden="true" tabindex="-1"></a>  pscore.weights <span class="ot">&lt;-</span> pscore<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>pscore)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">mean</span>(D.boot))<span class="sc">/</span><span class="fu">mean</span>(D.boot)</span>
<span id="cb296-23"><a href="OM.html#cb296-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get rid of weights for the treated</span></span>
<span id="cb296-24"><a href="OM.html#cb296-24" aria-hidden="true" tabindex="-1"></a>  pscore.weights[D.boot<span class="sc">==</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb296-25"><a href="OM.html#cb296-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># normalize by sum of weights for the untreated</span></span>
<span id="cb296-26"><a href="OM.html#cb296-26" aria-hidden="true" tabindex="-1"></a>  pscore.weights <span class="ot">&lt;-</span> pscore.weights<span class="sc">/</span><span class="fu">sum</span>(pscore.weights)</span>
<span id="cb296-27"><a href="OM.html#cb296-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># counterfactual estimation using reweighting:</span></span>
<span id="cb296-28"><a href="OM.html#cb296-28" aria-hidden="true" tabindex="-1"></a>  y0.D1.reweighting <span class="ot">&lt;-</span> <span class="fu">weighted.mean</span>(y.boot[D.boot<span class="sc">==</span><span class="dv">0</span>],<span class="at">w=</span>pscore.weights[D.boot<span class="sc">==</span><span class="dv">0</span>])</span>
<span id="cb296-29"><a href="OM.html#cb296-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># TT estimation</span></span>
<span id="cb296-30"><a href="OM.html#cb296-30" aria-hidden="true" tabindex="-1"></a>  TT.reweighting <span class="ot">&lt;-</span> <span class="fu">mean</span>(y.boot[D.boot<span class="sc">==</span><span class="dv">1</span>])<span class="sc">-</span>y0.D1.reweighting</span>
<span id="cb296-31"><a href="OM.html#cb296-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(TT.reweighting)</span>
<span id="cb296-32"><a href="OM.html#cb296-32" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb296-33"><a href="OM.html#cb296-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-34"><a href="OM.html#cb296-34" aria-hidden="true" tabindex="-1"></a><span class="co"># testing</span></span>
<span id="cb296-35"><a href="OM.html#cb296-35" aria-hidden="true" tabindex="-1"></a>test.boot.llr <span class="ot">&lt;-</span> <span class="fu">bootstrap.llr.trim</span>(<span class="dv">1234</span>,<span class="at">y=</span>y,<span class="at">D=</span>Ds,<span class="at">x=</span>yB,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb296-36"><a href="OM.html#cb296-36" aria-hidden="true" tabindex="-1"></a>test.boot.reweight <span class="ot">&lt;-</span> <span class="fu">bootstrap.reweigthing</span>(<span class="dv">1234</span>,<span class="at">y=</span>y,<span class="at">D=</span>Ds,<span class="at">x=</span>yB)</span>
<span id="cb296-37"><a href="OM.html#cb296-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-38"><a href="OM.html#cb296-38" aria-hidden="true" tabindex="-1"></a><span class="co"># parallelized computation of bootstrap</span></span>
<span id="cb296-39"><a href="OM.html#cb296-39" aria-hidden="true" tabindex="-1"></a>sf.boot.llr.N <span class="ot">&lt;-</span> <span class="cf">function</span>(Nsim,...){</span>
<span id="cb296-40"><a href="OM.html#cb296-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb296-41"><a href="OM.html#cb296-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfExport</span>(<span class="st">&#39;llr.match.trim&#39;</span>,<span class="st">&#39;llr&#39;</span>,<span class="st">&#39;dens.fun.point&#39;</span>,<span class="st">&#39;dens.fun&#39;</span>,<span class="st">&#39;com.supp&#39;</span>,<span class="st">&#39;bootstrap.llr.trim&#39;</span>)</span>
<span id="cb296-42"><a href="OM.html#cb296-42" aria-hidden="true" tabindex="-1"></a>  sim.boot.llr <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,bootstrap.llr.trim,...)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb296-43"><a href="OM.html#cb296-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb296-44"><a href="OM.html#cb296-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.boot.llr) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;BootLLR&#39;</span>)</span>
<span id="cb296-45"><a href="OM.html#cb296-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.boot.llr)</span>
<span id="cb296-46"><a href="OM.html#cb296-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb296-47"><a href="OM.html#cb296-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-48"><a href="OM.html#cb296-48" aria-hidden="true" tabindex="-1"></a>sf.boot.reweight.N <span class="ot">&lt;-</span> <span class="cf">function</span>(Nsim,...){</span>
<span id="cb296-49"><a href="OM.html#cb296-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfInit</span>(<span class="at">parallel=</span><span class="cn">TRUE</span>,<span class="at">cpus=</span><span class="dv">8</span>)</span>
<span id="cb296-50"><a href="OM.html#cb296-50" aria-hidden="true" tabindex="-1"></a>  sim.boot.reweight <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">unlist</span>(<span class="fu">sfLapply</span>(<span class="dv">1</span><span class="sc">:</span>Nsim,bootstrap.reweighting,...)),<span class="at">nrow=</span>Nsim,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb296-51"><a href="OM.html#cb296-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sfStop</span>()</span>
<span id="cb296-52"><a href="OM.html#cb296-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(sim.boot.reweight) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;BootReweight&#39;</span>)</span>
<span id="cb296-53"><a href="OM.html#cb296-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim.boot.reweight)</span>
<span id="cb296-54"><a href="OM.html#cb296-54" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb296-55"><a href="OM.html#cb296-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-56"><a href="OM.html#cb296-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-57"><a href="OM.html#cb296-57" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb296-58"><a href="OM.html#cb296-58" aria-hidden="true" tabindex="-1"></a>kernel <span class="ot">&lt;-</span> <span class="st">&#39;gaussian&#39;</span></span>
<span id="cb296-59"><a href="OM.html#cb296-59" aria-hidden="true" tabindex="-1"></a>N.boot <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb296-60"><a href="OM.html#cb296-60" aria-hidden="true" tabindex="-1"></a>bw <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb296-61"><a href="OM.html#cb296-61" aria-hidden="true" tabindex="-1"></a>boot.llr <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>N.boot,bootstrap.llr.trim,<span class="at">y=</span>y,<span class="at">D=</span>Ds,<span class="at">x=</span>yB,<span class="at">t=</span>t,<span class="at">bw=</span>bw,<span class="at">kernel=</span>kernel)</span>
<span id="cb296-62"><a href="OM.html#cb296-62" aria-hidden="true" tabindex="-1"></a>boot.reweight <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>N.boot,bootstrap.reweigthing,<span class="at">y=</span>y,<span class="at">D=</span>Ds,<span class="at">x=</span>yB)</span>
<span id="cb296-63"><a href="OM.html#cb296-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-64"><a href="OM.html#cb296-64" aria-hidden="true" tabindex="-1"></a><span class="co">#boot.llr &lt;- sf.boot.llr.N(Nsim=N.boot,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel)</span></span>
<span id="cb296-65"><a href="OM.html#cb296-65" aria-hidden="true" tabindex="-1"></a><span class="co">#boot.reweight &lt;- sf.boot.reweight.N(Nsim=N.boot,y=y,D=Ds,x=yB)</span></span>
<span id="cb296-66"><a href="OM.html#cb296-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb296-67"><a href="OM.html#cb296-67" aria-hidden="true" tabindex="-1"></a><span class="co">#  sfInit(parallel=TRUE,cpus=8)</span></span>
<span id="cb296-68"><a href="OM.html#cb296-68" aria-hidden="true" tabindex="-1"></a><span class="co">#  sfExport(&#39;llr.match.trim&#39;,&#39;llr&#39;,&#39;dens.fun.point&#39;,&#39;dens.fun&#39;,&#39;com.supp&#39;,&#39;bootstrap.llr.trim&#39;,&#39;y&#39;,&#39;Ds&#39;,&#39;yB&#39;)</span></span>
<span id="cb296-69"><a href="OM.html#cb296-69" aria-hidden="true" tabindex="-1"></a><span class="co">#  sim.boot.reweight &lt;- sfLapply(1:2,bootstrap.llr.trim,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel)</span></span>
<span id="cb296-70"><a href="OM.html#cb296-70" aria-hidden="true" tabindex="-1"></a><span class="co">#  sim.boot.reweight &lt;- lapply(1:2,bootstrap.llr.trim,y=y,D=Ds,x=yB,t=t,bw=bw,kernel=kernel)</span></span>
<span id="cb296-71"><a href="OM.html#cb296-71" aria-hidden="true" tabindex="-1"></a><span class="co">#  sfStop()</span></span></code></pre></div>
<p>Let’s now compute the precision estimators:</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="OM.html#cb297-1" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">&lt;-</span> <span class="fl">0.99</span></span>
<span id="cb297-2"><a href="OM.html#cb297-2" aria-hidden="true" tabindex="-1"></a>precision.llr <span class="ot">&lt;-</span> <span class="cf">function</span>(k){</span>
<span id="cb297-3"><a href="OM.html#cb297-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(simuls.llr[[k]][,<span class="st">&#39;LLR&#39;</span>]<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta)))</span>
<span id="cb297-4"><a href="OM.html#cb297-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb297-5"><a href="OM.html#cb297-5" aria-hidden="true" tabindex="-1"></a>precision.llr.trim <span class="ot">&lt;-</span> <span class="cf">function</span>(k){</span>
<span id="cb297-6"><a href="OM.html#cb297-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(simuls.llr.trim[[k]][,<span class="st">&#39;LLR Trim&#39;</span>]<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta)))</span>
<span id="cb297-7"><a href="OM.html#cb297-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb297-8"><a href="OM.html#cb297-8" aria-hidden="true" tabindex="-1"></a>precision.reweighting <span class="ot">&lt;-</span> <span class="cf">function</span>(k){</span>
<span id="cb297-9"><a href="OM.html#cb297-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(simuls.reweight[[k]][,<span class="st">&#39;Reweighting Matching&#39;</span>]<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta)))</span>
<span id="cb297-10"><a href="OM.html#cb297-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb297-11"><a href="OM.html#cb297-11" aria-hidden="true" tabindex="-1"></a>precision.nnm <span class="ot">&lt;-</span> <span class="cf">function</span>(k){</span>
<span id="cb297-12"><a href="OM.html#cb297-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(simuls.nnm[[k]][,<span class="st">&#39;NNM&#39;</span>]<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta)))</span>
<span id="cb297-13"><a href="OM.html#cb297-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb297-14"><a href="OM.html#cb297-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-15"><a href="OM.html#cb297-15" aria-hidden="true" tabindex="-1"></a>precision.nnm<span class="fl">.100</span> <span class="ot">&lt;-</span> <span class="fu">precision.nnm</span>(<span class="dv">1</span>)</span>
<span id="cb297-16"><a href="OM.html#cb297-16" aria-hidden="true" tabindex="-1"></a>precision.nnm<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="fu">precision.nnm</span>(<span class="dv">2</span>)</span>
<span id="cb297-17"><a href="OM.html#cb297-17" aria-hidden="true" tabindex="-1"></a>precision.llr<span class="fl">.100</span> <span class="ot">&lt;-</span> <span class="fu">precision.llr</span>(<span class="dv">1</span>)</span>
<span id="cb297-18"><a href="OM.html#cb297-18" aria-hidden="true" tabindex="-1"></a>precision.llr<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="fu">precision.llr</span>(<span class="dv">2</span>)</span>
<span id="cb297-19"><a href="OM.html#cb297-19" aria-hidden="true" tabindex="-1"></a>precision.llr.trim<span class="fl">.100</span> <span class="ot">&lt;-</span> <span class="fu">precision.llr.trim</span>(<span class="dv">1</span>)</span>
<span id="cb297-20"><a href="OM.html#cb297-20" aria-hidden="true" tabindex="-1"></a>precision.llr.trim<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="fu">precision.llr.trim</span>(<span class="dv">2</span>)</span>
<span id="cb297-21"><a href="OM.html#cb297-21" aria-hidden="true" tabindex="-1"></a>precision.reweighting<span class="fl">.100</span> <span class="ot">&lt;-</span> <span class="fu">precision.reweighting</span>(<span class="dv">1</span>)</span>
<span id="cb297-22"><a href="OM.html#cb297-22" aria-hidden="true" tabindex="-1"></a>precision.reweighting<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="fu">precision.reweighting</span>(<span class="dv">2</span>)</span>
<span id="cb297-23"><a href="OM.html#cb297-23" aria-hidden="true" tabindex="-1"></a>precision.llr.trim.boot<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(boot.llr<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta))</span>
<span id="cb297-24"><a href="OM.html#cb297-24" aria-hidden="true" tabindex="-1"></a>precision.reweighting.boot<span class="fl">.1000</span> <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">quantile</span>(<span class="fu">abs</span>(boot.reweight<span class="sc">-</span><span class="fu">delta.y.tt.com.supp</span>(param)),<span class="at">probs=</span><span class="fu">c</span>(delta))</span></code></pre></div>
<p>With 100 obs, the true precision of LLR Matching is 0.61, while it is of 4.81 with trimming and of 0.9 with reweighting.
With 1000 observation, the true precision of LLR Matching without trimming is 0.15 and with trimming is 0.3 and the precision of reweighting matching is 0.43.
Using the bootstrap with 1000 replications, the estimated precision of LLR with trimming is 0.14 while the estimated precision of reweighting matching is 0.86.</p>
</div>
<div id="estimating-the-precision-of-nearest-neighbour-matching" class="section level4 hasAnchor" number="5.2.3.3">
<h4><span class="header-section-number">5.2.3.3</span> Estimating the precision of Nearest Neighbour Matching<a href="OM.html#estimating-the-precision-of-nearest-neighbour-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> propose a variance estimator for Nearest Neighbor Matching based on the CLT.
But before that, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> prove several fundamental results on the properties of NNM.
They show that NNM is not <span class="math inline">\(\sqrt{N}\)</span>-consistent for ATE nor for TT.
It means that, in general, NNM is affected by a bias term that is larger than <span class="math inline">\(\frac{1}{\sqrt{N}}\)</span> even when sample size grows large.
Fortunately, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> show that this bias term goes to zero as sample size grows large, so that NNM is always consistent.
They also show that, under reasonable conditions, this bias term goes to zero faster than <span class="math inline">\(\sqrt{N}\)</span> when the number of untreated units is much larger than the number of treated units.
It means that under these conditions, this term can be ignored and the distribution of NNM converges to a standard normal at a <span class="math inline">\(\sqrt{N}\)</span> rate.
They also show that the NNM estimator does not reach the semi-parametric efficiency bound of Theorem <a href="OM.html#thm:effbound">5.8</a>, but they also that the difference between the two variances is smaller than <span class="math inline">\(\frac{1}{2M}\)</span> where <span class="math inline">\(M\)</span> is the number of matches used.
With NNM on one neighbor, the increase in variance relative to the most efficient estimator is of at most 50%, while with 5 neighbors, the increase in asymptotic variance is of at most 10%.
Finally, <a href="https://www.jstor.org/stable/40056514">Abadie and Imbens (2008)</a> show that even when NNM is asymptotically normal and <span class="math inline">\(\sqrt{N}\)</span>-consistent, the bootstrap might fail to approximate its distribution.
Note that the bootstrap recovers its value if we allow the number of matched neighbors to increase with sample size.</p>
<p>So, now, what is the CLT-based estimator for the variance of NNM proposed by <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a>?
It is a clever use of the matching method to compute a variance estilmate using pairwise comparisons.
Note that this estimator is correct only when NNM is asymptotically normal and <span class="math inline">\(\sqrt{N}\)</span>-consistent, so when there are many more control than treated observations, or when the number of neighbors is large enough.</p>
<p>Let us first derive the asymptotic distribution of the NNM estimator.
We need to assume something about the data generating process (in general that the data are i.i.d.).
The assumption needed for NNM to be consistent is slightly more involved and requires restrictions on the ratio of treated to untreated observations <span class="math inline">\(\frac{N_1}{N_0}\)</span>:</p>
<div class="hypothesis">
<p><span id="hyp:MatchIID" class="hypothesis"><strong>Hypothesis 5.8  (i.i.d. distribution for matching) </strong></span>Conditional on <span class="math inline">\(D_i=d\)</span>, the sample consists of independent draws from <span class="math inline">\(Y,X|D=d\)</span>, <span class="math inline">\(d\in\left\{0,1\right\}\)</span>. For some <span class="math inline">\(r\geq 1\)</span>, <span class="math inline">\(\frac{N^r_1}{N_0}\rightarrow \theta\)</span>, with <span class="math inline">\(0&lt;\theta&lt;\infty\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:NNMCLT" class="theorem"><strong>Theorem 5.10  (Asymptotic Distribution of NNM) </strong></span>Under Assumptions <a href="OM.html#hyp:CIA">5.2</a>, <a href="OM.html#hyp:comsupp">5.7</a>, <a href="OM.html#hyp:MatchIID">5.8</a> and Assumption 4 in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a>, we have:
<span class="math display">\[\begin{align*}
  \sqrt{N_1}(\hat{\Delta}^Y_{NNM}-\Delta^Y_{TT}) &amp; \stackrel{d}{\rightarrow}  \mathcal{N}\left(0,V^{E,TT}+V^{\Delta^Y_{TT}(X)}\right),
\end{align*}\]</span>
where:
<span class="math display">\[\begin{align*}
V^{E,TT} &amp; = \frac{1}{N_1}\sum_{i=1}^N\left(D_i-(1-D_i)\frac{\mathcal{K}_M(i)}{M}\right)^2\var{Y_i|D_i,X_i}\\
V^{\Delta^Y_{TT}(X)} &amp; = \esp{(\Delta^Y_{TT}(X_i)-\Delta^Y_{TT})^2|D_i=1}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-190" class="proof"><em>Proof</em>. </span>See Corollary 1 in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-191" class="remark"><em>Remark</em>. </span>The general formula for the precision of the NNM estimator is close to all the same estimators we have seen so far: its is a sum of the variance of the outcome conditional on <span class="math inline">\(X_i\)</span> among the treated and among the untreated weighted by their relative importance in the estimation.
In addition, a term reflecting the variance of treatment effects due to <span class="math inline">\(X_i\)</span> has appeared.</p>
</div>
<p>The key to <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> estimator is to find a way to estimate <span class="math inline">\(\var{Y_i|D_i,X_i}\)</span>.
We could use the residuals from linear regressions or from non-parametric regressions, but that would be extremely burdensome.
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> propose a very clever trick to simplify the estimation of <span class="math inline">\(\var{Y_i|D_i,X_i}\)</span> by using a variation of the matching estimator.
Define <span class="math inline">\(l_m(i)\)</span> the <span class="math inline">\(m^{\text{th}}\)</span> closest unit to <span class="math inline">\(i\)</span> among the units with the same value for the treatment indicator.
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a>’s estimator for <span class="math inline">\(\var{Y_i|D_i,X_i}\)</span> is:</p>
<p><span class="math display">\[\begin{align*}
  \hatvar{Y_i|D_i,X_i} &amp; = \frac{J}{J+1}\left(Y_i-\frac{1}{J}\sum_{m=1}^JY_{l_j(i)}\right)^2.
\end{align*}\]</span></p>
<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> then combine this estimator with an estimator for <span class="math inline">\(V^{\Delta^Y_{TT}(X)}\)</span> which has to be corrected by the size of the variance of outcomes given <span class="math inline">\(X_i\)</span>.
Eventually, after some algebra, we have:</p>
<p><span class="math display">\[\begin{align*}
  \hat{V}^{E,TT}+\hat{V}^{\Delta^Y_{TT}(X)} &amp; = \frac{1}{N_1}\sum_{i:D_i=1}\left(Y_i-\frac{1}{M}\sum_{j\in\mathcal{J}_M(i)}Y_j-\Delta^Y_{TT}\right)^2 \\
                                            &amp; \phantom{=}+\frac{1}{N_1}\sum_{i=1}^N(1-D_i)\left(\frac{\mathcal{K}_M(i)(\mathcal{K}_M(i)-1)}{M^2}\right)\hatvar{Y_i|D_i,X_i}.
\end{align*}\]</span></p>
<p>Theorem 7 in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a> shows that this is a consistent estimator of the variance terms of NNM under the same assumptions as the one stated in Theorem <a href="OM.html#thm:NNMCLT">5.10</a>.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-330" class="example"><strong>Example 5.14  </strong></span>Let us see how the <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2006.00655.x">Abadie and Imbens (2006)</a>’estimator for the precision of NNM performs in our dataset.</p>
</div>
<p>Unfortunately, <code>MatchIt</code> does not include this estimator.
We thus have to resort to the <code>Matching</code> package which relies on these estiamtors by default.
Let’s go:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="OM.html#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimating ATT and its variance using Matching:</span></span>
<span id="cb298-2"><a href="OM.html#cb298-2" aria-hidden="true" tabindex="-1"></a><span class="co"># M=1</span></span>
<span id="cb298-3"><a href="OM.html#cb298-3" aria-hidden="true" tabindex="-1"></a>NNM.Match.yB<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">Match</span>(y,Ds,yB,<span class="at">estimand=</span><span class="st">&quot;ATT&quot;</span>,<span class="at">M=</span><span class="dv">1</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">CommonSupport=</span><span class="cn">FALSE</span>,<span class="at">Weight=</span><span class="dv">1</span>,<span class="at">Var.calc=</span><span class="dv">1</span>,<span class="at">sample=</span><span class="cn">FALSE</span>)</span>
<span id="cb298-4"><a href="OM.html#cb298-4" aria-hidden="true" tabindex="-1"></a>NNM.Match.pscore<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">Match</span>(y,Ds,pscore,<span class="at">estimand=</span><span class="st">&quot;ATT&quot;</span>,<span class="at">M=</span><span class="dv">1</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">CommonSupport=</span><span class="cn">FALSE</span>,<span class="at">Weight=</span><span class="dv">1</span>,<span class="at">Var.calc=</span><span class="dv">1</span>,<span class="at">sample=</span><span class="cn">FALSE</span>)</span>
<span id="cb298-5"><a href="OM.html#cb298-5" aria-hidden="true" tabindex="-1"></a><span class="co"># M=5</span></span>
<span id="cb298-6"><a href="OM.html#cb298-6" aria-hidden="true" tabindex="-1"></a>NNM.Match.yB<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">Match</span>(y,Ds,yB,<span class="at">estimand=</span><span class="st">&quot;ATT&quot;</span>,<span class="at">M=</span><span class="dv">5</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">CommonSupport=</span><span class="cn">FALSE</span>,<span class="at">Weight=</span><span class="dv">1</span>,<span class="at">Var.calc=</span><span class="dv">5</span>,<span class="at">sample=</span><span class="cn">FALSE</span>)</span>
<span id="cb298-7"><a href="OM.html#cb298-7" aria-hidden="true" tabindex="-1"></a>NNM.Match.pscore<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">Match</span>(y,Ds,pscore,<span class="at">estimand=</span><span class="st">&quot;ATT&quot;</span>,<span class="at">M=</span><span class="dv">5</span>,<span class="at">replace=</span><span class="cn">TRUE</span>,<span class="at">CommonSupport=</span><span class="cn">FALSE</span>,<span class="at">Weight=</span><span class="dv">1</span>,<span class="at">Var.calc=</span><span class="dv">5</span>,<span class="at">sample=</span><span class="cn">FALSE</span>)</span>
<span id="cb298-8"><a href="OM.html#cb298-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb298-9"><a href="OM.html#cb298-9" aria-hidden="true" tabindex="-1"></a><span class="co"># precision</span></span>
<span id="cb298-10"><a href="OM.html#cb298-10" aria-hidden="true" tabindex="-1"></a>se.NNM.Match.yB<span class="fl">.1</span> <span class="ot">&lt;-</span> NNM.Match.yB<span class="fl">.1</span><span class="sc">$</span>se</span>
<span id="cb298-11"><a href="OM.html#cb298-11" aria-hidden="true" tabindex="-1"></a>se.NNM.Match.pscore<span class="fl">.1</span> <span class="ot">&lt;-</span> NNM.Match.pscore<span class="fl">.1</span><span class="sc">$</span>se</span>
<span id="cb298-12"><a href="OM.html#cb298-12" aria-hidden="true" tabindex="-1"></a>se.NNM.Match.yB<span class="fl">.5</span> <span class="ot">&lt;-</span> NNM.Match.yB<span class="fl">.5</span><span class="sc">$</span>se</span>
<span id="cb298-13"><a href="OM.html#cb298-13" aria-hidden="true" tabindex="-1"></a>se.NNM.Match.pscore<span class="fl">.5</span> <span class="ot">&lt;-</span> NNM.Match.pscore<span class="fl">.5</span><span class="sc">$</span>se</span></code></pre></div>
<p>The estimated precision of matching on the propensity score with one neighbor is equal to 0.152 while the true precision stemming from the simulations is 0.211.</p>
</div>
</div>
</div>
<div id="imputation-methods" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Imputation methods<a href="OM.html#imputation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="https://yiqingxu.org/packages/fect/fect.html">Generalized fixed effects methods</a></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="NE.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="threats.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/chabefer/STCI/blob/master/05_OM.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["STCI.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 1
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
